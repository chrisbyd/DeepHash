{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 256,
 'save_dir': './models/',
 'val_batch_size': 100}
initializing
launching session
loading img model from ../../architecture/pretrained_model/reference_pretrain.npy
['hash_layer', 'fc6', 'fc7', 'conv3', 'conv2', 'conv1', 'conv5', 'conv4']
img model loading finished
Initializing Dataset
Dataset already
2021-01-22 13:39:20.282952 #train# start training
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:38.057289 #train# step    1, loss = 2.0470, cross_entropy loss = 2.0470, 12.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:39.629470 #train# step    2, loss = 1.9721, cross_entropy loss = 1.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:41.196774 #train# step    3, loss = 1.7880, cross_entropy loss = 1.7880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:42.797175 #train# step    4, loss = 1.5811, cross_entropy loss = 1.5811, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:44.407630 #train# step    5, loss = 1.4438, cross_entropy loss = 1.4438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:45.957518 #train# step    6, loss = 1.2610, cross_entropy loss = 1.2610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:47.539470 #train# step    7, loss = 1.1916, cross_entropy loss = 1.1916, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:49.127351 #train# step    8, loss = 1.1855, cross_entropy loss = 1.1855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:50.748270 #train# step    9, loss = 1.1608, cross_entropy loss = 1.1608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:52.293392 #train# step   10, loss = 1.1701, cross_entropy loss = 1.1701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:53.848429 #train# step   11, loss = 1.1875, cross_entropy loss = 1.1875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:55.407793 #train# step   12, loss = 1.1983, cross_entropy loss = 1.1983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:56.961883 #train# step   13, loss = 1.2123, cross_entropy loss = 1.2123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:39:58.542811 #train# step   14, loss = 1.2562, cross_entropy loss = 1.2562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:00.103226 #train# step   15, loss = 1.2630, cross_entropy loss = 1.2630, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:01.631790 #train# step   16, loss = 1.2964, cross_entropy loss = 1.2964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:03.229022 #train# step   17, loss = 1.2973, cross_entropy loss = 1.2973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:04.775631 #train# step   18, loss = 1.2790, cross_entropy loss = 1.2790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:06.343315 #train# step   19, loss = 1.2490, cross_entropy loss = 1.2490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:07.901476 #train# step   20, loss = 1.2300, cross_entropy loss = 1.2300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:09.465897 #train# step   21, loss = 1.2009, cross_entropy loss = 1.2009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:11.031320 #train# step   22, loss = 1.1816, cross_entropy loss = 1.1816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:12.592256 #train# step   23, loss = 1.1866, cross_entropy loss = 1.1866, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:14.138025 #train# step   24, loss = 1.1609, cross_entropy loss = 1.1609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:15.697243 #train# step   25, loss = 1.1454, cross_entropy loss = 1.1454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:17.245057 #train# step   26, loss = 1.1554, cross_entropy loss = 1.1554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:18.840293 #train# step   27, loss = 1.1267, cross_entropy loss = 1.1267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:20.392001 #train# step   28, loss = 1.1406, cross_entropy loss = 1.1406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:21.968547 #train# step   29, loss = 1.1287, cross_entropy loss = 1.1287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:23.541028 #train# step   30, loss = 1.1450, cross_entropy loss = 1.1450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:25.095214 #train# step   31, loss = 1.1404, cross_entropy loss = 1.1404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:26.682983 #train# step   32, loss = 1.1431, cross_entropy loss = 1.1431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:28.234340 #train# step   33, loss = 1.1294, cross_entropy loss = 1.1294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:29.808370 #train# step   34, loss = 1.1427, cross_entropy loss = 1.1427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:31.356322 #train# step   35, loss = 1.1580, cross_entropy loss = 1.1580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:32.896762 #train# step   36, loss = 1.1552, cross_entropy loss = 1.1552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:34.449730 #train# step   37, loss = 1.1666, cross_entropy loss = 1.1666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:35.989328 #train# step   38, loss = 1.1521, cross_entropy loss = 1.1521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:37.557958 #train# step   39, loss = 1.1462, cross_entropy loss = 1.1462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:39.151987 #train# step   40, loss = 1.1423, cross_entropy loss = 1.1423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:40.687578 #train# step   41, loss = 1.1404, cross_entropy loss = 1.1404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:42.245026 #train# step   42, loss = 1.1388, cross_entropy loss = 1.1388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:43.815780 #train# step   43, loss = 1.1186, cross_entropy loss = 1.1186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:45.365878 #train# step   44, loss = 1.1492, cross_entropy loss = 1.1492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:46.928482 #train# step   45, loss = 1.1360, cross_entropy loss = 1.1360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:48.469959 #train# step   46, loss = 1.1413, cross_entropy loss = 1.1413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:50.054100 #train# step   47, loss = 1.1066, cross_entropy loss = 1.1066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:51.620357 #train# step   48, loss = 1.1120, cross_entropy loss = 1.1120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:53.186370 #train# step   49, loss = 1.1278, cross_entropy loss = 1.1278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:54.728322 #train# step   50, loss = 1.0989, cross_entropy loss = 1.0989, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:56.348333 #train# step   51, loss = 1.1163, cross_entropy loss = 1.1163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:57.914528 #train# step   52, loss = 1.1215, cross_entropy loss = 1.1215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:40:59.525441 #train# step   53, loss = 1.1223, cross_entropy loss = 1.1223, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:01.049771 #train# step   54, loss = 1.1184, cross_entropy loss = 1.1184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:02.610146 #train# step   55, loss = 1.1024, cross_entropy loss = 1.1024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:04.167638 #train# step   56, loss = 1.0996, cross_entropy loss = 1.0996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:05.734376 #train# step   57, loss = 1.1315, cross_entropy loss = 1.1315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:07.287430 #train# step   58, loss = 1.1184, cross_entropy loss = 1.1184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:08.868624 #train# step   59, loss = 1.1170, cross_entropy loss = 1.1170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:10.444217 #train# step   60, loss = 1.1306, cross_entropy loss = 1.1306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:12.007725 #train# step   61, loss = 1.1099, cross_entropy loss = 1.1099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:13.609046 #train# step   62, loss = 1.1156, cross_entropy loss = 1.1156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:15.144430 #train# step   63, loss = 1.1185, cross_entropy loss = 1.1185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:16.710554 #train# step   64, loss = 1.1079, cross_entropy loss = 1.1079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:18.251459 #train# step   65, loss = 1.1089, cross_entropy loss = 1.1089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:19.824863 #train# step   66, loss = 1.1133, cross_entropy loss = 1.1133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:21.359051 #train# step   67, loss = 1.1228, cross_entropy loss = 1.1228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:22.947086 #train# step   68, loss = 1.1152, cross_entropy loss = 1.1152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:24.505649 #train# step   69, loss = 1.0968, cross_entropy loss = 1.0968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:26.052429 #train# step   70, loss = 1.1077, cross_entropy loss = 1.1077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:27.617592 #train# step   71, loss = 1.1015, cross_entropy loss = 1.1015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:29.191098 #train# step   72, loss = 1.1095, cross_entropy loss = 1.1095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:30.771742 #train# step   73, loss = 1.0939, cross_entropy loss = 1.0939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:32.335801 #train# step   74, loss = 1.1120, cross_entropy loss = 1.1120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:33.904115 #train# step   75, loss = 1.1112, cross_entropy loss = 1.1112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:35.487149 #train# step   76, loss = 1.0933, cross_entropy loss = 1.0933, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:37.059191 #train# step   77, loss = 1.1259, cross_entropy loss = 1.1259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:38.617835 #train# step   78, loss = 1.0999, cross_entropy loss = 1.0999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:40.179746 #train# step   79, loss = 1.0792, cross_entropy loss = 1.0792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:41.738082 #train# step   80, loss = 1.1110, cross_entropy loss = 1.1110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:43.279999 #train# step   81, loss = 1.1064, cross_entropy loss = 1.1064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:44.862366 #train# step   82, loss = 1.1105, cross_entropy loss = 1.1105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:46.440181 #train# step   83, loss = 1.1149, cross_entropy loss = 1.1149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:48.024979 #train# step   84, loss = 1.0936, cross_entropy loss = 1.0936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:49.606004 #train# step   85, loss = 1.1136, cross_entropy loss = 1.1136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:51.178180 #train# step   86, loss = 1.1009, cross_entropy loss = 1.1009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:52.731437 #train# step   87, loss = 1.1011, cross_entropy loss = 1.1011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:54.437682 #train# step   88, loss = 1.0951, cross_entropy loss = 1.0951, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:55.991525 #train# step   89, loss = 1.1024, cross_entropy loss = 1.1024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:57.587198 #train# step   90, loss = 1.0805, cross_entropy loss = 1.0805, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:41:59.141375 #train# step   91, loss = 1.0959, cross_entropy loss = 1.0959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:00.726902 #train# step   92, loss = 1.0815, cross_entropy loss = 1.0815, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:02.299205 #train# step   93, loss = 1.0850, cross_entropy loss = 1.0850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:03.875123 #train# step   94, loss = 1.1073, cross_entropy loss = 1.1073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:05.451929 #train# step   95, loss = 1.0804, cross_entropy loss = 1.0804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:07.022860 #train# step   96, loss = 1.0771, cross_entropy loss = 1.0771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:08.544326 #train# step   97, loss = 1.0791, cross_entropy loss = 1.0791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:10.128190 #train# step   98, loss = 1.0830, cross_entropy loss = 1.0830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:11.685318 #train# step   99, loss = 1.0841, cross_entropy loss = 1.0841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:13.249725 #train# step  100, loss = 1.0991, cross_entropy loss = 1.0991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:14.817849 #train# step  101, loss = 1.0876, cross_entropy loss = 1.0876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:16.388791 #train# step  102, loss = 1.0693, cross_entropy loss = 1.0693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:17.944762 #train# step  103, loss = 1.0673, cross_entropy loss = 1.0673, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:19.506345 #train# step  104, loss = 1.0900, cross_entropy loss = 1.0900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:21.079710 #train# step  105, loss = 1.0851, cross_entropy loss = 1.0851, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:22.647551 #train# step  106, loss = 1.0861, cross_entropy loss = 1.0861, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:24.201067 #train# step  107, loss = 1.0769, cross_entropy loss = 1.0769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:25.766272 #train# step  108, loss = 1.0803, cross_entropy loss = 1.0803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:27.319464 #train# step  109, loss = 1.0599, cross_entropy loss = 1.0599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:28.904918 #train# step  110, loss = 1.0732, cross_entropy loss = 1.0732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:30.500074 #train# step  111, loss = 1.0933, cross_entropy loss = 1.0933, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:32.066639 #train# step  112, loss = 1.0774, cross_entropy loss = 1.0774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:33.623090 #train# step  113, loss = 1.0695, cross_entropy loss = 1.0695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:35.161499 #train# step  114, loss = 1.0967, cross_entropy loss = 1.0967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:36.740473 #train# step  115, loss = 1.0838, cross_entropy loss = 1.0838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:38.314094 #train# step  116, loss = 1.0755, cross_entropy loss = 1.0755, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:39.886785 #train# step  117, loss = 1.0692, cross_entropy loss = 1.0692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:41.450970 #train# step  118, loss = 1.0879, cross_entropy loss = 1.0879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:43.016486 #train# step  119, loss = 1.0656, cross_entropy loss = 1.0656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:44.607210 #train# step  120, loss = 1.0850, cross_entropy loss = 1.0850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:46.191508 #train# step  121, loss = 1.0741, cross_entropy loss = 1.0741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:47.773521 #train# step  122, loss = 1.0502, cross_entropy loss = 1.0502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:49.373059 #train# step  123, loss = 1.0851, cross_entropy loss = 1.0851, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:50.943117 #train# step  124, loss = 1.0687, cross_entropy loss = 1.0687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:52.521052 #train# step  125, loss = 1.0697, cross_entropy loss = 1.0697, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:54.097064 #train# step  126, loss = 1.0719, cross_entropy loss = 1.0719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:55.643693 #train# step  127, loss = 1.0684, cross_entropy loss = 1.0684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:57.188764 #train# step  128, loss = 1.0529, cross_entropy loss = 1.0529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:42:58.749583 #train# step  129, loss = 1.0547, cross_entropy loss = 1.0547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:00.352309 #train# step  130, loss = 1.0763, cross_entropy loss = 1.0763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:01.910570 #train# step  131, loss = 1.0569, cross_entropy loss = 1.0569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:03.479627 #train# step  132, loss = 1.0725, cross_entropy loss = 1.0725, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:05.035667 #train# step  133, loss = 1.0528, cross_entropy loss = 1.0528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:06.619061 #train# step  134, loss = 1.0588, cross_entropy loss = 1.0588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:08.193551 #train# step  135, loss = 1.0835, cross_entropy loss = 1.0835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:09.780049 #train# step  136, loss = 1.0581, cross_entropy loss = 1.0581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:11.334572 #train# step  137, loss = 1.0736, cross_entropy loss = 1.0736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:12.931831 #train# step  138, loss = 1.0601, cross_entropy loss = 1.0601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:14.485287 #train# step  139, loss = 1.0739, cross_entropy loss = 1.0739, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:16.065696 #train# step  140, loss = 1.0765, cross_entropy loss = 1.0765, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:17.626468 #train# step  141, loss = 1.0673, cross_entropy loss = 1.0673, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:19.201658 #train# step  142, loss = 1.0661, cross_entropy loss = 1.0661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:20.749657 #train# step  143, loss = 1.0728, cross_entropy loss = 1.0728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:22.333017 #train# step  144, loss = 1.0513, cross_entropy loss = 1.0513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:23.907383 #train# step  145, loss = 1.0538, cross_entropy loss = 1.0538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:25.485198 #train# step  146, loss = 1.0359, cross_entropy loss = 1.0359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:27.029728 #train# step  147, loss = 1.0620, cross_entropy loss = 1.0620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:28.604675 #train# step  148, loss = 1.0681, cross_entropy loss = 1.0681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:30.181873 #train# step  149, loss = 1.0567, cross_entropy loss = 1.0567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:31.758495 #train# step  150, loss = 1.0705, cross_entropy loss = 1.0705, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:33.320506 #train# step  151, loss = 1.0512, cross_entropy loss = 1.0512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:34.879991 #train# step  152, loss = 1.0768, cross_entropy loss = 1.0768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:36.446985 #train# step  153, loss = 1.0420, cross_entropy loss = 1.0420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:38.025284 #train# step  154, loss = 1.0556, cross_entropy loss = 1.0556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:39.633190 #train# step  155, loss = 1.0714, cross_entropy loss = 1.0714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:41.215383 #train# step  156, loss = 1.0430, cross_entropy loss = 1.0430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:42.826943 #train# step  157, loss = 1.0525, cross_entropy loss = 1.0525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:44.394586 #train# step  158, loss = 1.0738, cross_entropy loss = 1.0738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:45.946671 #train# step  159, loss = 1.0491, cross_entropy loss = 1.0491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:47.503716 #train# step  160, loss = 1.0833, cross_entropy loss = 1.0833, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:49.090872 #train# step  161, loss = 1.0601, cross_entropy loss = 1.0601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:50.677584 #train# step  162, loss = 1.0595, cross_entropy loss = 1.0595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:52.220799 #train# step  163, loss = 1.0380, cross_entropy loss = 1.0380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:53.782330 #train# step  164, loss = 1.0781, cross_entropy loss = 1.0781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:55.382070 #train# step  165, loss = 1.0599, cross_entropy loss = 1.0599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:56.936541 #train# step  166, loss = 1.0496, cross_entropy loss = 1.0496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:43:58.519470 #train# step  167, loss = 1.0564, cross_entropy loss = 1.0564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:00.067655 #train# step  168, loss = 1.0584, cross_entropy loss = 1.0584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:01.627805 #train# step  169, loss = 1.0474, cross_entropy loss = 1.0474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:03.202854 #train# step  170, loss = 1.0562, cross_entropy loss = 1.0562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:04.750107 #train# step  171, loss = 1.0563, cross_entropy loss = 1.0563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:06.320944 #train# step  172, loss = 1.0587, cross_entropy loss = 1.0587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:07.903392 #train# step  173, loss = 1.0446, cross_entropy loss = 1.0446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:09.483144 #train# step  174, loss = 1.0685, cross_entropy loss = 1.0685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:11.066098 #train# step  175, loss = 1.0527, cross_entropy loss = 1.0527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:12.629790 #train# step  176, loss = 1.0480, cross_entropy loss = 1.0480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:14.188213 #train# step  177, loss = 1.0532, cross_entropy loss = 1.0532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:15.747286 #train# step  178, loss = 1.0500, cross_entropy loss = 1.0500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:17.282676 #train# step  179, loss = 1.0694, cross_entropy loss = 1.0694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:18.875700 #train# step  180, loss = 1.0557, cross_entropy loss = 1.0557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:20.481114 #train# step  181, loss = 1.0431, cross_entropy loss = 1.0431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:22.055868 #train# step  182, loss = 1.0449, cross_entropy loss = 1.0449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:23.614813 #train# step  183, loss = 1.0657, cross_entropy loss = 1.0657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:25.183183 #train# step  184, loss = 1.0456, cross_entropy loss = 1.0456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:26.756851 #train# step  185, loss = 1.0537, cross_entropy loss = 1.0537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:28.374668 #train# step  186, loss = 1.0477, cross_entropy loss = 1.0477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:29.950386 #train# step  187, loss = 1.0391, cross_entropy loss = 1.0391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:31.537200 #train# step  188, loss = 1.0406, cross_entropy loss = 1.0406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:33.115730 #train# step  189, loss = 1.0423, cross_entropy loss = 1.0423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:34.669633 #train# step  190, loss = 1.0593, cross_entropy loss = 1.0593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:36.236904 #train# step  191, loss = 1.0573, cross_entropy loss = 1.0573, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:37.813868 #train# step  192, loss = 1.0380, cross_entropy loss = 1.0380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:39.396110 #train# step  193, loss = 1.0338, cross_entropy loss = 1.0338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:40.949186 #train# step  194, loss = 1.0492, cross_entropy loss = 1.0492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:42.511694 #train# step  195, loss = 1.0443, cross_entropy loss = 1.0443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:44.116425 #train# step  196, loss = 1.0398, cross_entropy loss = 1.0398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:45.685943 #train# step  197, loss = 1.0481, cross_entropy loss = 1.0481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:47.258659 #train# step  198, loss = 1.0329, cross_entropy loss = 1.0329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:48.839920 #train# step  199, loss = 1.0400, cross_entropy loss = 1.0400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:50.407525 #train# step  200, loss = 1.0582, cross_entropy loss = 1.0582, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:51.982595 #train# step  201, loss = 1.0395, cross_entropy loss = 1.0395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:53.578555 #train# step  202, loss = 1.0283, cross_entropy loss = 1.0283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:55.147413 #train# step  203, loss = 1.0526, cross_entropy loss = 1.0526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:56.747619 #train# step  204, loss = 1.0110, cross_entropy loss = 1.0110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:58.292862 #train# step  205, loss = 1.0600, cross_entropy loss = 1.0600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:44:59.852429 #train# step  206, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:01.430251 #train# step  207, loss = 1.0468, cross_entropy loss = 1.0468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:02.985637 #train# step  208, loss = 1.0426, cross_entropy loss = 1.0426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:04.568646 #train# step  209, loss = 1.0593, cross_entropy loss = 1.0593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:06.159070 #train# step  210, loss = 1.0555, cross_entropy loss = 1.0555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:07.729587 #train# step  211, loss = 1.0398, cross_entropy loss = 1.0398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:09.295625 #train# step  212, loss = 1.0552, cross_entropy loss = 1.0552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:10.883242 #train# step  213, loss = 1.0537, cross_entropy loss = 1.0537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:12.457759 #train# step  214, loss = 1.0602, cross_entropy loss = 1.0602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:14.052485 #train# step  215, loss = 1.0492, cross_entropy loss = 1.0492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:15.629276 #train# step  216, loss = 1.0422, cross_entropy loss = 1.0422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:17.184980 #train# step  217, loss = 1.0614, cross_entropy loss = 1.0614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:18.779961 #train# step  218, loss = 1.0295, cross_entropy loss = 1.0295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:20.358493 #train# step  219, loss = 1.0536, cross_entropy loss = 1.0536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:21.924410 #train# step  220, loss = 1.0391, cross_entropy loss = 1.0391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:23.468455 #train# step  221, loss = 1.0315, cross_entropy loss = 1.0315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:25.034923 #train# step  222, loss = 1.0346, cross_entropy loss = 1.0346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:26.586249 #train# step  223, loss = 1.0398, cross_entropy loss = 1.0398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:28.171461 #train# step  224, loss = 1.0433, cross_entropy loss = 1.0433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:29.744839 #train# step  225, loss = 1.0399, cross_entropy loss = 1.0399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:31.308495 #train# step  226, loss = 1.0326, cross_entropy loss = 1.0326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:32.877160 #train# step  227, loss = 1.0432, cross_entropy loss = 1.0432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:34.432919 #train# step  228, loss = 1.0530, cross_entropy loss = 1.0530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:35.991216 #train# step  229, loss = 1.0500, cross_entropy loss = 1.0500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:37.560240 #train# step  230, loss = 1.0309, cross_entropy loss = 1.0309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:39.137874 #train# step  231, loss = 1.0408, cross_entropy loss = 1.0408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:40.687529 #train# step  232, loss = 1.0264, cross_entropy loss = 1.0264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:42.257506 #train# step  233, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:43.853875 #train# step  234, loss = 1.0323, cross_entropy loss = 1.0323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:45.428652 #train# step  235, loss = 1.0374, cross_entropy loss = 1.0374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:47.022567 #train# step  236, loss = 1.0327, cross_entropy loss = 1.0327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:48.620348 #train# step  237, loss = 1.0522, cross_entropy loss = 1.0522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:50.176481 #train# step  238, loss = 1.0348, cross_entropy loss = 1.0348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:51.751442 #train# step  239, loss = 1.0377, cross_entropy loss = 1.0377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:53.316669 #train# step  240, loss = 1.0295, cross_entropy loss = 1.0295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:54.856049 #train# step  241, loss = 1.0598, cross_entropy loss = 1.0598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:56.430230 #train# step  242, loss = 1.0320, cross_entropy loss = 1.0320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:57.996994 #train# step  243, loss = 1.0273, cross_entropy loss = 1.0273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:45:59.545502 #train# step  244, loss = 1.0089, cross_entropy loss = 1.0089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:01.130670 #train# step  245, loss = 1.0386, cross_entropy loss = 1.0386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:02.714484 #train# step  246, loss = 1.0364, cross_entropy loss = 1.0364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:04.293177 #train# step  247, loss = 1.0314, cross_entropy loss = 1.0314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:05.867009 #train# step  248, loss = 1.0302, cross_entropy loss = 1.0302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:07.418761 #train# step  249, loss = 1.0408, cross_entropy loss = 1.0408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:08.989582 #train# step  250, loss = 1.0326, cross_entropy loss = 1.0326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:10.549410 #train# step  251, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:12.117426 #train# step  252, loss = 1.0214, cross_entropy loss = 1.0214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:13.695036 #train# step  253, loss = 1.0229, cross_entropy loss = 1.0229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:15.273546 #train# step  254, loss = 1.0214, cross_entropy loss = 1.0214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:16.843054 #train# step  255, loss = 1.0287, cross_entropy loss = 1.0287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:18.411540 #train# step  256, loss = 1.0489, cross_entropy loss = 1.0489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:19.970543 #train# step  257, loss = 1.0465, cross_entropy loss = 1.0465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:21.550607 #train# step  258, loss = 1.0329, cross_entropy loss = 1.0329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:23.114906 #train# step  259, loss = 1.0289, cross_entropy loss = 1.0289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:24.724280 #train# step  260, loss = 1.0405, cross_entropy loss = 1.0405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:26.306829 #train# step  261, loss = 1.0235, cross_entropy loss = 1.0235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:27.901117 #train# step  262, loss = 1.0368, cross_entropy loss = 1.0368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:29.485822 #train# step  263, loss = 1.0339, cross_entropy loss = 1.0339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:31.046068 #train# step  264, loss = 1.0191, cross_entropy loss = 1.0191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:32.629562 #train# step  265, loss = 1.0463, cross_entropy loss = 1.0463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:34.179194 #train# step  266, loss = 1.0493, cross_entropy loss = 1.0493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:35.788468 #train# step  267, loss = 1.0286, cross_entropy loss = 1.0286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:37.347451 #train# step  268, loss = 1.0249, cross_entropy loss = 1.0249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:38.933367 #train# step  269, loss = 1.0490, cross_entropy loss = 1.0490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:40.487212 #train# step  270, loss = 1.0356, cross_entropy loss = 1.0356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:42.062263 #train# step  271, loss = 1.0359, cross_entropy loss = 1.0359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:43.658641 #train# step  272, loss = 1.0203, cross_entropy loss = 1.0203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:45.232581 #train# step  273, loss = 1.0259, cross_entropy loss = 1.0259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:46.808785 #train# step  274, loss = 1.0307, cross_entropy loss = 1.0307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:48.363362 #train# step  275, loss = 1.0362, cross_entropy loss = 1.0362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:49.938821 #train# step  276, loss = 1.0226, cross_entropy loss = 1.0226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:51.489704 #train# step  277, loss = 1.0196, cross_entropy loss = 1.0196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:53.057443 #train# step  278, loss = 1.0314, cross_entropy loss = 1.0314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:54.659144 #train# step  279, loss = 1.0350, cross_entropy loss = 1.0350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:56.209167 #train# step  280, loss = 1.0279, cross_entropy loss = 1.0279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:57.842069 #train# step  281, loss = 1.0221, cross_entropy loss = 1.0221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:46:59.415645 #train# step  282, loss = 1.0439, cross_entropy loss = 1.0439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:01.014823 #train# step  283, loss = 1.0342, cross_entropy loss = 1.0342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:02.578000 #train# step  284, loss = 1.0114, cross_entropy loss = 1.0114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:04.159063 #train# step  285, loss = 1.0353, cross_entropy loss = 1.0353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:05.713198 #train# step  286, loss = 1.0221, cross_entropy loss = 1.0221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:07.279608 #train# step  287, loss = 1.0208, cross_entropy loss = 1.0208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:08.829522 #train# step  288, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:10.409280 #train# step  289, loss = 1.0281, cross_entropy loss = 1.0281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:11.974320 #train# step  290, loss = 1.0375, cross_entropy loss = 1.0375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:13.533693 #train# step  291, loss = 1.0394, cross_entropy loss = 1.0394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:15.098959 #train# step  292, loss = 1.0257, cross_entropy loss = 1.0257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:16.697319 #train# step  293, loss = 1.0195, cross_entropy loss = 1.0195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:18.253665 #train# step  294, loss = 1.0360, cross_entropy loss = 1.0360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:19.811453 #train# step  295, loss = 1.0183, cross_entropy loss = 1.0183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:21.401377 #train# step  296, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:22.979142 #train# step  297, loss = 1.0375, cross_entropy loss = 1.0375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:24.573642 #train# step  298, loss = 1.0146, cross_entropy loss = 1.0146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:26.147449 #train# step  299, loss = 1.0341, cross_entropy loss = 1.0341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:27.696721 #train# step  300, loss = 1.0203, cross_entropy loss = 1.0203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:29.293148 #train# step  301, loss = 1.0192, cross_entropy loss = 1.0192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:30.871314 #train# step  302, loss = 1.0101, cross_entropy loss = 1.0101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:32.431888 #train# step  303, loss = 1.0249, cross_entropy loss = 1.0249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:33.971739 #train# step  304, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:35.562263 #train# step  305, loss = 1.0226, cross_entropy loss = 1.0226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:37.144151 #train# step  306, loss = 1.0119, cross_entropy loss = 1.0119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:38.718264 #train# step  307, loss = 1.0239, cross_entropy loss = 1.0239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:40.315362 #train# step  308, loss = 0.9943, cross_entropy loss = 0.9943, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:41.919222 #train# step  309, loss = 1.0206, cross_entropy loss = 1.0206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:43.447215 #train# step  310, loss = 1.0166, cross_entropy loss = 1.0166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:45.014752 #train# step  311, loss = 1.0034, cross_entropy loss = 1.0034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:46.588349 #train# step  312, loss = 1.0169, cross_entropy loss = 1.0169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:48.159647 #train# step  313, loss = 1.0325, cross_entropy loss = 1.0325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:49.724140 #train# step  314, loss = 1.0166, cross_entropy loss = 1.0166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:51.349084 #train# step  315, loss = 1.0430, cross_entropy loss = 1.0430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:52.901454 #train# step  316, loss = 1.0194, cross_entropy loss = 1.0194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:54.459320 #train# step  317, loss = 1.0247, cross_entropy loss = 1.0247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:56.038832 #train# step  318, loss = 1.0144, cross_entropy loss = 1.0144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:57.627323 #train# step  319, loss = 1.0258, cross_entropy loss = 1.0258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:47:59.227666 #train# step  320, loss = 1.0187, cross_entropy loss = 1.0187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:00.827449 #train# step  321, loss = 1.0481, cross_entropy loss = 1.0481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:02.403307 #train# step  322, loss = 1.0130, cross_entropy loss = 1.0130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:03.954477 #train# step  323, loss = 1.0132, cross_entropy loss = 1.0132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:05.540316 #train# step  324, loss = 1.0371, cross_entropy loss = 1.0371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:07.108042 #train# step  325, loss = 1.0314, cross_entropy loss = 1.0314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:08.667957 #train# step  326, loss = 1.0306, cross_entropy loss = 1.0306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:10.252737 #train# step  327, loss = 1.0067, cross_entropy loss = 1.0067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:11.804128 #train# step  328, loss = 1.0259, cross_entropy loss = 1.0259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:13.363009 #train# step  329, loss = 1.0265, cross_entropy loss = 1.0265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:14.942256 #train# step  330, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:16.489032 #train# step  331, loss = 1.0187, cross_entropy loss = 1.0187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:18.030362 #train# step  332, loss = 1.0361, cross_entropy loss = 1.0361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:19.611564 #train# step  333, loss = 1.0422, cross_entropy loss = 1.0422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:21.176217 #train# step  334, loss = 1.0076, cross_entropy loss = 1.0076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:22.723815 #train# step  335, loss = 1.0347, cross_entropy loss = 1.0347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:24.279885 #train# step  336, loss = 1.0336, cross_entropy loss = 1.0336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:25.896070 #train# step  337, loss = 1.0241, cross_entropy loss = 1.0241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:27.473657 #train# step  338, loss = 1.0176, cross_entropy loss = 1.0176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:29.063491 #train# step  339, loss = 1.0192, cross_entropy loss = 1.0192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:30.645727 #train# step  340, loss = 1.0231, cross_entropy loss = 1.0231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:32.233857 #train# step  341, loss = 1.0162, cross_entropy loss = 1.0162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:33.817708 #train# step  342, loss = 1.0193, cross_entropy loss = 1.0193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:35.367377 #train# step  343, loss = 1.0075, cross_entropy loss = 1.0075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:36.964342 #train# step  344, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:38.536311 #train# step  345, loss = 1.0243, cross_entropy loss = 1.0243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:40.109713 #train# step  346, loss = 1.0170, cross_entropy loss = 1.0170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:41.675618 #train# step  347, loss = 1.0107, cross_entropy loss = 1.0107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:43.219415 #train# step  348, loss = 1.0163, cross_entropy loss = 1.0163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:44.805646 #train# step  349, loss = 1.0324, cross_entropy loss = 1.0324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:46.398424 #train# step  350, loss = 1.0278, cross_entropy loss = 1.0278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:47.964899 #train# step  351, loss = 1.0205, cross_entropy loss = 1.0205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:49.541723 #train# step  352, loss = 1.0198, cross_entropy loss = 1.0198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:51.119926 #train# step  353, loss = 1.0242, cross_entropy loss = 1.0242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:52.678743 #train# step  354, loss = 1.0128, cross_entropy loss = 1.0128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:54.229515 #train# step  355, loss = 1.0205, cross_entropy loss = 1.0205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:55.799520 #train# step  356, loss = 1.0336, cross_entropy loss = 1.0336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:57.387263 #train# step  357, loss = 1.0269, cross_entropy loss = 1.0269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:48:58.959320 #train# step  358, loss = 1.0138, cross_entropy loss = 1.0138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:00.543056 #train# step  359, loss = 1.0018, cross_entropy loss = 1.0018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:02.123763 #train# step  360, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:03.685784 #train# step  361, loss = 1.0275, cross_entropy loss = 1.0275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:05.261151 #train# step  362, loss = 1.0107, cross_entropy loss = 1.0107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:06.840442 #train# step  363, loss = 0.9980, cross_entropy loss = 0.9980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:08.429520 #train# step  364, loss = 1.0110, cross_entropy loss = 1.0110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:10.011414 #train# step  365, loss = 1.0238, cross_entropy loss = 1.0238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:11.595249 #train# step  366, loss = 1.0178, cross_entropy loss = 1.0178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:13.187751 #train# step  367, loss = 1.0181, cross_entropy loss = 1.0181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:14.741159 #train# step  368, loss = 1.0166, cross_entropy loss = 1.0166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:16.284184 #train# step  369, loss = 1.0244, cross_entropy loss = 1.0244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:17.847210 #train# step  370, loss = 1.0137, cross_entropy loss = 1.0137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:19.424743 #train# step  371, loss = 1.0143, cross_entropy loss = 1.0143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:20.995885 #train# step  372, loss = 1.0277, cross_entropy loss = 1.0277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:22.561204 #train# step  373, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:24.114985 #train# step  374, loss = 1.0203, cross_entropy loss = 1.0203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:25.695786 #train# step  375, loss = 1.0107, cross_entropy loss = 1.0107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:27.253913 #train# step  376, loss = 1.0161, cross_entropy loss = 1.0161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:28.811347 #train# step  377, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:30.385503 #train# step  378, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:31.955069 #train# step  379, loss = 1.0142, cross_entropy loss = 1.0142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:33.524185 #train# step  380, loss = 1.0366, cross_entropy loss = 1.0366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:35.083160 #train# step  381, loss = 0.9999, cross_entropy loss = 0.9999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:36.649921 #train# step  382, loss = 1.0095, cross_entropy loss = 1.0095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:38.223946 #train# step  383, loss = 1.0172, cross_entropy loss = 1.0172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:39.809999 #train# step  384, loss = 1.0153, cross_entropy loss = 1.0153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:41.367760 #train# step  385, loss = 1.0181, cross_entropy loss = 1.0181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:42.937875 #train# step  386, loss = 1.0161, cross_entropy loss = 1.0161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:44.527120 #train# step  387, loss = 1.0080, cross_entropy loss = 1.0080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:46.086207 #train# step  388, loss = 1.0079, cross_entropy loss = 1.0079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:47.638388 #train# step  389, loss = 1.0223, cross_entropy loss = 1.0223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:49.191666 #train# step  390, loss = 1.0320, cross_entropy loss = 1.0320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:50.754601 #train# step  391, loss = 1.0074, cross_entropy loss = 1.0074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:52.292911 #train# step  392, loss = 1.0137, cross_entropy loss = 1.0137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:53.860282 #train# step  393, loss = 1.0231, cross_entropy loss = 1.0231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:55.468851 #train# step  394, loss = 1.0146, cross_entropy loss = 1.0146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:57.021040 #train# step  395, loss = 1.0192, cross_entropy loss = 1.0192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:49:58.565692 #train# step  396, loss = 1.0274, cross_entropy loss = 1.0274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:00.144380 #train# step  397, loss = 1.0078, cross_entropy loss = 1.0078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:01.716756 #train# step  398, loss = 1.0157, cross_entropy loss = 1.0157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:03.315644 #train# step  399, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:04.879499 #train# step  400, loss = 1.0265, cross_entropy loss = 1.0265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:06.438051 #train# step  401, loss = 1.0347, cross_entropy loss = 1.0347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:08.004330 #train# step  402, loss = 1.0398, cross_entropy loss = 1.0398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:09.576301 #train# step  403, loss = 1.0311, cross_entropy loss = 1.0311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:11.162306 #train# step  404, loss = 1.0024, cross_entropy loss = 1.0024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:12.742393 #train# step  405, loss = 1.0082, cross_entropy loss = 1.0082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:14.284007 #train# step  406, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:15.870117 #train# step  407, loss = 1.0056, cross_entropy loss = 1.0056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:17.405540 #train# step  408, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:18.945037 #train# step  409, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:20.494075 #train# step  410, loss = 0.9987, cross_entropy loss = 0.9987, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:22.106016 #train# step  411, loss = 1.0157, cross_entropy loss = 1.0157, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:23.727050 #train# step  412, loss = 1.0248, cross_entropy loss = 1.0248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:25.319199 #train# step  413, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:26.890831 #train# step  414, loss = 1.0088, cross_entropy loss = 1.0088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:28.470587 #train# step  415, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:30.029763 #train# step  416, loss = 1.0153, cross_entropy loss = 1.0153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:31.632607 #train# step  417, loss = 1.0022, cross_entropy loss = 1.0022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:33.235847 #train# step  418, loss = 1.0003, cross_entropy loss = 1.0003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:34.796395 #train# step  419, loss = 1.0338, cross_entropy loss = 1.0338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:36.371085 #train# step  420, loss = 1.0090, cross_entropy loss = 1.0090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:37.952747 #train# step  421, loss = 1.0024, cross_entropy loss = 1.0024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:39.599031 #train# step  422, loss = 1.0050, cross_entropy loss = 1.0050, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:41.171428 #train# step  423, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:42.846513 #train# step  424, loss = 0.9963, cross_entropy loss = 0.9963, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:44.414856 #train# step  425, loss = 1.0343, cross_entropy loss = 1.0343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:45.982349 #train# step  426, loss = 1.0005, cross_entropy loss = 1.0005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:47.562227 #train# step  427, loss = 0.9918, cross_entropy loss = 0.9918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:49.154995 #train# step  428, loss = 1.0002, cross_entropy loss = 1.0002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:50.707615 #train# step  429, loss = 1.0244, cross_entropy loss = 1.0244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:52.264427 #train# step  430, loss = 1.0181, cross_entropy loss = 1.0181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:53.835395 #train# step  431, loss = 1.0142, cross_entropy loss = 1.0142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:55.384335 #train# step  432, loss = 1.0140, cross_entropy loss = 1.0140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:56.966771 #train# step  433, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:50:58.551363 #train# step  434, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:00.119189 #train# step  435, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:01.693035 #train# step  436, loss = 1.0110, cross_entropy loss = 1.0110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:03.270381 #train# step  437, loss = 1.0093, cross_entropy loss = 1.0093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:04.826979 #train# step  438, loss = 1.0187, cross_entropy loss = 1.0187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:06.408707 #train# step  439, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:07.963177 #train# step  440, loss = 1.0182, cross_entropy loss = 1.0182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:09.525555 #train# step  441, loss = 1.0249, cross_entropy loss = 1.0249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:11.107007 #train# step  442, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:12.681189 #train# step  443, loss = 0.9969, cross_entropy loss = 0.9969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:14.266892 #train# step  444, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:15.835322 #train# step  445, loss = 1.0109, cross_entropy loss = 1.0109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:17.412103 #train# step  446, loss = 1.0086, cross_entropy loss = 1.0086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:18.974177 #train# step  447, loss = 1.0260, cross_entropy loss = 1.0260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:20.555321 #train# step  448, loss = 1.0188, cross_entropy loss = 1.0188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:22.108558 #train# step  449, loss = 1.0058, cross_entropy loss = 1.0058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:23.678822 #train# step  450, loss = 1.0039, cross_entropy loss = 1.0039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:25.256721 #train# step  451, loss = 1.0099, cross_entropy loss = 1.0099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:26.820597 #train# step  452, loss = 1.0330, cross_entropy loss = 1.0330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:28.388277 #train# step  453, loss = 1.0215, cross_entropy loss = 1.0215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:29.964013 #train# step  454, loss = 0.9890, cross_entropy loss = 0.9890, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:31.540011 #train# step  455, loss = 0.9995, cross_entropy loss = 0.9995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:33.095672 #train# step  456, loss = 1.0156, cross_entropy loss = 1.0156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:34.668205 #train# step  457, loss = 1.0148, cross_entropy loss = 1.0148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:36.207561 #train# step  458, loss = 1.0320, cross_entropy loss = 1.0320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:37.767792 #train# step  459, loss = 1.0129, cross_entropy loss = 1.0129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:39.342463 #train# step  460, loss = 1.0223, cross_entropy loss = 1.0223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:40.933634 #train# step  461, loss = 1.0234, cross_entropy loss = 1.0234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:42.486602 #train# step  462, loss = 1.0116, cross_entropy loss = 1.0116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:44.025909 #train# step  463, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:45.613408 #train# step  464, loss = 0.9974, cross_entropy loss = 0.9974, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:47.176095 #train# step  465, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:48.741647 #train# step  466, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:50.325130 #train# step  467, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:51.876211 #train# step  468, loss = 1.0152, cross_entropy loss = 1.0152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:53.445303 #train# step  469, loss = 1.0082, cross_entropy loss = 1.0082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:55.002958 #train# step  470, loss = 1.0190, cross_entropy loss = 1.0190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:56.605498 #train# step  471, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:58.164829 #train# step  472, loss = 1.0342, cross_entropy loss = 1.0342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:51:59.699614 #train# step  473, loss = 1.0251, cross_entropy loss = 1.0251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:01.255026 #train# step  474, loss = 1.0024, cross_entropy loss = 1.0024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:02.817855 #train# step  475, loss = 1.0246, cross_entropy loss = 1.0246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:04.412756 #train# step  476, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:05.972245 #train# step  477, loss = 1.0142, cross_entropy loss = 1.0142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:07.533561 #train# step  478, loss = 1.0139, cross_entropy loss = 1.0139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:09.096241 #train# step  479, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:10.713559 #train# step  480, loss = 0.9925, cross_entropy loss = 0.9925, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:12.328766 #train# step  481, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:13.897890 #train# step  482, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:15.461590 #train# step  483, loss = 0.9877, cross_entropy loss = 0.9877, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:17.023711 #train# step  484, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:18.603604 #train# step  485, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:20.157591 #train# step  486, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:21.711993 #train# step  487, loss = 1.0130, cross_entropy loss = 1.0130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:23.270454 #train# step  488, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:24.847000 #train# step  489, loss = 1.0117, cross_entropy loss = 1.0117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:26.416605 #train# step  490, loss = 1.0047, cross_entropy loss = 1.0047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:27.977038 #train# step  491, loss = 1.0057, cross_entropy loss = 1.0057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:29.514386 #train# step  492, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:31.074066 #train# step  493, loss = 1.0172, cross_entropy loss = 1.0172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:32.665851 #train# step  494, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:34.247206 #train# step  495, loss = 1.0137, cross_entropy loss = 1.0137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:35.825320 #train# step  496, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:37.405975 #train# step  497, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:38.966253 #train# step  498, loss = 1.0312, cross_entropy loss = 1.0312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:40.528666 #train# step  499, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:42.094378 #train# step  500, loss = 1.0063, cross_entropy loss = 1.0063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:43.688883 #train# step  501, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:45.244409 #train# step  502, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:46.833158 #train# step  503, loss = 1.0094, cross_entropy loss = 1.0094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:48.428093 #train# step  504, loss = 1.0124, cross_entropy loss = 1.0124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:50.007138 #train# step  505, loss = 1.0193, cross_entropy loss = 1.0193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:51.572160 #train# step  506, loss = 0.9968, cross_entropy loss = 0.9968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:53.116696 #train# step  507, loss = 1.0130, cross_entropy loss = 1.0130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:54.664867 #train# step  508, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:56.224948 #train# step  509, loss = 1.0170, cross_entropy loss = 1.0170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:57.784363 #train# step  510, loss = 1.0048, cross_entropy loss = 1.0048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:52:59.351064 #train# step  511, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:00.918574 #train# step  512, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:02.469275 #train# step  513, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:04.055441 #train# step  514, loss = 0.9969, cross_entropy loss = 0.9969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:05.644800 #train# step  515, loss = 1.0119, cross_entropy loss = 1.0119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:07.184020 #train# step  516, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:08.723775 #train# step  517, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:10.300325 #train# step  518, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:11.887452 #train# step  519, loss = 1.0034, cross_entropy loss = 1.0034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:13.467265 #train# step  520, loss = 1.0029, cross_entropy loss = 1.0029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:15.040918 #train# step  521, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:16.604637 #train# step  522, loss = 1.0170, cross_entropy loss = 1.0170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:18.146634 #train# step  523, loss = 1.0142, cross_entropy loss = 1.0142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:19.722123 #train# step  524, loss = 1.0031, cross_entropy loss = 1.0031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:21.305884 #train# step  525, loss = 0.9942, cross_entropy loss = 0.9942, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:22.902529 #train# step  526, loss = 1.0147, cross_entropy loss = 1.0147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:24.479095 #train# step  527, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:26.060061 #train# step  528, loss = 1.0180, cross_entropy loss = 1.0180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:27.620658 #train# step  529, loss = 1.0149, cross_entropy loss = 1.0149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:29.197875 #train# step  530, loss = 1.0113, cross_entropy loss = 1.0113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:30.751391 #train# step  531, loss = 0.9987, cross_entropy loss = 0.9987, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:32.317531 #train# step  532, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:33.885397 #train# step  533, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:35.439401 #train# step  534, loss = 1.0221, cross_entropy loss = 1.0221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:36.994687 #train# step  535, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:38.589504 #train# step  536, loss = 1.0030, cross_entropy loss = 1.0030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:40.163924 #train# step  537, loss = 1.0017, cross_entropy loss = 1.0017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:41.746090 #train# step  538, loss = 1.0013, cross_entropy loss = 1.0013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:43.286145 #train# step  539, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:44.862328 #train# step  540, loss = 1.0056, cross_entropy loss = 1.0056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:46.426508 #train# step  541, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:48.004998 #train# step  542, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:49.588199 #train# step  543, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:51.154023 #train# step  544, loss = 1.0264, cross_entropy loss = 1.0264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:52.714771 #train# step  545, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:54.294875 #train# step  546, loss = 1.0145, cross_entropy loss = 1.0145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:55.829573 #train# step  547, loss = 1.0022, cross_entropy loss = 1.0022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:57.388480 #train# step  548, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:53:58.986031 #train# step  549, loss = 1.0031, cross_entropy loss = 1.0031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:00.552928 #train# step  550, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:02.142051 #train# step  551, loss = 1.0109, cross_entropy loss = 1.0109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:03.702527 #train# step  552, loss = 1.0025, cross_entropy loss = 1.0025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:05.285786 #train# step  553, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:06.847706 #train# step  554, loss = 0.9925, cross_entropy loss = 0.9925, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:08.418676 #train# step  555, loss = 1.0082, cross_entropy loss = 1.0082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:09.963532 #train# step  556, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:11.498665 #train# step  557, loss = 1.0130, cross_entropy loss = 1.0130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:13.075946 #train# step  558, loss = 1.0239, cross_entropy loss = 1.0239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:14.661824 #train# step  559, loss = 1.0020, cross_entropy loss = 1.0020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:16.248806 #train# step  560, loss = 1.0233, cross_entropy loss = 1.0233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:17.805363 #train# step  561, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:19.346671 #train# step  562, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:20.909229 #train# step  563, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:22.494034 #train# step  564, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:24.070647 #train# step  565, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:25.636953 #train# step  566, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:27.217829 #train# step  567, loss = 1.0009, cross_entropy loss = 1.0009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:28.799002 #train# step  568, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:30.369041 #train# step  569, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:31.952514 #train# step  570, loss = 1.0000, cross_entropy loss = 1.0000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:33.530171 #train# step  571, loss = 1.0104, cross_entropy loss = 1.0104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:35.095309 #train# step  572, loss = 1.0116, cross_entropy loss = 1.0116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:36.666380 #train# step  573, loss = 1.0008, cross_entropy loss = 1.0008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:38.213589 #train# step  574, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:39.766389 #train# step  575, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:41.353162 #train# step  576, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:42.896573 #train# step  577, loss = 1.0165, cross_entropy loss = 1.0165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:44.429508 #train# step  578, loss = 0.9909, cross_entropy loss = 0.9909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:46.025944 #train# step  579, loss = 1.0032, cross_entropy loss = 1.0032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:47.632157 #train# step  580, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:49.215615 #train# step  581, loss = 0.9961, cross_entropy loss = 0.9961, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:50.778937 #train# step  582, loss = 1.0113, cross_entropy loss = 1.0113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:52.351366 #train# step  583, loss = 1.0047, cross_entropy loss = 1.0047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:53.944202 #train# step  584, loss = 0.9937, cross_entropy loss = 0.9937, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:55.516019 #train# step  585, loss = 0.9968, cross_entropy loss = 0.9968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:57.105836 #train# step  586, loss = 1.0075, cross_entropy loss = 1.0075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:54:58.702551 #train# step  587, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:00.225671 #train# step  588, loss = 1.0095, cross_entropy loss = 1.0095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:01.818466 #train# step  589, loss = 1.0040, cross_entropy loss = 1.0040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:03.389723 #train# step  590, loss = 1.0231, cross_entropy loss = 1.0231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:04.941314 #train# step  591, loss = 0.9996, cross_entropy loss = 0.9996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:06.502873 #train# step  592, loss = 1.0040, cross_entropy loss = 1.0040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:08.085573 #train# step  593, loss = 1.0110, cross_entropy loss = 1.0110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:09.641201 #train# step  594, loss = 1.0132, cross_entropy loss = 1.0132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:11.220062 #train# step  595, loss = 1.0101, cross_entropy loss = 1.0101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:12.782578 #train# step  596, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:14.360718 #train# step  597, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:15.922519 #train# step  598, loss = 1.0087, cross_entropy loss = 1.0087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:17.479850 #train# step  599, loss = 1.0008, cross_entropy loss = 1.0008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:19.003791 #train# step  600, loss = 1.0153, cross_entropy loss = 1.0153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:20.588046 #train# step  601, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:22.140403 #train# step  602, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:23.694722 #train# step  603, loss = 1.0109, cross_entropy loss = 1.0109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:25.243401 #train# step  604, loss = 1.0132, cross_entropy loss = 1.0132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:26.831719 #train# step  605, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:28.414123 #train# step  606, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:29.984393 #train# step  607, loss = 0.9985, cross_entropy loss = 0.9985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:31.538764 #train# step  608, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:33.093099 #train# step  609, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:34.695363 #train# step  610, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:36.284240 #train# step  611, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:37.817283 #train# step  612, loss = 1.0048, cross_entropy loss = 1.0048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:39.405137 #train# step  613, loss = 0.9978, cross_entropy loss = 0.9978, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:40.989600 #train# step  614, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:42.555273 #train# step  615, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:44.108865 #train# step  616, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:45.676073 #train# step  617, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:47.239709 #train# step  618, loss = 1.0062, cross_entropy loss = 1.0062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:48.816981 #train# step  619, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:50.364268 #train# step  620, loss = 0.9993, cross_entropy loss = 0.9993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:51.935804 #train# step  621, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:53.510075 #train# step  622, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:55.081647 #train# step  623, loss = 1.0053, cross_entropy loss = 1.0053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:56.645144 #train# step  624, loss = 1.0036, cross_entropy loss = 1.0036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:58.201203 #train# step  625, loss = 1.0088, cross_entropy loss = 1.0088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:55:59.780293 #train# step  626, loss = 1.0052, cross_entropy loss = 1.0052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:01.303530 #train# step  627, loss = 1.0069, cross_entropy loss = 1.0069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:02.869473 #train# step  628, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:04.426174 #train# step  629, loss = 1.0179, cross_entropy loss = 1.0179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:05.999532 #train# step  630, loss = 1.0106, cross_entropy loss = 1.0106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:07.617350 #train# step  631, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:09.193764 #train# step  632, loss = 0.9923, cross_entropy loss = 0.9923, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:10.769718 #train# step  633, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:12.323581 #train# step  634, loss = 1.0100, cross_entropy loss = 1.0100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:13.900536 #train# step  635, loss = 1.0075, cross_entropy loss = 1.0075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:15.472728 #train# step  636, loss = 1.0063, cross_entropy loss = 1.0063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:17.025317 #train# step  637, loss = 1.0064, cross_entropy loss = 1.0064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:18.643270 #train# step  638, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:20.245150 #train# step  639, loss = 1.0005, cross_entropy loss = 1.0005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:21.808298 #train# step  640, loss = 1.0021, cross_entropy loss = 1.0021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:23.385843 #train# step  641, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:24.948069 #train# step  642, loss = 0.9903, cross_entropy loss = 0.9903, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:26.540215 #train# step  643, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:28.110623 #train# step  644, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:29.675902 #train# step  645, loss = 1.0024, cross_entropy loss = 1.0024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:31.237459 #train# step  646, loss = 1.0090, cross_entropy loss = 1.0090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:32.827363 #train# step  647, loss = 1.0143, cross_entropy loss = 1.0143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:34.382513 #train# step  648, loss = 1.0061, cross_entropy loss = 1.0061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:35.927669 #train# step  649, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:37.497714 #train# step  650, loss = 1.0025, cross_entropy loss = 1.0025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:39.073283 #train# step  651, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:40.626211 #train# step  652, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:42.155998 #train# step  653, loss = 1.0106, cross_entropy loss = 1.0106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:43.726475 #train# step  654, loss = 0.9977, cross_entropy loss = 0.9977, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:45.326844 #train# step  655, loss = 0.9935, cross_entropy loss = 0.9935, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:46.904015 #train# step  656, loss = 0.9978, cross_entropy loss = 0.9978, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:48.459175 #train# step  657, loss = 1.0131, cross_entropy loss = 1.0131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:50.042167 #train# step  658, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:51.606127 #train# step  659, loss = 0.9998, cross_entropy loss = 0.9998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:53.166701 #train# step  660, loss = 1.0082, cross_entropy loss = 1.0082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:54.752210 #train# step  661, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:56.359158 #train# step  662, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:57.947937 #train# step  663, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:56:59.525479 #train# step  664, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:01.061607 #train# step  665, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:02.629719 #train# step  666, loss = 1.0104, cross_entropy loss = 1.0104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:04.180026 #train# step  667, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:05.717175 #train# step  668, loss = 1.0074, cross_entropy loss = 1.0074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:07.252435 #train# step  669, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:08.810722 #train# step  670, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:10.392622 #train# step  671, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:12.000712 #train# step  672, loss = 1.0050, cross_entropy loss = 1.0050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:13.540034 #train# step  673, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:15.111819 #train# step  674, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:16.684594 #train# step  675, loss = 1.0105, cross_entropy loss = 1.0105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:18.271602 #train# step  676, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:19.854826 #train# step  677, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:21.428542 #train# step  678, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:22.978719 #train# step  679, loss = 1.0075, cross_entropy loss = 1.0075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:24.563104 #train# step  680, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:26.159233 #train# step  681, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:27.730266 #train# step  682, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:29.329833 #train# step  683, loss = 0.9990, cross_entropy loss = 0.9990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:30.909552 #train# step  684, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:32.451240 #train# step  685, loss = 1.0130, cross_entropy loss = 1.0130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:34.033619 #train# step  686, loss = 1.0003, cross_entropy loss = 1.0003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:35.621825 #train# step  687, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:37.162838 #train# step  688, loss = 0.9913, cross_entropy loss = 0.9913, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:38.712658 #train# step  689, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:40.278629 #train# step  690, loss = 1.0151, cross_entropy loss = 1.0151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:41.862556 #train# step  691, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:43.425867 #train# step  692, loss = 1.0078, cross_entropy loss = 1.0078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:44.986540 #train# step  693, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:46.568118 #train# step  694, loss = 1.0062, cross_entropy loss = 1.0062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:48.138880 #train# step  695, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:49.704761 #train# step  696, loss = 0.9942, cross_entropy loss = 0.9942, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:51.285758 #train# step  697, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:52.843584 #train# step  698, loss = 1.0016, cross_entropy loss = 1.0016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:54.391934 #train# step  699, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:55.947905 #train# step  700, loss = 1.0048, cross_entropy loss = 1.0048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:57.513640 #train# step  701, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:57:59.094043 #train# step  702, loss = 1.0078, cross_entropy loss = 1.0078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:00.667789 #train# step  703, loss = 1.0193, cross_entropy loss = 1.0193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:02.237882 #train# step  704, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:03.797652 #train# step  705, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:05.343912 #train# step  706, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:06.945781 #train# step  707, loss = 0.9967, cross_entropy loss = 0.9967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:08.544762 #train# step  708, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:10.137512 #train# step  709, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:11.698833 #train# step  710, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:13.273311 #train# step  711, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:14.832537 #train# step  712, loss = 1.0116, cross_entropy loss = 1.0116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:16.389030 #train# step  713, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:17.969106 #train# step  714, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:19.552395 #train# step  715, loss = 0.9931, cross_entropy loss = 0.9931, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:21.133710 #train# step  716, loss = 0.9992, cross_entropy loss = 0.9992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:22.724361 #train# step  717, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:24.284181 #train# step  718, loss = 1.0200, cross_entropy loss = 1.0200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:25.853041 #train# step  719, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:27.426296 #train# step  720, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:28.979024 #train# step  721, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:30.537490 #train# step  722, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:32.108523 #train# step  723, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:33.639328 #train# step  724, loss = 1.0118, cross_entropy loss = 1.0118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:35.237203 #train# step  725, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:36.831694 #train# step  726, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:38.368906 #train# step  727, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:39.955850 #train# step  728, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:41.546627 #train# step  729, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:43.112859 #train# step  730, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:44.735927 #train# step  731, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:46.287344 #train# step  732, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:47.855189 #train# step  733, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:49.410747 #train# step  734, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:50.989623 #train# step  735, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:52.550314 #train# step  736, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:54.142298 #train# step  737, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:55.663540 #train# step  738, loss = 1.0137, cross_entropy loss = 1.0137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:57.225461 #train# step  739, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:58:58.777349 #train# step  740, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:00.304824 #train# step  741, loss = 1.0047, cross_entropy loss = 1.0047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:01.875909 #train# step  742, loss = 0.9911, cross_entropy loss = 0.9911, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:03.468977 #train# step  743, loss = 1.0033, cross_entropy loss = 1.0033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:05.007764 #train# step  744, loss = 1.0013, cross_entropy loss = 1.0013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:06.568965 #train# step  745, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:08.178409 #train# step  746, loss = 0.9925, cross_entropy loss = 0.9925, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:09.761644 #train# step  747, loss = 1.0062, cross_entropy loss = 1.0062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:11.313714 #train# step  748, loss = 0.9999, cross_entropy loss = 0.9999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:12.872360 #train# step  749, loss = 1.0195, cross_entropy loss = 1.0195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:14.467746 #train# step  750, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:16.047857 #train# step  751, loss = 1.0081, cross_entropy loss = 1.0081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:17.595630 #train# step  752, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:19.143943 #train# step  753, loss = 0.9969, cross_entropy loss = 0.9969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:20.704673 #train# step  754, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:22.280552 #train# step  755, loss = 1.0176, cross_entropy loss = 1.0176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:23.843893 #train# step  756, loss = 0.9990, cross_entropy loss = 0.9990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:25.412125 #train# step  757, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:26.974094 #train# step  758, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:28.525278 #train# step  759, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:30.117678 #train# step  760, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:31.693596 #train# step  761, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:33.278622 #train# step  762, loss = 0.9998, cross_entropy loss = 0.9998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:34.821134 #train# step  763, loss = 1.0008, cross_entropy loss = 1.0008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:36.411822 #train# step  764, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:37.973880 #train# step  765, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:39.524251 #train# step  766, loss = 0.9966, cross_entropy loss = 0.9966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:41.107291 #train# step  767, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:42.655747 #train# step  768, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:44.239379 #train# step  769, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:45.804608 #train# step  770, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:47.354679 #train# step  771, loss = 1.0013, cross_entropy loss = 1.0013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:48.934658 #train# step  772, loss = 0.9895, cross_entropy loss = 0.9895, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:50.493423 #train# step  773, loss = 0.9894, cross_entropy loss = 0.9894, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:52.102526 #train# step  774, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:53.671963 #train# step  775, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:55.254134 #train# step  776, loss = 0.9916, cross_entropy loss = 0.9916, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:56.837725 #train# step  777, loss = 0.9929, cross_entropy loss = 0.9929, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:58.433694 #train# step  778, loss = 1.0040, cross_entropy loss = 1.0040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 13:59:59.998251 #train# step  779, loss = 0.9916, cross_entropy loss = 0.9916, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:01.609054 #train# step  780, loss = 0.9928, cross_entropy loss = 0.9928, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:03.154086 #train# step  781, loss = 1.0057, cross_entropy loss = 1.0057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:04.714868 #train# step  782, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:06.300100 #train# step  783, loss = 0.9927, cross_entropy loss = 0.9927, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:07.870926 #train# step  784, loss = 0.9865, cross_entropy loss = 0.9865, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:09.440100 #train# step  785, loss = 0.9890, cross_entropy loss = 0.9890, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:11.008265 #train# step  786, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:12.566244 #train# step  787, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:14.148421 #train# step  788, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:15.734476 #train# step  789, loss = 0.9869, cross_entropy loss = 0.9869, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:17.299287 #train# step  790, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:18.828711 #train# step  791, loss = 0.9897, cross_entropy loss = 0.9897, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:20.420338 #train# step  792, loss = 0.9937, cross_entropy loss = 0.9937, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:21.987236 #train# step  793, loss = 0.9916, cross_entropy loss = 0.9916, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:23.570629 #train# step  794, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:25.111957 #train# step  795, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:26.683993 #train# step  796, loss = 0.9961, cross_entropy loss = 0.9961, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:28.248977 #train# step  797, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:29.816016 #train# step  798, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:31.389716 #train# step  799, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:32.947279 #train# step  800, loss = 0.9909, cross_entropy loss = 0.9909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:34.507099 #train# step  801, loss = 0.9911, cross_entropy loss = 0.9911, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:36.085492 #train# step  802, loss = 0.9874, cross_entropy loss = 0.9874, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:37.632236 #train# step  803, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:39.180836 #train# step  804, loss = 0.9934, cross_entropy loss = 0.9934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:40.783286 #train# step  805, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:42.387597 #train# step  806, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:43.980870 #train# step  807, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:45.565110 #train# step  808, loss = 0.9998, cross_entropy loss = 0.9998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:47.212350 #train# step  809, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:48.769548 #train# step  810, loss = 1.0020, cross_entropy loss = 1.0020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:50.350205 #train# step  811, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:51.927339 #train# step  812, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:53.524197 #train# step  813, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:55.060341 #train# step  814, loss = 0.9975, cross_entropy loss = 0.9975, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:56.607219 #train# step  815, loss = 0.9874, cross_entropy loss = 0.9874, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:58.164648 #train# step  816, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:00:59.729786 #train# step  817, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:01.306994 #train# step  818, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:02.858408 #train# step  819, loss = 0.9934, cross_entropy loss = 0.9934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:04.432329 #train# step  820, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:06.005170 #train# step  821, loss = 0.9918, cross_entropy loss = 0.9918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:07.550249 #train# step  822, loss = 0.9987, cross_entropy loss = 0.9987, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:09.132712 #train# step  823, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:10.660242 #train# step  824, loss = 1.0022, cross_entropy loss = 1.0022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:12.189981 #train# step  825, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:13.757766 #train# step  826, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:15.313792 #train# step  827, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:16.867254 #train# step  828, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:18.414793 #train# step  829, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:20.015591 #train# step  830, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:21.580223 #train# step  831, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:23.139505 #train# step  832, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:24.710950 #train# step  833, loss = 0.9931, cross_entropy loss = 0.9931, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:26.274711 #train# step  834, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:27.834704 #train# step  835, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:29.399014 #train# step  836, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:30.949835 #train# step  837, loss = 1.0041, cross_entropy loss = 1.0041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:32.506568 #train# step  838, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:34.099176 #train# step  839, loss = 0.9885, cross_entropy loss = 0.9885, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:35.656553 #train# step  840, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:37.240667 #train# step  841, loss = 0.9996, cross_entropy loss = 0.9996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:38.802491 #train# step  842, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:40.346899 #train# step  843, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:41.928051 #train# step  844, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:43.522109 #train# step  845, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:45.121645 #train# step  846, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:46.676107 #train# step  847, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:48.232158 #train# step  848, loss = 0.9848, cross_entropy loss = 0.9848, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:49.808760 #train# step  849, loss = 1.0039, cross_entropy loss = 1.0039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:51.340650 #train# step  850, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:52.908930 #train# step  851, loss = 1.0035, cross_entropy loss = 1.0035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:54.491327 #train# step  852, loss = 0.9988, cross_entropy loss = 0.9988, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:56.029137 #train# step  853, loss = 1.0000, cross_entropy loss = 1.0000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:57.604149 #train# step  854, loss = 0.9909, cross_entropy loss = 0.9909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:01:59.158511 #train# step  855, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:00.733587 #train# step  856, loss = 1.0067, cross_entropy loss = 1.0067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:02.348828 #train# step  857, loss = 0.9777, cross_entropy loss = 0.9777, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:03.931286 #train# step  858, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:05.474791 #train# step  859, loss = 0.9966, cross_entropy loss = 0.9966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:07.027797 #train# step  860, loss = 1.0019, cross_entropy loss = 1.0019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:08.590761 #train# step  861, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:10.169372 #train# step  862, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:11.730598 #train# step  863, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:13.309999 #train# step  864, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:14.867572 #train# step  865, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:16.467494 #train# step  866, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:18.027362 #train# step  867, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:19.561525 #train# step  868, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:21.104691 #train# step  869, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:22.679000 #train# step  870, loss = 0.9914, cross_entropy loss = 0.9914, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:24.255083 #train# step  871, loss = 1.0079, cross_entropy loss = 1.0079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:25.819141 #train# step  872, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:27.411679 #train# step  873, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:28.984160 #train# step  874, loss = 0.9885, cross_entropy loss = 0.9885, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:30.574667 #train# step  875, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:32.178832 #train# step  876, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:33.785565 #train# step  877, loss = 1.0005, cross_entropy loss = 1.0005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:35.341340 #train# step  878, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:36.896572 #train# step  879, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:38.448473 #train# step  880, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:40.065241 #train# step  881, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:41.629646 #train# step  882, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:43.194845 #train# step  883, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:44.748970 #train# step  884, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:46.305603 #train# step  885, loss = 0.9890, cross_entropy loss = 0.9890, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:47.861426 #train# step  886, loss = 0.9935, cross_entropy loss = 0.9935, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:49.469025 #train# step  887, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:51.056651 #train# step  888, loss = 0.9848, cross_entropy loss = 0.9848, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:52.590382 #train# step  889, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:54.167706 #train# step  890, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:55.731635 #train# step  891, loss = 0.9911, cross_entropy loss = 0.9911, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:57.304695 #train# step  892, loss = 0.9869, cross_entropy loss = 0.9869, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:02:58.881646 #train# step  893, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:00.492949 #train# step  894, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:02.090940 #train# step  895, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:03.664520 #train# step  896, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:05.241102 #train# step  897, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:06.812409 #train# step  898, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:08.383595 #train# step  899, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:09.953001 #train# step  900, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:11.521448 #train# step  901, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:13.075136 #train# step  902, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:14.704272 #train# step  903, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:16.270982 #train# step  904, loss = 0.9861, cross_entropy loss = 0.9861, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:17.857596 #train# step  905, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:19.463809 #train# step  906, loss = 0.9911, cross_entropy loss = 0.9911, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:21.056027 #train# step  907, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:22.619926 #train# step  908, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:24.162952 #train# step  909, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:25.745229 #train# step  910, loss = 1.0092, cross_entropy loss = 1.0092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:27.335344 #train# step  911, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:28.930860 #train# step  912, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:30.483578 #train# step  913, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:32.050100 #train# step  914, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:33.588390 #train# step  915, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:35.150509 #train# step  916, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:36.697108 #train# step  917, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:38.248345 #train# step  918, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:39.824145 #train# step  919, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:41.384298 #train# step  920, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:42.956088 #train# step  921, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:44.535012 #train# step  922, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:46.092874 #train# step  923, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:47.652816 #train# step  924, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:49.191570 #train# step  925, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:50.768270 #train# step  926, loss = 0.9918, cross_entropy loss = 0.9918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:52.324714 #train# step  927, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:53.859583 #train# step  928, loss = 0.9795, cross_entropy loss = 0.9795, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:55.399164 #train# step  929, loss = 0.9909, cross_entropy loss = 0.9909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:56.988549 #train# step  930, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:03:58.558760 #train# step  931, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:00.149751 #train# step  932, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:01.707591 #train# step  933, loss = 1.0143, cross_entropy loss = 1.0143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:03.288312 #train# step  934, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:04.836329 #train# step  935, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:06.389362 #train# step  936, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:07.944151 #train# step  937, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:09.501133 #train# step  938, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:11.056400 #train# step  939, loss = 1.0035, cross_entropy loss = 1.0035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:12.634424 #train# step  940, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:14.212375 #train# step  941, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:15.787160 #train# step  942, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:17.383311 #train# step  943, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:18.938942 #train# step  944, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:20.493203 #train# step  945, loss = 0.9961, cross_entropy loss = 0.9961, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:22.073209 #train# step  946, loss = 0.9924, cross_entropy loss = 0.9924, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:23.660514 #train# step  947, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:25.232988 #train# step  948, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:26.802851 #train# step  949, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:28.358220 #train# step  950, loss = 0.9859, cross_entropy loss = 0.9859, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:29.926867 #train# step  951, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:31.486589 #train# step  952, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:33.051782 #train# step  953, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:34.640992 #train# step  954, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:36.217702 #train# step  955, loss = 1.0054, cross_entropy loss = 1.0054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:37.796818 #train# step  956, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:39.379342 #train# step  957, loss = 0.9945, cross_entropy loss = 0.9945, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:40.925781 #train# step  958, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:42.492478 #train# step  959, loss = 1.0067, cross_entropy loss = 1.0067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:44.076159 #train# step  960, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:45.608754 #train# step  961, loss = 0.9957, cross_entropy loss = 0.9957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:47.170646 #train# step  962, loss = 1.0201, cross_entropy loss = 1.0201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:48.737729 #train# step  963, loss = 1.0156, cross_entropy loss = 1.0156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:50.317446 #train# step  964, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:51.903569 #train# step  965, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:53.443745 #train# step  966, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:55.014805 #train# step  967, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:56.590255 #train# step  968, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:58.190630 #train# step  969, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:04:59.749799 #train# step  970, loss = 0.9927, cross_entropy loss = 0.9927, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:01.308917 #train# step  971, loss = 0.9933, cross_entropy loss = 0.9933, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:02.880630 #train# step  972, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:04.452684 #train# step  973, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:06.055458 #train# step  974, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:07.630630 #train# step  975, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:09.220101 #train# step  976, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:10.770186 #train# step  977, loss = 0.9797, cross_entropy loss = 0.9797, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:12.322441 #train# step  978, loss = 0.9967, cross_entropy loss = 0.9967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:13.903389 #train# step  979, loss = 0.9748, cross_entropy loss = 0.9748, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:15.456320 #train# step  980, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:17.017093 #train# step  981, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:18.562616 #train# step  982, loss = 0.9993, cross_entropy loss = 0.9993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:20.132468 #train# step  983, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:21.708014 #train# step  984, loss = 0.9928, cross_entropy loss = 0.9928, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:23.286207 #train# step  985, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:24.857997 #train# step  986, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:26.443280 #train# step  987, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:28.016388 #train# step  988, loss = 0.9827, cross_entropy loss = 0.9827, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:29.563167 #train# step  989, loss = 0.9869, cross_entropy loss = 0.9869, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:31.132603 #train# step  990, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:32.691886 #train# step  991, loss = 0.9909, cross_entropy loss = 0.9909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:34.277131 #train# step  992, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:35.880827 #train# step  993, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:37.428081 #train# step  994, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:38.993895 #train# step  995, loss = 0.9919, cross_entropy loss = 0.9919, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:40.585381 #train# step  996, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:42.176582 #train# step  997, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:43.761804 #train# step  998, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:45.353446 #train# step  999, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:46.909534 #train# step 1000, loss = 1.0013, cross_entropy loss = 1.0013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:48.508311 #train# step 1001, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:50.090427 #train# step 1002, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:51.680787 #train# step 1003, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:53.270126 #train# step 1004, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:54.858584 #train# step 1005, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:56.381331 #train# step 1006, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:57.945109 #train# step 1007, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:05:59.520264 #train# step 1008, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:01.052520 #train# step 1009, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:02.629054 #train# step 1010, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:04.199403 #train# step 1011, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:05.782599 #train# step 1012, loss = 0.9813, cross_entropy loss = 0.9813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:07.360928 #train# step 1013, loss = 0.9918, cross_entropy loss = 0.9918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:08.929929 #train# step 1014, loss = 0.9992, cross_entropy loss = 0.9992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:10.517588 #train# step 1015, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:12.093126 #train# step 1016, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:13.689229 #train# step 1017, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:15.266146 #train# step 1018, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:16.834032 #train# step 1019, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:18.380695 #train# step 1020, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:19.928853 #train# step 1021, loss = 0.9934, cross_entropy loss = 0.9934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:21.487106 #train# step 1022, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:23.041761 #train# step 1023, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:24.598674 #train# step 1024, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:26.181573 #train# step 1025, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:27.718075 #train# step 1026, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:29.314032 #train# step 1027, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:30.863714 #train# step 1028, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:32.424382 #train# step 1029, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:34.012801 #train# step 1030, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:35.583222 #train# step 1031, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:37.127595 #train# step 1032, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:38.713274 #train# step 1033, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:40.285058 #train# step 1034, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:41.836057 #train# step 1035, loss = 1.0146, cross_entropy loss = 1.0146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:43.403863 #train# step 1036, loss = 1.0009, cross_entropy loss = 1.0009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:44.961139 #train# step 1037, loss = 0.9983, cross_entropy loss = 0.9983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:46.516045 #train# step 1038, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:48.097525 #train# step 1039, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:49.671199 #train# step 1040, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:51.237451 #train# step 1041, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:52.814809 #train# step 1042, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:54.371192 #train# step 1043, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:55.948713 #train# step 1044, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:57.521031 #train# step 1045, loss = 0.9942, cross_entropy loss = 0.9942, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:06:59.114646 #train# step 1046, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:00.693842 #train# step 1047, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:02.250787 #train# step 1048, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:03.837120 #train# step 1049, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:05.411030 #train# step 1050, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:06.994343 #train# step 1051, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:08.560011 #train# step 1052, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:10.125493 #train# step 1053, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:11.704069 #train# step 1054, loss = 0.9869, cross_entropy loss = 0.9869, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:13.265937 #train# step 1055, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:14.858259 #train# step 1056, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:16.447966 #train# step 1057, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:18.018286 #train# step 1058, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:19.552415 #train# step 1059, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:21.088623 #train# step 1060, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:22.653545 #train# step 1061, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:24.210220 #train# step 1062, loss = 0.9913, cross_entropy loss = 0.9913, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:25.784620 #train# step 1063, loss = 0.9817, cross_entropy loss = 0.9817, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:27.374673 #train# step 1064, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:28.937158 #train# step 1065, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:30.506681 #train# step 1066, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:32.097302 #train# step 1067, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:33.679343 #train# step 1068, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:35.242958 #train# step 1069, loss = 1.0127, cross_entropy loss = 1.0127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:36.773316 #train# step 1070, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:38.369390 #train# step 1071, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:39.940977 #train# step 1072, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:41.544754 #train# step 1073, loss = 0.9824, cross_entropy loss = 0.9824, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:43.141910 #train# step 1074, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:44.712456 #train# step 1075, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:46.251058 #train# step 1076, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:47.827425 #train# step 1077, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:49.385939 #train# step 1078, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:50.984536 #train# step 1079, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:52.585458 #train# step 1080, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:54.119107 #train# step 1081, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:55.690707 #train# step 1082, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:57.271218 #train# step 1083, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:07:58.838623 #train# step 1084, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:00.400446 #train# step 1085, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:01.927557 #train# step 1086, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:03.489559 #train# step 1087, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:05.052217 #train# step 1088, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:06.629878 #train# step 1089, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:08.192271 #train# step 1090, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:09.770554 #train# step 1091, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:11.340185 #train# step 1092, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:12.914176 #train# step 1093, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:14.464864 #train# step 1094, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:16.057904 #train# step 1095, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:17.603955 #train# step 1096, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:19.183808 #train# step 1097, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:20.747378 #train# step 1098, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:22.336802 #train# step 1099, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:23.904959 #train# step 1100, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:25.457970 #train# step 1101, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:27.019392 #train# step 1102, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:28.581239 #train# step 1103, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:30.152043 #train# step 1104, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:31.742407 #train# step 1105, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:33.292649 #train# step 1106, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:34.844101 #train# step 1107, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:36.404927 #train# step 1108, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:37.973647 #train# step 1109, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:39.557949 #train# step 1110, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:41.116333 #train# step 1111, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:42.713468 #train# step 1112, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:44.299876 #train# step 1113, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:45.889113 #train# step 1114, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:47.498697 #train# step 1115, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:49.072645 #train# step 1116, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:50.637973 #train# step 1117, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:52.369134 #train# step 1118, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:53.937780 #train# step 1119, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:55.528860 #train# step 1120, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:57.097314 #train# step 1121, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:08:58.654871 #train# step 1122, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:00.273800 #train# step 1123, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:01.844568 #train# step 1124, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:03.392292 #train# step 1125, loss = 1.0057, cross_entropy loss = 1.0057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:04.960342 #train# step 1126, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:06.519218 #train# step 1127, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:08.067668 #train# step 1128, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:09.624940 #train# step 1129, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:11.236208 #train# step 1130, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:12.816478 #train# step 1131, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:14.393932 #train# step 1132, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:15.968189 #train# step 1133, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:17.537196 #train# step 1134, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:19.085841 #train# step 1135, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:20.661774 #train# step 1136, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:22.218594 #train# step 1137, loss = 0.9985, cross_entropy loss = 0.9985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:23.750978 #train# step 1138, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:25.317852 #train# step 1139, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:26.854373 #train# step 1140, loss = 0.9925, cross_entropy loss = 0.9925, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:28.436239 #train# step 1141, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:30.010470 #train# step 1142, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:31.568020 #train# step 1143, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:33.110577 #train# step 1144, loss = 1.0001, cross_entropy loss = 1.0001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:34.665572 #train# step 1145, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:36.252890 #train# step 1146, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:37.821760 #train# step 1147, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:39.413529 #train# step 1148, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:40.979917 #train# step 1149, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:42.544715 #train# step 1150, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:44.120619 #train# step 1151, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:45.702238 #train# step 1152, loss = 0.9966, cross_entropy loss = 0.9966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:47.310097 #train# step 1153, loss = 1.0016, cross_entropy loss = 1.0016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:48.866874 #train# step 1154, loss = 0.9913, cross_entropy loss = 0.9913, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:50.435149 #train# step 1155, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:52.028262 #train# step 1156, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:53.596179 #train# step 1157, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:55.124992 #train# step 1158, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:56.710365 #train# step 1159, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:58.302337 #train# step 1160, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:09:59.863342 #train# step 1161, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:01.446872 #train# step 1162, loss = 0.9942, cross_entropy loss = 0.9942, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:02.995144 #train# step 1163, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:04.600235 #train# step 1164, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:06.186014 #train# step 1165, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:07.752840 #train# step 1166, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:09.314669 #train# step 1167, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:10.873226 #train# step 1168, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:12.426312 #train# step 1169, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:13.998633 #train# step 1170, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:15.568232 #train# step 1171, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:17.144154 #train# step 1172, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:18.717338 #train# step 1173, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:20.313731 #train# step 1174, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:21.884872 #train# step 1175, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:23.457205 #train# step 1176, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:25.025451 #train# step 1177, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:26.593942 #train# step 1178, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:28.148683 #train# step 1179, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:29.737213 #train# step 1180, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:31.311245 #train# step 1181, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:32.866356 #train# step 1182, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:34.417078 #train# step 1183, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:35.965010 #train# step 1184, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:37.529228 #train# step 1185, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:39.106213 #train# step 1186, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:40.677117 #train# step 1187, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:42.246569 #train# step 1188, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:43.802300 #train# step 1189, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:45.404546 #train# step 1190, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:47.009644 #train# step 1191, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:48.588623 #train# step 1192, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:50.136270 #train# step 1193, loss = 0.9968, cross_entropy loss = 0.9968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:51.727952 #train# step 1194, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:53.322222 #train# step 1195, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:54.912653 #train# step 1196, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:56.497344 #train# step 1197, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:58.043886 #train# step 1198, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:10:59.588629 #train# step 1199, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:01.179891 #train# step 1200, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:02.751399 #train# step 1201, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:04.320773 #train# step 1202, loss = 0.9796, cross_entropy loss = 0.9796, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:05.895356 #train# step 1203, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:07.451411 #train# step 1204, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:09.033796 #train# step 1205, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:10.603378 #train# step 1206, loss = 0.9752, cross_entropy loss = 0.9752, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:12.184237 #train# step 1207, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:13.722973 #train# step 1208, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:15.264941 #train# step 1209, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:16.828242 #train# step 1210, loss = 0.9875, cross_entropy loss = 0.9875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:18.412655 #train# step 1211, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:20.017982 #train# step 1212, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:21.596086 #train# step 1213, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:23.164743 #train# step 1214, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:24.743816 #train# step 1215, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:26.304885 #train# step 1216, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:27.880810 #train# step 1217, loss = 0.9922, cross_entropy loss = 0.9922, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:29.431778 #train# step 1218, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:30.973146 #train# step 1219, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:32.555066 #train# step 1220, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:34.134648 #train# step 1221, loss = 0.9861, cross_entropy loss = 0.9861, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:35.717707 #train# step 1222, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:37.282240 #train# step 1223, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:38.894068 #train# step 1224, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:40.455866 #train# step 1225, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:42.012147 #train# step 1226, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:43.589788 #train# step 1227, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:45.116732 #train# step 1228, loss = 1.0113, cross_entropy loss = 1.0113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:46.696226 #train# step 1229, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:48.267645 #train# step 1230, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:49.829430 #train# step 1231, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:51.399409 #train# step 1232, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:53.011323 #train# step 1233, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:54.595512 #train# step 1234, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:56.170338 #train# step 1235, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:57.761104 #train# step 1236, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:11:59.315584 #train# step 1237, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:00.850064 #train# step 1238, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:02.401652 #train# step 1239, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:03.954384 #train# step 1240, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:05.518062 #train# step 1241, loss = 0.9827, cross_entropy loss = 0.9827, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:07.111874 #train# step 1242, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:08.739855 #train# step 1243, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:10.283859 #train# step 1244, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:11.871320 #train# step 1245, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:13.424709 #train# step 1246, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:14.989422 #train# step 1247, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:16.572853 #train# step 1248, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:18.145911 #train# step 1249, loss = 1.0005, cross_entropy loss = 1.0005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:19.720046 #train# step 1250, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:21.288850 #train# step 1251, loss = 0.9820, cross_entropy loss = 0.9820, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:22.857639 #train# step 1252, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:24.429547 #train# step 1253, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:26.033548 #train# step 1254, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:27.584138 #train# step 1255, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:29.159898 #train# step 1256, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:30.711664 #train# step 1257, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:32.256999 #train# step 1258, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:33.846883 #train# step 1259, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:35.404447 #train# step 1260, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:36.962924 #train# step 1261, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:38.509539 #train# step 1262, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:40.078998 #train# step 1263, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:41.630565 #train# step 1264, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:43.219735 #train# step 1265, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:44.788643 #train# step 1266, loss = 0.9765, cross_entropy loss = 0.9765, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:46.335820 #train# step 1267, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:47.923921 #train# step 1268, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:49.540646 #train# step 1269, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:51.122134 #train# step 1270, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:52.708047 #train# step 1271, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:54.249819 #train# step 1272, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:55.805750 #train# step 1273, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:57.407600 #train# step 1274, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:12:58.977066 #train# step 1275, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:00.527700 #train# step 1276, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:02.072233 #train# step 1277, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:03.626615 #train# step 1278, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:05.191243 #train# step 1279, loss = 0.9883, cross_entropy loss = 0.9883, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:06.774491 #train# step 1280, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:08.341444 #train# step 1281, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:09.923422 #train# step 1282, loss = 0.9976, cross_entropy loss = 0.9976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:11.504326 #train# step 1283, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:13.083752 #train# step 1284, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:14.642152 #train# step 1285, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:16.229866 #train# step 1286, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:17.823888 #train# step 1287, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:19.406538 #train# step 1288, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:20.981338 #train# step 1289, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:22.537920 #train# step 1290, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:24.120675 #train# step 1291, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:25.687781 #train# step 1292, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:27.237482 #train# step 1293, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:28.778344 #train# step 1294, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:30.377151 #train# step 1295, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:31.992909 #train# step 1296, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:33.537780 #train# step 1297, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:35.111198 #train# step 1298, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:36.689375 #train# step 1299, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:38.225249 #train# step 1300, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:39.790245 #train# step 1301, loss = 0.9833, cross_entropy loss = 0.9833, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:41.383945 #train# step 1302, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:42.943332 #train# step 1303, loss = 0.9845, cross_entropy loss = 0.9845, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:44.498037 #train# step 1304, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:46.081664 #train# step 1305, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:47.644989 #train# step 1306, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:49.202837 #train# step 1307, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:50.785815 #train# step 1308, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:52.380529 #train# step 1309, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:53.939256 #train# step 1310, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:55.485929 #train# step 1311, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:57.057881 #train# step 1312, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:13:58.654379 #train# step 1313, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:00.265322 #train# step 1314, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:01.797344 #train# step 1315, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:03.364172 #train# step 1316, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:04.907102 #train# step 1317, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:06.458600 #train# step 1318, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:08.037016 #train# step 1319, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:09.605840 #train# step 1320, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:11.183048 #train# step 1321, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:12.751917 #train# step 1322, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:14.297060 #train# step 1323, loss = 0.9765, cross_entropy loss = 0.9765, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:15.907726 #train# step 1324, loss = 0.9877, cross_entropy loss = 0.9877, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:17.470563 #train# step 1325, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:19.070209 #train# step 1326, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:20.685684 #train# step 1327, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:22.262837 #train# step 1328, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:23.828853 #train# step 1329, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:25.373924 #train# step 1330, loss = 0.9897, cross_entropy loss = 0.9897, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:26.936294 #train# step 1331, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:28.514684 #train# step 1332, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:30.083934 #train# step 1333, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:31.653724 #train# step 1334, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:33.217745 #train# step 1335, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:34.813150 #train# step 1336, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:36.396067 #train# step 1337, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:37.946518 #train# step 1338, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:39.521667 #train# step 1339, loss = 0.9881, cross_entropy loss = 0.9881, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:41.082266 #train# step 1340, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:42.631470 #train# step 1341, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:44.224663 #train# step 1342, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:45.796534 #train# step 1343, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:47.373552 #train# step 1344, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:48.947283 #train# step 1345, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:50.509263 #train# step 1346, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:52.081364 #train# step 1347, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:53.659368 #train# step 1348, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:55.229394 #train# step 1349, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:56.783899 #train# step 1350, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:58.348061 #train# step 1351, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:14:59.909098 #train# step 1352, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:01.511288 #train# step 1353, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:03.091981 #train# step 1354, loss = 0.9881, cross_entropy loss = 0.9881, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:04.676170 #train# step 1355, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:06.244162 #train# step 1356, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:07.816357 #train# step 1357, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:09.384954 #train# step 1358, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:10.969810 #train# step 1359, loss = 1.0055, cross_entropy loss = 1.0055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:12.526683 #train# step 1360, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:14.080316 #train# step 1361, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:15.624239 #train# step 1362, loss = 0.9796, cross_entropy loss = 0.9796, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:17.209868 #train# step 1363, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:18.804472 #train# step 1364, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:20.418741 #train# step 1365, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:22.017415 #train# step 1366, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:23.604718 #train# step 1367, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:25.187744 #train# step 1368, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:26.765577 #train# step 1369, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:28.338905 #train# step 1370, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:29.886312 #train# step 1371, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:31.469684 #train# step 1372, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:33.061575 #train# step 1373, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:34.626154 #train# step 1374, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:36.170234 #train# step 1375, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:37.736489 #train# step 1376, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:39.331705 #train# step 1377, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:40.895156 #train# step 1378, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:42.457573 #train# step 1379, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:43.989639 #train# step 1380, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:45.565732 #train# step 1381, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:47.120255 #train# step 1382, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:48.678610 #train# step 1383, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:50.240671 #train# step 1384, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:51.816692 #train# step 1385, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:53.406214 #train# step 1386, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:54.950455 #train# step 1387, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:56.507658 #train# step 1388, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:58.104369 #train# step 1389, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:15:59.681091 #train# step 1390, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:01.252352 #train# step 1391, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:02.808273 #train# step 1392, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:04.378438 #train# step 1393, loss = 0.9813, cross_entropy loss = 0.9813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:05.985435 #train# step 1394, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:07.558220 #train# step 1395, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:09.110685 #train# step 1396, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:10.670077 #train# step 1397, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:12.236348 #train# step 1398, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:13.785121 #train# step 1399, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:15.341634 #train# step 1400, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:16.922451 #train# step 1401, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:18.492637 #train# step 1402, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:20.062197 #train# step 1403, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:21.593845 #train# step 1404, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:23.135367 #train# step 1405, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:24.717090 #train# step 1406, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:26.286390 #train# step 1407, loss = 0.9748, cross_entropy loss = 0.9748, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:27.870196 #train# step 1408, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:29.438661 #train# step 1409, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:31.031033 #train# step 1410, loss = 0.9845, cross_entropy loss = 0.9845, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:32.647084 #train# step 1411, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:34.245959 #train# step 1412, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:35.824811 #train# step 1413, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:37.408834 #train# step 1414, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:38.964814 #train# step 1415, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:40.555362 #train# step 1416, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:42.149607 #train# step 1417, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:43.704117 #train# step 1418, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:45.270296 #train# step 1419, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:46.833682 #train# step 1420, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:48.399942 #train# step 1421, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:49.978164 #train# step 1422, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:51.535760 #train# step 1423, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:53.115345 #train# step 1424, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:54.688410 #train# step 1425, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:56.288873 #train# step 1426, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:57.839629 #train# step 1427, loss = 0.9813, cross_entropy loss = 0.9813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:16:59.410998 #train# step 1428, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:00.966501 #train# step 1429, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:02.549524 #train# step 1430, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:04.116047 #train# step 1431, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:05.676603 #train# step 1432, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:07.254967 #train# step 1433, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:08.849552 #train# step 1434, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:10.449996 #train# step 1435, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:12.008260 #train# step 1436, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:13.576469 #train# step 1437, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:15.138556 #train# step 1438, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:16.700856 #train# step 1439, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:18.269651 #train# step 1440, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:19.843012 #train# step 1441, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:21.418748 #train# step 1442, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:22.998848 #train# step 1443, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:24.596389 #train# step 1444, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:26.184547 #train# step 1445, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:27.725012 #train# step 1446, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:29.271538 #train# step 1447, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:30.840086 #train# step 1448, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:32.389769 #train# step 1449, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:33.943407 #train# step 1450, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:35.511544 #train# step 1451, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:37.091778 #train# step 1452, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:38.655135 #train# step 1453, loss = 0.9777, cross_entropy loss = 0.9777, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:40.207727 #train# step 1454, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:41.775753 #train# step 1455, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:43.330333 #train# step 1456, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:44.904130 #train# step 1457, loss = 0.9795, cross_entropy loss = 0.9795, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:46.475652 #train# step 1458, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:48.048337 #train# step 1459, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:49.606231 #train# step 1460, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:51.192212 #train# step 1461, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:52.765270 #train# step 1462, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:54.320131 #train# step 1463, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:55.889333 #train# step 1464, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:57.435636 #train# step 1465, loss = 0.9795, cross_entropy loss = 0.9795, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:17:59.002868 #train# step 1466, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:00.602581 #train# step 1467, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:02.187848 #train# step 1468, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:03.784397 #train# step 1469, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:05.366466 #train# step 1470, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:06.941187 #train# step 1471, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:08.513572 #train# step 1472, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:10.112413 #train# step 1473, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:11.697926 #train# step 1474, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:13.246753 #train# step 1475, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:14.818620 #train# step 1476, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:16.390406 #train# step 1477, loss = 0.9885, cross_entropy loss = 0.9885, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:17.942194 #train# step 1478, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:19.515942 #train# step 1479, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:21.108563 #train# step 1480, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:22.678173 #train# step 1481, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:24.234696 #train# step 1482, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:25.792661 #train# step 1483, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:27.359754 #train# step 1484, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:28.920895 #train# step 1485, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:30.493547 #train# step 1486, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:32.089450 #train# step 1487, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:33.669755 #train# step 1488, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:35.228463 #train# step 1489, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:36.808175 #train# step 1490, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:38.389298 #train# step 1491, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:39.972245 #train# step 1492, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:41.551838 #train# step 1493, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:43.103697 #train# step 1494, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:44.669885 #train# step 1495, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:46.218632 #train# step 1496, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:47.791629 #train# step 1497, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:49.372498 #train# step 1498, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:50.927321 #train# step 1499, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:52.461617 #train# step 1500, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:54.006737 #train# step 1501, loss = 0.9916, cross_entropy loss = 0.9916, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:55.562962 #train# step 1502, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:57.125601 #train# step 1503, loss = 0.9796, cross_entropy loss = 0.9796, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:18:58.698355 #train# step 1504, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:00.240108 #train# step 1505, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:01.810371 #train# step 1506, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:03.390470 #train# step 1507, loss = 0.9827, cross_entropy loss = 0.9827, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:04.930111 #train# step 1508, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:06.512652 #train# step 1509, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:08.042256 #train# step 1510, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:09.648912 #train# step 1511, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:11.239903 #train# step 1512, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:12.780149 #train# step 1513, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:14.359555 #train# step 1514, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:15.955487 #train# step 1515, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:17.499827 #train# step 1516, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:19.096701 #train# step 1517, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:20.661728 #train# step 1518, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:22.229857 #train# step 1519, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:23.780958 #train# step 1520, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:25.353501 #train# step 1521, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:26.920986 #train# step 1522, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:28.490080 #train# step 1523, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:30.051067 #train# step 1524, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:31.662666 #train# step 1525, loss = 0.9833, cross_entropy loss = 0.9833, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:33.218299 #train# step 1526, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:34.783923 #train# step 1527, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:36.368840 #train# step 1528, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:37.951375 #train# step 1529, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:39.519302 #train# step 1530, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:41.109183 #train# step 1531, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:42.699914 #train# step 1532, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:44.288418 #train# step 1533, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:45.877827 #train# step 1534, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:47.455534 #train# step 1535, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:49.056249 #train# step 1536, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:50.603059 #train# step 1537, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:52.172344 #train# step 1538, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:53.766989 #train# step 1539, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:55.335618 #train# step 1540, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:56.918638 #train# step 1541, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:19:58.463596 #train# step 1542, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:00.034920 #train# step 1543, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:01.602112 #train# step 1544, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:03.172245 #train# step 1545, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:04.757760 #train# step 1546, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:06.324705 #train# step 1547, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:07.907713 #train# step 1548, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:09.474123 #train# step 1549, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:11.036671 #train# step 1550, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:12.582671 #train# step 1551, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:14.151688 #train# step 1552, loss = 0.9752, cross_entropy loss = 0.9752, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:15.726445 #train# step 1553, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:17.277987 #train# step 1554, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:18.876891 #train# step 1555, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:20.437847 #train# step 1556, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:21.998287 #train# step 1557, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:23.586157 #train# step 1558, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:25.140254 #train# step 1559, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:26.695211 #train# step 1560, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:28.274389 #train# step 1561, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:29.855931 #train# step 1562, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:31.452861 #train# step 1563, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:33.014561 #train# step 1564, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:34.597958 #train# step 1565, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:36.154971 #train# step 1566, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:37.753943 #train# step 1567, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:39.313461 #train# step 1568, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:40.904828 #train# step 1569, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:42.456619 #train# step 1570, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:44.032783 #train# step 1571, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:45.584181 #train# step 1572, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:47.129905 #train# step 1573, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:48.704025 #train# step 1574, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:50.283921 #train# step 1575, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:51.855943 #train# step 1576, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:53.432013 #train# step 1577, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:54.996759 #train# step 1578, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:56.558122 #train# step 1579, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:58.144584 #train# step 1580, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:20:59.703558 #train# step 1581, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:01.245322 #train# step 1582, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:02.780220 #train# step 1583, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:04.393195 #train# step 1584, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:05.975736 #train# step 1585, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:07.520103 #train# step 1586, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:09.113757 #train# step 1587, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:10.686699 #train# step 1588, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:12.285660 #train# step 1589, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:13.836148 #train# step 1590, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:15.434692 #train# step 1591, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:17.038536 #train# step 1592, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:18.576543 #train# step 1593, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:20.150590 #train# step 1594, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:21.733544 #train# step 1595, loss = 0.9775, cross_entropy loss = 0.9775, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:23.299221 #train# step 1596, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:24.896371 #train# step 1597, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:26.452635 #train# step 1598, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:28.012680 #train# step 1599, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:29.593846 #train# step 1600, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:31.165833 #train# step 1601, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:32.737272 #train# step 1602, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:34.286164 #train# step 1603, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:35.870358 #train# step 1604, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:37.416441 #train# step 1605, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:38.983342 #train# step 1606, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:40.565913 #train# step 1607, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:42.145081 #train# step 1608, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:43.701749 #train# step 1609, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:45.245115 #train# step 1610, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:46.807446 #train# step 1611, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:48.392564 #train# step 1612, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:49.991304 #train# step 1613, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:51.568638 #train# step 1614, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:53.134580 #train# step 1615, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:54.689764 #train# step 1616, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:56.279244 #train# step 1617, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:57.804238 #train# step 1618, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:21:59.381164 #train# step 1619, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:00.948538 #train# step 1620, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:02.513441 #train# step 1621, loss = 0.9742, cross_entropy loss = 0.9742, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:04.085811 #train# step 1622, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:05.657061 #train# step 1623, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:07.246990 #train# step 1624, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:08.784737 #train# step 1625, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:10.362248 #train# step 1626, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:11.938781 #train# step 1627, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:13.519458 #train# step 1628, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:15.090630 #train# step 1629, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:16.642111 #train# step 1630, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:18.200093 #train# step 1631, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:19.766423 #train# step 1632, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:21.354254 #train# step 1633, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:22.932534 #train# step 1634, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:24.503330 #train# step 1635, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:26.102994 #train# step 1636, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:27.688643 #train# step 1637, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:29.243465 #train# step 1638, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:30.809668 #train# step 1639, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:32.389181 #train# step 1640, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:33.963492 #train# step 1641, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:35.553210 #train# step 1642, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:37.133253 #train# step 1643, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:38.719175 #train# step 1644, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:40.303114 #train# step 1645, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:41.821731 #train# step 1646, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:43.387791 #train# step 1647, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:44.973052 #train# step 1648, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:46.529007 #train# step 1649, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:48.085094 #train# step 1650, loss = 0.9660, cross_entropy loss = 0.9660, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:49.658010 #train# step 1651, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:51.222754 #train# step 1652, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:52.788177 #train# step 1653, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:54.354863 #train# step 1654, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:55.937783 #train# step 1655, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:57.513394 #train# step 1656, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:22:59.110048 #train# step 1657, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:00.671124 #train# step 1658, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:02.252487 #train# step 1659, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:03.825603 #train# step 1660, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:05.408765 #train# step 1661, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:06.962220 #train# step 1662, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:08.532485 #train# step 1663, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:10.109228 #train# step 1664, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:11.637414 #train# step 1665, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:13.209294 #train# step 1666, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:14.760832 #train# step 1667, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:16.353170 #train# step 1668, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:17.932115 #train# step 1669, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:19.549569 #train# step 1670, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:21.123329 #train# step 1671, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:22.676481 #train# step 1672, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:24.265791 #train# step 1673, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:25.806384 #train# step 1674, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:27.354176 #train# step 1675, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:28.897929 #train# step 1676, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:30.453626 #train# step 1677, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:32.033083 #train# step 1678, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:33.586745 #train# step 1679, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:35.175664 #train# step 1680, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:36.759926 #train# step 1681, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:38.337633 #train# step 1682, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:39.887532 #train# step 1683, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:41.438727 #train# step 1684, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:43.003690 #train# step 1685, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:44.577895 #train# step 1686, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:46.153611 #train# step 1687, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:47.730936 #train# step 1688, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:49.330429 #train# step 1689, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:50.933259 #train# step 1690, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:52.520882 #train# step 1691, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:54.124725 #train# step 1692, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:55.697391 #train# step 1693, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:57.268664 #train# step 1694, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:23:58.839894 #train# step 1695, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:00.383550 #train# step 1696, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:01.921376 #train# step 1697, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:03.495743 #train# step 1698, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:05.053736 #train# step 1699, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:06.631638 #train# step 1700, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:08.184765 #train# step 1701, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:09.759960 #train# step 1702, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:11.346111 #train# step 1703, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:12.907577 #train# step 1704, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:14.484332 #train# step 1705, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:16.073341 #train# step 1706, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:17.659763 #train# step 1707, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:19.222500 #train# step 1708, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:20.802225 #train# step 1709, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:22.409521 #train# step 1710, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:23.958247 #train# step 1711, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:25.538947 #train# step 1712, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:27.094637 #train# step 1713, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:28.665376 #train# step 1714, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:30.236971 #train# step 1715, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:31.810574 #train# step 1716, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:33.391023 #train# step 1717, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:34.933060 #train# step 1718, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:36.492154 #train# step 1719, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:38.048097 #train# step 1720, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:39.627524 #train# step 1721, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:41.179450 #train# step 1722, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:42.772100 #train# step 1723, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:44.348681 #train# step 1724, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:45.928547 #train# step 1725, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:47.498504 #train# step 1726, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:49.039881 #train# step 1727, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:50.581503 #train# step 1728, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:52.181803 #train# step 1729, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:53.762504 #train# step 1730, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:55.319434 #train# step 1731, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:56.908412 #train# step 1732, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:24:58.508639 #train# step 1733, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:00.129827 #train# step 1734, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:01.705091 #train# step 1735, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:03.256069 #train# step 1736, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:04.839867 #train# step 1737, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:06.429497 #train# step 1738, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:07.978926 #train# step 1739, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:09.561574 #train# step 1740, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:11.137797 #train# step 1741, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:12.721979 #train# step 1742, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:14.324087 #train# step 1743, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:15.874505 #train# step 1744, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:17.411004 #train# step 1745, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:18.951978 #train# step 1746, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:20.537956 #train# step 1747, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:22.132648 #train# step 1748, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:23.712568 #train# step 1749, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:25.288458 #train# step 1750, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:26.863188 #train# step 1751, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:28.418331 #train# step 1752, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:29.993811 #train# step 1753, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:31.532146 #train# step 1754, loss = 0.9673, cross_entropy loss = 0.9673, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:33.078109 #train# step 1755, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:34.652670 #train# step 1756, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:36.201119 #train# step 1757, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:37.776479 #train# step 1758, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:39.379673 #train# step 1759, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:40.966058 #train# step 1760, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:42.570576 #train# step 1761, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:44.124189 #train# step 1762, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:45.719215 #train# step 1763, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:47.297777 #train# step 1764, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:48.863843 #train# step 1765, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:50.401281 #train# step 1766, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:51.984475 #train# step 1767, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:53.553389 #train# step 1768, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:55.127240 #train# step 1769, loss = 0.9824, cross_entropy loss = 0.9824, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:56.703142 #train# step 1770, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:58.275480 #train# step 1771, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:25:59.880940 #train# step 1772, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:01.449030 #train# step 1773, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:03.036627 #train# step 1774, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:04.599666 #train# step 1775, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:06.184573 #train# step 1776, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:07.773129 #train# step 1777, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:09.358543 #train# step 1778, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:10.938009 #train# step 1779, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:12.551675 #train# step 1780, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:14.082377 #train# step 1781, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:15.651965 #train# step 1782, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:17.201775 #train# step 1783, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:18.771717 #train# step 1784, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:20.344060 #train# step 1785, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:21.925065 #train# step 1786, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:23.489816 #train# step 1787, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:25.077468 #train# step 1788, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:26.673946 #train# step 1789, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:28.261582 #train# step 1790, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:29.864969 #train# step 1791, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:31.422706 #train# step 1792, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:32.976180 #train# step 1793, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:34.532548 #train# step 1794, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:36.103389 #train# step 1795, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:37.704541 #train# step 1796, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:39.218460 #train# step 1797, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:40.791180 #train# step 1798, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:42.382403 #train# step 1799, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:43.961200 #train# step 1800, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:45.520141 #train# step 1801, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:47.071380 #train# step 1802, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:48.653949 #train# step 1803, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:50.217819 #train# step 1804, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:51.785551 #train# step 1805, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:53.323347 #train# step 1806, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:54.887489 #train# step 1807, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:56.476213 #train# step 1808, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:58.064788 #train# step 1809, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:26:59.644709 #train# step 1810, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:01.197750 #train# step 1811, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:02.770522 #train# step 1812, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:04.355458 #train# step 1813, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:05.933989 #train# step 1814, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:07.545999 #train# step 1815, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:09.114488 #train# step 1816, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:10.681332 #train# step 1817, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:12.249268 #train# step 1818, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:13.822936 #train# step 1819, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:15.355492 #train# step 1820, loss = 0.9752, cross_entropy loss = 0.9752, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:16.916639 #train# step 1821, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:18.504974 #train# step 1822, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:20.036996 #train# step 1823, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:21.629899 #train# step 1824, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:23.224987 #train# step 1825, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:24.778477 #train# step 1826, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:26.333458 #train# step 1827, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:27.899581 #train# step 1828, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:29.469217 #train# step 1829, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:31.030900 #train# step 1830, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:32.581773 #train# step 1831, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:34.132077 #train# step 1832, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:35.744706 #train# step 1833, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:37.324416 #train# step 1834, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:38.869854 #train# step 1835, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:40.427403 #train# step 1836, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:42.020660 #train# step 1837, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:43.572881 #train# step 1838, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:45.155006 #train# step 1839, loss = 0.9813, cross_entropy loss = 0.9813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:46.724678 #train# step 1840, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:48.287061 #train# step 1841, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:49.857966 #train# step 1842, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:51.405426 #train# step 1843, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:52.987759 #train# step 1844, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:54.572315 #train# step 1845, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:56.145247 #train# step 1846, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:57.741405 #train# step 1847, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:27:59.305263 #train# step 1848, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:00.845213 #train# step 1849, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:02.422340 #train# step 1850, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:03.996801 #train# step 1851, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:05.590805 #train# step 1852, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:07.183524 #train# step 1853, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:08.749011 #train# step 1854, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:10.307686 #train# step 1855, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:11.860554 #train# step 1856, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:13.462956 #train# step 1857, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:15.062460 #train# step 1858, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:16.625594 #train# step 1859, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:18.203748 #train# step 1860, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:19.762376 #train# step 1861, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:21.299824 #train# step 1862, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:22.876245 #train# step 1863, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:24.459011 #train# step 1864, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:26.020875 #train# step 1865, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:27.578734 #train# step 1866, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:29.145838 #train# step 1867, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:30.713095 #train# step 1868, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:32.250525 #train# step 1869, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:33.813254 #train# step 1870, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:35.408958 #train# step 1871, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:36.953696 #train# step 1872, loss = 0.9748, cross_entropy loss = 0.9748, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:38.561049 #train# step 1873, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:40.128848 #train# step 1874, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:41.699808 #train# step 1875, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:43.275332 #train# step 1876, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:44.852299 #train# step 1877, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:46.474843 #train# step 1878, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:48.012298 #train# step 1879, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:49.563710 #train# step 1880, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:51.128560 #train# step 1881, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:52.708030 #train# step 1882, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:54.268636 #train# step 1883, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:55.850582 #train# step 1884, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:57.411609 #train# step 1885, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:28:58.984681 #train# step 1886, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:00.553248 #train# step 1887, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:02.136516 #train# step 1888, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:03.730809 #train# step 1889, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:05.279314 #train# step 1890, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:06.842215 #train# step 1891, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:08.418873 #train# step 1892, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:10.031375 #train# step 1893, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:11.597606 #train# step 1894, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:13.180823 #train# step 1895, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:14.748871 #train# step 1896, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:16.310263 #train# step 1897, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:17.865993 #train# step 1898, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:19.415464 #train# step 1899, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:21.034546 #train# step 1900, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:22.610111 #train# step 1901, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:24.174218 #train# step 1902, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:25.755402 #train# step 1903, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:27.315040 #train# step 1904, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:28.872510 #train# step 1905, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:30.461958 #train# step 1906, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:32.020269 #train# step 1907, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:33.565446 #train# step 1908, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:35.159261 #train# step 1909, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:36.760504 #train# step 1910, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:38.309762 #train# step 1911, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:39.896407 #train# step 1912, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:41.455091 #train# step 1913, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:43.022016 #train# step 1914, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:44.602460 #train# step 1915, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:46.175601 #train# step 1916, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:47.785261 #train# step 1917, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:49.352508 #train# step 1918, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:50.912991 #train# step 1919, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:52.481813 #train# step 1920, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:54.042330 #train# step 1921, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:55.604670 #train# step 1922, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:57.197998 #train# step 1923, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:29:58.749308 #train# step 1924, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:00.325853 #train# step 1925, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:01.898063 #train# step 1926, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:03.460242 #train# step 1927, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:05.014739 #train# step 1928, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:06.558505 #train# step 1929, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:08.121165 #train# step 1930, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:09.725553 #train# step 1931, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:11.285328 #train# step 1932, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:12.859811 #train# step 1933, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:14.460499 #train# step 1934, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:16.044583 #train# step 1935, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:17.626842 #train# step 1936, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:19.213530 #train# step 1937, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:20.765380 #train# step 1938, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:22.369504 #train# step 1939, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:23.923627 #train# step 1940, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:25.482404 #train# step 1941, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:27.051047 #train# step 1942, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:28.658820 #train# step 1943, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:30.211480 #train# step 1944, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:31.794946 #train# step 1945, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:33.378499 #train# step 1946, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:34.956472 #train# step 1947, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:36.541471 #train# step 1948, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:38.132710 #train# step 1949, loss = 0.9765, cross_entropy loss = 0.9765, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:39.689134 #train# step 1950, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:41.267952 #train# step 1951, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:42.845258 #train# step 1952, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:44.407696 #train# step 1953, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:45.961527 #train# step 1954, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:47.519042 #train# step 1955, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:49.080641 #train# step 1956, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:50.660785 #train# step 1957, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:52.214717 #train# step 1958, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:53.758630 #train# step 1959, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:55.345184 #train# step 1960, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:56.904383 #train# step 1961, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:30:58.449533 #train# step 1962, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:00.018983 #train# step 1963, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:01.599963 #train# step 1964, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:03.173642 #train# step 1965, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:04.787217 #train# step 1966, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:06.353201 #train# step 1967, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:07.929706 #train# step 1968, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:09.493916 #train# step 1969, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:11.040746 #train# step 1970, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:12.605024 #train# step 1971, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:14.200546 #train# step 1972, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:15.804911 #train# step 1973, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:17.395715 #train# step 1974, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:18.988919 #train# step 1975, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:20.561165 #train# step 1976, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:22.136632 #train# step 1977, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:23.734933 #train# step 1978, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:25.267691 #train# step 1979, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:26.846438 #train# step 1980, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:28.408479 #train# step 1981, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:29.985225 #train# step 1982, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:31.580926 #train# step 1983, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:33.120582 #train# step 1984, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:34.702968 #train# step 1985, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:36.286949 #train# step 1986, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:37.883734 #train# step 1987, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:39.449773 #train# step 1988, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:41.044323 #train# step 1989, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:42.656404 #train# step 1990, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:44.236919 #train# step 1991, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:45.794118 #train# step 1992, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:47.372895 #train# step 1993, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:48.950973 #train# step 1994, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:50.524354 #train# step 1995, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:52.115362 #train# step 1996, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:53.690998 #train# step 1997, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:55.226378 #train# step 1998, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:56.813305 #train# step 1999, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:58.367710 #train# step 2000, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:31:59.970001 #train# step 2001, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:01.556138 #train# step 2002, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:03.134134 #train# step 2003, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:04.710822 #train# step 2004, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:06.284240 #train# step 2005, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:07.850280 #train# step 2006, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:09.407748 #train# step 2007, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:10.975383 #train# step 2008, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:12.520457 #train# step 2009, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:14.097126 #train# step 2010, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:15.668651 #train# step 2011, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:17.214540 #train# step 2012, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:18.779274 #train# step 2013, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:20.355086 #train# step 2014, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:21.922030 #train# step 2015, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:23.502279 #train# step 2016, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:25.054215 #train# step 2017, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:26.618994 #train# step 2018, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:28.180891 #train# step 2019, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:29.711524 #train# step 2020, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:31.285899 #train# step 2021, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:32.901782 #train# step 2022, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:34.461463 #train# step 2023, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:36.036106 #train# step 2024, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:37.592244 #train# step 2025, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:39.201147 #train# step 2026, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:40.784750 #train# step 2027, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:42.353541 #train# step 2028, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:43.927888 #train# step 2029, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:45.496733 #train# step 2030, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:47.056457 #train# step 2031, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:48.609428 #train# step 2032, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:50.188466 #train# step 2033, loss = 0.9697, cross_entropy loss = 0.9697, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:51.756531 #train# step 2034, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:53.314294 #train# step 2035, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:54.896521 #train# step 2036, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:56.488410 #train# step 2037, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:58.026702 #train# step 2038, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:32:59.643944 #train# step 2039, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:01.206895 #train# step 2040, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:02.790039 #train# step 2041, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:04.370971 #train# step 2042, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:05.956768 #train# step 2043, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:07.501676 #train# step 2044, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:09.067845 #train# step 2045, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:10.635045 #train# step 2046, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:12.201024 #train# step 2047, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:13.740627 #train# step 2048, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:15.293728 #train# step 2049, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:16.858844 #train# step 2050, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:18.444055 #train# step 2051, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:19.992128 #train# step 2052, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:21.547746 #train# step 2053, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:23.133981 #train# step 2054, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:24.697680 #train# step 2055, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:26.270022 #train# step 2056, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:27.825554 #train# step 2057, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:29.423054 #train# step 2058, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:31.037402 #train# step 2059, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:32.589338 #train# step 2060, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:34.174579 #train# step 2061, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:35.754761 #train# step 2062, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:37.334535 #train# step 2063, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:38.884838 #train# step 2064, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:40.462058 #train# step 2065, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:42.055907 #train# step 2066, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:43.642017 #train# step 2067, loss = 0.9742, cross_entropy loss = 0.9742, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:45.219631 #train# step 2068, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:46.762506 #train# step 2069, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:48.344098 #train# step 2070, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:49.917494 #train# step 2071, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:51.483674 #train# step 2072, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:53.053708 #train# step 2073, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:54.656321 #train# step 2074, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:56.212220 #train# step 2075, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:57.778678 #train# step 2076, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:33:59.389535 #train# step 2077, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:00.987352 #train# step 2078, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:02.580116 #train# step 2079, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:04.152839 #train# step 2080, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:05.700513 #train# step 2081, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:07.268521 #train# step 2082, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:08.871057 #train# step 2083, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:10.446761 #train# step 2084, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:12.056502 #train# step 2085, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:13.629087 #train# step 2086, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:15.229102 #train# step 2087, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:16.793946 #train# step 2088, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:18.352605 #train# step 2089, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:19.914920 #train# step 2090, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:21.448594 #train# step 2091, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:23.013409 #train# step 2092, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:24.539493 #train# step 2093, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:26.114487 #train# step 2094, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:27.692644 #train# step 2095, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:29.277210 #train# step 2096, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:30.860571 #train# step 2097, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:32.446359 #train# step 2098, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:34.040205 #train# step 2099, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:35.577660 #train# step 2100, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:37.141415 #train# step 2101, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:38.722957 #train# step 2102, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:40.287230 #train# step 2103, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:41.865835 #train# step 2104, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:43.404327 #train# step 2105, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:44.999784 #train# step 2106, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:46.600087 #train# step 2107, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:48.170452 #train# step 2108, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:49.741697 #train# step 2109, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:51.320172 #train# step 2110, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:52.862540 #train# step 2111, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:54.437792 #train# step 2112, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:56.010684 #train# step 2113, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:57.581177 #train# step 2114, loss = 0.9673, cross_entropy loss = 0.9673, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:34:59.149030 #train# step 2115, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:00.742217 #train# step 2116, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:02.289935 #train# step 2117, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:03.861596 #train# step 2118, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:05.406858 #train# step 2119, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:06.994776 #train# step 2120, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:08.564308 #train# step 2121, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:10.133611 #train# step 2122, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:11.733981 #train# step 2123, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:13.303194 #train# step 2124, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:14.874884 #train# step 2125, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:16.429363 #train# step 2126, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:17.999176 #train# step 2127, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:19.538410 #train# step 2128, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:21.108464 #train# step 2129, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:22.712660 #train# step 2130, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:24.285097 #train# step 2131, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:25.842409 #train# step 2132, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:27.389064 #train# step 2133, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:28.965972 #train# step 2134, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:30.545859 #train# step 2135, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:32.090350 #train# step 2136, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:33.683721 #train# step 2137, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:35.269821 #train# step 2138, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:36.841597 #train# step 2139, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:38.410861 #train# step 2140, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:39.997284 #train# step 2141, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:41.562639 #train# step 2142, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:43.148071 #train# step 2143, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:44.723541 #train# step 2144, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:46.301259 #train# step 2145, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:47.860977 #train# step 2146, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:49.472698 #train# step 2147, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:51.047432 #train# step 2148, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:52.640786 #train# step 2149, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:54.211018 #train# step 2150, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:55.840816 #train# step 2151, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:57.396659 #train# step 2152, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:35:58.967138 #train# step 2153, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:00.530032 #train# step 2154, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:02.101629 #train# step 2155, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:03.659026 #train# step 2156, loss = 0.9748, cross_entropy loss = 0.9748, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:05.224991 #train# step 2157, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:06.815890 #train# step 2158, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:08.386760 #train# step 2159, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:09.974957 #train# step 2160, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:11.547337 #train# step 2161, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:13.127817 #train# step 2162, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:14.699896 #train# step 2163, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:16.276279 #train# step 2164, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:17.855278 #train# step 2165, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:19.406578 #train# step 2166, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:20.968691 #train# step 2167, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:22.527115 #train# step 2168, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:24.086474 #train# step 2169, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:25.635254 #train# step 2170, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:27.208281 #train# step 2171, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:28.785751 #train# step 2172, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:30.325516 #train# step 2173, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:31.918969 #train# step 2174, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:33.500175 #train# step 2175, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:35.106482 #train# step 2176, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:36.669310 #train# step 2177, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:38.222549 #train# step 2178, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:39.824519 #train# step 2179, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:41.401349 #train# step 2180, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:42.945848 #train# step 2181, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:44.562626 #train# step 2182, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:46.144995 #train# step 2183, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:47.730378 #train# step 2184, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:49.298661 #train# step 2185, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:50.866684 #train# step 2186, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:52.423255 #train# step 2187, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:53.999692 #train# step 2188, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:55.560087 #train# step 2189, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:57.133027 #train# step 2190, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:36:58.684360 #train# step 2191, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:00.253266 #train# step 2192, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:01.853096 #train# step 2193, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:03.442710 #train# step 2194, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:05.022465 #train# step 2195, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:06.595469 #train# step 2196, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:08.156313 #train# step 2197, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:09.736408 #train# step 2198, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:11.301566 #train# step 2199, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:12.858297 #train# step 2200, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:14.432810 #train# step 2201, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:15.998667 #train# step 2202, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:17.571372 #train# step 2203, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:19.125393 #train# step 2204, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:20.674743 #train# step 2205, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:22.267129 #train# step 2206, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:23.835795 #train# step 2207, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:25.428089 #train# step 2208, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:27.055106 #train# step 2209, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:28.648819 #train# step 2210, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:30.199670 #train# step 2211, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:31.812989 #train# step 2212, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:33.376541 #train# step 2213, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:34.948757 #train# step 2214, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:36.507141 #train# step 2215, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:38.051432 #train# step 2216, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:39.624451 #train# step 2217, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:41.193965 #train# step 2218, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:42.737000 #train# step 2219, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:44.300918 #train# step 2220, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:45.874540 #train# step 2221, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:47.450246 #train# step 2222, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:49.024092 #train# step 2223, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:50.626976 #train# step 2224, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:52.205269 #train# step 2225, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:53.762642 #train# step 2226, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:55.342209 #train# step 2227, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:56.921206 #train# step 2228, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:37:58.502681 #train# step 2229, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:00.079043 #train# step 2230, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:01.660924 #train# step 2231, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:03.238732 #train# step 2232, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:04.803966 #train# step 2233, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:06.380543 #train# step 2234, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:07.964788 #train# step 2235, loss = 0.9811, cross_entropy loss = 0.9811, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:09.546693 #train# step 2236, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:11.126382 #train# step 2237, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:12.723110 #train# step 2238, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:14.322793 #train# step 2239, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:15.907832 #train# step 2240, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:17.506096 #train# step 2241, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:19.071284 #train# step 2242, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:20.629208 #train# step 2243, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:22.193730 #train# step 2244, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:23.756345 #train# step 2245, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:25.308674 #train# step 2246, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:26.853974 #train# step 2247, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:28.444586 #train# step 2248, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:29.990542 #train# step 2249, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:31.561142 #train# step 2250, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:33.116216 #train# step 2251, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:34.643310 #train# step 2252, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:36.185130 #train# step 2253, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:37.756287 #train# step 2254, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:39.368341 #train# step 2255, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:40.954829 #train# step 2256, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:42.524957 #train# step 2257, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:44.095591 #train# step 2258, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:45.664623 #train# step 2259, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:47.227433 #train# step 2260, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:48.810655 #train# step 2261, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:50.371866 #train# step 2262, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:51.929241 #train# step 2263, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:53.479484 #train# step 2264, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:55.075360 #train# step 2265, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:56.636648 #train# step 2266, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:58.194249 #train# step 2267, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:38:59.790320 #train# step 2268, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:01.389401 #train# step 2269, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:02.951581 #train# step 2270, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:04.531036 #train# step 2271, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:06.117738 #train# step 2272, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:07.657406 #train# step 2273, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:09.226825 #train# step 2274, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:10.783928 #train# step 2275, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:12.393389 #train# step 2276, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:13.963752 #train# step 2277, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:15.527233 #train# step 2278, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:17.075417 #train# step 2279, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:18.640188 #train# step 2280, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:20.213949 #train# step 2281, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:21.774928 #train# step 2282, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:23.328076 #train# step 2283, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:24.903742 #train# step 2284, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:26.456308 #train# step 2285, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:28.032374 #train# step 2286, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:29.602960 #train# step 2287, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:31.196272 #train# step 2288, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:32.768783 #train# step 2289, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:34.345264 #train# step 2290, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:35.961919 #train# step 2291, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:37.541252 #train# step 2292, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:39.118946 #train# step 2293, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:40.712231 #train# step 2294, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:42.281804 #train# step 2295, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:43.842641 #train# step 2296, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:45.445275 #train# step 2297, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:47.046467 #train# step 2298, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:48.634069 #train# step 2299, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:50.220260 #train# step 2300, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:51.796673 #train# step 2301, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:53.358130 #train# step 2302, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:54.968237 #train# step 2303, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:56.541435 #train# step 2304, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:58.102348 #train# step 2305, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:39:59.663458 #train# step 2306, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:01.251617 #train# step 2307, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:02.839779 #train# step 2308, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:04.395885 #train# step 2309, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:05.977758 #train# step 2310, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:07.530193 #train# step 2311, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:09.117079 #train# step 2312, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:10.680581 #train# step 2313, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:12.260751 #train# step 2314, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:13.856837 #train# step 2315, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:15.437191 #train# step 2316, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:17.041459 #train# step 2317, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:18.617498 #train# step 2318, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:20.191100 #train# step 2319, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:21.727123 #train# step 2320, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:23.314159 #train# step 2321, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:24.876945 #train# step 2322, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:26.441887 #train# step 2323, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:28.033075 #train# step 2324, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:29.618786 #train# step 2325, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:31.195103 #train# step 2326, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:32.736527 #train# step 2327, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:34.281547 #train# step 2328, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:35.900532 #train# step 2329, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:37.465622 #train# step 2330, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:39.046379 #train# step 2331, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:40.621870 #train# step 2332, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:42.220354 #train# step 2333, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:43.796595 #train# step 2334, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:45.369447 #train# step 2335, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:46.944690 #train# step 2336, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:48.523887 #train# step 2337, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:50.145119 #train# step 2338, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:51.709488 #train# step 2339, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:53.273486 #train# step 2340, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:54.874782 #train# step 2341, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:56.434129 #train# step 2342, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:58.032534 #train# step 2343, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:40:59.632209 #train# step 2344, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:01.207252 #train# step 2345, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:02.748663 #train# step 2346, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:04.294305 #train# step 2347, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:05.827251 #train# step 2348, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:07.400617 #train# step 2349, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:08.991690 #train# step 2350, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:10.539295 #train# step 2351, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:12.118323 #train# step 2352, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:13.717127 #train# step 2353, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:15.303300 #train# step 2354, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:16.861562 #train# step 2355, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:18.449265 #train# step 2356, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:20.020700 #train# step 2357, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:21.569409 #train# step 2358, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:23.112443 #train# step 2359, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:24.704065 #train# step 2360, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:26.267124 #train# step 2361, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:27.831756 #train# step 2362, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:29.414810 #train# step 2363, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:30.996194 #train# step 2364, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:32.559337 #train# step 2365, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:34.143085 #train# step 2366, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:35.711139 #train# step 2367, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:37.292877 #train# step 2368, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:38.858895 #train# step 2369, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:40.434137 #train# step 2370, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:41.988895 #train# step 2371, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:43.547838 #train# step 2372, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:45.116803 #train# step 2373, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:46.676228 #train# step 2374, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:48.284943 #train# step 2375, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:49.859201 #train# step 2376, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:51.417030 #train# step 2377, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:53.015566 #train# step 2378, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:54.595533 #train# step 2379, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:56.177625 #train# step 2380, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:57.738448 #train# step 2381, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:41:59.308639 #train# step 2382, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:00.896185 #train# step 2383, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:02.467398 #train# step 2384, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:04.026995 #train# step 2385, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:05.622411 #train# step 2386, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:07.219396 #train# step 2387, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:08.801103 #train# step 2388, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:10.384802 #train# step 2389, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:11.973319 #train# step 2390, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:13.537377 #train# step 2391, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:15.116773 #train# step 2392, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:16.679333 #train# step 2393, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:18.250510 #train# step 2394, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:19.832948 #train# step 2395, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:21.399732 #train# step 2396, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:22.983483 #train# step 2397, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:24.570803 #train# step 2398, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:26.137034 #train# step 2399, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:27.675035 #train# step 2400, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:29.253787 #train# step 2401, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:30.829507 #train# step 2402, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:32.421017 #train# step 2403, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:34.004951 #train# step 2404, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:35.589146 #train# step 2405, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:37.140168 #train# step 2406, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:38.704117 #train# step 2407, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:40.290502 #train# step 2408, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:41.860082 #train# step 2409, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:43.461636 #train# step 2410, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:45.013305 #train# step 2411, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:46.581082 #train# step 2412, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:48.156260 #train# step 2413, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:49.729443 #train# step 2414, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:51.293033 #train# step 2415, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:52.887263 #train# step 2416, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:54.455547 #train# step 2417, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:56.023702 #train# step 2418, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:57.600271 #train# step 2419, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:42:59.187206 #train# step 2420, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:00.772067 #train# step 2421, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:02.320088 #train# step 2422, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:03.901438 #train# step 2423, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:05.488827 #train# step 2424, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:07.070746 #train# step 2425, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:08.668012 #train# step 2426, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:10.263878 #train# step 2427, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:11.819929 #train# step 2428, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:13.384589 #train# step 2429, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:14.963082 #train# step 2430, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:16.511887 #train# step 2431, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:18.104547 #train# step 2432, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:19.649685 #train# step 2433, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:21.250758 #train# step 2434, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:22.811466 #train# step 2435, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:24.384175 #train# step 2436, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:25.927314 #train# step 2437, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:27.479765 #train# step 2438, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:29.056254 #train# step 2439, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:30.623450 #train# step 2440, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:32.165128 #train# step 2441, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:33.744526 #train# step 2442, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:35.349427 #train# step 2443, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:36.904684 #train# step 2444, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:38.452439 #train# step 2445, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:40.022436 #train# step 2446, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:41.578046 #train# step 2447, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:43.160072 #train# step 2448, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:44.736666 #train# step 2449, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:46.331532 #train# step 2450, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:47.897042 #train# step 2451, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:49.485946 #train# step 2452, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:51.041089 #train# step 2453, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:52.637136 #train# step 2454, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:54.219779 #train# step 2455, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:55.818866 #train# step 2456, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:57.400268 #train# step 2457, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:43:58.969308 #train# step 2458, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:00.548305 #train# step 2459, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:02.118381 #train# step 2460, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:03.691125 #train# step 2461, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:05.294111 #train# step 2462, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:06.863487 #train# step 2463, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:08.402449 #train# step 2464, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:09.996501 #train# step 2465, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:11.554650 #train# step 2466, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:13.159733 #train# step 2467, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:14.730883 #train# step 2468, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:16.282491 #train# step 2469, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:17.853907 #train# step 2470, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:19.433757 #train# step 2471, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:20.988094 #train# step 2472, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:22.578916 #train# step 2473, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:24.158573 #train# step 2474, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:25.735606 #train# step 2475, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:27.347160 #train# step 2476, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:28.909067 #train# step 2477, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:30.462946 #train# step 2478, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:32.024793 #train# step 2479, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:33.586187 #train# step 2480, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:35.130090 #train# step 2481, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:36.710274 #train# step 2482, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:38.326328 #train# step 2483, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:39.881733 #train# step 2484, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:41.473310 #train# step 2485, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:43.033617 #train# step 2486, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:44.612685 #train# step 2487, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:46.179881 #train# step 2488, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:47.736081 #train# step 2489, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:49.291253 #train# step 2490, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:50.882656 #train# step 2491, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:52.442325 #train# step 2492, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:54.005786 #train# step 2493, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:55.569833 #train# step 2494, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:57.130075 #train# step 2495, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:44:58.696953 #train# step 2496, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:00.287850 #train# step 2497, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:01.879213 #train# step 2498, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:03.469807 #train# step 2499, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:05.073246 #train# step 2500, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:06.637803 #train# step 2501, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:08.186696 #train# step 2502, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:09.785362 #train# step 2503, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:11.353233 #train# step 2504, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:12.928659 #train# step 2505, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:14.486989 #train# step 2506, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:16.075700 #train# step 2507, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:17.639687 #train# step 2508, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:19.202669 #train# step 2509, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:20.758791 #train# step 2510, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:22.328457 #train# step 2511, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:23.914825 #train# step 2512, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:25.464851 #train# step 2513, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:27.051893 #train# step 2514, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:28.639404 #train# step 2515, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:30.189692 #train# step 2516, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:31.765353 #train# step 2517, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:33.342758 #train# step 2518, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:34.898152 #train# step 2519, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:36.463402 #train# step 2520, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:38.067667 #train# step 2521, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:39.645038 #train# step 2522, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:41.228097 #train# step 2523, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:42.771903 #train# step 2524, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:44.312470 #train# step 2525, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:45.868970 #train# step 2526, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:47.437619 #train# step 2527, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:49.038012 #train# step 2528, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:50.623053 #train# step 2529, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:52.205400 #train# step 2530, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:53.779135 #train# step 2531, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:55.348291 #train# step 2532, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:56.905746 #train# step 2533, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:45:58.503962 #train# step 2534, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:00.093100 #train# step 2535, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:01.671757 #train# step 2536, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:03.264544 #train# step 2537, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:04.847480 #train# step 2538, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:06.387647 #train# step 2539, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:07.988469 #train# step 2540, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:09.582319 #train# step 2541, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:11.142420 #train# step 2542, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:12.697412 #train# step 2543, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:14.246073 #train# step 2544, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:15.824963 #train# step 2545, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:17.415216 #train# step 2546, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:19.003954 #train# step 2547, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:20.563822 #train# step 2548, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:22.134915 #train# step 2549, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:23.717499 #train# step 2550, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:25.345743 #train# step 2551, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:26.930876 #train# step 2552, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:28.495539 #train# step 2553, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:30.068976 #train# step 2554, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:31.646659 #train# step 2555, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:33.236689 #train# step 2556, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:34.812994 #train# step 2557, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:36.398763 #train# step 2558, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:37.960684 #train# step 2559, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:39.522972 #train# step 2560, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:41.111808 #train# step 2561, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:42.670060 #train# step 2562, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:44.250676 #train# step 2563, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:45.821933 #train# step 2564, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:47.382019 #train# step 2565, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:48.948807 #train# step 2566, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:50.554594 #train# step 2567, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:52.130334 #train# step 2568, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:53.703014 #train# step 2569, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:55.315519 #train# step 2570, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:56.913926 #train# step 2571, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:46:58.506267 #train# step 2572, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:00.081026 #train# step 2573, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:01.666721 #train# step 2574, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:03.238917 #train# step 2575, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:04.769194 #train# step 2576, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:06.315524 #train# step 2577, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:07.882183 #train# step 2578, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:09.488242 #train# step 2579, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:11.020654 #train# step 2580, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:12.574862 #train# step 2581, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:14.177843 #train# step 2582, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:15.743017 #train# step 2583, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:17.284070 #train# step 2584, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:18.870325 #train# step 2585, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:20.401337 #train# step 2586, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:21.997071 #train# step 2587, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:23.559750 #train# step 2588, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:25.108307 #train# step 2589, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:26.655153 #train# step 2590, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:28.218803 #train# step 2591, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:29.828018 #train# step 2592, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:31.420633 #train# step 2593, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:32.989615 #train# step 2594, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:34.570680 #train# step 2595, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:36.125163 #train# step 2596, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:37.683030 #train# step 2597, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:39.260771 #train# step 2598, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:40.842922 #train# step 2599, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:42.395976 #train# step 2600, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:43.947583 #train# step 2601, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:45.531466 #train# step 2602, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:47.085047 #train# step 2603, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:48.698114 #train# step 2604, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:50.303020 #train# step 2605, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:51.895797 #train# step 2606, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:53.433411 #train# step 2607, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:55.017791 #train# step 2608, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:56.612830 #train# step 2609, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:58.183547 #train# step 2610, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:47:59.732594 #train# step 2611, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:01.341292 #train# step 2612, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:02.919675 #train# step 2613, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:04.514756 #train# step 2614, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:06.073033 #train# step 2615, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:07.620101 #train# step 2616, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:09.217031 #train# step 2617, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:10.785452 #train# step 2618, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:12.340980 #train# step 2619, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:13.881192 #train# step 2620, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:15.492805 #train# step 2621, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:17.103522 #train# step 2622, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:18.709184 #train# step 2623, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:20.280193 #train# step 2624, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:21.836763 #train# step 2625, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:23.373042 #train# step 2626, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:24.944278 #train# step 2627, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:26.509255 #train# step 2628, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:28.068612 #train# step 2629, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:29.630177 #train# step 2630, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:31.239454 #train# step 2631, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:32.818719 #train# step 2632, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:34.393383 #train# step 2633, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:35.983623 #train# step 2634, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:37.583017 #train# step 2635, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:39.145334 #train# step 2636, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:40.731612 #train# step 2637, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:42.310591 #train# step 2638, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:43.886938 #train# step 2639, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:45.422163 #train# step 2640, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:47.029491 #train# step 2641, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:48.615737 #train# step 2642, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:50.187974 #train# step 2643, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:51.768031 #train# step 2644, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:53.325202 #train# step 2645, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:54.919575 #train# step 2646, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:56.500605 #train# step 2647, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:58.073133 #train# step 2648, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:48:59.623796 #train# step 2649, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:01.170845 #train# step 2650, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:02.719100 #train# step 2651, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:04.314955 #train# step 2652, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:05.876379 #train# step 2653, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:07.436498 #train# step 2654, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:09.024729 #train# step 2655, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:10.612542 #train# step 2656, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:12.203273 #train# step 2657, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:13.770764 #train# step 2658, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:15.355470 #train# step 2659, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:16.931475 #train# step 2660, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:18.535366 #train# step 2661, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:20.115776 #train# step 2662, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:21.705173 #train# step 2663, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:23.265952 #train# step 2664, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:24.856347 #train# step 2665, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:26.405889 #train# step 2666, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:27.973889 #train# step 2667, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:29.540532 #train# step 2668, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:31.098348 #train# step 2669, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:32.662875 #train# step 2670, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:34.255082 #train# step 2671, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:35.825496 #train# step 2672, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:37.396020 #train# step 2673, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:38.978259 #train# step 2674, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:40.550329 #train# step 2675, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:42.095581 #train# step 2676, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:43.685792 #train# step 2677, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:45.252346 #train# step 2678, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:46.842009 #train# step 2679, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:48.412789 #train# step 2680, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:50.015850 #train# step 2681, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:51.573555 #train# step 2682, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:53.143907 #train# step 2683, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:54.699254 #train# step 2684, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:56.301902 #train# step 2685, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:57.889495 #train# step 2686, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:49:59.487888 #train# step 2687, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:01.033288 #train# step 2688, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:02.610661 #train# step 2689, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:04.193436 #train# step 2690, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:05.788598 #train# step 2691, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:07.362774 #train# step 2692, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:08.939611 #train# step 2693, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:10.509275 #train# step 2694, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:12.095526 #train# step 2695, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:13.664265 #train# step 2696, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:15.239959 #train# step 2697, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:16.798830 #train# step 2698, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:18.386063 #train# step 2699, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:19.949172 #train# step 2700, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:21.526900 #train# step 2701, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:23.085166 #train# step 2702, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:24.685379 #train# step 2703, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:26.257262 #train# step 2704, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:27.840177 #train# step 2705, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:29.406940 #train# step 2706, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:30.972575 #train# step 2707, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:32.544789 #train# step 2708, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:34.136448 #train# step 2709, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:35.699991 #train# step 2710, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:37.277300 #train# step 2711, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:38.860543 #train# step 2712, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:40.454939 #train# step 2713, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:42.051070 #train# step 2714, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:43.627454 #train# step 2715, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:45.206143 #train# step 2716, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:46.795929 #train# step 2717, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:48.410442 #train# step 2718, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:50.018722 #train# step 2719, loss = 0.9474, cross_entropy loss = 0.9474, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:51.601564 #train# step 2720, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:53.144532 #train# step 2721, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:54.690685 #train# step 2722, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:56.242414 #train# step 2723, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:57.804034 #train# step 2724, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:50:59.351198 #train# step 2725, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:00.904754 #train# step 2726, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:02.477572 #train# step 2727, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:04.028903 #train# step 2728, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:05.589825 #train# step 2729, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:07.148307 #train# step 2730, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:08.736167 #train# step 2731, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:10.283737 #train# step 2732, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:11.852487 #train# step 2733, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:13.385722 #train# step 2734, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:14.944804 #train# step 2735, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:16.551728 #train# step 2736, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:18.114035 #train# step 2737, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:19.666991 #train# step 2738, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:21.222163 #train# step 2739, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:22.783939 #train# step 2740, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:24.331337 #train# step 2741, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:25.882982 #train# step 2742, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:27.423257 #train# step 2743, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:29.005117 #train# step 2744, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:30.554769 #train# step 2745, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:32.100628 #train# step 2746, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:33.718544 #train# step 2747, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:35.315081 #train# step 2748, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:36.871593 #train# step 2749, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:38.468384 #train# step 2750, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:40.041233 #train# step 2751, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:41.625357 #train# step 2752, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:43.197965 #train# step 2753, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:44.752254 #train# step 2754, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:46.306004 #train# step 2755, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:47.863301 #train# step 2756, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:49.405671 #train# step 2757, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:50.978809 #train# step 2758, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:52.516244 #train# step 2759, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:54.081256 #train# step 2760, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:55.635211 #train# step 2761, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:57.179188 #train# step 2762, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:51:58.729246 #train# step 2763, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:00.319768 #train# step 2764, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:01.845414 #train# step 2765, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:03.418966 #train# step 2766, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:04.988691 #train# step 2767, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:06.515244 #train# step 2768, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:08.076166 #train# step 2769, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:09.622889 #train# step 2770, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:11.164259 #train# step 2771, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:12.707081 #train# step 2772, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:14.257253 #train# step 2773, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:15.823297 #train# step 2774, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:17.369494 #train# step 2775, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:18.926040 #train# step 2776, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:20.496169 #train# step 2777, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:22.029138 #train# step 2778, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:23.591185 #train# step 2779, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:25.147359 #train# step 2780, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:26.710060 #train# step 2781, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:28.281193 #train# step 2782, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:29.838946 #train# step 2783, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:31.373694 #train# step 2784, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:32.933343 #train# step 2785, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:34.501603 #train# step 2786, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:36.073970 #train# step 2787, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:37.655310 #train# step 2788, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:39.267460 #train# step 2789, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:40.846184 #train# step 2790, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:42.414547 #train# step 2791, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:43.961746 #train# step 2792, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:45.516928 #train# step 2793, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:47.045128 #train# step 2794, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:48.581209 #train# step 2795, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:50.131508 #train# step 2796, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:51.659352 #train# step 2797, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:53.231471 #train# step 2798, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:54.805585 #train# step 2799, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:56.364941 #train# step 2800, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:57.904115 #train# step 2801, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:52:59.445177 #train# step 2802, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:01.024074 #train# step 2803, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:02.573927 #train# step 2804, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:04.141917 #train# step 2805, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:05.690212 #train# step 2806, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:07.247322 #train# step 2807, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:08.796818 #train# step 2808, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:10.358707 #train# step 2809, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:11.920551 #train# step 2810, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:13.459866 #train# step 2811, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:15.017299 #train# step 2812, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:16.607434 #train# step 2813, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:18.211289 #train# step 2814, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:19.755230 #train# step 2815, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:21.299460 #train# step 2816, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:22.893068 #train# step 2817, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:24.460869 #train# step 2818, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:26.022382 #train# step 2819, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:27.627893 #train# step 2820, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:29.196251 #train# step 2821, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:30.744364 #train# step 2822, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:32.288494 #train# step 2823, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:33.865423 #train# step 2824, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:35.416668 #train# step 2825, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:36.962700 #train# step 2826, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:38.511996 #train# step 2827, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:40.083186 #train# step 2828, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:41.621443 #train# step 2829, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:43.221389 #train# step 2830, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:44.762581 #train# step 2831, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:46.328683 #train# step 2832, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:47.850539 #train# step 2833, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:49.411019 #train# step 2834, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:50.935377 #train# step 2835, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:52.466428 #train# step 2836, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:54.029591 #train# step 2837, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:55.579181 #train# step 2838, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:57.140795 #train# step 2839, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:53:58.718179 #train# step 2840, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:00.297259 #train# step 2841, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:01.878124 #train# step 2842, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:03.469701 #train# step 2843, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:05.031765 #train# step 2844, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:06.644456 #train# step 2845, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:08.179064 #train# step 2846, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:09.731214 #train# step 2847, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:11.312164 #train# step 2848, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:12.882262 #train# step 2849, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:14.435667 #train# step 2850, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:16.007662 #train# step 2851, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:17.570535 #train# step 2852, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:19.134813 #train# step 2853, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:20.745000 #train# step 2854, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:22.321370 #train# step 2855, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:23.885274 #train# step 2856, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:25.480074 #train# step 2857, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:27.037269 #train# step 2858, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:28.586714 #train# step 2859, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:30.189818 #train# step 2860, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:31.744035 #train# step 2861, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:33.273039 #train# step 2862, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:34.826843 #train# step 2863, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:36.348300 #train# step 2864, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:37.935838 #train# step 2865, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:39.491308 #train# step 2866, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:41.043197 #train# step 2867, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:42.591426 #train# step 2868, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:44.155311 #train# step 2869, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:45.719989 #train# step 2870, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:47.293045 #train# step 2871, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:48.866152 #train# step 2872, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:50.455891 #train# step 2873, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:51.999850 #train# step 2874, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:53.539272 #train# step 2875, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:55.087231 #train# step 2876, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:56.683267 #train# step 2877, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:58.232061 #train# step 2878, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:54:59.811421 #train# step 2879, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:01.374132 #train# step 2880, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:02.931253 #train# step 2881, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:04.515392 #train# step 2882, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:06.051976 #train# step 2883, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:07.598800 #train# step 2884, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:09.177062 #train# step 2885, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:10.727454 #train# step 2886, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:12.289389 #train# step 2887, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:13.866625 #train# step 2888, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:15.462435 #train# step 2889, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:17.033104 #train# step 2890, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:18.591314 #train# step 2891, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:20.136959 #train# step 2892, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:21.693034 #train# step 2893, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:23.266731 #train# step 2894, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:24.824231 #train# step 2895, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:26.396231 #train# step 2896, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:27.971064 #train# step 2897, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:29.563090 #train# step 2898, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:31.127332 #train# step 2899, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:32.685991 #train# step 2900, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:34.254829 #train# step 2901, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:35.826210 #train# step 2902, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:37.363738 #train# step 2903, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:38.906526 #train# step 2904, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:40.472727 #train# step 2905, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:42.036233 #train# step 2906, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:43.584323 #train# step 2907, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:45.134180 #train# step 2908, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:46.669229 #train# step 2909, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:48.198359 #train# step 2910, loss = 0.9697, cross_entropy loss = 0.9697, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:49.761218 #train# step 2911, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:51.313348 #train# step 2912, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:52.873583 #train# step 2913, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:54.435161 #train# step 2914, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:56.024588 #train# step 2915, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:57.582240 #train# step 2916, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:55:59.193591 #train# step 2917, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:00.734135 #train# step 2918, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:02.283336 #train# step 2919, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:03.878584 #train# step 2920, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:05.434733 #train# step 2921, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:06.994705 #train# step 2922, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:08.534766 #train# step 2923, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:10.111627 #train# step 2924, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:11.663739 #train# step 2925, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:13.224524 #train# step 2926, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:14.790803 #train# step 2927, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:16.347278 #train# step 2928, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:17.874466 #train# step 2929, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:19.428474 #train# step 2930, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:20.984861 #train# step 2931, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:22.558684 #train# step 2932, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:24.129032 #train# step 2933, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:25.695709 #train# step 2934, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:27.230874 #train# step 2935, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:28.760961 #train# step 2936, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:30.345119 #train# step 2937, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:31.930061 #train# step 2938, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:33.499297 #train# step 2939, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:35.057276 #train# step 2940, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:36.595500 #train# step 2941, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:38.143473 #train# step 2942, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:39.706339 #train# step 2943, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:41.281948 #train# step 2944, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:42.844804 #train# step 2945, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:44.401565 #train# step 2946, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:45.963900 #train# step 2947, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:47.538341 #train# step 2948, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:49.078556 #train# step 2949, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:50.667181 #train# step 2950, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:52.233811 #train# step 2951, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:53.781027 #train# step 2952, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:55.335772 #train# step 2953, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:56.887372 #train# step 2954, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:56:58.462206 #train# step 2955, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:00.036545 #train# step 2956, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:01.591916 #train# step 2957, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:03.184556 #train# step 2958, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:04.724370 #train# step 2959, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:06.292400 #train# step 2960, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:07.819005 #train# step 2961, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:09.369287 #train# step 2962, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:10.938075 #train# step 2963, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:12.501471 #train# step 2964, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:14.050750 #train# step 2965, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:15.597537 #train# step 2966, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:17.149360 #train# step 2967, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:18.718918 #train# step 2968, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:20.281620 #train# step 2969, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:21.828124 #train# step 2970, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:23.387953 #train# step 2971, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:24.965134 #train# step 2972, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:26.482995 #train# step 2973, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:28.039893 #train# step 2974, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:29.629224 #train# step 2975, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:31.203478 #train# step 2976, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:32.785727 #train# step 2977, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:34.380172 #train# step 2978, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:35.925084 #train# step 2979, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:37.485129 #train# step 2980, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:39.060556 #train# step 2981, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:40.623191 #train# step 2982, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:42.166521 #train# step 2983, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:43.743919 #train# step 2984, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:45.288424 #train# step 2985, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:46.863053 #train# step 2986, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:48.436640 #train# step 2987, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:50.009736 #train# step 2988, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:51.596888 #train# step 2989, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:53.169398 #train# step 2990, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:54.699695 #train# step 2991, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:56.278279 #train# step 2992, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:57.831481 #train# step 2993, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:57:59.373502 #train# step 2994, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:00.925899 #train# step 2995, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:02.493062 #train# step 2996, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:04.062085 #train# step 2997, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:05.619218 #train# step 2998, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:07.173480 #train# step 2999, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:08.725780 #train# step 3000, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:10.303111 #train# step 3001, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:11.857774 #train# step 3002, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:13.431625 #train# step 3003, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:14.937364 #train# step 3004, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:16.506501 #train# step 3005, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:18.095290 #train# step 3006, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:19.638242 #train# step 3007, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:21.223009 #train# step 3008, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:22.795121 #train# step 3009, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:24.379063 #train# step 3010, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:25.923086 #train# step 3011, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:27.484554 #train# step 3012, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:29.016899 #train# step 3013, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:30.588374 #train# step 3014, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:32.134776 #train# step 3015, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:33.712812 #train# step 3016, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:35.301840 #train# step 3017, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:36.892325 #train# step 3018, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:38.447948 #train# step 3019, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:40.028251 #train# step 3020, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:41.595865 #train# step 3021, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:43.159796 #train# step 3022, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:44.706376 #train# step 3023, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:46.271461 #train# step 3024, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:47.817265 #train# step 3025, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:49.404874 #train# step 3026, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:50.990880 #train# step 3027, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:52.523273 #train# step 3028, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:54.072138 #train# step 3029, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:55.619533 #train# step 3030, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:57.197865 #train# step 3031, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:58:58.750691 #train# step 3032, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:00.312727 #train# step 3033, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:01.842666 #train# step 3034, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:03.396784 #train# step 3035, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:04.951026 #train# step 3036, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:06.498774 #train# step 3037, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:08.049292 #train# step 3038, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:09.599835 #train# step 3039, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:11.166910 #train# step 3040, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:12.745625 #train# step 3041, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:14.304374 #train# step 3042, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:15.866738 #train# step 3043, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:17.426048 #train# step 3044, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:18.975235 #train# step 3045, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:20.545210 #train# step 3046, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:22.122677 #train# step 3047, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:23.676061 #train# step 3048, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:25.249123 #train# step 3049, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:26.786960 #train# step 3050, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:28.338993 #train# step 3051, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:29.874949 #train# step 3052, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:31.468216 #train# step 3053, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:33.039506 #train# step 3054, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:34.604185 #train# step 3055, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:36.171164 #train# step 3056, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:37.770892 #train# step 3057, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:39.331301 #train# step 3058, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:40.883158 #train# step 3059, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:42.433859 #train# step 3060, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:44.008678 #train# step 3061, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:45.615278 #train# step 3062, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:47.202565 #train# step 3063, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:48.785840 #train# step 3064, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:50.336763 #train# step 3065, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:51.875162 #train# step 3066, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:53.425174 #train# step 3067, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:55.005781 #train# step 3068, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:56.560075 #train# step 3069, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:58.153197 #train# step 3070, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 14:59:59.715577 #train# step 3071, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:01.286498 #train# step 3072, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:02.859305 #train# step 3073, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:04.407309 #train# step 3074, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:05.998913 #train# step 3075, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:07.527721 #train# step 3076, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:09.082919 #train# step 3077, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:10.635291 #train# step 3078, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:12.206734 #train# step 3079, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:13.745044 #train# step 3080, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:15.301806 #train# step 3081, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:16.882176 #train# step 3082, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:18.453663 #train# step 3083, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:19.988313 #train# step 3084, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:21.561375 #train# step 3085, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:23.097659 #train# step 3086, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:24.660998 #train# step 3087, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:26.200101 #train# step 3088, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:27.767051 #train# step 3089, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:29.363011 #train# step 3090, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:30.938109 #train# step 3091, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:32.515770 #train# step 3092, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:34.087134 #train# step 3093, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:35.614714 #train# step 3094, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:37.182496 #train# step 3095, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:38.730961 #train# step 3096, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:40.303429 #train# step 3097, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:41.858723 #train# step 3098, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:43.413827 #train# step 3099, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:45.003490 #train# step 3100, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:46.544268 #train# step 3101, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:48.081982 #train# step 3102, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:49.681860 #train# step 3103, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:51.263888 #train# step 3104, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:52.849410 #train# step 3105, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:54.412668 #train# step 3106, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:55.974676 #train# step 3107, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:57.553237 #train# step 3108, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:00:59.123934 #train# step 3109, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:00.686221 #train# step 3110, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:02.231085 #train# step 3111, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:03.837771 #train# step 3112, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:05.374486 #train# step 3113, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:06.962960 #train# step 3114, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:08.515428 #train# step 3115, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:10.087794 #train# step 3116, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:11.647656 #train# step 3117, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:13.229366 #train# step 3118, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:14.786914 #train# step 3119, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:16.317892 #train# step 3120, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:17.874990 #train# step 3121, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:19.453650 #train# step 3122, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:21.006154 #train# step 3123, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:22.573720 #train# step 3124, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:24.116278 #train# step 3125, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:25.655003 #train# step 3126, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:27.212556 #train# step 3127, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:28.764678 #train# step 3128, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:30.327019 #train# step 3129, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:31.844417 #train# step 3130, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:33.428087 #train# step 3131, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:35.020312 #train# step 3132, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:36.591970 #train# step 3133, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:38.122714 #train# step 3134, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:39.706840 #train# step 3135, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:41.244659 #train# step 3136, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:42.824645 #train# step 3137, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:44.363802 #train# step 3138, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:45.932141 #train# step 3139, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:47.457358 #train# step 3140, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:49.023101 #train# step 3141, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:50.568154 #train# step 3142, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:52.131195 #train# step 3143, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:53.727496 #train# step 3144, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:55.263481 #train# step 3145, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:56.832145 #train# step 3146, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:58.372271 #train# step 3147, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:01:59.908354 #train# step 3148, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:01.476926 #train# step 3149, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:03.064003 #train# step 3150, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:04.619995 #train# step 3151, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:06.203343 #train# step 3152, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:07.766412 #train# step 3153, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:09.347847 #train# step 3154, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:10.893607 #train# step 3155, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:12.447627 #train# step 3156, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:14.042400 #train# step 3157, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:15.593445 #train# step 3158, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:17.147797 #train# step 3159, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:18.711571 #train# step 3160, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:20.257944 #train# step 3161, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:21.827845 #train# step 3162, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:23.355262 #train# step 3163, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:24.895581 #train# step 3164, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:26.462900 #train# step 3165, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:28.035718 #train# step 3166, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:29.578010 #train# step 3167, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:31.150164 #train# step 3168, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:32.734361 #train# step 3169, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:34.303145 #train# step 3170, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:35.863211 #train# step 3171, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:37.413078 #train# step 3172, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:38.984875 #train# step 3173, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:40.570356 #train# step 3174, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:42.107568 #train# step 3175, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:43.680967 #train# step 3176, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:45.238447 #train# step 3177, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:46.817140 #train# step 3178, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:48.376988 #train# step 3179, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:49.951808 #train# step 3180, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:51.501026 #train# step 3181, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:53.090789 #train# step 3182, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:54.641312 #train# step 3183, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:56.187384 #train# step 3184, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:57.745484 #train# step 3185, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:02:59.307318 #train# step 3186, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:00.851323 #train# step 3187, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:02.418960 #train# step 3188, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:03.968758 #train# step 3189, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:05.512834 #train# step 3190, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:07.057218 #train# step 3191, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:08.595028 #train# step 3192, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:10.171504 #train# step 3193, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:11.737486 #train# step 3194, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:13.290726 #train# step 3195, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:14.850772 #train# step 3196, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:16.436531 #train# step 3197, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:17.998820 #train# step 3198, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:19.566568 #train# step 3199, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:21.103800 #train# step 3200, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:22.651757 #train# step 3201, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:24.202706 #train# step 3202, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:25.793220 #train# step 3203, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:27.373826 #train# step 3204, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:28.927384 #train# step 3205, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:30.514492 #train# step 3206, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:32.086583 #train# step 3207, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:33.647742 #train# step 3208, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:35.177763 #train# step 3209, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:36.745924 #train# step 3210, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:38.301035 #train# step 3211, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:39.853678 #train# step 3212, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:41.426446 #train# step 3213, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:42.986692 #train# step 3214, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:44.549116 #train# step 3215, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:46.101385 #train# step 3216, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:47.636299 #train# step 3217, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:49.188710 #train# step 3218, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:50.721157 #train# step 3219, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:52.273491 #train# step 3220, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:53.834396 #train# step 3221, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:55.366884 #train# step 3222, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:56.924904 #train# step 3223, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:03:58.487968 #train# step 3224, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:00.054834 #train# step 3225, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:01.613436 #train# step 3226, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:03.165265 #train# step 3227, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:04.698856 #train# step 3228, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:06.260224 #train# step 3229, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:07.827267 #train# step 3230, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:09.391415 #train# step 3231, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:10.977016 #train# step 3232, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:12.520128 #train# step 3233, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:14.088839 #train# step 3234, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:15.682400 #train# step 3235, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:17.243570 #train# step 3236, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:18.837476 #train# step 3237, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:20.418326 #train# step 3238, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:21.991553 #train# step 3239, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:23.539142 #train# step 3240, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:25.138581 #train# step 3241, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:26.684282 #train# step 3242, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:28.259520 #train# step 3243, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:29.828988 #train# step 3244, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:31.392939 #train# step 3245, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:32.926176 #train# step 3246, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:34.493108 #train# step 3247, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:36.059941 #train# step 3248, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:37.627921 #train# step 3249, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:39.195781 #train# step 3250, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:40.775026 #train# step 3251, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:42.303445 #train# step 3252, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:43.909457 #train# step 3253, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:45.448641 #train# step 3254, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:47.030167 #train# step 3255, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:48.626171 #train# step 3256, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:50.189952 #train# step 3257, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:51.763944 #train# step 3258, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:53.299132 #train# step 3259, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:54.842588 #train# step 3260, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:56.397702 #train# step 3261, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:57.987183 #train# step 3262, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:04:59.520017 #train# step 3263, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:01.092229 #train# step 3264, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:02.648874 #train# step 3265, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:04.206379 #train# step 3266, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:05.759311 #train# step 3267, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:07.353615 #train# step 3268, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:08.938892 #train# step 3269, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:10.528497 #train# step 3270, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:12.082061 #train# step 3271, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:13.632027 #train# step 3272, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:15.183232 #train# step 3273, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:16.756203 #train# step 3274, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:18.345085 #train# step 3275, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:19.911322 #train# step 3276, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:21.450602 #train# step 3277, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:23.008570 #train# step 3278, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:24.546311 #train# step 3279, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:26.072979 #train# step 3280, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:27.640320 #train# step 3281, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:29.242539 #train# step 3282, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:30.808466 #train# step 3283, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:32.322406 #train# step 3284, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:33.896056 #train# step 3285, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:35.442155 #train# step 3286, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:37.013068 #train# step 3287, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:38.531406 #train# step 3288, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:40.106143 #train# step 3289, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:41.649651 #train# step 3290, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:43.245517 #train# step 3291, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:44.792573 #train# step 3292, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:46.334611 #train# step 3293, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:47.899452 #train# step 3294, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:49.431023 #train# step 3295, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:50.980482 #train# step 3296, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:52.556342 #train# step 3297, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:54.109475 #train# step 3298, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:55.633788 #train# step 3299, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:57.160130 #train# step 3300, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:05:58.692099 #train# step 3301, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:00.269687 #train# step 3302, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:01.871858 #train# step 3303, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:03.448940 #train# step 3304, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:05.024015 #train# step 3305, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:06.588151 #train# step 3306, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:08.141223 #train# step 3307, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:09.718906 #train# step 3308, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:11.299810 #train# step 3309, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:12.829864 #train# step 3310, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:14.417695 #train# step 3311, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:16.008566 #train# step 3312, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:17.558951 #train# step 3313, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:19.070351 #train# step 3314, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:20.641897 #train# step 3315, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:22.195233 #train# step 3316, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:23.820373 #train# step 3317, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:25.375262 #train# step 3318, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:26.960528 #train# step 3319, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:28.518505 #train# step 3320, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:30.083993 #train# step 3321, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:31.674466 #train# step 3322, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:33.241872 #train# step 3323, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:34.803889 #train# step 3324, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:36.380222 #train# step 3325, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:37.931994 #train# step 3326, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:39.480097 #train# step 3327, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:41.001815 #train# step 3328, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:42.545102 #train# step 3329, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:44.142771 #train# step 3330, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:45.708134 #train# step 3331, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:47.270256 #train# step 3332, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:48.834911 #train# step 3333, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:50.417814 #train# step 3334, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:51.992700 #train# step 3335, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:53.541179 #train# step 3336, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:55.103442 #train# step 3337, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:56.687002 #train# step 3338, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:58.242088 #train# step 3339, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:06:59.808305 #train# step 3340, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:01.357159 #train# step 3341, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:02.957458 #train# step 3342, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:04.537472 #train# step 3343, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:06.116351 #train# step 3344, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:07.682001 #train# step 3345, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:09.255361 #train# step 3346, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:10.808803 #train# step 3347, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:12.352075 #train# step 3348, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:13.916680 #train# step 3349, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:15.450829 #train# step 3350, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:16.995363 #train# step 3351, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:18.563950 #train# step 3352, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:20.103726 #train# step 3353, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:21.672129 #train# step 3354, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:23.211920 #train# step 3355, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:24.763659 #train# step 3356, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:26.349571 #train# step 3357, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:27.891008 #train# step 3358, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:29.437407 #train# step 3359, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:30.962226 #train# step 3360, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:32.529974 #train# step 3361, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:34.076204 #train# step 3362, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:35.638399 #train# step 3363, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:37.190160 #train# step 3364, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:38.748322 #train# step 3365, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:40.317141 #train# step 3366, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:41.885326 #train# step 3367, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:43.436314 #train# step 3368, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:45.024811 #train# step 3369, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:46.568468 #train# step 3370, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:48.158172 #train# step 3371, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:49.704061 #train# step 3372, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:51.269794 #train# step 3373, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:52.826932 #train# step 3374, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:54.423826 #train# step 3375, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:55.992701 #train# step 3376, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:57.532340 #train# step 3377, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:07:59.128562 #train# step 3378, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:00.719141 #train# step 3379, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:02.260780 #train# step 3380, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:03.848889 #train# step 3381, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:05.424090 #train# step 3382, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:07.009343 #train# step 3383, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:08.538562 #train# step 3384, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:10.098036 #train# step 3385, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:11.661552 #train# step 3386, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:13.222867 #train# step 3387, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:14.778702 #train# step 3388, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:16.358077 #train# step 3389, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:17.896715 #train# step 3390, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:19.471176 #train# step 3391, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:21.039398 #train# step 3392, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:22.608652 #train# step 3393, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:24.172362 #train# step 3394, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:25.697771 #train# step 3395, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:27.270863 #train# step 3396, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:28.821237 #train# step 3397, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:30.369969 #train# step 3398, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:31.924783 #train# step 3399, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:33.518050 #train# step 3400, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:35.089122 #train# step 3401, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:36.637305 #train# step 3402, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:38.198897 #train# step 3403, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:39.763413 #train# step 3404, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:41.282874 #train# step 3405, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:42.827010 #train# step 3406, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:44.422189 #train# step 3407, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:45.982296 #train# step 3408, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:47.541699 #train# step 3409, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:49.099242 #train# step 3410, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:50.675352 #train# step 3411, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:52.290451 #train# step 3412, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:53.855540 #train# step 3413, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:55.400768 #train# step 3414, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:56.972715 #train# step 3415, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:08:58.546290 #train# step 3416, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:00.074239 #train# step 3417, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:01.633034 #train# step 3418, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:03.198243 #train# step 3419, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:04.752924 #train# step 3420, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:06.345066 #train# step 3421, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:07.889019 #train# step 3422, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:09.450798 #train# step 3423, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:11.034685 #train# step 3424, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:12.619017 #train# step 3425, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:14.171977 #train# step 3426, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:15.718594 #train# step 3427, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:17.274820 #train# step 3428, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:18.864393 #train# step 3429, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:20.433626 #train# step 3430, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:21.985308 #train# step 3431, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:23.520337 #train# step 3432, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:25.107686 #train# step 3433, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:26.678234 #train# step 3434, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:28.222320 #train# step 3435, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:29.796625 #train# step 3436, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:31.378032 #train# step 3437, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:32.917947 #train# step 3438, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:34.462689 #train# step 3439, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:36.038655 #train# step 3440, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:37.567978 #train# step 3441, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:39.151999 #train# step 3442, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:40.746926 #train# step 3443, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:42.279335 #train# step 3444, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:43.833804 #train# step 3445, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:45.408950 #train# step 3446, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:46.986567 #train# step 3447, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:48.561471 #train# step 3448, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:50.129883 #train# step 3449, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:51.729430 #train# step 3450, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:53.310803 #train# step 3451, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:54.854148 #train# step 3452, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:56.470344 #train# step 3453, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:58.078721 #train# step 3454, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:09:59.647620 #train# step 3455, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:01.205932 #train# step 3456, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:02.741316 #train# step 3457, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:04.269418 #train# step 3458, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:05.855883 #train# step 3459, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:07.440758 #train# step 3460, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:08.980686 #train# step 3461, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:10.525618 #train# step 3462, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:12.101763 #train# step 3463, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:13.646004 #train# step 3464, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:15.183181 #train# step 3465, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:16.716779 #train# step 3466, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:18.260229 #train# step 3467, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:19.797577 #train# step 3468, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:21.336668 #train# step 3469, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:22.876726 #train# step 3470, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:24.434981 #train# step 3471, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:26.007318 #train# step 3472, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:27.591219 #train# step 3473, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:29.124793 #train# step 3474, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:30.697004 #train# step 3475, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:32.244790 #train# step 3476, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:33.837953 #train# step 3477, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:35.387438 #train# step 3478, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:36.941314 #train# step 3479, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:38.498458 #train# step 3480, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:40.031820 #train# step 3481, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:41.595939 #train# step 3482, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:43.174195 #train# step 3483, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:44.757780 #train# step 3484, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:46.332786 #train# step 3485, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:47.920811 #train# step 3486, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:49.464161 #train# step 3487, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:51.008811 #train# step 3488, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:52.563220 #train# step 3489, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:54.135948 #train# step 3490, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:55.709651 #train# step 3491, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:57.260474 #train# step 3492, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:10:58.852186 #train# step 3493, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:00.441103 #train# step 3494, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:01.986476 #train# step 3495, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:03.547041 #train# step 3496, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:05.089149 #train# step 3497, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:06.633815 #train# step 3498, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:08.212236 #train# step 3499, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:09.766170 #train# step 3500, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:11.339558 #train# step 3501, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:12.898683 #train# step 3502, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:14.441695 #train# step 3503, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:15.992903 #train# step 3504, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:17.555319 #train# step 3505, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:19.132740 #train# step 3506, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:20.709349 #train# step 3507, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:22.295272 #train# step 3508, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:23.844492 #train# step 3509, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:25.406099 #train# step 3510, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:26.950684 #train# step 3511, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:28.510195 #train# step 3512, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:30.060996 #train# step 3513, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:31.607912 #train# step 3514, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:33.178423 #train# step 3515, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:34.764145 #train# step 3516, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:36.334529 #train# step 3517, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:37.909911 #train# step 3518, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:39.465017 #train# step 3519, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:40.980864 #train# step 3520, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:42.556861 #train# step 3521, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:44.102092 #train# step 3522, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:45.691436 #train# step 3523, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:47.254109 #train# step 3524, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:48.816625 #train# step 3525, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:50.383933 #train# step 3526, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:51.915329 #train# step 3527, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:53.456839 #train# step 3528, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:55.018764 #train# step 3529, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:56.588783 #train# step 3530, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:58.180233 #train# step 3531, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:11:59.769908 #train# step 3532, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:01.289231 #train# step 3533, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:02.839572 #train# step 3534, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:04.393061 #train# step 3535, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:05.951518 #train# step 3536, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:07.518789 #train# step 3537, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:09.108032 #train# step 3538, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:10.698428 #train# step 3539, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:12.234403 #train# step 3540, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:13.811969 #train# step 3541, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:15.405294 #train# step 3542, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:16.985991 #train# step 3543, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:18.543504 #train# step 3544, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:20.089895 #train# step 3545, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:21.636419 #train# step 3546, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:23.200904 #train# step 3547, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:24.754976 #train# step 3548, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:26.353128 #train# step 3549, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:27.935272 #train# step 3550, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:29.496099 #train# step 3551, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:31.076721 #train# step 3552, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:32.652333 #train# step 3553, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:34.211594 #train# step 3554, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:35.785867 #train# step 3555, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:37.303287 #train# step 3556, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:38.862499 #train# step 3557, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:40.409630 #train# step 3558, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:41.946884 #train# step 3559, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:43.496651 #train# step 3560, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:45.079460 #train# step 3561, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:46.681125 #train# step 3562, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:48.266943 #train# step 3563, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:49.838782 #train# step 3564, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:51.374852 #train# step 3565, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:52.923114 #train# step 3566, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:54.501850 #train# step 3567, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:56.040276 #train# step 3568, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:57.567409 #train# step 3569, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:12:59.131510 #train# step 3570, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:00.678839 #train# step 3571, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:02.242817 #train# step 3572, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:03.772082 #train# step 3573, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:05.315603 #train# step 3574, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:06.877388 #train# step 3575, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:08.417755 #train# step 3576, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:10.002091 #train# step 3577, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:11.560289 #train# step 3578, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:13.102315 #train# step 3579, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:14.682510 #train# step 3580, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:16.228538 #train# step 3581, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:17.787212 #train# step 3582, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:19.354817 #train# step 3583, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:20.969265 #train# step 3584, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:22.516928 #train# step 3585, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:24.085331 #train# step 3586, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:25.663229 #train# step 3587, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:27.210944 #train# step 3588, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:28.740130 #train# step 3589, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:30.321760 #train# step 3590, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:31.859280 #train# step 3591, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:33.423896 #train# step 3592, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:34.961863 #train# step 3593, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:36.541203 #train# step 3594, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:38.088821 #train# step 3595, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:39.641105 #train# step 3596, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:41.210151 #train# step 3597, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:42.780795 #train# step 3598, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:44.337092 #train# step 3599, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:45.914976 #train# step 3600, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:47.488216 #train# step 3601, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:49.049540 #train# step 3602, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:50.636942 #train# step 3603, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:52.170083 #train# step 3604, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:53.709434 #train# step 3605, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:55.261360 #train# step 3606, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:56.824684 #train# step 3607, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:58.393628 #train# step 3608, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:13:59.960735 #train# step 3609, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:01.482355 #train# step 3610, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:03.055636 #train# step 3611, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:04.645306 #train# step 3612, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:06.222082 #train# step 3613, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:07.834993 #train# step 3614, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:09.421135 #train# step 3615, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:10.989291 #train# step 3616, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:12.526909 #train# step 3617, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:14.105000 #train# step 3618, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:15.663893 #train# step 3619, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:17.218682 #train# step 3620, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:18.810452 #train# step 3621, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:20.344720 #train# step 3622, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:21.897355 #train# step 3623, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:23.470800 #train# step 3624, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:25.015360 #train# step 3625, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:26.590771 #train# step 3626, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:28.152071 #train# step 3627, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:29.671619 #train# step 3628, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:31.231202 #train# step 3629, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:32.787749 #train# step 3630, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:34.379723 #train# step 3631, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:35.949750 #train# step 3632, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:37.546640 #train# step 3633, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:39.109669 #train# step 3634, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:40.673907 #train# step 3635, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:42.223240 #train# step 3636, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:43.792136 #train# step 3637, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:45.353266 #train# step 3638, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:46.928870 #train# step 3639, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:48.468762 #train# step 3640, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:50.046634 #train# step 3641, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:51.607372 #train# step 3642, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:53.180916 #train# step 3643, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:54.717301 #train# step 3644, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:56.276091 #train# step 3645, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:57.856228 #train# step 3646, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:14:59.421222 #train# step 3647, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:00.997150 #train# step 3648, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:02.584095 #train# step 3649, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:04.120207 #train# step 3650, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:05.658370 #train# step 3651, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:07.183866 #train# step 3652, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:08.729411 #train# step 3653, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:10.266979 #train# step 3654, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:11.841906 #train# step 3655, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:13.439589 #train# step 3656, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:14.987564 #train# step 3657, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:16.568267 #train# step 3658, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:18.096451 #train# step 3659, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:19.659144 #train# step 3660, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:21.260345 #train# step 3661, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:22.831864 #train# step 3662, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:24.417443 #train# step 3663, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:25.965851 #train# step 3664, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:27.554903 #train# step 3665, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:29.105940 #train# step 3666, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:30.626823 #train# step 3667, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:32.195187 #train# step 3668, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:33.757862 #train# step 3669, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:35.308886 #train# step 3670, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:36.876843 #train# step 3671, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:38.431615 #train# step 3672, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:39.988580 #train# step 3673, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:41.538484 #train# step 3674, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:43.157858 #train# step 3675, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:44.721716 #train# step 3676, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:46.287475 #train# step 3677, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:47.864039 #train# step 3678, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:49.410928 #train# step 3679, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:50.977523 #train# step 3680, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:52.516767 #train# step 3681, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:54.114000 #train# step 3682, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:55.647812 #train# step 3683, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:57.228171 #train# step 3684, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:15:58.826286 #train# step 3685, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:00.385420 #train# step 3686, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:01.914152 #train# step 3687, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:03.466130 #train# step 3688, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:05.028687 #train# step 3689, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:06.581711 #train# step 3690, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:08.149028 #train# step 3691, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:09.726490 #train# step 3692, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:11.301456 #train# step 3693, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:12.849627 #train# step 3694, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:14.449860 #train# step 3695, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:16.002170 #train# step 3696, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:17.540491 #train# step 3697, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:19.095398 #train# step 3698, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:20.665164 #train# step 3699, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:22.219139 #train# step 3700, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:23.788246 #train# step 3701, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:25.363176 #train# step 3702, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:26.926967 #train# step 3703, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:28.487803 #train# step 3704, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:30.060437 #train# step 3705, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:31.632340 #train# step 3706, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:33.205817 #train# step 3707, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:34.745936 #train# step 3708, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:36.304083 #train# step 3709, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:37.902639 #train# step 3710, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:39.438378 #train# step 3711, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:40.997847 #train# step 3712, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:42.560506 #train# step 3713, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:44.128942 #train# step 3714, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:45.735675 #train# step 3715, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:47.304960 #train# step 3716, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:48.876007 #train# step 3717, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:50.421578 #train# step 3718, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:52.001597 #train# step 3719, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:53.581013 #train# step 3720, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:55.149178 #train# step 3721, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:56.707756 #train# step 3722, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:58.258657 #train# step 3723, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:16:59.807391 #train# step 3724, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:01.346666 #train# step 3725, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:02.887225 #train# step 3726, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:04.460894 #train# step 3727, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:06.002851 #train# step 3728, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:07.552557 #train# step 3729, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:09.167638 #train# step 3730, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:10.743812 #train# step 3731, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:12.316895 #train# step 3732, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:13.899528 #train# step 3733, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:15.490643 #train# step 3734, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:17.055150 #train# step 3735, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:18.595775 #train# step 3736, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:20.150477 #train# step 3737, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:21.712540 #train# step 3738, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:23.247094 #train# step 3739, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:24.811354 #train# step 3740, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:26.361017 #train# step 3741, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:27.910089 #train# step 3742, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:29.507586 #train# step 3743, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:31.055754 #train# step 3744, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:32.609850 #train# step 3745, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:34.153285 #train# step 3746, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:35.741273 #train# step 3747, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:37.315520 #train# step 3748, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:38.880913 #train# step 3749, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:40.430332 #train# step 3750, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:41.977783 #train# step 3751, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:43.541294 #train# step 3752, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:45.054613 #train# step 3753, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:46.580137 #train# step 3754, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:48.157337 #train# step 3755, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:49.735130 #train# step 3756, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:51.289013 #train# step 3757, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:52.836381 #train# step 3758, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:54.376112 #train# step 3759, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:55.948318 #train# step 3760, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:57.507099 #train# step 3761, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:17:59.038378 #train# step 3762, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:00.610696 #train# step 3763, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:02.176740 #train# step 3764, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:03.748018 #train# step 3765, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:05.274537 #train# step 3766, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:06.863344 #train# step 3767, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:08.464313 #train# step 3768, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:10.021291 #train# step 3769, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:11.579268 #train# step 3770, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:13.132589 #train# step 3771, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:14.704411 #train# step 3772, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:16.255059 #train# step 3773, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:17.843191 #train# step 3774, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:19.383275 #train# step 3775, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:20.941654 #train# step 3776, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:22.524070 #train# step 3777, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:24.077477 #train# step 3778, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:25.654783 #train# step 3779, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:27.191582 #train# step 3780, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:28.772774 #train# step 3781, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:30.341132 #train# step 3782, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:31.898022 #train# step 3783, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:33.456054 #train# step 3784, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:35.028240 #train# step 3785, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:36.619014 #train# step 3786, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:38.197521 #train# step 3787, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:39.755875 #train# step 3788, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:41.313598 #train# step 3789, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:42.858372 #train# step 3790, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:44.423140 #train# step 3791, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:45.978114 #train# step 3792, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:47.531249 #train# step 3793, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:49.081880 #train# step 3794, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:50.623625 #train# step 3795, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:52.170520 #train# step 3796, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:53.719387 #train# step 3797, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:55.283466 #train# step 3798, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:56.822825 #train# step 3799, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:58.357712 #train# step 3800, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:18:59.942512 #train# step 3801, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:01.521629 #train# step 3802, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:03.097234 #train# step 3803, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:04.659804 #train# step 3804, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:06.214036 #train# step 3805, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:07.786202 #train# step 3806, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:09.355105 #train# step 3807, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:10.909083 #train# step 3808, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:12.474073 #train# step 3809, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:14.030962 #train# step 3810, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:15.603698 #train# step 3811, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:17.177182 #train# step 3812, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:18.752263 #train# step 3813, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:20.310880 #train# step 3814, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:21.868678 #train# step 3815, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:23.414299 #train# step 3816, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:24.972299 #train# step 3817, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:26.548094 #train# step 3818, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:28.081056 #train# step 3819, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:29.642331 #train# step 3820, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:31.204429 #train# step 3821, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:32.770870 #train# step 3822, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:34.340098 #train# step 3823, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:35.910172 #train# step 3824, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:37.449956 #train# step 3825, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:38.996374 #train# step 3826, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:40.527737 #train# step 3827, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:42.109614 #train# step 3828, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:43.666556 #train# step 3829, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:45.264129 #train# step 3830, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:46.816813 #train# step 3831, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:48.377184 #train# step 3832, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:49.932987 #train# step 3833, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:51.508439 #train# step 3834, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:53.099609 #train# step 3835, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:54.669962 #train# step 3836, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:56.227002 #train# step 3837, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:57.768587 #train# step 3838, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:19:59.327148 #train# step 3839, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:00.889016 #train# step 3840, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:02.467249 #train# step 3841, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:04.023335 #train# step 3842, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:05.584554 #train# step 3843, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:07.123298 #train# step 3844, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:08.657701 #train# step 3845, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:10.224558 #train# step 3846, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:11.814430 #train# step 3847, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:13.386365 #train# step 3848, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:14.926169 #train# step 3849, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:16.514465 #train# step 3850, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:18.069529 #train# step 3851, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:19.645975 #train# step 3852, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:21.176980 #train# step 3853, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:22.728379 #train# step 3854, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:24.309449 #train# step 3855, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:25.872269 #train# step 3856, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:27.466177 #train# step 3857, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:29.037955 #train# step 3858, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:30.567410 #train# step 3859, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:32.112039 #train# step 3860, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:33.676582 #train# step 3861, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:35.238171 #train# step 3862, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:36.813557 #train# step 3863, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:38.374325 #train# step 3864, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:39.946606 #train# step 3865, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:41.528515 #train# step 3866, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:43.099577 #train# step 3867, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:44.670849 #train# step 3868, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:46.257395 #train# step 3869, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:47.793801 #train# step 3870, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:49.366792 #train# step 3871, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:50.919099 #train# step 3872, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:52.494927 #train# step 3873, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:54.055611 #train# step 3874, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:55.612628 #train# step 3875, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:57.188851 #train# step 3876, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:20:58.752178 #train# step 3877, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:00.319890 #train# step 3878, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:01.885481 #train# step 3879, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:03.459204 #train# step 3880, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:05.018716 #train# step 3881, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:06.607003 #train# step 3882, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:08.165059 #train# step 3883, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:09.698912 #train# step 3884, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:11.270279 #train# step 3885, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:12.824583 #train# step 3886, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:14.385238 #train# step 3887, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:15.935588 #train# step 3888, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:17.484830 #train# step 3889, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:19.052250 #train# step 3890, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:20.602024 #train# step 3891, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:22.170770 #train# step 3892, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:23.719579 #train# step 3893, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:25.291238 #train# step 3894, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:26.805312 #train# step 3895, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:28.372457 #train# step 3896, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:29.911756 #train# step 3897, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:31.463866 #train# step 3898, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:33.050866 #train# step 3899, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:34.610656 #train# step 3900, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:36.174960 #train# step 3901, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:37.734946 #train# step 3902, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:39.310008 #train# step 3903, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:40.859532 #train# step 3904, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:42.423918 #train# step 3905, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:44.003617 #train# step 3906, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:45.559180 #train# step 3907, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:47.139858 #train# step 3908, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:48.699388 #train# step 3909, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:50.275353 #train# step 3910, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:51.815868 #train# step 3911, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:53.378390 #train# step 3912, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:54.937539 #train# step 3913, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:56.474268 #train# step 3914, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:58.034265 #train# step 3915, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:21:59.616636 #train# step 3916, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:01.180355 #train# step 3917, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:02.757544 #train# step 3918, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:04.296566 #train# step 3919, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:05.868004 #train# step 3920, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:07.416608 #train# step 3921, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:08.991461 #train# step 3922, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:10.543969 #train# step 3923, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:12.076053 #train# step 3924, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:13.629485 #train# step 3925, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:15.190276 #train# step 3926, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:16.771246 #train# step 3927, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:18.338397 #train# step 3928, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:19.888186 #train# step 3929, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:21.444946 #train# step 3930, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:23.006390 #train# step 3931, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:24.570562 #train# step 3932, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:26.144352 #train# step 3933, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:27.753379 #train# step 3934, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:29.342358 #train# step 3935, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:30.908159 #train# step 3936, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:32.503274 #train# step 3937, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:34.065027 #train# step 3938, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:35.608749 #train# step 3939, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:37.183774 #train# step 3940, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:38.728038 #train# step 3941, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:40.296739 #train# step 3942, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:41.840591 #train# step 3943, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:43.398566 #train# step 3944, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:44.964139 #train# step 3945, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:46.509886 #train# step 3946, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:48.056049 #train# step 3947, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:49.581683 #train# step 3948, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:51.122111 #train# step 3949, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:52.706926 #train# step 3950, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:54.277192 #train# step 3951, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:55.818465 #train# step 3952, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:57.371610 #train# step 3953, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:22:58.941579 #train# step 3954, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:00.506129 #train# step 3955, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:02.084891 #train# step 3956, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:03.638380 #train# step 3957, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:05.165557 #train# step 3958, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:06.735187 #train# step 3959, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:08.293181 #train# step 3960, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:09.858556 #train# step 3961, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:11.442949 #train# step 3962, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:13.016019 #train# step 3963, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:14.586154 #train# step 3964, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:16.155708 #train# step 3965, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:17.700026 #train# step 3966, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:19.255605 #train# step 3967, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:20.811456 #train# step 3968, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:22.380484 #train# step 3969, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:23.921296 #train# step 3970, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:25.518191 #train# step 3971, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:27.107492 #train# step 3972, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:28.699130 #train# step 3973, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:30.267590 #train# step 3974, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:31.798332 #train# step 3975, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:33.357438 #train# step 3976, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:34.947858 #train# step 3977, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:36.501768 #train# step 3978, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:38.075151 #train# step 3979, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:39.644814 #train# step 3980, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:41.195140 #train# step 3981, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:42.770856 #train# step 3982, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:44.359327 #train# step 3983, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:45.877486 #train# step 3984, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:47.410092 #train# step 3985, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:49.003082 #train# step 3986, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:50.588423 #train# step 3987, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:52.167789 #train# step 3988, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:53.724817 #train# step 3989, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:55.244629 #train# step 3990, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:56.786264 #train# step 3991, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:58.348199 #train# step 3992, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:23:59.911796 #train# step 3993, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:01.499833 #train# step 3994, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:03.041656 #train# step 3995, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:04.623616 #train# step 3996, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:06.231961 #train# step 3997, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:07.801907 #train# step 3998, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:09.386226 #train# step 3999, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:10.942141 #train# step 4000, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:12.497812 #train# step 4001, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:14.059533 #train# step 4002, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:15.650331 #train# step 4003, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:17.190265 #train# step 4004, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:18.766811 #train# step 4005, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:20.313517 #train# step 4006, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:21.863400 #train# step 4007, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:23.434431 #train# step 4008, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:25.019467 #train# step 4009, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:26.576304 #train# step 4010, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:28.141091 #train# step 4011, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:29.706896 #train# step 4012, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:31.233612 #train# step 4013, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:32.826936 #train# step 4014, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:34.393313 #train# step 4015, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:35.964519 #train# step 4016, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:37.463831 #train# step 4017, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:39.028053 #train# step 4018, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:40.581381 #train# step 4019, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:42.142974 #train# step 4020, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:43.723140 #train# step 4021, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:45.326862 #train# step 4022, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:46.865639 #train# step 4023, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:48.420219 #train# step 4024, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:49.979573 #train# step 4025, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:51.540735 #train# step 4026, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:53.101455 #train# step 4027, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:54.668239 #train# step 4028, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:56.238624 #train# step 4029, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:57.804151 #train# step 4030, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:24:59.347592 #train# step 4031, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:00.920854 #train# step 4032, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:02.470563 #train# step 4033, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:04.046784 #train# step 4034, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:05.600857 #train# step 4035, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:07.142940 #train# step 4036, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:08.698811 #train# step 4037, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:10.238756 #train# step 4038, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:11.812288 #train# step 4039, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:13.379542 #train# step 4040, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:14.910228 #train# step 4041, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:16.493175 #train# step 4042, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:18.042658 #train# step 4043, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:19.585496 #train# step 4044, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:21.138838 #train# step 4045, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:22.675453 #train# step 4046, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:24.241754 #train# step 4047, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:25.794475 #train# step 4048, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:27.336997 #train# step 4049, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:28.867397 #train# step 4050, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:30.420143 #train# step 4051, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:31.939691 #train# step 4052, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:33.462280 #train# step 4053, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:35.006474 #train# step 4054, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:36.559853 #train# step 4055, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:38.142474 #train# step 4056, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:39.720931 #train# step 4057, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:41.281291 #train# step 4058, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:42.859883 #train# step 4059, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:44.421400 #train# step 4060, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:46.009647 #train# step 4061, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:47.563494 #train# step 4062, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:49.097918 #train# step 4063, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:50.634790 #train# step 4064, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:52.206147 #train# step 4065, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:53.780935 #train# step 4066, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:55.360342 #train# step 4067, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:56.915561 #train# step 4068, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:25:58.461686 #train# step 4069, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:00.060451 #train# step 4070, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:01.644047 #train# step 4071, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:03.234710 #train# step 4072, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:04.845614 #train# step 4073, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:06.440396 #train# step 4074, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:07.992343 #train# step 4075, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:09.579671 #train# step 4076, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:11.138890 #train# step 4077, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:12.708641 #train# step 4078, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:14.263247 #train# step 4079, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:15.814630 #train# step 4080, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:17.384463 #train# step 4081, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:18.963915 #train# step 4082, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:20.535036 #train# step 4083, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:22.110382 #train# step 4084, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:23.680340 #train# step 4085, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:25.236064 #train# step 4086, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:26.813375 #train# step 4087, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:28.368159 #train# step 4088, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:29.916535 #train# step 4089, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:31.511359 #train# step 4090, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:33.093749 #train# step 4091, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:34.635272 #train# step 4092, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:36.192985 #train# step 4093, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:37.730613 #train# step 4094, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:39.334426 #train# step 4095, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:40.879548 #train# step 4096, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:42.425487 #train# step 4097, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:43.975083 #train# step 4098, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:45.542774 #train# step 4099, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:47.087299 #train# step 4100, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:48.662371 #train# step 4101, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:50.219608 #train# step 4102, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:51.774276 #train# step 4103, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:53.338680 #train# step 4104, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:54.880856 #train# step 4105, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:56.445450 #train# step 4106, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:57.992393 #train# step 4107, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:26:59.549200 #train# step 4108, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:01.145655 #train# step 4109, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:02.696240 #train# step 4110, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:04.279324 #train# step 4111, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:05.856936 #train# step 4112, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:07.424398 #train# step 4113, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:08.973317 #train# step 4114, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:10.537734 #train# step 4115, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:12.104367 #train# step 4116, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:13.649202 #train# step 4117, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:15.197824 #train# step 4118, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:16.772649 #train# step 4119, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:18.316200 #train# step 4120, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:19.861587 #train# step 4121, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:21.395932 #train# step 4122, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:22.959888 #train# step 4123, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:24.496988 #train# step 4124, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:26.068569 #train# step 4125, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:27.624673 #train# step 4126, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:29.203623 #train# step 4127, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:30.769674 #train# step 4128, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:32.324601 #train# step 4129, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:33.884324 #train# step 4130, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:35.463440 #train# step 4131, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:37.016010 #train# step 4132, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:38.579878 #train# step 4133, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:40.148272 #train# step 4134, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:41.743415 #train# step 4135, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:43.321109 #train# step 4136, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:44.880367 #train# step 4137, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:46.445485 #train# step 4138, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:48.012032 #train# step 4139, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:49.543101 #train# step 4140, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:51.089862 #train# step 4141, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:52.674638 #train# step 4142, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:54.231283 #train# step 4143, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:55.841049 #train# step 4144, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:57.409859 #train# step 4145, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:27:58.980991 #train# step 4146, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:00.556253 #train# step 4147, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:02.106941 #train# step 4148, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:03.658014 #train# step 4149, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:05.200631 #train# step 4150, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:06.779303 #train# step 4151, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:08.341126 #train# step 4152, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:09.919157 #train# step 4153, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:11.481595 #train# step 4154, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:13.015477 #train# step 4155, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:14.572070 #train# step 4156, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:16.124011 #train# step 4157, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:17.689069 #train# step 4158, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:19.255488 #train# step 4159, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:20.809289 #train# step 4160, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:22.385082 #train# step 4161, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:23.972607 #train# step 4162, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:25.531577 #train# step 4163, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:27.101178 #train# step 4164, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:28.652450 #train# step 4165, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:30.220730 #train# step 4166, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:31.780193 #train# step 4167, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:33.327229 #train# step 4168, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:34.859654 #train# step 4169, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:36.418397 #train# step 4170, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:37.955293 #train# step 4171, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:39.525663 #train# step 4172, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:41.092166 #train# step 4173, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:42.629552 #train# step 4174, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:44.163657 #train# step 4175, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:45.713641 #train# step 4176, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:47.288472 #train# step 4177, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:48.859033 #train# step 4178, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:50.432472 #train# step 4179, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:51.991435 #train# step 4180, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:53.550297 #train# step 4181, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:55.145653 #train# step 4182, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:56.726994 #train# step 4183, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:58.320647 #train# step 4184, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:28:59.869831 #train# step 4185, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:01.447789 #train# step 4186, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:03.006151 #train# step 4187, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:04.581927 #train# step 4188, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:06.173584 #train# step 4189, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:07.708162 #train# step 4190, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:09.277887 #train# step 4191, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:10.877546 #train# step 4192, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:12.428440 #train# step 4193, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:13.998082 #train# step 4194, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:15.561501 #train# step 4195, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:17.099884 #train# step 4196, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:18.638047 #train# step 4197, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:20.170316 #train# step 4198, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:21.728974 #train# step 4199, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:23.309266 #train# step 4200, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:24.874113 #train# step 4201, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:26.437606 #train# step 4202, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:27.976492 #train# step 4203, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:29.594695 #train# step 4204, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:31.173306 #train# step 4205, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:32.745052 #train# step 4206, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:34.261603 #train# step 4207, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:35.823772 #train# step 4208, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:37.369506 #train# step 4209, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:38.924636 #train# step 4210, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:40.496964 #train# step 4211, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:42.056459 #train# step 4212, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:43.602551 #train# step 4213, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:45.169031 #train# step 4214, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:46.721201 #train# step 4215, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:48.252371 #train# step 4216, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:49.829966 #train# step 4217, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:51.381642 #train# step 4218, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:52.965805 #train# step 4219, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:54.513883 #train# step 4220, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:56.072538 #train# step 4221, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:57.674204 #train# step 4222, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:29:59.215171 #train# step 4223, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:00.773963 #train# step 4224, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:02.357986 #train# step 4225, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:03.947012 #train# step 4226, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:05.502723 #train# step 4227, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:07.035693 #train# step 4228, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:08.584105 #train# step 4229, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:10.175045 #train# step 4230, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:11.744167 #train# step 4231, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:13.312545 #train# step 4232, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:14.883869 #train# step 4233, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:16.451086 #train# step 4234, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:18.013320 #train# step 4235, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:19.568577 #train# step 4236, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:21.144425 #train# step 4237, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:22.726429 #train# step 4238, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:24.277776 #train# step 4239, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:25.835016 #train# step 4240, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:27.438044 #train# step 4241, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:29.009031 #train# step 4242, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:30.561924 #train# step 4243, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:32.108840 #train# step 4244, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:33.655112 #train# step 4245, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:35.185319 #train# step 4246, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:36.716570 #train# step 4247, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:38.299646 #train# step 4248, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:39.865305 #train# step 4249, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:41.391466 #train# step 4250, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:42.962179 #train# step 4251, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:44.531530 #train# step 4252, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:46.092948 #train# step 4253, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:47.663320 #train# step 4254, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:49.228607 #train# step 4255, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:50.780747 #train# step 4256, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:52.353672 #train# step 4257, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:53.914410 #train# step 4258, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:55.471978 #train# step 4259, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:57.026426 #train# step 4260, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:30:58.577963 #train# step 4261, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:00.132392 #train# step 4262, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:01.693781 #train# step 4263, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:03.250704 #train# step 4264, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:04.828514 #train# step 4265, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:06.404528 #train# step 4266, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:08.019016 #train# step 4267, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:09.575686 #train# step 4268, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:11.143248 #train# step 4269, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:12.705189 #train# step 4270, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:14.256476 #train# step 4271, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:15.833664 #train# step 4272, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:17.391393 #train# step 4273, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:18.976562 #train# step 4274, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:20.515945 #train# step 4275, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:22.087778 #train# step 4276, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:23.627940 #train# step 4277, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:25.165182 #train# step 4278, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:26.720323 #train# step 4279, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:28.279378 #train# step 4280, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:29.842308 #train# step 4281, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:31.340040 #train# step 4282, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:32.874219 #train# step 4283, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:34.420196 #train# step 4284, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:35.991484 #train# step 4285, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:37.538500 #train# step 4286, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:39.126367 #train# step 4287, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:40.687909 #train# step 4288, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:42.228307 #train# step 4289, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:43.777702 #train# step 4290, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:45.318267 #train# step 4291, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:46.876571 #train# step 4292, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:48.410157 #train# step 4293, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:50.018138 #train# step 4294, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:51.578248 #train# step 4295, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:53.158259 #train# step 4296, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:54.718786 #train# step 4297, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:56.311364 #train# step 4298, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:57.887374 #train# step 4299, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:31:59.466535 #train# step 4300, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:01.014915 #train# step 4301, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:02.594813 #train# step 4302, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:04.177458 #train# step 4303, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:05.744265 #train# step 4304, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:07.323284 #train# step 4305, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:08.889178 #train# step 4306, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:10.434582 #train# step 4307, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:11.995597 #train# step 4308, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:13.585507 #train# step 4309, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:15.169071 #train# step 4310, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:16.706732 #train# step 4311, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:18.285071 #train# step 4312, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:19.862081 #train# step 4313, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:21.428693 #train# step 4314, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:22.970593 #train# step 4315, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:24.522353 #train# step 4316, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:26.070572 #train# step 4317, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:27.664749 #train# step 4318, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:29.248152 #train# step 4319, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:30.810268 #train# step 4320, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:32.381979 #train# step 4321, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:33.965542 #train# step 4322, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:35.522754 #train# step 4323, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:37.109251 #train# step 4324, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:38.649290 #train# step 4325, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:40.184966 #train# step 4326, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:41.747613 #train# step 4327, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:43.302473 #train# step 4328, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:44.852687 #train# step 4329, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:46.386420 #train# step 4330, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:47.954289 #train# step 4331, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:49.531592 #train# step 4332, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:51.110061 #train# step 4333, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:52.671912 #train# step 4334, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:54.256686 #train# step 4335, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:55.815906 #train# step 4336, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:57.361176 #train# step 4337, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:32:58.931195 #train# step 4338, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:00.484504 #train# step 4339, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:02.058325 #train# step 4340, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:03.629694 #train# step 4341, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:05.200646 #train# step 4342, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:06.758060 #train# step 4343, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:08.307447 #train# step 4344, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:09.862663 #train# step 4345, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:11.417577 #train# step 4346, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:13.009193 #train# step 4347, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:14.565350 #train# step 4348, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:16.110862 #train# step 4349, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:17.681398 #train# step 4350, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:19.258989 #train# step 4351, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:20.832469 #train# step 4352, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:22.418571 #train# step 4353, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:23.993229 #train# step 4354, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:25.567900 #train# step 4355, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:27.109057 #train# step 4356, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:28.664177 #train# step 4357, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:30.249904 #train# step 4358, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:31.838042 #train# step 4359, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:33.420203 #train# step 4360, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:34.970372 #train# step 4361, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:36.531207 #train# step 4362, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:38.104471 #train# step 4363, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:39.667452 #train# step 4364, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:41.263407 #train# step 4365, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:42.812553 #train# step 4366, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:44.380329 #train# step 4367, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:45.937504 #train# step 4368, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:47.491562 #train# step 4369, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:49.049548 #train# step 4370, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:50.594582 #train# step 4371, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:52.158441 #train# step 4372, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:53.713560 #train# step 4373, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:55.276498 #train# step 4374, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:56.842841 #train# step 4375, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:58.390547 #train# step 4376, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:33:59.953789 #train# step 4377, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:01.528836 #train# step 4378, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:03.128799 #train# step 4379, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:04.716695 #train# step 4380, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:06.268213 #train# step 4381, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:07.840211 #train# step 4382, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:09.402050 #train# step 4383, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:10.987534 #train# step 4384, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:12.557457 #train# step 4385, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:14.150015 #train# step 4386, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:15.747117 #train# step 4387, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:17.305497 #train# step 4388, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:18.845064 #train# step 4389, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:20.419206 #train# step 4390, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:21.974102 #train# step 4391, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:23.546679 #train# step 4392, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:25.105969 #train# step 4393, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:26.673148 #train# step 4394, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:28.243621 #train# step 4395, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:29.791417 #train# step 4396, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:31.357187 #train# step 4397, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:32.890360 #train# step 4398, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:34.423563 #train# step 4399, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:36.019386 #train# step 4400, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:37.581993 #train# step 4401, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:39.142499 #train# step 4402, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:40.719343 #train# step 4403, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:42.289847 #train# step 4404, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:43.857923 #train# step 4405, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:45.433773 #train# step 4406, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:46.988204 #train# step 4407, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:48.529908 #train# step 4408, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:50.071451 #train# step 4409, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:51.619782 #train# step 4410, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:53.221457 #train# step 4411, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:54.781511 #train# step 4412, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:56.362147 #train# step 4413, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:57.917552 #train# step 4414, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:34:59.456827 #train# step 4415, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:01.016907 #train# step 4416, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:02.570503 #train# step 4417, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:04.114758 #train# step 4418, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:05.693592 #train# step 4419, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:07.257537 #train# step 4420, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:08.830735 #train# step 4421, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:10.404823 #train# step 4422, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:12.023943 #train# step 4423, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:13.595754 #train# step 4424, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:15.173543 #train# step 4425, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:16.740678 #train# step 4426, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:18.295055 #train# step 4427, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:19.851513 #train# step 4428, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:21.436558 #train# step 4429, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:22.965401 #train# step 4430, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:24.544439 #train# step 4431, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:26.092036 #train# step 4432, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:27.660697 #train# step 4433, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:29.234824 #train# step 4434, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:30.795950 #train# step 4435, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:32.380329 #train# step 4436, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:33.948501 #train# step 4437, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:35.533131 #train# step 4438, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:37.115132 #train# step 4439, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:38.709190 #train# step 4440, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:40.230769 #train# step 4441, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:41.779235 #train# step 4442, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:43.318061 #train# step 4443, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:44.904392 #train# step 4444, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:46.450356 #train# step 4445, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:47.980370 #train# step 4446, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:49.547082 #train# step 4447, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:51.087584 #train# step 4448, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:52.642928 #train# step 4449, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:54.222584 #train# step 4450, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:55.799936 #train# step 4451, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:57.338474 #train# step 4452, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:35:58.876860 #train# step 4453, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:00.428983 #train# step 4454, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:01.990650 #train# step 4455, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:03.554462 #train# step 4456, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:05.113944 #train# step 4457, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:06.708199 #train# step 4458, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:08.252562 #train# step 4459, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:09.789268 #train# step 4460, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:11.348891 #train# step 4461, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:12.897681 #train# step 4462, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:14.457962 #train# step 4463, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:16.019921 #train# step 4464, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:17.604672 #train# step 4465, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:19.209090 #train# step 4466, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:20.737985 #train# step 4467, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:22.322727 #train# step 4468, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:23.856641 #train# step 4469, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:25.414221 #train# step 4470, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:26.970664 #train# step 4471, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:28.553949 #train# step 4472, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:30.143469 #train# step 4473, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:31.682463 #train# step 4474, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:33.245373 #train# step 4475, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:34.824514 #train# step 4476, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:36.381444 #train# step 4477, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:37.944599 #train# step 4478, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:39.532169 #train# step 4479, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:41.076830 #train# step 4480, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:42.664180 #train# step 4481, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:44.237380 #train# step 4482, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:45.814464 #train# step 4483, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:47.351690 #train# step 4484, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:48.910776 #train# step 4485, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:50.502704 #train# step 4486, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:52.068442 #train# step 4487, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:53.609482 #train# step 4488, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:55.152415 #train# step 4489, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:56.709128 #train# step 4490, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:58.251269 #train# step 4491, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:36:59.828845 #train# step 4492, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:01.394953 #train# step 4493, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:02.941907 #train# step 4494, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:04.499083 #train# step 4495, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:06.056107 #train# step 4496, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:07.610964 #train# step 4497, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:09.194140 #train# step 4498, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:10.756964 #train# step 4499, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:12.329270 #train# step 4500, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:13.893272 #train# step 4501, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:15.438388 #train# step 4502, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:17.005528 #train# step 4503, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:18.597807 #train# step 4504, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:20.157027 #train# step 4505, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:21.724645 #train# step 4506, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:23.260421 #train# step 4507, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:24.824952 #train# step 4508, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:26.355377 #train# step 4509, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:27.939800 #train# step 4510, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:29.475071 #train# step 4511, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:31.037028 #train# step 4512, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:32.620312 #train# step 4513, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:34.184621 #train# step 4514, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:35.754734 #train# step 4515, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:37.318318 #train# step 4516, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:38.862045 #train# step 4517, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:40.436744 #train# step 4518, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:42.013682 #train# step 4519, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:43.580341 #train# step 4520, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:45.120852 #train# step 4521, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:46.662364 #train# step 4522, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:48.230880 #train# step 4523, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:49.788380 #train# step 4524, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:51.331674 #train# step 4525, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:52.906844 #train# step 4526, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:54.487242 #train# step 4527, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:56.028622 #train# step 4528, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:57.573983 #train# step 4529, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:37:59.139071 #train# step 4530, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:00.692918 #train# step 4531, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:02.266602 #train# step 4532, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:03.823652 #train# step 4533, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:05.407612 #train# step 4534, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:06.957619 #train# step 4535, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:08.505580 #train# step 4536, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:10.092788 #train# step 4537, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:11.638583 #train# step 4538, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:13.194960 #train# step 4539, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:14.724083 #train# step 4540, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:16.285900 #train# step 4541, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:17.843789 #train# step 4542, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:19.401683 #train# step 4543, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:20.974511 #train# step 4544, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:22.563384 #train# step 4545, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:24.128756 #train# step 4546, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:25.680852 #train# step 4547, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:27.254477 #train# step 4548, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:28.834851 #train# step 4549, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:30.397623 #train# step 4550, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:31.951517 #train# step 4551, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:33.525227 #train# step 4552, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:35.096209 #train# step 4553, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:36.676426 #train# step 4554, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:38.275430 #train# step 4555, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:39.828044 #train# step 4556, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:41.396833 #train# step 4557, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:42.949630 #train# step 4558, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:44.509052 #train# step 4559, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:46.041790 #train# step 4560, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:47.615687 #train# step 4561, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:49.156425 #train# step 4562, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:50.714162 #train# step 4563, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:52.280771 #train# step 4564, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:53.860108 #train# step 4565, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:55.420325 #train# step 4566, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:56.998429 #train# step 4567, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:38:58.579613 #train# step 4568, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:00.139953 #train# step 4569, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:01.719337 #train# step 4570, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:03.227587 #train# step 4571, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:04.806869 #train# step 4572, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:06.356818 #train# step 4573, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:07.933230 #train# step 4574, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:09.511356 #train# step 4575, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:11.094575 #train# step 4576, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:12.672704 #train# step 4577, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:14.245189 #train# step 4578, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:15.787411 #train# step 4579, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:17.351418 #train# step 4580, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:18.933209 #train# step 4581, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:20.495751 #train# step 4582, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:22.066630 #train# step 4583, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:23.634792 #train# step 4584, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:25.182665 #train# step 4585, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:26.767022 #train# step 4586, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:28.341709 #train# step 4587, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:29.885944 #train# step 4588, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:31.416908 #train# step 4589, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:32.998319 #train# step 4590, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:34.558729 #train# step 4591, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:36.105657 #train# step 4592, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:37.692241 #train# step 4593, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:39.271162 #train# step 4594, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:40.840564 #train# step 4595, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:42.416796 #train# step 4596, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:44.025948 #train# step 4597, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:45.614395 #train# step 4598, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:47.182824 #train# step 4599, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:48.734340 #train# step 4600, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:50.290418 #train# step 4601, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:51.860263 #train# step 4602, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:53.422395 #train# step 4603, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:54.954913 #train# step 4604, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:56.507363 #train# step 4605, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:58.036195 #train# step 4606, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:39:59.580891 #train# step 4607, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:01.123216 #train# step 4608, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:02.704783 #train# step 4609, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:04.292090 #train# step 4610, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:05.823795 #train# step 4611, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:07.368973 #train# step 4612, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:08.935395 #train# step 4613, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:10.498030 #train# step 4614, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:12.044648 #train# step 4615, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:13.606612 #train# step 4616, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:15.179281 #train# step 4617, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:16.749111 #train# step 4618, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:18.331421 #train# step 4619, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:19.896527 #train# step 4620, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:21.454265 #train# step 4621, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:23.031803 #train# step 4622, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:24.568086 #train# step 4623, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:26.141791 #train# step 4624, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:27.723080 #train# step 4625, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:29.273178 #train# step 4626, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:30.824904 #train# step 4627, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:32.386855 #train# step 4628, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:33.954359 #train# step 4629, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:35.521018 #train# step 4630, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:37.084254 #train# step 4631, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:38.613643 #train# step 4632, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:40.132476 #train# step 4633, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:41.699096 #train# step 4634, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:43.281759 #train# step 4635, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:44.833030 #train# step 4636, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:46.411685 #train# step 4637, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:47.988707 #train# step 4638, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:49.527311 #train# step 4639, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:51.121190 #train# step 4640, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:52.711063 #train# step 4641, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:54.238510 #train# step 4642, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:55.770228 #train# step 4643, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:57.328307 #train# step 4644, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:40:58.884327 #train# step 4645, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:00.441167 #train# step 4646, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:02.043540 #train# step 4647, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:03.602777 #train# step 4648, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:05.153339 #train# step 4649, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:06.740514 #train# step 4650, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:08.315290 #train# step 4651, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:09.883781 #train# step 4652, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:11.450272 #train# step 4653, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:13.017981 #train# step 4654, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:14.572330 #train# step 4655, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:16.131121 #train# step 4656, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:17.667260 #train# step 4657, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:19.265245 #train# step 4658, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:20.820183 #train# step 4659, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:22.380211 #train# step 4660, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:23.959544 #train# step 4661, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:25.503875 #train# step 4662, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:27.059597 #train# step 4663, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:28.620334 #train# step 4664, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:30.154604 #train# step 4665, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:31.720485 #train# step 4666, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:33.290163 #train# step 4667, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:34.858120 #train# step 4668, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:36.394126 #train# step 4669, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:37.959023 #train# step 4670, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:39.532241 #train# step 4671, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:41.071386 #train# step 4672, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:42.615780 #train# step 4673, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:44.157940 #train# step 4674, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:45.715527 #train# step 4675, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:47.321755 #train# step 4676, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:48.863670 #train# step 4677, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:50.409436 #train# step 4678, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:51.982186 #train# step 4679, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:53.536468 #train# step 4680, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:55.119340 #train# step 4681, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:56.678892 #train# step 4682, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:58.230083 #train# step 4683, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:41:59.836282 #train# step 4684, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:01.409684 #train# step 4685, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:02.994315 #train# step 4686, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:04.588271 #train# step 4687, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:06.199276 #train# step 4688, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:07.743001 #train# step 4689, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:09.310535 #train# step 4690, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:10.879577 #train# step 4691, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:12.429625 #train# step 4692, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:14.019064 #train# step 4693, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:15.581851 #train# step 4694, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:17.148255 #train# step 4695, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:18.687347 #train# step 4696, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:20.210088 #train# step 4697, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:21.756827 #train# step 4698, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:23.322766 #train# step 4699, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:24.893110 #train# step 4700, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:26.465884 #train# step 4701, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:28.016874 #train# step 4702, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:29.547810 #train# step 4703, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:31.089883 #train# step 4704, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:32.637083 #train# step 4705, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:34.230084 #train# step 4706, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:35.796582 #train# step 4707, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:37.376252 #train# step 4708, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:38.957070 #train# step 4709, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:40.530384 #train# step 4710, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:42.051883 #train# step 4711, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:43.620667 #train# step 4712, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:45.192871 #train# step 4713, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:46.754946 #train# step 4714, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:48.323344 #train# step 4715, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:49.889002 #train# step 4716, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:51.436624 #train# step 4717, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:53.013700 #train# step 4718, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:54.574823 #train# step 4719, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:56.122618 #train# step 4720, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:57.670553 #train# step 4721, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:42:59.266946 #train# step 4722, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:00.830874 #train# step 4723, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:02.378909 #train# step 4724, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:03.903919 #train# step 4725, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:05.470399 #train# step 4726, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:07.041038 #train# step 4727, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:08.580703 #train# step 4728, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:10.160137 #train# step 4729, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:11.710258 #train# step 4730, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:13.257397 #train# step 4731, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:14.827729 #train# step 4732, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:16.392255 #train# step 4733, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:17.962953 #train# step 4734, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:19.499820 #train# step 4735, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:21.084599 #train# step 4736, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:22.662034 #train# step 4737, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:24.224811 #train# step 4738, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:25.795453 #train# step 4739, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:27.328460 #train# step 4740, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:28.873825 #train# step 4741, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:30.428013 #train# step 4742, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:32.012558 #train# step 4743, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:33.578780 #train# step 4744, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:35.192778 #train# step 4745, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:36.776838 #train# step 4746, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:38.394878 #train# step 4747, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:39.943917 #train# step 4748, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:41.504484 #train# step 4749, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:43.051590 #train# step 4750, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:44.598164 #train# step 4751, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:46.163416 #train# step 4752, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:47.716270 #train# step 4753, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:49.287169 #train# step 4754, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:50.893250 #train# step 4755, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:52.448362 #train# step 4756, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:54.014464 #train# step 4757, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:55.582481 #train# step 4758, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:57.107553 #train# step 4759, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:43:58.653994 #train# step 4760, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:00.205819 #train# step 4761, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:01.756776 #train# step 4762, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:03.303641 #train# step 4763, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:04.839591 #train# step 4764, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:06.405545 #train# step 4765, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:07.976588 #train# step 4766, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:09.539615 #train# step 4767, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:11.089467 #train# step 4768, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:12.676891 #train# step 4769, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:14.280631 #train# step 4770, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:15.830824 #train# step 4771, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:17.400733 #train# step 4772, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:18.974211 #train# step 4773, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:20.542229 #train# step 4774, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:22.105340 #train# step 4775, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:23.649207 #train# step 4776, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:25.228492 #train# step 4777, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:26.792684 #train# step 4778, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:28.357565 #train# step 4779, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:29.910303 #train# step 4780, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:31.476706 #train# step 4781, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:33.034922 #train# step 4782, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:34.596136 #train# step 4783, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:36.170913 #train# step 4784, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:37.736676 #train# step 4785, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:39.308426 #train# step 4786, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:40.884793 #train# step 4787, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:42.482076 #train# step 4788, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:44.059035 #train# step 4789, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:45.658115 #train# step 4790, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:47.225244 #train# step 4791, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:48.800208 #train# step 4792, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:50.332680 #train# step 4793, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:51.915175 #train# step 4794, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:53.483539 #train# step 4795, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:55.043612 #train# step 4796, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:56.601416 #train# step 4797, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:58.157912 #train# step 4798, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:44:59.706241 #train# step 4799, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:01.304792 #train# step 4800, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:02.873731 #train# step 4801, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:04.467281 #train# step 4802, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:06.040384 #train# step 4803, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:07.601064 #train# step 4804, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:09.181533 #train# step 4805, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:10.785611 #train# step 4806, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:12.339948 #train# step 4807, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:13.907105 #train# step 4808, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:15.456606 #train# step 4809, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:17.042390 #train# step 4810, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:18.597177 #train# step 4811, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:20.146664 #train# step 4812, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:21.719299 #train# step 4813, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:23.289938 #train# step 4814, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:24.874701 #train# step 4815, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:26.454332 #train# step 4816, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:27.986157 #train# step 4817, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:29.530011 #train# step 4818, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:31.081289 #train# step 4819, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:32.660656 #train# step 4820, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:34.243912 #train# step 4821, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:35.826282 #train# step 4822, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:37.389520 #train# step 4823, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:38.961818 #train# step 4824, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:40.538721 #train# step 4825, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:42.103549 #train# step 4826, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:43.645799 #train# step 4827, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:45.193176 #train# step 4828, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:46.778069 #train# step 4829, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:48.333102 #train# step 4830, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:49.890599 #train# step 4831, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:51.466280 #train# step 4832, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:53.037014 #train# step 4833, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:54.578950 #train# step 4834, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:56.135316 #train# step 4835, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:57.685875 #train# step 4836, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:45:59.247445 #train# step 4837, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:00.790308 #train# step 4838, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:02.349366 #train# step 4839, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:03.904625 #train# step 4840, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:05.458827 #train# step 4841, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:07.024625 #train# step 4842, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:08.585983 #train# step 4843, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:10.149752 #train# step 4844, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:11.719384 #train# step 4845, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:13.270537 #train# step 4846, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:14.808089 #train# step 4847, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:16.353077 #train# step 4848, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:17.921941 #train# step 4849, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:19.462568 #train# step 4850, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:21.016788 #train# step 4851, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:22.579726 #train# step 4852, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:24.148768 #train# step 4853, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:25.701255 #train# step 4854, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:27.271351 #train# step 4855, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:28.827859 #train# step 4856, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:30.387032 #train# step 4857, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:31.967038 #train# step 4858, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:33.521033 #train# step 4859, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:35.086721 #train# step 4860, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:36.645456 #train# step 4861, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:38.173848 #train# step 4862, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:39.725327 #train# step 4863, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:41.280218 #train# step 4864, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:42.819326 #train# step 4865, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:44.381352 #train# step 4866, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:45.958309 #train# step 4867, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:47.512235 #train# step 4868, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:49.101087 #train# step 4869, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:50.655662 #train# step 4870, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:52.232776 #train# step 4871, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:53.790108 #train# step 4872, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:55.334393 #train# step 4873, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:56.915664 #train# step 4874, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:46:58.478197 #train# step 4875, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:00.059568 #train# step 4876, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:01.622091 #train# step 4877, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:03.174654 #train# step 4878, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:04.759070 #train# step 4879, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:06.322422 #train# step 4880, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:07.903893 #train# step 4881, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:09.473615 #train# step 4882, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:11.060563 #train# step 4883, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:12.632158 #train# step 4884, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:14.187646 #train# step 4885, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:15.734499 #train# step 4886, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:17.311267 #train# step 4887, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:18.888681 #train# step 4888, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:20.478440 #train# step 4889, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:22.037702 #train# step 4890, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:23.605310 #train# step 4891, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:25.157869 #train# step 4892, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:26.708317 #train# step 4893, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:28.309412 #train# step 4894, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:29.868057 #train# step 4895, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:31.435324 #train# step 4896, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:32.992902 #train# step 4897, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:34.516186 #train# step 4898, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:36.082983 #train# step 4899, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:37.640235 #train# step 4900, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:39.206881 #train# step 4901, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:40.754824 #train# step 4902, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:42.330938 #train# step 4903, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:43.878527 #train# step 4904, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:45.443883 #train# step 4905, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:46.999030 #train# step 4906, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:48.546395 #train# step 4907, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:50.156072 #train# step 4908, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:51.722347 #train# step 4909, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:53.295499 #train# step 4910, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:54.843037 #train# step 4911, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:56.415202 #train# step 4912, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:57.964318 #train# step 4913, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:47:59.534064 #train# step 4914, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:01.106725 #train# step 4915, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:02.663228 #train# step 4916, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:04.231368 #train# step 4917, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:05.798806 #train# step 4918, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:07.341030 #train# step 4919, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:08.920502 #train# step 4920, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:10.503212 #train# step 4921, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:12.094862 #train# step 4922, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:13.680030 #train# step 4923, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:15.249883 #train# step 4924, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:16.807276 #train# step 4925, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:18.368354 #train# step 4926, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:19.920695 #train# step 4927, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:21.457456 #train# step 4928, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:23.030868 #train# step 4929, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:24.585525 #train# step 4930, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:26.139279 #train# step 4931, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:27.683384 #train# step 4932, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:29.207631 #train# step 4933, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:30.791320 #train# step 4934, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:32.362440 #train# step 4935, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:33.936963 #train# step 4936, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:35.521947 #train# step 4937, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:37.057903 #train# step 4938, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:38.631550 #train# step 4939, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:40.189633 #train# step 4940, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:41.759730 #train# step 4941, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:43.327813 #train# step 4942, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:44.898557 #train# step 4943, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:46.456798 #train# step 4944, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:48.018994 #train# step 4945, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:49.570189 #train# step 4946, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:51.112698 #train# step 4947, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:52.684681 #train# step 4948, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:54.254485 #train# step 4949, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:55.844941 #train# step 4950, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:57.403415 #train# step 4951, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:48:58.964451 #train# step 4952, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:00.505068 #train# step 4953, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:02.067893 #train# step 4954, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:03.637503 #train# step 4955, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:05.203279 #train# step 4956, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:06.764511 #train# step 4957, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:08.303305 #train# step 4958, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:09.884715 #train# step 4959, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:11.446238 #train# step 4960, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:13.010828 #train# step 4961, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:14.595744 #train# step 4962, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:16.135747 #train# step 4963, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:17.688396 #train# step 4964, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:19.272225 #train# step 4965, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:20.849712 #train# step 4966, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:22.384921 #train# step 4967, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:23.943048 #train# step 4968, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:25.504301 #train# step 4969, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:27.078999 #train# step 4970, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:28.613693 #train# step 4971, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:30.220603 #train# step 4972, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:31.772234 #train# step 4973, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:33.365235 #train# step 4974, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:34.908661 #train# step 4975, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:36.477248 #train# step 4976, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:38.031597 #train# step 4977, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:39.577587 #train# step 4978, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:41.157199 #train# step 4979, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:42.740645 #train# step 4980, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:44.269939 #train# step 4981, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:45.870560 #train# step 4982, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:47.410791 #train# step 4983, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:48.986378 #train# step 4984, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:50.555327 #train# step 4985, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:52.098844 #train# step 4986, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:53.669193 #train# step 4987, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:55.219094 #train# step 4988, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:56.780760 #train# step 4989, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:58.328724 #train# step 4990, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:49:59.878757 #train# step 4991, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:01.404748 #train# step 4992, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:02.969922 #train# step 4993, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:04.535039 #train# step 4994, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:06.114025 #train# step 4995, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:07.684281 #train# step 4996, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:09.224491 #train# step 4997, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:10.782593 #train# step 4998, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:12.357857 #train# step 4999, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:13.920726 #train# step 5000, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:15.484606 #train# step 5001, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:17.052652 #train# step 5002, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:18.623790 #train# step 5003, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:20.221017 #train# step 5004, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:21.762773 #train# step 5005, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:23.316696 #train# step 5006, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:24.871584 #train# step 5007, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:26.444265 #train# step 5008, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:28.016957 #train# step 5009, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:29.606843 #train# step 5010, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:31.170572 #train# step 5011, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:32.725293 #train# step 5012, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:34.264983 #train# step 5013, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:35.863541 #train# step 5014, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:37.427760 #train# step 5015, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:39.019980 #train# step 5016, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:40.579003 #train# step 5017, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:42.137190 #train# step 5018, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:43.671325 #train# step 5019, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:45.234790 #train# step 5020, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:46.824491 #train# step 5021, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:48.400674 #train# step 5022, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:49.976585 #train# step 5023, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:51.537589 #train# step 5024, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:53.116178 #train# step 5025, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:54.671167 #train# step 5026, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:56.233045 #train# step 5027, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:57.813836 #train# step 5028, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:50:59.394591 #train# step 5029, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:00.956405 #train# step 5030, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:02.534604 #train# step 5031, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:04.150226 #train# step 5032, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:05.692503 #train# step 5033, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:07.250454 #train# step 5034, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:08.801677 #train# step 5035, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:10.354826 #train# step 5036, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:11.917452 #train# step 5037, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:13.490350 #train# step 5038, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:15.046899 #train# step 5039, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:16.594793 #train# step 5040, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:18.156805 #train# step 5041, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:19.734017 #train# step 5042, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:21.324249 #train# step 5043, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:22.893336 #train# step 5044, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:24.456463 #train# step 5045, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:26.049665 #train# step 5046, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:27.599756 #train# step 5047, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:29.156866 #train# step 5048, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:30.737868 #train# step 5049, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:32.301312 #train# step 5050, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:33.878387 #train# step 5051, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:35.437008 #train# step 5052, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:36.990702 #train# step 5053, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:38.575262 #train# step 5054, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:40.131273 #train# step 5055, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:41.698872 #train# step 5056, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:43.238708 #train# step 5057, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:44.786346 #train# step 5058, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:46.345846 #train# step 5059, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:47.936661 #train# step 5060, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:49.464102 #train# step 5061, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:50.987356 #train# step 5062, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:52.550309 #train# step 5063, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:54.090346 #train# step 5064, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:55.632424 #train# step 5065, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:57.179626 #train# step 5066, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:51:58.804391 #train# step 5067, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:00.377904 #train# step 5068, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:01.940687 #train# step 5069, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:03.534722 #train# step 5070, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:05.080773 #train# step 5071, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:06.661730 #train# step 5072, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:08.245086 #train# step 5073, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:09.797639 #train# step 5074, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:11.339968 #train# step 5075, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:12.900193 #train# step 5076, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:14.440035 #train# step 5077, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:15.998797 #train# step 5078, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:17.598207 #train# step 5079, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:19.179342 #train# step 5080, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:20.730242 #train# step 5081, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:22.292773 #train# step 5082, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:23.842545 #train# step 5083, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:25.412921 #train# step 5084, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:26.980457 #train# step 5085, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:28.515538 #train# step 5086, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:30.084185 #train# step 5087, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:31.650199 #train# step 5088, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:33.206347 #train# step 5089, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:34.791393 #train# step 5090, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:36.338801 #train# step 5091, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:37.868365 #train# step 5092, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:39.458520 #train# step 5093, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:41.023042 #train# step 5094, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:42.546183 #train# step 5095, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:44.107689 #train# step 5096, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:45.719124 #train# step 5097, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:47.276363 #train# step 5098, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:48.837631 #train# step 5099, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:50.420159 #train# step 5100, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:51.978000 #train# step 5101, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:53.565268 #train# step 5102, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:55.119696 #train# step 5103, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:56.653663 #train# step 5104, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:58.247081 #train# step 5105, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:52:59.810013 #train# step 5106, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:01.403582 #train# step 5107, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:02.993325 #train# step 5108, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:04.596557 #train# step 5109, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:06.133360 #train# step 5110, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:07.661150 #train# step 5111, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:09.217165 #train# step 5112, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:10.794661 #train# step 5113, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:12.337983 #train# step 5114, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:13.912732 #train# step 5115, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:15.498347 #train# step 5116, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:17.061374 #train# step 5117, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:18.622405 #train# step 5118, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:20.188264 #train# step 5119, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:21.735038 #train# step 5120, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:23.280566 #train# step 5121, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:24.827472 #train# step 5122, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:26.379576 #train# step 5123, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:27.933912 #train# step 5124, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:29.480377 #train# step 5125, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:31.065846 #train# step 5126, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:32.620853 #train# step 5127, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:34.206263 #train# step 5128, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:35.749141 #train# step 5129, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:37.270521 #train# step 5130, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:38.877872 #train# step 5131, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:40.460642 #train# step 5132, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:42.053159 #train# step 5133, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:43.590118 #train# step 5134, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:45.172767 #train# step 5135, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:46.715587 #train# step 5136, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:48.280322 #train# step 5137, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:49.852472 #train# step 5138, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:51.384655 #train# step 5139, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:52.919760 #train# step 5140, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:54.500014 #train# step 5141, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:56.071686 #train# step 5142, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:57.614129 #train# step 5143, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:53:59.154229 #train# step 5144, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:00.726742 #train# step 5145, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:02.290830 #train# step 5146, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:03.864850 #train# step 5147, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:05.434770 #train# step 5148, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:06.996864 #train# step 5149, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:08.577808 #train# step 5150, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:10.157691 #train# step 5151, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:11.746090 #train# step 5152, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:13.308466 #train# step 5153, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:14.890421 #train# step 5154, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:16.442954 #train# step 5155, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:17.995714 #train# step 5156, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:19.540042 #train# step 5157, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:21.102399 #train# step 5158, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:22.656900 #train# step 5159, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:24.245796 #train# step 5160, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:25.820314 #train# step 5161, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:27.373104 #train# step 5162, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:28.948375 #train# step 5163, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:30.540385 #train# step 5164, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:32.115985 #train# step 5165, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:33.686253 #train# step 5166, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:35.239473 #train# step 5167, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:36.793436 #train# step 5168, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:38.361720 #train# step 5169, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:39.900977 #train# step 5170, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:41.484405 #train# step 5171, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:43.022680 #train# step 5172, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:44.570336 #train# step 5173, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:46.126535 #train# step 5174, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:47.688942 #train# step 5175, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:49.255873 #train# step 5176, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:50.811376 #train# step 5177, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:52.368380 #train# step 5178, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:53.958684 #train# step 5179, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:55.519965 #train# step 5180, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:57.063839 #train# step 5181, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:54:58.605375 #train# step 5182, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:00.174122 #train# step 5183, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:01.728979 #train# step 5184, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:03.279170 #train# step 5185, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:04.814766 #train# step 5186, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:06.344151 #train# step 5187, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:07.911605 #train# step 5188, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:09.441200 #train# step 5189, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:10.994599 #train# step 5190, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:12.560724 #train# step 5191, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:14.158253 #train# step 5192, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:15.742289 #train# step 5193, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:17.315525 #train# step 5194, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:18.881490 #train# step 5195, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:20.479638 #train# step 5196, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:22.059644 #train# step 5197, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:23.632797 #train# step 5198, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:25.201551 #train# step 5199, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:26.780430 #train# step 5200, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:28.390270 #train# step 5201, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:29.946628 #train# step 5202, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:31.501462 #train# step 5203, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:33.070070 #train# step 5204, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:34.645463 #train# step 5205, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:36.214260 #train# step 5206, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:37.800448 #train# step 5207, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:39.368497 #train# step 5208, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:40.911057 #train# step 5209, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:42.458926 #train# step 5210, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:44.014202 #train# step 5211, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:45.576889 #train# step 5212, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:47.131875 #train# step 5213, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:48.716769 #train# step 5214, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:50.315050 #train# step 5215, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:51.889781 #train# step 5216, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:53.447140 #train# step 5217, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:55.027657 #train# step 5218, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:56.577062 #train# step 5219, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:58.095916 #train# step 5220, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:55:59.652800 #train# step 5221, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:01.211048 #train# step 5222, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:02.795814 #train# step 5223, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:04.348867 #train# step 5224, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:05.928746 #train# step 5225, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:07.507533 #train# step 5226, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:09.055161 #train# step 5227, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:10.623635 #train# step 5228, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:12.189523 #train# step 5229, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:13.718918 #train# step 5230, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:15.300238 #train# step 5231, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:16.879884 #train# step 5232, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:18.448134 #train# step 5233, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:19.995007 #train# step 5234, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:21.574856 #train# step 5235, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:23.155947 #train# step 5236, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:24.690795 #train# step 5237, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:26.255103 #train# step 5238, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:27.805262 #train# step 5239, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:29.409619 #train# step 5240, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:30.970197 #train# step 5241, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:32.565943 #train# step 5242, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:34.148774 #train# step 5243, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:35.699186 #train# step 5244, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:37.242432 #train# step 5245, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:38.823551 #train# step 5246, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:40.397651 #train# step 5247, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:41.949595 #train# step 5248, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:43.507954 #train# step 5249, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:45.058124 #train# step 5250, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:46.612882 #train# step 5251, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:48.178885 #train# step 5252, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:49.736488 #train# step 5253, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:51.305514 #train# step 5254, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:52.859503 #train# step 5255, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:54.460079 #train# step 5256, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:56.024789 #train# step 5257, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:57.614168 #train# step 5258, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:56:59.200409 #train# step 5259, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:00.752393 #train# step 5260, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:02.295958 #train# step 5261, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:03.851191 #train# step 5262, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:05.399272 #train# step 5263, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:06.968105 #train# step 5264, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:08.526655 #train# step 5265, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:10.095778 #train# step 5266, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:11.638391 #train# step 5267, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:13.184836 #train# step 5268, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:14.727279 #train# step 5269, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:16.293729 #train# step 5270, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:17.857246 #train# step 5271, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:19.402552 #train# step 5272, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:20.958043 #train# step 5273, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:22.538217 #train# step 5274, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:24.090726 #train# step 5275, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:25.704965 #train# step 5276, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:27.265850 #train# step 5277, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:28.839612 #train# step 5278, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:30.409925 #train# step 5279, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:31.967612 #train# step 5280, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:33.525815 #train# step 5281, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:35.090229 #train# step 5282, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:36.667612 #train# step 5283, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:38.285760 #train# step 5284, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:39.878002 #train# step 5285, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:41.462155 #train# step 5286, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:43.023457 #train# step 5287, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:44.581398 #train# step 5288, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:46.149849 #train# step 5289, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:47.682227 #train# step 5290, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:49.265296 #train# step 5291, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:50.836671 #train# step 5292, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:52.424614 #train# step 5293, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:54.006427 #train# step 5294, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:55.578494 #train# step 5295, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:57.145339 #train# step 5296, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:57:58.680854 #train# step 5297, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:00.245045 #train# step 5298, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:01.776152 #train# step 5299, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:03.329666 #train# step 5300, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:04.877646 #train# step 5301, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:06.440724 #train# step 5302, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:07.996702 #train# step 5303, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:09.567244 #train# step 5304, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:11.114613 #train# step 5305, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:12.668711 #train# step 5306, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:14.237759 #train# step 5307, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:15.820688 #train# step 5308, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:17.377544 #train# step 5309, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:18.945429 #train# step 5310, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:20.502652 #train# step 5311, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:22.059226 #train# step 5312, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:23.645780 #train# step 5313, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:25.197544 #train# step 5314, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:26.777556 #train# step 5315, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:28.347109 #train# step 5316, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:29.919503 #train# step 5317, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:31.485780 #train# step 5318, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:33.042626 #train# step 5319, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:34.610194 #train# step 5320, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:36.163231 #train# step 5321, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:37.725106 #train# step 5322, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:39.303752 #train# step 5323, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:40.926034 #train# step 5324, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:42.476960 #train# step 5325, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:44.020386 #train# step 5326, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:45.568673 #train# step 5327, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:47.148129 #train# step 5328, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:48.700136 #train# step 5329, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:50.261258 #train# step 5330, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:51.824138 #train# step 5331, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:53.372215 #train# step 5332, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:54.929080 #train# step 5333, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:56.490127 #train# step 5334, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:58.036241 #train# step 5335, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:58:59.575362 #train# step 5336, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:01.129286 #train# step 5337, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:02.679028 #train# step 5338, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:04.257659 #train# step 5339, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:05.823746 #train# step 5340, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:07.386346 #train# step 5341, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:08.956095 #train# step 5342, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:10.538268 #train# step 5343, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:12.100701 #train# step 5344, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:13.656781 #train# step 5345, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:15.200422 #train# step 5346, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:16.766129 #train# step 5347, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:18.331550 #train# step 5348, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:19.899036 #train# step 5349, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:21.468645 #train# step 5350, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:23.048014 #train# step 5351, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:24.621608 #train# step 5352, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:26.209351 #train# step 5353, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:27.773004 #train# step 5354, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:29.361181 #train# step 5355, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:30.922097 #train# step 5356, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:32.489102 #train# step 5357, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:34.061514 #train# step 5358, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:35.641319 #train# step 5359, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:37.180868 #train# step 5360, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:38.743428 #train# step 5361, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:40.297987 #train# step 5362, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:41.856779 #train# step 5363, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:43.432221 #train# step 5364, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:45.008720 #train# step 5365, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:46.585181 #train# step 5366, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:48.163399 #train# step 5367, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:49.708197 #train# step 5368, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:51.313652 #train# step 5369, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:52.876716 #train# step 5370, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:54.422188 #train# step 5371, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:56.010742 #train# step 5372, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:57.588131 #train# step 5373, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 15:59:59.159020 #train# step 5374, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:00.703351 #train# step 5375, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:02.229180 #train# step 5376, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:03.800095 #train# step 5377, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:05.366172 #train# step 5378, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:06.929436 #train# step 5379, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:08.478730 #train# step 5380, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:10.068637 #train# step 5381, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:11.626263 #train# step 5382, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:13.186121 #train# step 5383, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:14.740946 #train# step 5384, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:16.293770 #train# step 5385, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:17.872292 #train# step 5386, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:19.449179 #train# step 5387, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:21.019504 #train# step 5388, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:22.584997 #train# step 5389, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:24.126295 #train# step 5390, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:25.689401 #train# step 5391, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:27.257225 #train# step 5392, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:28.798609 #train# step 5393, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:30.364594 #train# step 5394, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:31.930226 #train# step 5395, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:33.491069 #train# step 5396, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:35.076093 #train# step 5397, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:36.653009 #train# step 5398, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:38.215371 #train# step 5399, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:39.759935 #train# step 5400, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:41.347672 #train# step 5401, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:42.927215 #train# step 5402, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:44.494167 #train# step 5403, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:46.059770 #train# step 5404, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:47.616207 #train# step 5405, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:49.178532 #train# step 5406, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:50.741975 #train# step 5407, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:52.315974 #train# step 5408, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:53.898234 #train# step 5409, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:55.445217 #train# step 5410, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:57.024670 #train# step 5411, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:00:58.615366 #train# step 5412, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:00.195734 #train# step 5413, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:01.759707 #train# step 5414, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:03.336082 #train# step 5415, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:04.852814 #train# step 5416, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:06.406578 #train# step 5417, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:07.956011 #train# step 5418, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:09.532395 #train# step 5419, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:11.073248 #train# step 5420, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:12.640024 #train# step 5421, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:14.204018 #train# step 5422, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:15.765890 #train# step 5423, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:17.339125 #train# step 5424, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:18.905733 #train# step 5425, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:20.438713 #train# step 5426, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:21.991800 #train# step 5427, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:23.559634 #train# step 5428, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:25.166841 #train# step 5429, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:26.727093 #train# step 5430, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:28.298774 #train# step 5431, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:29.883379 #train# step 5432, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:31.434345 #train# step 5433, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:32.972805 #train# step 5434, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:34.549747 #train# step 5435, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:36.118818 #train# step 5436, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:37.648619 #train# step 5437, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:39.211890 #train# step 5438, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:40.770810 #train# step 5439, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:42.353814 #train# step 5440, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:43.923168 #train# step 5441, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:45.510821 #train# step 5442, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:47.058058 #train# step 5443, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:48.606475 #train# step 5444, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:50.153433 #train# step 5445, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:51.733200 #train# step 5446, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:53.296264 #train# step 5447, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:54.866192 #train# step 5448, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:56.414895 #train# step 5449, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:58.005524 #train# step 5450, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:01:59.552290 #train# step 5451, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:01.133823 #train# step 5452, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:02.722155 #train# step 5453, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:04.259523 #train# step 5454, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:05.819805 #train# step 5455, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:07.381274 #train# step 5456, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:08.945724 #train# step 5457, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:10.521538 #train# step 5458, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:12.104786 #train# step 5459, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:13.679761 #train# step 5460, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:15.271206 #train# step 5461, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:16.872879 #train# step 5462, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:18.463988 #train# step 5463, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:20.055709 #train# step 5464, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:21.627906 #train# step 5465, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:23.171391 #train# step 5466, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:24.741616 #train# step 5467, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:26.294126 #train# step 5468, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:27.856746 #train# step 5469, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:29.401285 #train# step 5470, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:30.980472 #train# step 5471, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:32.553279 #train# step 5472, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:34.142499 #train# step 5473, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:35.675126 #train# step 5474, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:37.253826 #train# step 5475, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:38.820258 #train# step 5476, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:40.365227 #train# step 5477, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:41.925067 #train# step 5478, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:43.481491 #train# step 5479, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:45.014392 #train# step 5480, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:46.567593 #train# step 5481, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:48.116013 #train# step 5482, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:49.691041 #train# step 5483, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:51.249369 #train# step 5484, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:52.832660 #train# step 5485, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:54.392028 #train# step 5486, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:55.966175 #train# step 5487, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:57.545668 #train# step 5488, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:02:59.116102 #train# step 5489, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:00.644374 #train# step 5490, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:02.217743 #train# step 5491, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:03.809369 #train# step 5492, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:05.376514 #train# step 5493, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:06.912700 #train# step 5494, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:08.443575 #train# step 5495, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:09.977487 #train# step 5496, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:11.537089 #train# step 5497, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:13.104497 #train# step 5498, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:14.668475 #train# step 5499, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:16.281395 #train# step 5500, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:17.824703 #train# step 5501, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:19.396899 #train# step 5502, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:20.939463 #train# step 5503, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:22.517712 #train# step 5504, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:24.119633 #train# step 5505, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:25.680196 #train# step 5506, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:27.227755 #train# step 5507, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:28.810586 #train# step 5508, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:30.356489 #train# step 5509, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:31.898397 #train# step 5510, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:33.449852 #train# step 5511, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:35.010306 #train# step 5512, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:36.570323 #train# step 5513, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:38.119448 #train# step 5514, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:39.655909 #train# step 5515, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:41.252159 #train# step 5516, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:42.814452 #train# step 5517, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:44.360504 #train# step 5518, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:45.946837 #train# step 5519, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:47.503562 #train# step 5520, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:49.051510 #train# step 5521, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:50.649060 #train# step 5522, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:52.201633 #train# step 5523, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:53.744784 #train# step 5524, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:55.300661 #train# step 5525, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:56.848069 #train# step 5526, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:58.411429 #train# step 5527, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:03:59.942871 #train# step 5528, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:01.502543 #train# step 5529, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:03.087355 #train# step 5530, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:04.666442 #train# step 5531, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:06.217484 #train# step 5532, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:07.794352 #train# step 5533, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:09.346773 #train# step 5534, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:10.930115 #train# step 5535, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:12.486202 #train# step 5536, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:14.084069 #train# step 5537, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:15.672687 #train# step 5538, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:17.233274 #train# step 5539, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:18.795326 #train# step 5540, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:20.348243 #train# step 5541, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:21.897084 #train# step 5542, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:23.449638 #train# step 5543, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:25.018272 #train# step 5544, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:26.608721 #train# step 5545, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:28.185801 #train# step 5546, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:29.730198 #train# step 5547, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:31.256216 #train# step 5548, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:32.816536 #train# step 5549, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:34.355953 #train# step 5550, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:35.949130 #train# step 5551, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:37.494371 #train# step 5552, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:39.028736 #train# step 5553, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:40.575784 #train# step 5554, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:42.163064 #train# step 5555, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:43.727452 #train# step 5556, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:45.309522 #train# step 5557, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:46.854042 #train# step 5558, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:48.414631 #train# step 5559, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:49.977512 #train# step 5560, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:51.545419 #train# step 5561, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:53.117630 #train# step 5562, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:54.707699 #train# step 5563, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:56.288248 #train# step 5564, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:57.870305 #train# step 5565, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:04:59.432598 #train# step 5566, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:01.000695 #train# step 5567, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:02.564720 #train# step 5568, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:04.160120 #train# step 5569, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:05.756764 #train# step 5570, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:07.322663 #train# step 5571, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:08.879202 #train# step 5572, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:10.472650 #train# step 5573, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:12.010858 #train# step 5574, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:13.586687 #train# step 5575, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:15.109528 #train# step 5576, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:16.711117 #train# step 5577, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:18.333260 #train# step 5578, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:19.893282 #train# step 5579, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:21.433233 #train# step 5580, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:22.985809 #train# step 5581, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:24.558285 #train# step 5582, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:26.103473 #train# step 5583, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:27.669117 #train# step 5584, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:29.186169 #train# step 5585, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:30.755673 #train# step 5586, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:32.338663 #train# step 5587, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:33.906840 #train# step 5588, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:35.475551 #train# step 5589, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:37.046427 #train# step 5590, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:38.606757 #train# step 5591, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:40.170515 #train# step 5592, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:41.710397 #train# step 5593, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:43.286731 #train# step 5594, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:44.880866 #train# step 5595, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:46.438189 #train# step 5596, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:47.998348 #train# step 5597, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:49.586053 #train# step 5598, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:51.146593 #train# step 5599, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:52.700529 #train# step 5600, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:54.218216 #train# step 5601, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:55.778267 #train# step 5602, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:57.340078 #train# step 5603, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:05:58.898462 #train# step 5604, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:00.462843 #train# step 5605, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:01.986707 #train# step 5606, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:03.556484 #train# step 5607, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:05.113072 #train# step 5608, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:06.695877 #train# step 5609, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:08.250334 #train# step 5610, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:09.847278 #train# step 5611, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:11.412821 #train# step 5612, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:12.982058 #train# step 5613, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:14.533864 #train# step 5614, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:16.101225 #train# step 5615, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:17.683881 #train# step 5616, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:19.242938 #train# step 5617, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:20.792444 #train# step 5618, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:22.343338 #train# step 5619, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:23.892524 #train# step 5620, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:25.444974 #train# step 5621, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:27.009231 #train# step 5622, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:28.595188 #train# step 5623, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:30.138353 #train# step 5624, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:31.714426 #train# step 5625, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:33.286430 #train# step 5626, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:34.838420 #train# step 5627, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:36.400489 #train# step 5628, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:37.960342 #train# step 5629, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:39.544558 #train# step 5630, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:41.149750 #train# step 5631, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:42.711821 #train# step 5632, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:44.235711 #train# step 5633, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:45.837503 #train# step 5634, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:47.417552 #train# step 5635, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:49.006829 #train# step 5636, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:50.587381 #train# step 5637, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:52.152848 #train# step 5638, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:53.710023 #train# step 5639, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:55.275248 #train# step 5640, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:56.856711 #train# step 5641, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:58.414062 #train# step 5642, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:06:59.963685 #train# step 5643, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:01.531505 #train# step 5644, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:03.103904 #train# step 5645, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:04.668456 #train# step 5646, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:06.234353 #train# step 5647, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:07.788449 #train# step 5648, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:09.344891 #train# step 5649, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:10.920550 #train# step 5650, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:12.464676 #train# step 5651, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:14.025722 #train# step 5652, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:15.623444 #train# step 5653, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:17.174294 #train# step 5654, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:18.778756 #train# step 5655, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:20.324667 #train# step 5656, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:21.883371 #train# step 5657, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:23.419309 #train# step 5658, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:24.965693 #train# step 5659, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:26.544318 #train# step 5660, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:28.121464 #train# step 5661, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:29.657569 #train# step 5662, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:31.217418 #train# step 5663, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:32.793858 #train# step 5664, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:34.326558 #train# step 5665, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:35.917575 #train# step 5666, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:37.452590 #train# step 5667, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:39.041517 #train# step 5668, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:40.615406 #train# step 5669, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:42.179928 #train# step 5670, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:43.761876 #train# step 5671, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:45.335611 #train# step 5672, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:46.888005 #train# step 5673, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:48.434160 #train# step 5674, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:50.022283 #train# step 5675, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:51.586158 #train# step 5676, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:53.167005 #train# step 5677, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:54.734772 #train# step 5678, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:56.278179 #train# step 5679, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:57.860552 #train# step 5680, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:07:59.412052 #train# step 5681, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:00.963425 #train# step 5682, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:02.528598 #train# step 5683, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:04.099402 #train# step 5684, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:05.676801 #train# step 5685, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:07.232382 #train# step 5686, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:08.801852 #train# step 5687, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:10.392566 #train# step 5688, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:11.939617 #train# step 5689, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:13.489736 #train# step 5690, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:15.024885 #train# step 5691, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:16.584540 #train# step 5692, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:18.144425 #train# step 5693, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:19.699814 #train# step 5694, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:21.277818 #train# step 5695, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:22.851927 #train# step 5696, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:24.450311 #train# step 5697, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:26.032484 #train# step 5698, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:27.570897 #train# step 5699, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:29.132671 #train# step 5700, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:30.711700 #train# step 5701, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:32.291329 #train# step 5702, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:33.841372 #train# step 5703, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:35.409501 #train# step 5704, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:36.946273 #train# step 5705, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:38.488533 #train# step 5706, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:40.088151 #train# step 5707, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:41.629941 #train# step 5708, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:43.182009 #train# step 5709, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:44.726754 #train# step 5710, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:46.270209 #train# step 5711, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:47.854605 #train# step 5712, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:49.452948 #train# step 5713, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:51.031741 #train# step 5714, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:52.635442 #train# step 5715, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:54.186971 #train# step 5716, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:55.753738 #train# step 5717, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:57.289559 #train# step 5718, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:08:58.857365 #train# step 5719, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:00.437669 #train# step 5720, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:01.963052 #train# step 5721, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:03.505404 #train# step 5722, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:05.049804 #train# step 5723, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:06.598207 #train# step 5724, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:08.176942 #train# step 5725, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:09.745073 #train# step 5726, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:11.312875 #train# step 5727, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:12.902173 #train# step 5728, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:14.488676 #train# step 5729, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:16.079001 #train# step 5730, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:17.661554 #train# step 5731, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:19.188944 #train# step 5732, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:20.761682 #train# step 5733, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:22.337175 #train# step 5734, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:23.906036 #train# step 5735, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:25.434856 #train# step 5736, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:26.989493 #train# step 5737, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:28.562653 #train# step 5738, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:30.111628 #train# step 5739, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:31.683672 #train# step 5740, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:33.239914 #train# step 5741, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:34.816897 #train# step 5742, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:36.347327 #train# step 5743, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:37.871023 #train# step 5744, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:39.490104 #train# step 5745, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:41.061250 #train# step 5746, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:42.607996 #train# step 5747, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:44.197697 #train# step 5748, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:45.772904 #train# step 5749, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:47.295986 #train# step 5750, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:48.845116 #train# step 5751, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:50.385708 #train# step 5752, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:51.943573 #train# step 5753, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:53.496130 #train# step 5754, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:55.092833 #train# step 5755, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:56.660609 #train# step 5756, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:58.219106 #train# step 5757, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:09:59.774349 #train# step 5758, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:01.346503 #train# step 5759, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:02.953662 #train# step 5760, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:04.542394 #train# step 5761, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:06.118065 #train# step 5762, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:07.645801 #train# step 5763, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:09.236799 #train# step 5764, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:10.815285 #train# step 5765, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:12.392618 #train# step 5766, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:13.959610 #train# step 5767, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:15.530732 #train# step 5768, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:17.117735 #train# step 5769, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:18.683889 #train# step 5770, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:20.239847 #train# step 5771, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:21.817713 #train# step 5772, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:23.421214 #train# step 5773, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:25.003609 #train# step 5774, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:26.542274 #train# step 5775, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:28.086320 #train# step 5776, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:29.647218 #train# step 5777, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:31.186763 #train# step 5778, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:32.733816 #train# step 5779, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:34.293444 #train# step 5780, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:35.835908 #train# step 5781, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:37.385637 #train# step 5782, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:38.942654 #train# step 5783, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:40.496428 #train# step 5784, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:42.064980 #train# step 5785, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:43.612375 #train# step 5786, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:45.150778 #train# step 5787, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:46.704787 #train# step 5788, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:48.256570 #train# step 5789, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:49.826167 #train# step 5790, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:51.404559 #train# step 5791, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:52.969790 #train# step 5792, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:54.536301 #train# step 5793, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:56.063612 #train# step 5794, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:57.641293 #train# step 5795, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:10:59.223634 #train# step 5796, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:00.770703 #train# step 5797, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:02.306325 #train# step 5798, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:03.862871 #train# step 5799, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:05.453159 #train# step 5800, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:06.987501 #train# step 5801, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:08.567681 #train# step 5802, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:10.172176 #train# step 5803, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:11.726770 #train# step 5804, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:13.284954 #train# step 5805, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:14.831379 #train# step 5806, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:16.382848 #train# step 5807, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:17.994492 #train# step 5808, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:19.546085 #train# step 5809, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:21.062393 #train# step 5810, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:22.626838 #train# step 5811, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:24.193341 #train# step 5812, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:25.761990 #train# step 5813, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:27.346485 #train# step 5814, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:28.904427 #train# step 5815, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:30.495810 #train# step 5816, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:32.078427 #train# step 5817, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:33.606937 #train# step 5818, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:35.179479 #train# step 5819, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:36.767241 #train# step 5820, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:38.349093 #train# step 5821, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:39.947184 #train# step 5822, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:41.536178 #train# step 5823, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:43.074948 #train# step 5824, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:44.656050 #train# step 5825, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:46.249310 #train# step 5826, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:47.839067 #train# step 5827, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:49.389058 #train# step 5828, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:50.943993 #train# step 5829, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:52.505887 #train# step 5830, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:54.082668 #train# step 5831, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:55.648663 #train# step 5832, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:57.197288 #train# step 5833, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:11:58.745263 #train# step 5834, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:00.315040 #train# step 5835, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:01.903246 #train# step 5836, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:03.465818 #train# step 5837, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:05.004067 #train# step 5838, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:06.579966 #train# step 5839, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:08.129740 #train# step 5840, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:09.735670 #train# step 5841, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:11.329094 #train# step 5842, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:12.911669 #train# step 5843, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:14.475598 #train# step 5844, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:16.031564 #train# step 5845, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:17.602321 #train# step 5846, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:19.207378 #train# step 5847, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:20.761820 #train# step 5848, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:22.312403 #train# step 5849, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:23.844146 #train# step 5850, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:25.396032 #train# step 5851, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:26.988603 #train# step 5852, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:28.578034 #train# step 5853, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:30.141478 #train# step 5854, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:31.678910 #train# step 5855, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:33.212619 #train# step 5856, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:34.735000 #train# step 5857, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:36.298670 #train# step 5858, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:37.896280 #train# step 5859, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:39.484747 #train# step 5860, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:41.043447 #train# step 5861, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:42.608892 #train# step 5862, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:44.181124 #train# step 5863, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:45.754278 #train# step 5864, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:47.329955 #train# step 5865, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:48.883625 #train# step 5866, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:50.438528 #train# step 5867, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:51.995059 #train# step 5868, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:53.549855 #train# step 5869, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:55.110615 #train# step 5870, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:56.666014 #train# step 5871, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:58.241058 #train# step 5872, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:12:59.833538 #train# step 5873, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:01.388274 #train# step 5874, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:02.961035 #train# step 5875, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:04.530909 #train# step 5876, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:06.096926 #train# step 5877, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:07.658952 #train# step 5878, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:09.218070 #train# step 5879, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:10.795458 #train# step 5880, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:12.332506 #train# step 5881, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:13.910459 #train# step 5882, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:15.451502 #train# step 5883, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:17.000905 #train# step 5884, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:18.545828 #train# step 5885, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:20.088431 #train# step 5886, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:21.651434 #train# step 5887, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:23.195819 #train# step 5888, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:24.779794 #train# step 5889, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:26.332537 #train# step 5890, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:27.883760 #train# step 5891, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:29.424449 #train# step 5892, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:30.998105 #train# step 5893, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:32.557116 #train# step 5894, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:34.158669 #train# step 5895, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:35.745245 #train# step 5896, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:37.268850 #train# step 5897, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:38.860665 #train# step 5898, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:40.422814 #train# step 5899, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:42.000990 #train# step 5900, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:43.567660 #train# step 5901, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:45.159027 #train# step 5902, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:46.732831 #train# step 5903, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:48.311557 #train# step 5904, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:49.880965 #train# step 5905, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:51.457774 #train# step 5906, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:53.029115 #train# step 5907, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:54.640051 #train# step 5908, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:56.196856 #train# step 5909, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:57.752707 #train# step 5910, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:13:59.313435 #train# step 5911, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:00.872248 #train# step 5912, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:02.427584 #train# step 5913, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:03.972594 #train# step 5914, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:05.564776 #train# step 5915, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:07.153030 #train# step 5916, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:08.721805 #train# step 5917, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:10.291348 #train# step 5918, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:11.833406 #train# step 5919, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:13.405942 #train# step 5920, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:14.945919 #train# step 5921, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:16.482251 #train# step 5922, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:18.032787 #train# step 5923, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:19.592093 #train# step 5924, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:21.195110 #train# step 5925, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:22.785872 #train# step 5926, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:24.346234 #train# step 5927, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:25.963767 #train# step 5928, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:27.530087 #train# step 5929, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:29.086379 #train# step 5930, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:30.649474 #train# step 5931, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:32.222855 #train# step 5932, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:33.791134 #train# step 5933, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:35.395205 #train# step 5934, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:36.908960 #train# step 5935, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:38.499400 #train# step 5936, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:40.054589 #train# step 5937, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:41.627427 #train# step 5938, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:43.179050 #train# step 5939, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:44.734492 #train# step 5940, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:46.270554 #train# step 5941, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:47.848379 #train# step 5942, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:49.441210 #train# step 5943, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:50.970289 #train# step 5944, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:52.515235 #train# step 5945, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:54.083251 #train# step 5946, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:55.646040 #train# step 5947, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:57.221756 #train# step 5948, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:14:58.783446 #train# step 5949, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:00.323193 #train# step 5950, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:01.891572 #train# step 5951, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:03.450546 #train# step 5952, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:05.005190 #train# step 5953, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:06.588784 #train# step 5954, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:08.156383 #train# step 5955, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:09.729116 #train# step 5956, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:11.291820 #train# step 5957, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:12.855120 #train# step 5958, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:14.377537 #train# step 5959, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:15.947171 #train# step 5960, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:17.506890 #train# step 5961, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:19.062959 #train# step 5962, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:20.629920 #train# step 5963, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:22.181351 #train# step 5964, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:23.769809 #train# step 5965, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:25.340433 #train# step 5966, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:26.932605 #train# step 5967, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:28.474055 #train# step 5968, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:30.041033 #train# step 5969, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:31.578476 #train# step 5970, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:33.151174 #train# step 5971, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:34.679251 #train# step 5972, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:36.229003 #train# step 5973, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:37.812307 #train# step 5974, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:39.358689 #train# step 5975, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:40.925801 #train# step 5976, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:42.516302 #train# step 5977, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:44.070900 #train# step 5978, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:45.629925 #train# step 5979, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:47.215189 #train# step 5980, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:48.767246 #train# step 5981, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:50.340868 #train# step 5982, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:51.891139 #train# step 5983, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:53.431680 #train# step 5984, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:54.974642 #train# step 5985, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:56.530581 #train# step 5986, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:58.080504 #train# step 5987, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:15:59.642722 #train# step 5988, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:01.176392 #train# step 5989, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:02.729704 #train# step 5990, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:04.275819 #train# step 5991, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:05.845472 #train# step 5992, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:07.416319 #train# step 5993, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:08.981239 #train# step 5994, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:10.580967 #train# step 5995, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:12.145780 #train# step 5996, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:13.714700 #train# step 5997, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:15.289350 #train# step 5998, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:16.848832 #train# step 5999, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:18.379663 #train# step 6000, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:19.941211 #train# step 6001, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:21.522049 #train# step 6002, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:23.088835 #train# step 6003, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:24.659185 #train# step 6004, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:26.200422 #train# step 6005, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:27.740319 #train# step 6006, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:29.318267 #train# step 6007, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:30.905964 #train# step 6008, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:32.454216 #train# step 6009, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:34.016329 #train# step 6010, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:35.590648 #train# step 6011, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:37.175097 #train# step 6012, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:38.767888 #train# step 6013, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:40.376812 #train# step 6014, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:41.948221 #train# step 6015, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:43.531210 #train# step 6016, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:45.153375 #train# step 6017, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:46.730697 #train# step 6018, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:48.267274 #train# step 6019, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:49.797133 #train# step 6020, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:51.358010 #train# step 6021, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:52.893419 #train# step 6022, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:54.443059 #train# step 6023, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:56.002320 #train# step 6024, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:57.573757 #train# step 6025, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:16:59.156819 #train# step 6026, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:00.727945 #train# step 6027, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:02.314821 #train# step 6028, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:03.888354 #train# step 6029, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:05.443548 #train# step 6030, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:07.010552 #train# step 6031, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:08.575829 #train# step 6032, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:10.113939 #train# step 6033, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:11.693921 #train# step 6034, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:13.246442 #train# step 6035, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:14.789851 #train# step 6036, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:16.350509 #train# step 6037, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:17.932668 #train# step 6038, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:19.492461 #train# step 6039, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:21.050653 #train# step 6040, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:22.619137 #train# step 6041, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:24.175383 #train# step 6042, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:25.756417 #train# step 6043, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:27.344252 #train# step 6044, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:28.901105 #train# step 6045, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:30.471651 #train# step 6046, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:32.050664 #train# step 6047, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:33.594533 #train# step 6048, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:35.167899 #train# step 6049, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:36.747301 #train# step 6050, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:38.298946 #train# step 6051, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:39.867646 #train# step 6052, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:41.459208 #train# step 6053, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:43.014914 #train# step 6054, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:44.556214 #train# step 6055, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:46.131311 #train# step 6056, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:47.683347 #train# step 6057, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:49.273526 #train# step 6058, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:50.821084 #train# step 6059, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:52.370348 #train# step 6060, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:53.945595 #train# step 6061, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:55.512531 #train# step 6062, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:57.062259 #train# step 6063, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:17:58.645190 #train# step 6064, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:00.192997 #train# step 6065, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:01.777989 #train# step 6066, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:03.326288 #train# step 6067, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:04.881503 #train# step 6068, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:06.450828 #train# step 6069, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:08.004721 #train# step 6070, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:09.573533 #train# step 6071, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:11.143965 #train# step 6072, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:12.719296 #train# step 6073, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:14.277356 #train# step 6074, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:15.838035 #train# step 6075, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:17.386853 #train# step 6076, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:18.957512 #train# step 6077, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:20.513444 #train# step 6078, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:22.109831 #train# step 6079, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:23.683027 #train# step 6080, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:25.241151 #train# step 6081, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:26.769853 #train# step 6082, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:28.343147 #train# step 6083, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:29.906856 #train# step 6084, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:31.457212 #train# step 6085, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:33.040184 #train# step 6086, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:34.619548 #train# step 6087, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:36.204941 #train# step 6088, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:37.755366 #train# step 6089, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:39.326431 #train# step 6090, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:40.881820 #train# step 6091, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:42.418077 #train# step 6092, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:43.977419 #train# step 6093, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:45.536206 #train# step 6094, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:47.112838 #train# step 6095, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:48.694630 #train# step 6096, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:50.271795 #train# step 6097, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:51.838092 #train# step 6098, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:53.405816 #train# step 6099, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:54.992644 #train# step 6100, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:56.554825 #train# step 6101, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:58.117926 #train# step 6102, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:18:59.667556 #train# step 6103, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:01.241453 #train# step 6104, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:02.831672 #train# step 6105, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:04.404145 #train# step 6106, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:05.963792 #train# step 6107, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:07.550773 #train# step 6108, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:09.128511 #train# step 6109, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:10.673833 #train# step 6110, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:12.236671 #train# step 6111, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:13.820087 #train# step 6112, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:15.397181 #train# step 6113, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:16.971794 #train# step 6114, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:18.551066 #train# step 6115, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:20.127298 #train# step 6116, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:21.688081 #train# step 6117, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:23.257857 #train# step 6118, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:24.805547 #train# step 6119, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:26.367475 #train# step 6120, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:27.936840 #train# step 6121, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:29.500809 #train# step 6122, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:31.072727 #train# step 6123, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:32.640782 #train# step 6124, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:34.204981 #train# step 6125, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:35.762784 #train# step 6126, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:37.306177 #train# step 6127, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:38.841511 #train# step 6128, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:40.427445 #train# step 6129, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:41.997524 #train# step 6130, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:43.542423 #train# step 6131, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:45.102266 #train# step 6132, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:46.628529 #train# step 6133, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:48.169267 #train# step 6134, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:49.727829 #train# step 6135, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:51.309879 #train# step 6136, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:52.841700 #train# step 6137, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:54.421440 #train# step 6138, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:56.001414 #train# step 6139, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:57.597837 #train# step 6140, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:19:59.142607 #train# step 6141, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:00.708856 #train# step 6142, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:02.256002 #train# step 6143, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:03.837401 #train# step 6144, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:05.404292 #train# step 6145, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:06.939717 #train# step 6146, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:08.476243 #train# step 6147, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:10.013441 #train# step 6148, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:11.610300 #train# step 6149, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:13.194128 #train# step 6150, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:14.791806 #train# step 6151, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:16.382493 #train# step 6152, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:17.956750 #train# step 6153, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:19.520341 #train# step 6154, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:21.061843 #train# step 6155, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:22.648820 #train# step 6156, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:24.203620 #train# step 6157, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:25.794535 #train# step 6158, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:27.354239 #train# step 6159, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:28.892054 #train# step 6160, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:30.435955 #train# step 6161, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:31.990381 #train# step 6162, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:33.569891 #train# step 6163, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:35.140783 #train# step 6164, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:36.688630 #train# step 6165, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:38.263586 #train# step 6166, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:39.840355 #train# step 6167, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:41.413492 #train# step 6168, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:42.954590 #train# step 6169, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:44.538605 #train# step 6170, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:46.080442 #train# step 6171, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:47.623425 #train# step 6172, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:49.188110 #train# step 6173, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:50.734611 #train# step 6174, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:52.305152 #train# step 6175, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:53.865590 #train# step 6176, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:55.444674 #train# step 6177, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:57.018698 #train# step 6178, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:20:58.599393 #train# step 6179, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:00.164315 #train# step 6180, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:01.739774 #train# step 6181, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:03.298042 #train# step 6182, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:04.898731 #train# step 6183, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:06.434988 #train# step 6184, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:07.994025 #train# step 6185, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:09.558291 #train# step 6186, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:11.102355 #train# step 6187, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:12.671125 #train# step 6188, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:14.212833 #train# step 6189, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:15.821502 #train# step 6190, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:17.426792 #train# step 6191, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:18.975218 #train# step 6192, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:20.551301 #train# step 6193, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:22.102826 #train# step 6194, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:23.675030 #train# step 6195, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:25.253663 #train# step 6196, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:26.813680 #train# step 6197, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:28.393541 #train# step 6198, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:29.960775 #train# step 6199, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:31.546391 #train# step 6200, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:33.101005 #train# step 6201, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:34.671842 #train# step 6202, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:36.237185 #train# step 6203, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:37.807616 #train# step 6204, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:39.385360 #train# step 6205, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:40.944915 #train# step 6206, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:42.498947 #train# step 6207, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:44.046076 #train# step 6208, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:45.602187 #train# step 6209, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:47.167491 #train# step 6210, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:48.722604 #train# step 6211, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:50.266590 #train# step 6212, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:51.833361 #train# step 6213, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:53.380865 #train# step 6214, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:54.964829 #train# step 6215, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:56.518034 #train# step 6216, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:58.069756 #train# step 6217, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:21:59.607368 #train# step 6218, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:01.179997 #train# step 6219, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:02.734098 #train# step 6220, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:04.259091 #train# step 6221, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:05.844085 #train# step 6222, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:07.432669 #train# step 6223, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:09.019737 #train# step 6224, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:10.575887 #train# step 6225, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:12.163461 #train# step 6226, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:13.743871 #train# step 6227, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:15.337290 #train# step 6228, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:16.889944 #train# step 6229, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:18.466882 #train# step 6230, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:20.022829 #train# step 6231, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:21.603663 #train# step 6232, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:23.165972 #train# step 6233, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:24.716296 #train# step 6234, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:26.281972 #train# step 6235, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:27.823622 #train# step 6236, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:29.402632 #train# step 6237, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:30.936907 #train# step 6238, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:32.536328 #train# step 6239, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:34.070486 #train# step 6240, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:35.657855 #train# step 6241, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:37.251772 #train# step 6242, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:38.792366 #train# step 6243, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:40.352176 #train# step 6244, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:41.899979 #train# step 6245, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:43.454358 #train# step 6246, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:45.029463 #train# step 6247, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:46.585948 #train# step 6248, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:48.138065 #train# step 6249, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:49.709062 #train# step 6250, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:51.298199 #train# step 6251, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:52.859514 #train# step 6252, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:54.421604 #train# step 6253, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:55.981194 #train# step 6254, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:57.552855 #train# step 6255, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:22:59.103808 #train# step 6256, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:00.673270 #train# step 6257, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:02.255288 #train# step 6258, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:03.792323 #train# step 6259, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:05.327244 #train# step 6260, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:06.934386 #train# step 6261, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:08.483771 #train# step 6262, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:10.048329 #train# step 6263, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:11.637165 #train# step 6264, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:13.211149 #train# step 6265, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:14.784740 #train# step 6266, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:16.372901 #train# step 6267, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:17.955377 #train# step 6268, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:19.520984 #train# step 6269, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:21.115386 #train# step 6270, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:22.674618 #train# step 6271, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:24.254957 #train# step 6272, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:25.837804 #train# step 6273, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:27.397823 #train# step 6274, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:28.965687 #train# step 6275, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:30.492838 #train# step 6276, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:32.043628 #train# step 6277, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:33.658926 #train# step 6278, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:35.210626 #train# step 6279, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:36.755455 #train# step 6280, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:38.295563 #train# step 6281, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:39.865388 #train# step 6282, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:41.402363 #train# step 6283, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:42.960804 #train# step 6284, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:44.537626 #train# step 6285, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:46.130679 #train# step 6286, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:47.672762 #train# step 6287, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:49.242065 #train# step 6288, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:50.783913 #train# step 6289, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:52.354722 #train# step 6290, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:53.943520 #train# step 6291, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:55.501291 #train# step 6292, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:57.078341 #train# step 6293, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:23:58.626829 #train# step 6294, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:00.177701 #train# step 6295, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:01.737706 #train# step 6296, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:03.306376 #train# step 6297, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:04.868917 #train# step 6298, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:06.442902 #train# step 6299, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:08.001207 #train# step 6300, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:09.566629 #train# step 6301, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:11.127741 #train# step 6302, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:12.690718 #train# step 6303, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:14.247976 #train# step 6304, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:15.823007 #train# step 6305, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:17.381574 #train# step 6306, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:18.959356 #train# step 6307, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:20.509314 #train# step 6308, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:22.063773 #train# step 6309, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:23.627188 #train# step 6310, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:25.196886 #train# step 6311, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:26.771159 #train# step 6312, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:28.329408 #train# step 6313, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:29.942165 #train# step 6314, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:31.523307 #train# step 6315, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:33.092453 #train# step 6316, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:34.661329 #train# step 6317, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:36.192537 #train# step 6318, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:37.742925 #train# step 6319, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:39.324277 #train# step 6320, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:40.900388 #train# step 6321, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:42.462609 #train# step 6322, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:44.059407 #train# step 6323, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:45.614409 #train# step 6324, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:47.197725 #train# step 6325, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:48.772529 #train# step 6326, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:50.310249 #train# step 6327, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:51.852728 #train# step 6328, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:53.407816 #train# step 6329, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:54.981807 #train# step 6330, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:56.524410 #train# step 6331, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:58.103134 #train# step 6332, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:24:59.650766 #train# step 6333, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:01.208614 #train# step 6334, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:02.786865 #train# step 6335, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:04.310321 #train# step 6336, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:05.884600 #train# step 6337, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:07.468922 #train# step 6338, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:09.035289 #train# step 6339, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:10.614030 #train# step 6340, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:12.198305 #train# step 6341, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:13.766033 #train# step 6342, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:15.325262 #train# step 6343, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:16.857378 #train# step 6344, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:18.454404 #train# step 6345, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:20.012162 #train# step 6346, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:21.574408 #train# step 6347, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:23.182897 #train# step 6348, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:24.764226 #train# step 6349, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:26.341220 #train# step 6350, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:27.937535 #train# step 6351, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:29.493635 #train# step 6352, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:31.054202 #train# step 6353, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:32.629331 #train# step 6354, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:34.159465 #train# step 6355, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:35.735964 #train# step 6356, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:37.309456 #train# step 6357, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:38.892294 #train# step 6358, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:40.442957 #train# step 6359, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:41.992079 #train# step 6360, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:43.538093 #train# step 6361, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:45.102563 #train# step 6362, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:46.659427 #train# step 6363, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:48.212946 #train# step 6364, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:49.782220 #train# step 6365, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:51.348249 #train# step 6366, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:52.946141 #train# step 6367, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:54.495367 #train# step 6368, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:56.068039 #train# step 6369, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:57.639436 #train# step 6370, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:25:59.193347 #train# step 6371, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:00.744452 #train# step 6372, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:02.342773 #train# step 6373, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:03.877593 #train# step 6374, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:05.452300 #train# step 6375, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:07.019203 #train# step 6376, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:08.594845 #train# step 6377, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:10.155583 #train# step 6378, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:11.721973 #train# step 6379, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:13.312789 #train# step 6380, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:14.893642 #train# step 6381, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:16.456613 #train# step 6382, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:17.989436 #train# step 6383, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:19.538786 #train# step 6384, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:21.100605 #train# step 6385, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:22.679354 #train# step 6386, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:24.235565 #train# step 6387, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:25.789197 #train# step 6388, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:27.342910 #train# step 6389, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:28.864928 #train# step 6390, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:30.469652 #train# step 6391, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:32.045430 #train# step 6392, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:33.597549 #train# step 6393, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:35.201316 #train# step 6394, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:36.797845 #train# step 6395, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:38.377726 #train# step 6396, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:39.920379 #train# step 6397, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:41.490157 #train# step 6398, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:43.070993 #train# step 6399, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:44.659293 #train# step 6400, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:46.207924 #train# step 6401, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:47.762725 #train# step 6402, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:49.327579 #train# step 6403, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:50.850236 #train# step 6404, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:52.403718 #train# step 6405, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:53.959755 #train# step 6406, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:55.530996 #train# step 6407, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:57.101725 #train# step 6408, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:26:58.652257 #train# step 6409, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:00.197510 #train# step 6410, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:01.737085 #train# step 6411, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:03.281078 #train# step 6412, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:04.850917 #train# step 6413, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:06.415622 #train# step 6414, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:07.991471 #train# step 6415, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:09.553994 #train# step 6416, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:11.119748 #train# step 6417, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:12.637581 #train# step 6418, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:14.227337 #train# step 6419, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:15.779667 #train# step 6420, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:17.339538 #train# step 6421, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:18.944266 #train# step 6422, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:20.522829 #train# step 6423, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:22.116378 #train# step 6424, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:23.682162 #train# step 6425, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:25.243331 #train# step 6426, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:26.818752 #train# step 6427, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:28.363026 #train# step 6428, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:29.964864 #train# step 6429, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:31.534015 #train# step 6430, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:33.093042 #train# step 6431, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:34.665425 #train# step 6432, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:36.203243 #train# step 6433, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:37.763416 #train# step 6434, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:39.337066 #train# step 6435, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:40.899693 #train# step 6436, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:42.480228 #train# step 6437, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:44.015804 #train# step 6438, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:45.577837 #train# step 6439, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:47.147493 #train# step 6440, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:48.684632 #train# step 6441, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:50.258807 #train# step 6442, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:51.841773 #train# step 6443, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:53.407451 #train# step 6444, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:55.000234 #train# step 6445, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:56.598307 #train# step 6446, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:58.141405 #train# step 6447, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:27:59.711776 #train# step 6448, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:01.315372 #train# step 6449, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:02.870111 #train# step 6450, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:04.438849 #train# step 6451, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:06.004702 #train# step 6452, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:07.549810 #train# step 6453, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:09.096711 #train# step 6454, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:10.638927 #train# step 6455, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:12.207483 #train# step 6456, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:13.763559 #train# step 6457, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:15.297146 #train# step 6458, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:16.886902 #train# step 6459, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:18.448399 #train# step 6460, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:20.034113 #train# step 6461, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:21.627689 #train# step 6462, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:23.180905 #train# step 6463, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:24.771967 #train# step 6464, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:26.320483 #train# step 6465, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:27.890457 #train# step 6466, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:29.441781 #train# step 6467, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:31.009954 #train# step 6468, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:32.579791 #train# step 6469, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:34.159203 #train# step 6470, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:35.725381 #train# step 6471, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:37.303946 #train# step 6472, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:38.856721 #train# step 6473, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:40.397483 #train# step 6474, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:41.961747 #train# step 6475, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:43.494590 #train# step 6476, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:45.024455 #train# step 6477, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:46.608771 #train# step 6478, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:48.192898 #train# step 6479, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:49.734666 #train# step 6480, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:51.265618 #train# step 6481, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:52.857073 #train# step 6482, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:54.429861 #train# step 6483, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:55.995531 #train# step 6484, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:57.530273 #train# step 6485, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:28:59.087199 #train# step 6486, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:00.655160 #train# step 6487, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:02.226543 #train# step 6488, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:03.771430 #train# step 6489, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:05.316632 #train# step 6490, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:06.890178 #train# step 6491, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:08.416663 #train# step 6492, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:09.961649 #train# step 6493, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:11.516830 #train# step 6494, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:13.049579 #train# step 6495, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:14.598177 #train# step 6496, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:16.155985 #train# step 6497, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:17.750599 #train# step 6498, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:19.314228 #train# step 6499, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:20.888429 #train# step 6500, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:22.508951 #train# step 6501, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:24.074293 #train# step 6502, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:25.638566 #train# step 6503, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:27.184171 #train# step 6504, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:28.785896 #train# step 6505, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:30.347612 #train# step 6506, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:31.919871 #train# step 6507, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:33.477462 #train# step 6508, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:35.051382 #train# step 6509, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:36.600341 #train# step 6510, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:38.164073 #train# step 6511, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:39.713203 #train# step 6512, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:41.261594 #train# step 6513, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:42.862816 #train# step 6514, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:44.417110 #train# step 6515, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:45.995716 #train# step 6516, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:47.556789 #train# step 6517, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:49.152615 #train# step 6518, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:50.741295 #train# step 6519, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:52.302826 #train# step 6520, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:53.893176 #train# step 6521, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:55.444224 #train# step 6522, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:57.008095 #train# step 6523, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:29:58.569312 #train# step 6524, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:00.137103 #train# step 6525, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:01.690470 #train# step 6526, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:03.240571 #train# step 6527, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:04.810333 #train# step 6528, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:06.351706 #train# step 6529, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:07.928383 #train# step 6530, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:09.506706 #train# step 6531, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:11.081485 #train# step 6532, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:12.661079 #train# step 6533, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:14.222737 #train# step 6534, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:15.786510 #train# step 6535, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:17.342781 #train# step 6536, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:18.888405 #train# step 6537, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:20.438626 #train# step 6538, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:21.992505 #train# step 6539, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:23.580854 #train# step 6540, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:25.125198 #train# step 6541, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:26.651137 #train# step 6542, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:28.235166 #train# step 6543, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:29.824178 #train# step 6544, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:31.395562 #train# step 6545, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:33.009476 #train# step 6546, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:34.583642 #train# step 6547, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:36.120539 #train# step 6548, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:37.671014 #train# step 6549, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:39.241916 #train# step 6550, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:40.805940 #train# step 6551, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:42.412593 #train# step 6552, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:43.964692 #train# step 6553, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:45.506580 #train# step 6554, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:47.080278 #train# step 6555, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:48.623516 #train# step 6556, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:50.225684 #train# step 6557, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:51.777584 #train# step 6558, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:53.353847 #train# step 6559, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:54.899590 #train# step 6560, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:56.468241 #train# step 6561, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:58.043036 #train# step 6562, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:30:59.591754 #train# step 6563, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:01.191351 #train# step 6564, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:02.727535 #train# step 6565, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:04.302008 #train# step 6566, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:05.851069 #train# step 6567, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:07.416691 #train# step 6568, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:08.975307 #train# step 6569, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:10.521013 #train# step 6570, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:12.105646 #train# step 6571, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:13.689453 #train# step 6572, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:15.241190 #train# step 6573, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:16.841358 #train# step 6574, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:18.407540 #train# step 6575, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:19.969684 #train# step 6576, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:21.551877 #train# step 6577, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:23.141196 #train# step 6578, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:24.711024 #train# step 6579, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:26.257900 #train# step 6580, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:27.813594 #train# step 6581, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:29.368666 #train# step 6582, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:30.922498 #train# step 6583, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:32.485865 #train# step 6584, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:34.056959 #train# step 6585, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:35.628698 #train# step 6586, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:37.169006 #train# step 6587, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:38.763747 #train# step 6588, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:40.337909 #train# step 6589, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:41.894448 #train# step 6590, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:43.491768 #train# step 6591, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:45.074587 #train# step 6592, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:46.641279 #train# step 6593, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:48.209781 #train# step 6594, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:49.797982 #train# step 6595, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:51.353547 #train# step 6596, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:52.933927 #train# step 6597, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:54.497551 #train# step 6598, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:56.032251 #train# step 6599, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:57.581361 #train# step 6600, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:31:59.149447 #train# step 6601, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:00.730091 #train# step 6602, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:02.310663 #train# step 6603, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:03.856306 #train# step 6604, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:05.416858 #train# step 6605, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:06.973528 #train# step 6606, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:08.499325 #train# step 6607, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:10.054679 #train# step 6608, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:11.651609 #train# step 6609, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:13.224111 #train# step 6610, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:14.790550 #train# step 6611, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:16.359227 #train# step 6612, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:17.918998 #train# step 6613, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:19.488380 #train# step 6614, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:21.219219 #train# step 6615, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:22.772431 #train# step 6616, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:24.321786 #train# step 6617, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:25.883203 #train# step 6618, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:27.463616 #train# step 6619, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:29.038524 #train# step 6620, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:30.583059 #train# step 6621, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:32.122421 #train# step 6622, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:33.707131 #train# step 6623, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:35.270700 #train# step 6624, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:36.836111 #train# step 6625, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:38.383688 #train# step 6626, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:39.938446 #train# step 6627, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:41.523836 #train# step 6628, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:43.089872 #train# step 6629, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:44.653636 #train# step 6630, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:46.218159 #train# step 6631, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:47.754959 #train# step 6632, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:49.303598 #train# step 6633, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:50.911360 #train# step 6634, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:52.454041 #train# step 6635, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:54.024026 #train# step 6636, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:55.592815 #train# step 6637, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:57.165701 #train# step 6638, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:32:58.725736 #train# step 6639, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:00.329110 #train# step 6640, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:01.901883 #train# step 6641, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:03.488638 #train# step 6642, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:05.090043 #train# step 6643, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:06.682522 #train# step 6644, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:08.254168 #train# step 6645, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:09.811086 #train# step 6646, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:11.394206 #train# step 6647, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:12.958050 #train# step 6648, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:14.529503 #train# step 6649, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:16.062648 #train# step 6650, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:17.606217 #train# step 6651, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:19.163647 #train# step 6652, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:20.728535 #train# step 6653, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:22.305341 #train# step 6654, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:23.846709 #train# step 6655, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:25.394334 #train# step 6656, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:26.973118 #train# step 6657, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:28.545367 #train# step 6658, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:30.069771 #train# step 6659, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:31.621966 #train# step 6660, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:33.181505 #train# step 6661, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:34.729470 #train# step 6662, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:36.295172 #train# step 6663, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:37.861468 #train# step 6664, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:39.417509 #train# step 6665, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:40.977508 #train# step 6666, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:42.575225 #train# step 6667, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:44.123416 #train# step 6668, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:45.678335 #train# step 6669, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:47.233933 #train# step 6670, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:48.785494 #train# step 6671, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:50.367179 #train# step 6672, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:51.904414 #train# step 6673, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:53.481539 #train# step 6674, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:55.030525 #train# step 6675, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:56.587887 #train# step 6676, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:58.147909 #train# step 6677, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:33:59.721995 #train# step 6678, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:01.258178 #train# step 6679, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:02.843429 #train# step 6680, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:04.399706 #train# step 6681, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:05.948650 #train# step 6682, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:07.561480 #train# step 6683, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:09.123699 #train# step 6684, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:10.667800 #train# step 6685, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:12.211109 #train# step 6686, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:13.785267 #train# step 6687, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:15.360398 #train# step 6688, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:16.885397 #train# step 6689, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:18.487998 #train# step 6690, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:20.019353 #train# step 6691, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:21.558940 #train# step 6692, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:23.114481 #train# step 6693, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:24.712075 #train# step 6694, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:26.291439 #train# step 6695, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:27.853438 #train# step 6696, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:29.459016 #train# step 6697, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:31.045975 #train# step 6698, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:32.646680 #train# step 6699, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:34.203321 #train# step 6700, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:35.795572 #train# step 6701, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:37.354654 #train# step 6702, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:38.953993 #train# step 6703, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:40.523791 #train# step 6704, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:42.097950 #train# step 6705, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:43.633532 #train# step 6706, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:45.196880 #train# step 6707, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:46.726616 #train# step 6708, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:48.323868 #train# step 6709, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:49.840689 #train# step 6710, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:51.393217 #train# step 6711, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:52.957515 #train# step 6712, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:54.521230 #train# step 6713, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:56.065751 #train# step 6714, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:57.638298 #train# step 6715, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:34:59.220317 #train# step 6716, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:00.810772 #train# step 6717, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:02.354858 #train# step 6718, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:03.902962 #train# step 6719, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:05.476961 #train# step 6720, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:07.045301 #train# step 6721, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:08.624601 #train# step 6722, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:10.213867 #train# step 6723, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:11.827025 #train# step 6724, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:13.426992 #train# step 6725, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:14.992450 #train# step 6726, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:16.554988 #train# step 6727, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:18.125460 #train# step 6728, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:19.658676 #train# step 6729, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:21.241595 #train# step 6730, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:22.826548 #train# step 6731, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:24.382466 #train# step 6732, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:25.958939 #train# step 6733, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:27.500518 #train# step 6734, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:29.034435 #train# step 6735, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:30.597798 #train# step 6736, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:32.172143 #train# step 6737, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:33.755476 #train# step 6738, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:35.308109 #train# step 6739, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:36.856879 #train# step 6740, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:38.418849 #train# step 6741, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:39.985261 #train# step 6742, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:41.568449 #train# step 6743, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:43.122787 #train# step 6744, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:44.720166 #train# step 6745, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:46.264546 #train# step 6746, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:47.845008 #train# step 6747, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:49.418765 #train# step 6748, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:50.982542 #train# step 6749, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:52.516613 #train# step 6750, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:54.088443 #train# step 6751, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:55.650961 #train# step 6752, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:57.199134 #train# step 6753, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:35:58.767749 #train# step 6754, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:00.337716 #train# step 6755, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:01.884530 #train# step 6756, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:03.413411 #train# step 6757, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:04.979559 #train# step 6758, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:06.518229 #train# step 6759, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:08.091005 #train# step 6760, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:09.667762 #train# step 6761, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:11.207928 #train# step 6762, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:12.742033 #train# step 6763, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:14.292309 #train# step 6764, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:15.855221 #train# step 6765, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:17.445751 #train# step 6766, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:19.000933 #train# step 6767, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:20.564137 #train# step 6768, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:22.116608 #train# step 6769, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:23.696289 #train# step 6770, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:25.273055 #train# step 6771, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:26.818184 #train# step 6772, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:28.389393 #train# step 6773, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:29.960678 #train# step 6774, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:31.518516 #train# step 6775, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:33.089386 #train# step 6776, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:34.639420 #train# step 6777, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:36.215290 #train# step 6778, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:37.795891 #train# step 6779, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:39.361871 #train# step 6780, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:40.942481 #train# step 6781, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:42.480091 #train# step 6782, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:44.028179 #train# step 6783, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:45.597200 #train# step 6784, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:47.173287 #train# step 6785, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:48.720211 #train# step 6786, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:50.332532 #train# step 6787, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:51.907555 #train# step 6788, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:53.446327 #train# step 6789, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:55.014033 #train# step 6790, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:56.572842 #train# step 6791, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:58.108811 #train# step 6792, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:36:59.670594 #train# step 6793, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:01.245403 #train# step 6794, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:02.857029 #train# step 6795, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:04.416689 #train# step 6796, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:05.973575 #train# step 6797, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:07.534033 #train# step 6798, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:09.096989 #train# step 6799, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:10.654946 #train# step 6800, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:12.199694 #train# step 6801, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:13.771697 #train# step 6802, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:15.302893 #train# step 6803, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:16.840037 #train# step 6804, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:18.415785 #train# step 6805, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:19.980531 #train# step 6806, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:21.524195 #train# step 6807, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:23.086251 #train# step 6808, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:24.647465 #train# step 6809, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:26.178107 #train# step 6810, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:27.742174 #train# step 6811, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:29.313089 #train# step 6812, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:30.834190 #train# step 6813, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:32.439945 #train# step 6814, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:34.059826 #train# step 6815, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:35.669884 #train# step 6816, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:37.205355 #train# step 6817, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:38.773509 #train# step 6818, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:40.341517 #train# step 6819, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:41.897965 #train# step 6820, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:43.439325 #train# step 6821, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:45.020043 #train# step 6822, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:46.603652 #train# step 6823, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:48.155926 #train# step 6824, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:49.721527 #train# step 6825, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:51.283717 #train# step 6826, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:52.879863 #train# step 6827, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:54.441107 #train# step 6828, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:56.040974 #train# step 6829, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:57.606348 #train# step 6830, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:37:59.176126 #train# step 6831, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:00.732479 #train# step 6832, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:02.288262 #train# step 6833, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:03.834374 #train# step 6834, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:05.400244 #train# step 6835, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:06.993056 #train# step 6836, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:08.541332 #train# step 6837, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:10.110164 #train# step 6838, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:11.672981 #train# step 6839, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:13.238988 #train# step 6840, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:14.788906 #train# step 6841, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:16.331312 #train# step 6842, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:17.923991 #train# step 6843, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:19.498631 #train# step 6844, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:21.054971 #train# step 6845, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:22.576505 #train# step 6846, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:24.134778 #train# step 6847, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:25.696995 #train# step 6848, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:27.253573 #train# step 6849, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:28.800441 #train# step 6850, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:30.401821 #train# step 6851, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:31.970883 #train# step 6852, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:33.531498 #train# step 6853, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:35.084142 #train# step 6854, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:36.651790 #train# step 6855, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:38.208096 #train# step 6856, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:39.758397 #train# step 6857, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:41.339407 #train# step 6858, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:42.899358 #train# step 6859, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:44.469708 #train# step 6860, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:46.042141 #train# step 6861, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:47.613260 #train# step 6862, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:49.206655 #train# step 6863, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:50.738060 #train# step 6864, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:52.297710 #train# step 6865, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:53.857587 #train# step 6866, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:55.452363 #train# step 6867, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:57.004308 #train# step 6868, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:38:58.567384 #train# step 6869, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:00.124749 #train# step 6870, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:01.671382 #train# step 6871, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:03.246304 #train# step 6872, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:04.789797 #train# step 6873, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:06.400508 #train# step 6874, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:07.955591 #train# step 6875, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:09.503275 #train# step 6876, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:11.089176 #train# step 6877, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:12.640735 #train# step 6878, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:14.192714 #train# step 6879, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:15.745619 #train# step 6880, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:17.312251 #train# step 6881, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:18.881275 #train# step 6882, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:20.454273 #train# step 6883, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:22.052906 #train# step 6884, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:23.651838 #train# step 6885, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:25.196649 #train# step 6886, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:26.764789 #train# step 6887, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:28.336545 #train# step 6888, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:29.923457 #train# step 6889, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:31.491749 #train# step 6890, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:33.055872 #train# step 6891, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:34.628664 #train# step 6892, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:36.213395 #train# step 6893, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:37.780225 #train# step 6894, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:39.332644 #train# step 6895, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:40.870417 #train# step 6896, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:42.426033 #train# step 6897, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:44.017377 #train# step 6898, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:45.597929 #train# step 6899, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:47.130933 #train# step 6900, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:48.710331 #train# step 6901, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:50.276482 #train# step 6902, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:51.851466 #train# step 6903, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:53.400594 #train# step 6904, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:54.968739 #train# step 6905, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:56.529344 #train# step 6906, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:58.090533 #train# step 6907, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:39:59.649537 #train# step 6908, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:01.218582 #train# step 6909, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:02.765789 #train# step 6910, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:04.325286 #train# step 6911, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:05.889116 #train# step 6912, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:07.415287 #train# step 6913, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:08.991300 #train# step 6914, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:10.553005 #train# step 6915, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:12.112295 #train# step 6916, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:13.644288 #train# step 6917, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:15.222425 #train# step 6918, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:16.751972 #train# step 6919, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:18.327501 #train# step 6920, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:19.888378 #train# step 6921, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:21.447797 #train# step 6922, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:23.003605 #train# step 6923, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:24.563541 #train# step 6924, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:26.103735 #train# step 6925, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:27.673888 #train# step 6926, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:29.267651 #train# step 6927, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:30.832427 #train# step 6928, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:32.426784 #train# step 6929, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:33.986584 #train# step 6930, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:35.567780 #train# step 6931, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:37.131500 #train# step 6932, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:38.705672 #train# step 6933, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:40.257959 #train# step 6934, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:41.832061 #train# step 6935, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:43.376367 #train# step 6936, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:44.960713 #train# step 6937, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:46.499244 #train# step 6938, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:48.060789 #train# step 6939, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:49.635001 #train# step 6940, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:51.169227 #train# step 6941, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:52.742969 #train# step 6942, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:54.315278 #train# step 6943, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:55.907423 #train# step 6944, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:57.462330 #train# step 6945, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:40:59.059304 #train# step 6946, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:00.573180 #train# step 6947, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:02.173251 #train# step 6948, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:03.723275 #train# step 6949, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:05.268604 #train# step 6950, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:06.827414 #train# step 6951, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:08.419445 #train# step 6952, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:09.986628 #train# step 6953, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:11.609801 #train# step 6954, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:13.186992 #train# step 6955, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:14.775924 #train# step 6956, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:16.319106 #train# step 6957, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:17.846599 #train# step 6958, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:19.415708 #train# step 6959, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:20.962671 #train# step 6960, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:22.544016 #train# step 6961, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:24.114417 #train# step 6962, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:25.649127 #train# step 6963, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:27.201372 #train# step 6964, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:28.783425 #train# step 6965, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:30.359730 #train# step 6966, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:31.939124 #train# step 6967, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:33.530498 #train# step 6968, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:35.102819 #train# step 6969, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:36.656576 #train# step 6970, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:38.213229 #train# step 6971, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:39.784205 #train# step 6972, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:41.368123 #train# step 6973, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:42.873079 #train# step 6974, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:44.412579 #train# step 6975, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:45.984273 #train# step 6976, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:47.536654 #train# step 6977, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:49.125115 #train# step 6978, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:50.707066 #train# step 6979, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:52.292163 #train# step 6980, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:53.874601 #train# step 6981, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:55.450198 #train# step 6982, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:57.032251 #train# step 6983, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:41:58.614082 #train# step 6984, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:00.178986 #train# step 6985, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:01.731249 #train# step 6986, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:03.278205 #train# step 6987, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:04.826087 #train# step 6988, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:06.442397 #train# step 6989, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:08.002049 #train# step 6990, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:09.528464 #train# step 6991, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:11.092421 #train# step 6992, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:12.646862 #train# step 6993, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:14.197190 #train# step 6994, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:15.757327 #train# step 6995, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:17.314110 #train# step 6996, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:18.875513 #train# step 6997, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:20.460097 #train# step 6998, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:22.041670 #train# step 6999, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:23.575646 #train# step 7000, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:25.130813 #train# step 7001, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:26.774271 #train# step 7002, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:28.311350 #train# step 7003, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:29.889263 #train# step 7004, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:31.456415 #train# step 7005, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:33.030669 #train# step 7006, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:34.592685 #train# step 7007, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:36.144334 #train# step 7008, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:37.699855 #train# step 7009, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:39.286474 #train# step 7010, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:40.845567 #train# step 7011, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:42.388108 #train# step 7012, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:43.936730 #train# step 7013, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:45.542527 #train# step 7014, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:47.154950 #train# step 7015, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:48.718008 #train# step 7016, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:50.246689 #train# step 7017, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:51.789477 #train# step 7018, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:53.374881 #train# step 7019, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:54.949335 #train# step 7020, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:56.498166 #train# step 7021, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:58.085324 #train# step 7022, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:42:59.653596 #train# step 7023, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:01.226966 #train# step 7024, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:02.786337 #train# step 7025, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:04.340099 #train# step 7026, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:05.947162 #train# step 7027, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:07.531906 #train# step 7028, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:09.063716 #train# step 7029, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:10.605172 #train# step 7030, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:12.188174 #train# step 7031, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:13.713378 #train# step 7032, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:15.297986 #train# step 7033, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:16.874896 #train# step 7034, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:18.449245 #train# step 7035, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:20.041869 #train# step 7036, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:21.598703 #train# step 7037, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:23.158505 #train# step 7038, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:24.735407 #train# step 7039, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:26.272942 #train# step 7040, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:27.840617 #train# step 7041, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:29.427095 #train# step 7042, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:30.980547 #train# step 7043, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:32.514201 #train# step 7044, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:34.057327 #train# step 7045, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:35.627159 #train# step 7046, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:37.198052 #train# step 7047, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:38.783816 #train# step 7048, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:40.373807 #train# step 7049, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:41.918077 #train# step 7050, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:43.500704 #train# step 7051, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:45.091607 #train# step 7052, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:46.649018 #train# step 7053, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:48.232841 #train# step 7054, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:49.793605 #train# step 7055, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:51.338987 #train# step 7056, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:52.899576 #train# step 7057, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:54.465520 #train# step 7058, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:56.022577 #train# step 7059, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:57.603169 #train# step 7060, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:43:59.179830 #train# step 7061, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:00.751315 #train# step 7062, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:02.292167 #train# step 7063, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:03.840291 #train# step 7064, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:05.391910 #train# step 7065, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:06.974661 #train# step 7066, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:08.523122 #train# step 7067, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:10.098570 #train# step 7068, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:11.713903 #train# step 7069, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:13.277324 #train# step 7070, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:14.829419 #train# step 7071, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:16.402090 #train# step 7072, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:17.946716 #train# step 7073, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:19.508763 #train# step 7074, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:21.066992 #train# step 7075, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:22.623539 #train# step 7076, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:24.222075 #train# step 7077, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:25.812325 #train# step 7078, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:27.340095 #train# step 7079, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:28.898627 #train# step 7080, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:30.481191 #train# step 7081, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:32.019409 #train# step 7082, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:33.594889 #train# step 7083, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:35.160124 #train# step 7084, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:36.738928 #train# step 7085, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:38.321514 #train# step 7086, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:39.890824 #train# step 7087, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:41.452903 #train# step 7088, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:43.010113 #train# step 7089, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:44.574091 #train# step 7090, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:46.134178 #train# step 7091, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:47.705517 #train# step 7092, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:49.287739 #train# step 7093, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:50.863476 #train# step 7094, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:52.397005 #train# step 7095, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:53.970433 #train# step 7096, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:55.490361 #train# step 7097, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:57.057902 #train# step 7098, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:44:58.651541 #train# step 7099, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:00.236393 #train# step 7100, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:01.801240 #train# step 7101, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:03.358014 #train# step 7102, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:04.943243 #train# step 7103, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:06.518466 #train# step 7104, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:08.099441 #train# step 7105, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:09.667338 #train# step 7106, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:11.235512 #train# step 7107, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:12.783127 #train# step 7108, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:14.350726 #train# step 7109, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:15.919711 #train# step 7110, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:17.466704 #train# step 7111, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:19.068842 #train# step 7112, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:20.618840 #train# step 7113, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:22.198005 #train# step 7114, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:23.759253 #train# step 7115, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:25.267270 #train# step 7116, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:26.821634 #train# step 7117, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:28.370794 #train# step 7118, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:29.936058 #train# step 7119, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:31.469397 #train# step 7120, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:33.041402 #train# step 7121, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:34.587151 #train# step 7122, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:36.167731 #train# step 7123, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:37.711763 #train# step 7124, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:39.305898 #train# step 7125, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:40.861521 #train# step 7126, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:42.466781 #train# step 7127, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:43.998795 #train# step 7128, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:45.551961 #train# step 7129, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:47.114735 #train# step 7130, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:48.655746 #train# step 7131, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:50.283768 #train# step 7132, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:51.866505 #train# step 7133, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:53.460118 #train# step 7134, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:55.013809 #train# step 7135, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:56.558968 #train# step 7136, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:58.109434 #train# step 7137, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:45:59.644082 #train# step 7138, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:01.198893 #train# step 7139, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:02.772402 #train# step 7140, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:04.347417 #train# step 7141, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:05.888304 #train# step 7142, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:07.463012 #train# step 7143, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:09.040336 #train# step 7144, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:10.583869 #train# step 7145, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:12.160154 #train# step 7146, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:13.740687 #train# step 7147, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:15.310122 #train# step 7148, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:16.883835 #train# step 7149, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:18.452549 #train# step 7150, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:20.030466 #train# step 7151, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:21.610506 #train# step 7152, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:23.162112 #train# step 7153, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:24.704085 #train# step 7154, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:26.278718 #train# step 7155, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:27.857614 #train# step 7156, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:29.423888 #train# step 7157, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:30.996689 #train# step 7158, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:32.590859 #train# step 7159, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:34.153673 #train# step 7160, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:35.749020 #train# step 7161, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:37.282297 #train# step 7162, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:38.831926 #train# step 7163, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:40.386579 #train# step 7164, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:41.965199 #train# step 7165, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:43.542800 #train# step 7166, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:45.122243 #train# step 7167, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:46.678089 #train# step 7168, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:48.243968 #train# step 7169, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:49.784886 #train# step 7170, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:51.340262 #train# step 7171, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:52.918099 #train# step 7172, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:54.495492 #train# step 7173, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:56.040543 #train# step 7174, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:57.593285 #train# step 7175, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:46:59.172175 #train# step 7176, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:00.726292 #train# step 7177, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:02.303824 #train# step 7178, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:03.870157 #train# step 7179, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:05.447844 #train# step 7180, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:06.986282 #train# step 7181, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:08.560956 #train# step 7182, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:10.129290 #train# step 7183, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:11.675318 #train# step 7184, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:13.225532 #train# step 7185, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:14.752992 #train# step 7186, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:16.376783 #train# step 7187, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:17.931451 #train# step 7188, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:19.514075 #train# step 7189, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:21.085444 #train# step 7190, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:22.641622 #train# step 7191, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:24.185866 #train# step 7192, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:25.742790 #train# step 7193, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:27.314554 #train# step 7194, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:28.883554 #train# step 7195, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:30.422690 #train# step 7196, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:32.014172 #train# step 7197, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:33.568335 #train# step 7198, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:35.114930 #train# step 7199, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:36.644865 #train# step 7200, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:38.165853 #train# step 7201, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:39.729161 #train# step 7202, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:41.297412 #train# step 7203, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:42.843089 #train# step 7204, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:44.402892 #train# step 7205, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:45.987694 #train# step 7206, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:47.563514 #train# step 7207, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:49.131569 #train# step 7208, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:50.710354 #train# step 7209, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:52.282925 #train# step 7210, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:53.858230 #train# step 7211, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:55.438885 #train# step 7212, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:56.989204 #train# step 7213, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:47:58.580846 #train# step 7214, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:00.149562 #train# step 7215, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:01.734018 #train# step 7216, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:03.303227 #train# step 7217, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:04.845165 #train# step 7218, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:06.397851 #train# step 7219, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:07.940049 #train# step 7220, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:09.515623 #train# step 7221, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:11.074166 #train# step 7222, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:12.661476 #train# step 7223, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:14.187988 #train# step 7224, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:15.794073 #train# step 7225, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:17.350798 #train# step 7226, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:18.931997 #train# step 7227, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:20.503133 #train# step 7228, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:22.053856 #train# step 7229, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:23.630752 #train# step 7230, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:25.223674 #train# step 7231, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:26.809507 #train# step 7232, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:28.369086 #train# step 7233, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:29.948458 #train# step 7234, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:31.495153 #train# step 7235, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:33.057247 #train# step 7236, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:34.597654 #train# step 7237, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:36.180896 #train# step 7238, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:37.750938 #train# step 7239, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:39.328839 #train# step 7240, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:40.891223 #train# step 7241, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:42.456828 #train# step 7242, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:44.019644 #train# step 7243, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:45.586655 #train# step 7244, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:47.147726 #train# step 7245, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:48.716236 #train# step 7246, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:50.278927 #train# step 7247, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:51.812178 #train# step 7248, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:53.386233 #train# step 7249, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:54.936582 #train# step 7250, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:56.499582 #train# step 7251, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:58.031785 #train# step 7252, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:48:59.603395 #train# step 7253, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:01.180934 #train# step 7254, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:02.765120 #train# step 7255, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:04.338476 #train# step 7256, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:05.868265 #train# step 7257, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:07.435247 #train# step 7258, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:08.982683 #train# step 7259, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:10.560088 #train# step 7260, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:12.124302 #train# step 7261, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:13.649108 #train# step 7262, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:15.201552 #train# step 7263, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:16.784507 #train# step 7264, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:18.371240 #train# step 7265, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:19.965993 #train# step 7266, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:21.529804 #train# step 7267, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:23.128926 #train# step 7268, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:24.689888 #train# step 7269, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:26.265087 #train# step 7270, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:27.862436 #train# step 7271, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:29.388182 #train# step 7272, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:30.988440 #train# step 7273, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:32.558199 #train# step 7274, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:34.116514 #train# step 7275, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:35.685944 #train# step 7276, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:37.226826 #train# step 7277, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:38.776889 #train# step 7278, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:40.362477 #train# step 7279, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:41.898447 #train# step 7280, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:43.471179 #train# step 7281, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:45.064407 #train# step 7282, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:46.643490 #train# step 7283, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:48.206848 #train# step 7284, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:49.752691 #train# step 7285, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:51.309280 #train# step 7286, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:52.876924 #train# step 7287, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:54.451893 #train# step 7288, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:55.999542 #train# step 7289, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:57.543783 #train# step 7290, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:49:59.114744 #train# step 7291, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:00.649746 #train# step 7292, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:02.199693 #train# step 7293, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:03.763567 #train# step 7294, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:05.372520 #train# step 7295, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:06.921403 #train# step 7296, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:08.492093 #train# step 7297, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:10.035897 #train# step 7298, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:11.618280 #train# step 7299, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:13.208346 #train# step 7300, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:14.761414 #train# step 7301, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:16.329760 #train# step 7302, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:17.889869 #train# step 7303, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:19.492816 #train# step 7304, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:21.042866 #train# step 7305, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:22.600364 #train# step 7306, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:24.208856 #train# step 7307, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:25.748207 #train# step 7308, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:27.341018 #train# step 7309, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:28.932529 #train# step 7310, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:30.473287 #train# step 7311, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:32.030990 #train# step 7312, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:33.605479 #train# step 7313, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:35.196768 #train# step 7314, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:36.798100 #train# step 7315, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:38.345268 #train# step 7316, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:39.895295 #train# step 7317, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:41.442308 #train# step 7318, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:42.995064 #train# step 7319, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:44.563902 #train# step 7320, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:46.133566 #train# step 7321, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:47.698950 #train# step 7322, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:49.248394 #train# step 7323, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:50.808264 #train# step 7324, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:52.387054 #train# step 7325, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:53.947196 #train# step 7326, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:55.511303 #train# step 7327, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:57.044364 #train# step 7328, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:50:58.637860 #train# step 7329, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:00.195987 #train# step 7330, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:01.774646 #train# step 7331, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:03.314073 #train# step 7332, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:04.890133 #train# step 7333, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:06.467282 #train# step 7334, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:08.015034 #train# step 7335, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:09.601589 #train# step 7336, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:11.188624 #train# step 7337, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:12.760995 #train# step 7338, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:14.348524 #train# step 7339, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:15.917049 #train# step 7340, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:17.469077 #train# step 7341, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:19.058279 #train# step 7342, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:20.606161 #train# step 7343, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:22.169871 #train# step 7344, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:23.724365 #train# step 7345, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:25.297225 #train# step 7346, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:26.860393 #train# step 7347, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:28.398629 #train# step 7348, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:29.954447 #train# step 7349, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:31.508344 #train# step 7350, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:33.052176 #train# step 7351, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:34.592938 #train# step 7352, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:36.168982 #train# step 7353, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:37.706353 #train# step 7354, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:39.276288 #train# step 7355, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:40.848545 #train# step 7356, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:42.411933 #train# step 7357, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:43.967906 #train# step 7358, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:45.556601 #train# step 7359, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:47.099179 #train# step 7360, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:48.670834 #train# step 7361, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:50.222227 #train# step 7362, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:51.790215 #train# step 7363, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:53.341315 #train# step 7364, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:54.941745 #train# step 7365, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:56.500487 #train# step 7366, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:58.099736 #train# step 7367, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:51:59.662141 #train# step 7368, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:01.226967 #train# step 7369, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:02.800484 #train# step 7370, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:04.351288 #train# step 7371, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:05.886952 #train# step 7372, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:07.457582 #train# step 7373, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:09.034792 #train# step 7374, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:10.643155 #train# step 7375, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:12.209086 #train# step 7376, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:13.758356 #train# step 7377, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:15.326780 #train# step 7378, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:16.910049 #train# step 7379, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:18.455021 #train# step 7380, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:20.050437 #train# step 7381, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:21.606088 #train# step 7382, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:23.171823 #train# step 7383, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:24.777408 #train# step 7384, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:26.345365 #train# step 7385, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:27.887175 #train# step 7386, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:29.447371 #train# step 7387, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:31.002347 #train# step 7388, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:32.575507 #train# step 7389, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:34.129326 #train# step 7390, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:35.656215 #train# step 7391, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:37.207585 #train# step 7392, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:38.766812 #train# step 7393, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:40.344109 #train# step 7394, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:41.921543 #train# step 7395, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:43.491154 #train# step 7396, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:45.036016 #train# step 7397, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:46.611495 #train# step 7398, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:48.176328 #train# step 7399, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:49.746657 #train# step 7400, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:51.313129 #train# step 7401, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:52.863754 #train# step 7402, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:54.448111 #train# step 7403, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:56.018446 #train# step 7404, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:57.609270 #train# step 7405, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:52:59.169239 #train# step 7406, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:00.759879 #train# step 7407, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:02.322616 #train# step 7408, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:03.900038 #train# step 7409, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:05.483907 #train# step 7410, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:07.063567 #train# step 7411, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:08.634341 #train# step 7412, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:10.198647 #train# step 7413, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:11.788726 #train# step 7414, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:13.353139 #train# step 7415, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:14.885043 #train# step 7416, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:16.454122 #train# step 7417, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:18.032920 #train# step 7418, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:19.594408 #train# step 7419, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:21.171518 #train# step 7420, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:22.723558 #train# step 7421, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:24.280856 #train# step 7422, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:25.816052 #train# step 7423, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:27.381611 #train# step 7424, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:28.933537 #train# step 7425, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:30.523853 #train# step 7426, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:32.108879 #train# step 7427, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:33.659480 #train# step 7428, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:35.223045 #train# step 7429, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:36.756146 #train# step 7430, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:38.302299 #train# step 7431, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:39.935809 #train# step 7432, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:41.505032 #train# step 7433, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:43.067618 #train# step 7434, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:44.615433 #train# step 7435, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:46.174579 #train# step 7436, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:47.745733 #train# step 7437, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:49.330719 #train# step 7438, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:50.901601 #train# step 7439, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:52.447329 #train# step 7440, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:53.996507 #train# step 7441, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:55.571465 #train# step 7442, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:57.114890 #train# step 7443, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:53:58.682860 #train# step 7444, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:00.241942 #train# step 7445, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:01.817943 #train# step 7446, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:03.379112 #train# step 7447, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:04.939165 #train# step 7448, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:06.510201 #train# step 7449, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:08.062582 #train# step 7450, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:09.609527 #train# step 7451, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:11.179124 #train# step 7452, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:12.736352 #train# step 7453, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:14.319928 #train# step 7454, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:15.856374 #train# step 7455, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:17.445450 #train# step 7456, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:19.034507 #train# step 7457, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:20.606219 #train# step 7458, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:22.157493 #train# step 7459, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:23.722292 #train# step 7460, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:25.269649 #train# step 7461, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:26.809953 #train# step 7462, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:28.387093 #train# step 7463, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:29.933118 #train# step 7464, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:31.546861 #train# step 7465, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:33.111511 #train# step 7466, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:34.693104 #train# step 7467, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:36.272578 #train# step 7468, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:37.804784 #train# step 7469, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:39.337532 #train# step 7470, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:40.926317 #train# step 7471, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:42.502462 #train# step 7472, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:44.069598 #train# step 7473, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:45.640800 #train# step 7474, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:47.214062 #train# step 7475, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:48.796031 #train# step 7476, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:50.349017 #train# step 7477, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:51.939332 #train# step 7478, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:53.508793 #train# step 7479, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:55.079587 #train# step 7480, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:56.645341 #train# step 7481, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:58.199650 #train# step 7482, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:54:59.747108 #train# step 7483, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:01.285228 #train# step 7484, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:02.848722 #train# step 7485, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:04.418368 #train# step 7486, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:05.983772 #train# step 7487, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:07.595601 #train# step 7488, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:09.128608 #train# step 7489, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:10.690065 #train# step 7490, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:12.271268 #train# step 7491, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:13.835021 #train# step 7492, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:15.411669 #train# step 7493, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:16.977782 #train# step 7494, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:18.549931 #train# step 7495, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:20.076612 #train# step 7496, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:21.658257 #train# step 7497, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:23.232525 #train# step 7498, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:24.829835 #train# step 7499, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:26.389714 #train# step 7500, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:27.991817 #train# step 7501, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:29.561082 #train# step 7502, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:31.113937 #train# step 7503, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:32.648323 #train# step 7504, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:34.189166 #train# step 7505, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:35.757631 #train# step 7506, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:37.329827 #train# step 7507, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:38.909982 #train# step 7508, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:40.468012 #train# step 7509, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:41.998559 #train# step 7510, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:43.569673 #train# step 7511, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:45.123617 #train# step 7512, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:46.675622 #train# step 7513, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:48.279178 #train# step 7514, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:49.851917 #train# step 7515, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:51.410889 #train# step 7516, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:52.956266 #train# step 7517, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:54.524870 #train# step 7518, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:56.084636 #train# step 7519, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:57.661803 #train# step 7520, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:55:59.224919 #train# step 7521, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:00.796637 #train# step 7522, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:02.381549 #train# step 7523, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:03.937398 #train# step 7524, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:05.481817 #train# step 7525, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:07.035357 #train# step 7526, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:08.599285 #train# step 7527, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:10.157342 #train# step 7528, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:11.708785 #train# step 7529, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:13.298348 #train# step 7530, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:14.893087 #train# step 7531, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:16.459178 #train# step 7532, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:18.004050 #train# step 7533, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:19.516845 #train# step 7534, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:21.071414 #train# step 7535, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:22.600842 #train# step 7536, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:24.139984 #train# step 7537, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:25.737689 #train# step 7538, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:27.282161 #train# step 7539, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:28.854090 #train# step 7540, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:30.442664 #train# step 7541, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:32.002695 #train# step 7542, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:33.595320 #train# step 7543, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:35.161868 #train# step 7544, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:36.726579 #train# step 7545, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:38.276607 #train# step 7546, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:39.856968 #train# step 7547, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:41.443042 #train# step 7548, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:43.008390 #train# step 7549, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:44.579980 #train# step 7550, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:46.146645 #train# step 7551, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:47.699378 #train# step 7552, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:49.271112 #train# step 7553, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:50.815290 #train# step 7554, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:52.372105 #train# step 7555, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:53.961608 #train# step 7556, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:55.543263 #train# step 7557, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:57.104634 #train# step 7558, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:56:58.669984 #train# step 7559, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:00.256110 #train# step 7560, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:01.842481 #train# step 7561, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:03.397139 #train# step 7562, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:04.959505 #train# step 7563, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:06.511694 #train# step 7564, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:08.061814 #train# step 7565, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:09.626353 #train# step 7566, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:11.194175 #train# step 7567, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:12.762213 #train# step 7568, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:14.328062 #train# step 7569, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:15.886213 #train# step 7570, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:17.466403 #train# step 7571, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:19.034149 #train# step 7572, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:20.599277 #train# step 7573, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:22.165827 #train# step 7574, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:23.748810 #train# step 7575, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:25.333759 #train# step 7576, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:26.881676 #train# step 7577, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:28.482325 #train# step 7578, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:30.026009 #train# step 7579, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:31.581900 #train# step 7580, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:33.137983 #train# step 7581, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:34.689243 #train# step 7582, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:36.255525 #train# step 7583, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:37.849322 #train# step 7584, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:39.409203 #train# step 7585, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:41.027636 #train# step 7586, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:42.566075 #train# step 7587, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:44.115461 #train# step 7588, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:45.687922 #train# step 7589, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:47.216292 #train# step 7590, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:48.795878 #train# step 7591, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:50.348282 #train# step 7592, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:51.903297 #train# step 7593, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:53.492910 #train# step 7594, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:55.065799 #train# step 7595, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:56.631660 #train# step 7596, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:58.204783 #train# step 7597, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:57:59.760818 #train# step 7598, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:01.311781 #train# step 7599, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:02.887286 #train# step 7600, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:04.453336 #train# step 7601, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:06.023479 #train# step 7602, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:07.580037 #train# step 7603, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:09.150897 #train# step 7604, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:10.692678 #train# step 7605, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:12.241668 #train# step 7606, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:13.784932 #train# step 7607, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:15.374082 #train# step 7608, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:16.922919 #train# step 7609, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:18.493483 #train# step 7610, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:20.051053 #train# step 7611, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:21.598294 #train# step 7612, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:23.177752 #train# step 7613, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:24.758986 #train# step 7614, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:26.367980 #train# step 7615, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:27.928537 #train# step 7616, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:29.497468 #train# step 7617, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:31.042925 #train# step 7618, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:32.589275 #train# step 7619, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:34.122352 #train# step 7620, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:35.661968 #train# step 7621, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:37.214865 #train# step 7622, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:38.810128 #train# step 7623, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:40.364263 #train# step 7624, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:41.910297 #train# step 7625, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:43.488085 #train# step 7626, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:45.056418 #train# step 7627, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:46.612607 #train# step 7628, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:48.187767 #train# step 7629, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:49.784157 #train# step 7630, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:51.364160 #train# step 7631, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:52.910731 #train# step 7632, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:54.487139 #train# step 7633, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:56.082727 #train# step 7634, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:57.668281 #train# step 7635, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:58:59.230785 #train# step 7636, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:00.793252 #train# step 7637, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:02.373767 #train# step 7638, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:03.903908 #train# step 7639, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:05.454438 #train# step 7640, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:07.036773 #train# step 7641, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:08.553879 #train# step 7642, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:10.146163 #train# step 7643, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:11.704877 #train# step 7644, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:13.278210 #train# step 7645, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:14.877334 #train# step 7646, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:16.430262 #train# step 7647, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:17.977777 #train# step 7648, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:19.555556 #train# step 7649, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:21.107815 #train# step 7650, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:22.687632 #train# step 7651, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:24.260022 #train# step 7652, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:25.815202 #train# step 7653, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:27.374885 #train# step 7654, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:28.978395 #train# step 7655, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:30.530392 #train# step 7656, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:32.073741 #train# step 7657, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:33.647755 #train# step 7658, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:35.194639 #train# step 7659, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:36.759308 #train# step 7660, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:38.324160 #train# step 7661, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:39.917613 #train# step 7662, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:41.503762 #train# step 7663, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:43.031500 #train# step 7664, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:44.594377 #train# step 7665, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:46.135240 #train# step 7666, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:47.678177 #train# step 7667, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:49.219965 #train# step 7668, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:50.785574 #train# step 7669, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:52.318680 #train# step 7670, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:53.859435 #train# step 7671, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:55.410796 #train# step 7672, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:56.971021 #train# step 7673, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 16:59:58.548846 #train# step 7674, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:00.144467 #train# step 7675, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:01.700619 #train# step 7676, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:03.268580 #train# step 7677, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:04.845270 #train# step 7678, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:06.431321 #train# step 7679, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:08.019315 #train# step 7680, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:09.568852 #train# step 7681, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:11.116778 #train# step 7682, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:12.666011 #train# step 7683, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:14.240860 #train# step 7684, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:15.815244 #train# step 7685, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:17.393795 #train# step 7686, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:18.969394 #train# step 7687, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:20.551948 #train# step 7688, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:22.134006 #train# step 7689, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:23.677453 #train# step 7690, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:25.275943 #train# step 7691, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:26.836031 #train# step 7692, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:28.391493 #train# step 7693, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:29.951747 #train# step 7694, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:31.508982 #train# step 7695, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:33.069191 #train# step 7696, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:34.608172 #train# step 7697, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:36.195664 #train# step 7698, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:37.730411 #train# step 7699, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:39.263482 #train# step 7700, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:40.843755 #train# step 7701, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:42.445446 #train# step 7702, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:44.010220 #train# step 7703, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:45.563510 #train# step 7704, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:47.137665 #train# step 7705, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:48.713795 #train# step 7706, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:50.281202 #train# step 7707, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:51.838089 #train# step 7708, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:53.388182 #train# step 7709, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:54.944834 #train# step 7710, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:56.492249 #train# step 7711, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:58.044541 #train# step 7712, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:00:59.583458 #train# step 7713, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:01.187225 #train# step 7714, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:02.748690 #train# step 7715, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:04.319743 #train# step 7716, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:05.890092 #train# step 7717, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:07.473629 #train# step 7718, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:09.082806 #train# step 7719, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:10.664335 #train# step 7720, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:12.204274 #train# step 7721, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:13.772927 #train# step 7722, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:15.316618 #train# step 7723, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:16.897539 #train# step 7724, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:18.474662 #train# step 7725, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:20.064682 #train# step 7726, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:21.658623 #train# step 7727, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:23.262903 #train# step 7728, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:24.859354 #train# step 7729, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:26.394604 #train# step 7730, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:27.983600 #train# step 7731, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:29.544803 #train# step 7732, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:31.092858 #train# step 7733, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:32.652267 #train# step 7734, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:34.229757 #train# step 7735, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:35.774286 #train# step 7736, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:37.337237 #train# step 7737, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:38.896607 #train# step 7738, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:40.458511 #train# step 7739, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:42.037625 #train# step 7740, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:43.636189 #train# step 7741, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:45.199617 #train# step 7742, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:46.756484 #train# step 7743, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:48.293028 #train# step 7744, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:49.847236 #train# step 7745, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:51.383233 #train# step 7746, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:52.947735 #train# step 7747, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:54.488422 #train# step 7748, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:56.065244 #train# step 7749, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:57.626126 #train# step 7750, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:01:59.188808 #train# step 7751, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:00.761278 #train# step 7752, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:02.316625 #train# step 7753, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:03.877151 #train# step 7754, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:05.445628 #train# step 7755, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:07.022748 #train# step 7756, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:08.579194 #train# step 7757, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:10.126506 #train# step 7758, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:11.676712 #train# step 7759, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:13.219985 #train# step 7760, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:14.817799 #train# step 7761, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:16.380311 #train# step 7762, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:17.955682 #train# step 7763, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:19.522794 #train# step 7764, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:21.076597 #train# step 7765, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:22.645616 #train# step 7766, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:24.206601 #train# step 7767, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:25.829442 #train# step 7768, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:27.387472 #train# step 7769, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:28.978113 #train# step 7770, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:30.543551 #train# step 7771, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:32.093002 #train# step 7772, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:33.671791 #train# step 7773, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:35.219704 #train# step 7774, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:36.800901 #train# step 7775, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:38.383785 #train# step 7776, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:39.951614 #train# step 7777, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:41.514285 #train# step 7778, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:43.071174 #train# step 7779, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:44.635042 #train# step 7780, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:46.180864 #train# step 7781, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:47.771538 #train# step 7782, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:49.320005 #train# step 7783, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:50.901776 #train# step 7784, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:52.470467 #train# step 7785, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:54.024082 #train# step 7786, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:55.563589 #train# step 7787, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:57.133685 #train# step 7788, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:02:58.681046 #train# step 7789, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:00.219059 #train# step 7790, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:01.780597 #train# step 7791, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:03.344120 #train# step 7792, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:04.910961 #train# step 7793, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:06.476567 #train# step 7794, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:08.029080 #train# step 7795, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:09.622792 #train# step 7796, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:11.179605 #train# step 7797, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:12.743276 #train# step 7798, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:14.333213 #train# step 7799, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:15.889965 #train# step 7800, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:17.426135 #train# step 7801, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:18.973205 #train# step 7802, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:20.555458 #train# step 7803, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:22.158853 #train# step 7804, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:23.678303 #train# step 7805, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:25.252332 #train# step 7806, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:26.813168 #train# step 7807, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:28.358243 #train# step 7808, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:29.932891 #train# step 7809, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:31.504048 #train# step 7810, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:33.074907 #train# step 7811, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:34.652154 #train# step 7812, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:36.205490 #train# step 7813, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:37.799530 #train# step 7814, loss = 0.8902, cross_entropy loss = 0.8902, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:39.335468 #train# step 7815, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:40.908526 #train# step 7816, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:42.511839 #train# step 7817, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:44.059285 #train# step 7818, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:45.599636 #train# step 7819, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:47.118971 #train# step 7820, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:48.699907 #train# step 7821, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:50.259073 #train# step 7822, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:51.834068 #train# step 7823, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:53.398499 #train# step 7824, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:54.931043 #train# step 7825, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:56.491777 #train# step 7826, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:58.059199 #train# step 7827, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:03:59.650947 #train# step 7828, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:01.207573 #train# step 7829, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:02.757309 #train# step 7830, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:04.304058 #train# step 7831, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:05.889420 #train# step 7832, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:07.451049 #train# step 7833, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:09.010166 #train# step 7834, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:10.594599 #train# step 7835, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:12.151694 #train# step 7836, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:13.732857 #train# step 7837, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:15.300541 #train# step 7838, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:16.869132 #train# step 7839, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:18.426168 #train# step 7840, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:19.983970 #train# step 7841, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:21.524034 #train# step 7842, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:23.082900 #train# step 7843, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:24.658717 #train# step 7844, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:26.224700 #train# step 7845, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:27.779192 #train# step 7846, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:29.342693 #train# step 7847, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:30.928510 #train# step 7848, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:32.549054 #train# step 7849, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:34.141341 #train# step 7850, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:35.723423 #train# step 7851, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:37.288870 #train# step 7852, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:38.821921 #train# step 7853, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:40.387121 #train# step 7854, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:41.937668 #train# step 7855, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:43.501794 #train# step 7856, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:45.049008 #train# step 7857, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:46.610158 #train# step 7858, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:48.165577 #train# step 7859, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:49.758218 #train# step 7860, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:51.302860 #train# step 7861, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:52.843146 #train# step 7862, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:54.445206 #train# step 7863, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:56.035188 #train# step 7864, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:57.597739 #train# step 7865, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:04:59.165894 #train# step 7866, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:00.710269 #train# step 7867, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:02.258617 #train# step 7868, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:03.795030 #train# step 7869, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:05.371573 #train# step 7870, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:06.942906 #train# step 7871, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:08.545789 #train# step 7872, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:10.102051 #train# step 7873, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:11.660272 #train# step 7874, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:13.238418 #train# step 7875, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:14.818883 #train# step 7876, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:16.371822 #train# step 7877, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:17.912174 #train# step 7878, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:19.480101 #train# step 7879, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:21.057470 #train# step 7880, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:22.629921 #train# step 7881, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:24.204114 #train# step 7882, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:25.752916 #train# step 7883, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:27.344236 #train# step 7884, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:28.920387 #train# step 7885, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:30.478443 #train# step 7886, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:32.053221 #train# step 7887, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:33.610950 #train# step 7888, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:35.157539 #train# step 7889, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:36.688625 #train# step 7890, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:38.251466 #train# step 7891, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:39.806948 #train# step 7892, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:41.346427 #train# step 7893, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:42.929511 #train# step 7894, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:44.535357 #train# step 7895, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:46.093984 #train# step 7896, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:47.685453 #train# step 7897, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:49.233849 #train# step 7898, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:50.784567 #train# step 7899, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:52.339042 #train# step 7900, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:53.920762 #train# step 7901, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:55.483165 #train# step 7902, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:57.085518 #train# step 7903, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:05:58.654872 #train# step 7904, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:00.226244 #train# step 7905, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:01.755807 #train# step 7906, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:03.308554 #train# step 7907, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:04.864872 #train# step 7908, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:06.419145 #train# step 7909, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:07.980433 #train# step 7910, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:09.551622 #train# step 7911, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:11.107443 #train# step 7912, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:12.654449 #train# step 7913, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:14.218938 #train# step 7914, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:15.775210 #train# step 7915, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:17.304117 #train# step 7916, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:18.869034 #train# step 7917, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:20.428434 #train# step 7918, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:21.994912 #train# step 7919, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:23.551114 #train# step 7920, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:25.125406 #train# step 7921, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:26.692963 #train# step 7922, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:28.245400 #train# step 7923, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:29.810506 #train# step 7924, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:31.385953 #train# step 7925, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:32.939334 #train# step 7926, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:34.500544 #train# step 7927, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:36.048030 #train# step 7928, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:37.582177 #train# step 7929, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:39.141904 #train# step 7930, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:40.728234 #train# step 7931, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:42.295681 #train# step 7932, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:43.893835 #train# step 7933, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:45.465752 #train# step 7934, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:47.009486 #train# step 7935, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:48.595458 #train# step 7936, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:50.175779 #train# step 7937, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:51.718900 #train# step 7938, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:53.304553 #train# step 7939, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:54.884193 #train# step 7940, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:56.472084 #train# step 7941, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:58.038808 #train# step 7942, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:06:59.634745 #train# step 7943, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:01.214519 #train# step 7944, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:02.760756 #train# step 7945, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:04.304206 #train# step 7946, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:05.840557 #train# step 7947, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:07.408641 #train# step 7948, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:08.967657 #train# step 7949, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:10.546770 #train# step 7950, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:12.109497 #train# step 7951, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:13.681380 #train# step 7952, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:15.262523 #train# step 7953, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:16.791949 #train# step 7954, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:18.351923 #train# step 7955, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:19.945179 #train# step 7956, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:21.528239 #train# step 7957, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:23.118034 #train# step 7958, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:24.680804 #train# step 7959, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:26.243686 #train# step 7960, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:27.810739 #train# step 7961, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:29.365651 #train# step 7962, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:30.907647 #train# step 7963, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:32.477864 #train# step 7964, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:34.064214 #train# step 7965, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:35.663292 #train# step 7966, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:37.205437 #train# step 7967, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:38.770817 #train# step 7968, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:40.330622 #train# step 7969, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:41.918230 #train# step 7970, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:43.474933 #train# step 7971, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:45.022359 #train# step 7972, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:46.585819 #train# step 7973, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:48.154692 #train# step 7974, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:49.701172 #train# step 7975, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:51.290170 #train# step 7976, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:52.863827 #train# step 7977, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:54.446668 #train# step 7978, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:55.987588 #train# step 7979, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:57.550957 #train# step 7980, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:07:59.103701 #train# step 7981, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:00.693889 #train# step 7982, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:02.264874 #train# step 7983, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:03.827437 #train# step 7984, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:05.407884 #train# step 7985, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:06.965557 #train# step 7986, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:08.523442 #train# step 7987, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:10.092310 #train# step 7988, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:11.644572 #train# step 7989, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:13.195086 #train# step 7990, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:14.761525 #train# step 7991, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:16.305107 #train# step 7992, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:17.857254 #train# step 7993, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:19.428561 #train# step 7994, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:20.977273 #train# step 7995, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:22.542580 #train# step 7996, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:24.105641 #train# step 7997, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:25.697947 #train# step 7998, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:27.256398 #train# step 7999, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:28.799250 #train# step 8000, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:30.390621 #train# step 8001, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:31.955994 #train# step 8002, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:33.507455 #train# step 8003, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:35.088443 #train# step 8004, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:36.646978 #train# step 8005, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:38.195763 #train# step 8006, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:39.779298 #train# step 8007, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:41.336867 #train# step 8008, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:42.911122 #train# step 8009, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:44.496716 #train# step 8010, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:46.084377 #train# step 8011, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:47.623805 #train# step 8012, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:49.200284 #train# step 8013, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:50.757041 #train# step 8014, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:52.290021 #train# step 8015, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:53.866170 #train# step 8016, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:55.398713 #train# step 8017, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:56.967640 #train# step 8018, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:08:58.523587 #train# step 8019, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:00.107290 #train# step 8020, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:01.672805 #train# step 8021, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:03.209470 #train# step 8022, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:04.781147 #train# step 8023, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:06.345822 #train# step 8024, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:07.905619 #train# step 8025, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:09.476281 #train# step 8026, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:11.062105 #train# step 8027, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:12.628400 #train# step 8028, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:14.190553 #train# step 8029, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:15.759822 #train# step 8030, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:17.306080 #train# step 8031, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:18.880358 #train# step 8032, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:20.436389 #train# step 8033, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:22.039959 #train# step 8034, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:23.602897 #train# step 8035, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:25.172256 #train# step 8036, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:26.753785 #train# step 8037, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:28.327100 #train# step 8038, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:29.937381 #train# step 8039, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:31.478696 #train# step 8040, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:33.044057 #train# step 8041, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:34.631914 #train# step 8042, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:36.213138 #train# step 8043, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:37.804918 #train# step 8044, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:39.392121 #train# step 8045, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:40.988690 #train# step 8046, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:42.560395 #train# step 8047, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:44.128129 #train# step 8048, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:45.674218 #train# step 8049, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:47.223162 #train# step 8050, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:48.776984 #train# step 8051, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:50.371827 #train# step 8052, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:51.892352 #train# step 8053, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:53.470917 #train# step 8054, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:55.033697 #train# step 8055, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:56.594332 #train# step 8056, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:58.133221 #train# step 8057, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:09:59.729154 #train# step 8058, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:01.303258 #train# step 8059, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:02.876355 #train# step 8060, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:04.425536 #train# step 8061, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:06.007244 #train# step 8062, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:07.556697 #train# step 8063, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:09.134146 #train# step 8064, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:10.690528 #train# step 8065, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:12.248830 #train# step 8066, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:13.791705 #train# step 8067, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:15.347065 #train# step 8068, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:16.873595 #train# step 8069, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:18.413114 #train# step 8070, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:19.993380 #train# step 8071, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:21.558012 #train# step 8072, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:23.131403 #train# step 8073, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:24.703868 #train# step 8074, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:26.246218 #train# step 8075, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:27.808423 #train# step 8076, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:29.364522 #train# step 8077, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:30.949932 #train# step 8078, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:32.522432 #train# step 8079, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:34.068152 #train# step 8080, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:35.625895 #train# step 8081, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:37.171174 #train# step 8082, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:38.750380 #train# step 8083, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:40.311703 #train# step 8084, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:41.894427 #train# step 8085, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:43.458890 #train# step 8086, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:45.013206 #train# step 8087, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:46.574470 #train# step 8088, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:48.159283 #train# step 8089, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:49.705291 #train# step 8090, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:51.307478 #train# step 8091, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:52.882221 #train# step 8092, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:54.456435 #train# step 8093, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:56.013512 #train# step 8094, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:57.570230 #train# step 8095, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:10:59.123434 #train# step 8096, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:00.700130 #train# step 8097, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:02.237925 #train# step 8098, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:03.808091 #train# step 8099, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:05.376452 #train# step 8100, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:06.953681 #train# step 8101, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:08.521755 #train# step 8102, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:10.051692 #train# step 8103, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:11.602069 #train# step 8104, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:13.190478 #train# step 8105, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:14.792018 #train# step 8106, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:16.344832 #train# step 8107, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:17.891049 #train# step 8108, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:19.428677 #train# step 8109, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:21.007098 #train# step 8110, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:22.565362 #train# step 8111, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:24.100448 #train# step 8112, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:25.640501 #train# step 8113, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:27.231732 #train# step 8114, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:28.824775 #train# step 8115, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:30.374863 #train# step 8116, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:31.975716 #train# step 8117, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:33.553482 #train# step 8118, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:35.092794 #train# step 8119, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:36.642956 #train# step 8120, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:38.197192 #train# step 8121, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:39.773634 #train# step 8122, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:41.289761 #train# step 8123, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:42.853802 #train# step 8124, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:44.390461 #train# step 8125, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:45.969040 #train# step 8126, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:47.572556 #train# step 8127, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:49.169982 #train# step 8128, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:50.741205 #train# step 8129, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:52.313175 #train# step 8130, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:53.893404 #train# step 8131, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:55.459108 #train# step 8132, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:57.029429 #train# step 8133, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:11:58.582914 #train# step 8134, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:00.157398 #train# step 8135, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:01.708568 #train# step 8136, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:03.270962 #train# step 8137, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:04.861834 #train# step 8138, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:06.443345 #train# step 8139, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:08.015380 #train# step 8140, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:09.570162 #train# step 8141, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:11.147427 #train# step 8142, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:12.701722 #train# step 8143, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:14.276739 #train# step 8144, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:15.808117 #train# step 8145, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:17.358874 #train# step 8146, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:18.941486 #train# step 8147, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:20.478452 #train# step 8148, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:22.011093 #train# step 8149, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:23.567123 #train# step 8150, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:25.101254 #train# step 8151, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:26.664266 #train# step 8152, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:28.237550 #train# step 8153, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:29.787038 #train# step 8154, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:31.361827 #train# step 8155, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:32.961722 #train# step 8156, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:34.515772 #train# step 8157, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:36.087920 #train# step 8158, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:37.643940 #train# step 8159, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:39.241534 #train# step 8160, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:40.813481 #train# step 8161, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:42.357464 #train# step 8162, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:43.933161 #train# step 8163, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:45.501056 #train# step 8164, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:47.072343 #train# step 8165, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:48.646524 #train# step 8166, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:50.233672 #train# step 8167, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:51.756084 #train# step 8168, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:53.339065 #train# step 8169, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:54.910170 #train# step 8170, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:56.471529 #train# step 8171, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:58.010481 #train# step 8172, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:12:59.587097 #train# step 8173, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:01.137456 #train# step 8174, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:02.732872 #train# step 8175, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:04.274201 #train# step 8176, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:05.878230 #train# step 8177, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:07.435645 #train# step 8178, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:08.998086 #train# step 8179, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:10.567585 #train# step 8180, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:12.150882 #train# step 8181, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:13.707101 #train# step 8182, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:15.285935 #train# step 8183, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:16.808243 #train# step 8184, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:18.394484 #train# step 8185, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:19.958194 #train# step 8186, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:21.525887 #train# step 8187, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:23.081493 #train# step 8188, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:24.647575 #train# step 8189, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:26.206340 #train# step 8190, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:27.750779 #train# step 8191, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:29.332711 #train# step 8192, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:30.900574 #train# step 8193, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:32.485549 #train# step 8194, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:34.053698 #train# step 8195, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:35.647856 #train# step 8196, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:37.196057 #train# step 8197, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:38.740105 #train# step 8198, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:40.317921 #train# step 8199, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:41.869116 #train# step 8200, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:43.384393 #train# step 8201, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:44.922303 #train# step 8202, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:46.483325 #train# step 8203, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:48.029518 #train# step 8204, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:49.582714 #train# step 8205, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:51.140852 #train# step 8206, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:52.725351 #train# step 8207, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:54.265548 #train# step 8208, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:55.814580 #train# step 8209, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:57.390524 #train# step 8210, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:13:58.974883 #train# step 8211, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:00.535919 #train# step 8212, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:02.100247 #train# step 8213, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:03.662541 #train# step 8214, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:05.239601 #train# step 8215, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:06.840224 #train# step 8216, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:08.401903 #train# step 8217, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:09.971573 #train# step 8218, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:11.547876 #train# step 8219, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:13.097778 #train# step 8220, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:14.646317 #train# step 8221, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:16.220758 #train# step 8222, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:17.792582 #train# step 8223, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:19.378699 #train# step 8224, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:20.972564 #train# step 8225, loss = 0.8858, cross_entropy loss = 0.8858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:22.530663 #train# step 8226, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:24.086745 #train# step 8227, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:25.660325 #train# step 8228, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:27.227954 #train# step 8229, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:28.774647 #train# step 8230, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:30.321721 #train# step 8231, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:31.889873 #train# step 8232, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:33.457922 #train# step 8233, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:35.016089 #train# step 8234, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:36.592927 #train# step 8235, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:38.159951 #train# step 8236, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:39.734593 #train# step 8237, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:41.294517 #train# step 8238, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:42.862271 #train# step 8239, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:44.425478 #train# step 8240, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:45.961363 #train# step 8241, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:47.493006 #train# step 8242, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:49.069898 #train# step 8243, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:50.642456 #train# step 8244, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:52.208466 #train# step 8245, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:53.775242 #train# step 8246, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:55.353828 #train# step 8247, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:56.931042 #train# step 8248, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:14:58.496619 #train# step 8249, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:00.051232 #train# step 8250, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:01.598957 #train# step 8251, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:03.196132 #train# step 8252, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:04.739219 #train# step 8253, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:06.320630 #train# step 8254, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:07.868912 #train# step 8255, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:09.459104 #train# step 8256, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:11.014387 #train# step 8257, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:12.578773 #train# step 8258, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:14.149102 #train# step 8259, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:15.743842 #train# step 8260, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:17.309995 #train# step 8261, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:18.839686 #train# step 8262, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:20.434782 #train# step 8263, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:22.004879 #train# step 8264, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:23.514177 #train# step 8265, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:25.102330 #train# step 8266, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:26.667464 #train# step 8267, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:28.234275 #train# step 8268, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:29.791856 #train# step 8269, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:31.386506 #train# step 8270, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:32.949222 #train# step 8271, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:34.543639 #train# step 8272, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:36.118313 #train# step 8273, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:37.685903 #train# step 8274, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:39.252149 #train# step 8275, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:40.813658 #train# step 8276, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:42.379092 #train# step 8277, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:43.943419 #train# step 8278, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:45.513683 #train# step 8279, loss = 0.8896, cross_entropy loss = 0.8896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:47.082541 #train# step 8280, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:48.644084 #train# step 8281, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:50.178679 #train# step 8282, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:51.726489 #train# step 8283, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:53.279659 #train# step 8284, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:54.846952 #train# step 8285, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:56.400005 #train# step 8286, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:57.968271 #train# step 8287, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:15:59.570169 #train# step 8288, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:01.147510 #train# step 8289, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:02.701139 #train# step 8290, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:04.271955 #train# step 8291, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:05.839887 #train# step 8292, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:07.402533 #train# step 8293, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:08.934414 #train# step 8294, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:10.486277 #train# step 8295, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:12.019218 #train# step 8296, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:13.589902 #train# step 8297, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:15.177895 #train# step 8298, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:16.724234 #train# step 8299, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:18.299336 #train# step 8300, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:19.821624 #train# step 8301, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:21.391992 #train# step 8302, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:22.980438 #train# step 8303, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:24.586698 #train# step 8304, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:26.180647 #train# step 8305, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:27.765405 #train# step 8306, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:29.360501 #train# step 8307, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:30.926769 #train# step 8308, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:32.500419 #train# step 8309, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:34.083068 #train# step 8310, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:35.662811 #train# step 8311, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:37.248072 #train# step 8312, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:38.783431 #train# step 8313, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:40.326153 #train# step 8314, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:41.888387 #train# step 8315, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:43.441273 #train# step 8316, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:45.004866 #train# step 8317, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:46.549189 #train# step 8318, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:48.109727 #train# step 8319, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:49.661356 #train# step 8320, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:51.189099 #train# step 8321, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:52.748477 #train# step 8322, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:54.313875 #train# step 8323, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:55.889945 #train# step 8324, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:57.437530 #train# step 8325, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:16:59.009900 #train# step 8326, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:00.562723 #train# step 8327, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:02.134869 #train# step 8328, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:03.685574 #train# step 8329, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:05.266652 #train# step 8330, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:06.838621 #train# step 8331, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:08.373056 #train# step 8332, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:09.924513 #train# step 8333, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:11.482541 #train# step 8334, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:13.059427 #train# step 8335, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:14.608219 #train# step 8336, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:16.172466 #train# step 8337, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:17.741805 #train# step 8338, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:19.288359 #train# step 8339, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:20.857611 #train# step 8340, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:22.412074 #train# step 8341, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:23.997880 #train# step 8342, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:25.558227 #train# step 8343, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:27.132212 #train# step 8344, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:28.681851 #train# step 8345, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:30.242820 #train# step 8346, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:31.830404 #train# step 8347, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:33.398867 #train# step 8348, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:34.942979 #train# step 8349, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:36.557904 #train# step 8350, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:38.170362 #train# step 8351, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:39.706340 #train# step 8352, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:41.255961 #train# step 8353, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:42.827447 #train# step 8354, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:44.397550 #train# step 8355, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:45.963200 #train# step 8356, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:47.547905 #train# step 8357, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:49.121309 #train# step 8358, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:50.654966 #train# step 8359, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:52.243175 #train# step 8360, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:53.805066 #train# step 8361, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:55.394734 #train# step 8362, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:56.958048 #train# step 8363, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:17:58.527312 #train# step 8364, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:00.104436 #train# step 8365, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:01.644591 #train# step 8366, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:03.222707 #train# step 8367, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:04.781001 #train# step 8368, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:06.349079 #train# step 8369, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:07.944228 #train# step 8370, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:09.499388 #train# step 8371, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:11.054963 #train# step 8372, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:12.576458 #train# step 8373, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:14.127369 #train# step 8374, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:15.722679 #train# step 8375, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:17.298849 #train# step 8376, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:18.842496 #train# step 8377, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:20.395599 #train# step 8378, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:21.954046 #train# step 8379, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:23.523973 #train# step 8380, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:25.095177 #train# step 8381, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:26.670528 #train# step 8382, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:28.243097 #train# step 8383, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:29.770715 #train# step 8384, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:31.329639 #train# step 8385, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:32.891123 #train# step 8386, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:34.490559 #train# step 8387, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:36.077809 #train# step 8388, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:37.675010 #train# step 8389, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:39.244893 #train# step 8390, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:40.789313 #train# step 8391, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:42.349376 #train# step 8392, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:43.902137 #train# step 8393, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:45.468754 #train# step 8394, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:46.978855 #train# step 8395, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:48.514231 #train# step 8396, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:50.092706 #train# step 8397, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:51.654099 #train# step 8398, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:53.236342 #train# step 8399, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:54.790478 #train# step 8400, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:56.368806 #train# step 8401, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:57.922533 #train# step 8402, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:18:59.492519 #train# step 8403, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:01.087691 #train# step 8404, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:02.644897 #train# step 8405, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:04.242703 #train# step 8406, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:05.791858 #train# step 8407, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:07.348071 #train# step 8408, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:08.920122 #train# step 8409, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:10.476909 #train# step 8410, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:12.064930 #train# step 8411, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:13.633832 #train# step 8412, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:15.200531 #train# step 8413, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:16.748241 #train# step 8414, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:18.326060 #train# step 8415, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:19.906888 #train# step 8416, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:21.473201 #train# step 8417, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:23.072947 #train# step 8418, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:24.651826 #train# step 8419, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:26.203203 #train# step 8420, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:27.797172 #train# step 8421, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:29.355618 #train# step 8422, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:30.911779 #train# step 8423, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:32.479570 #train# step 8424, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:34.051659 #train# step 8425, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:35.630535 #train# step 8426, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:37.220591 #train# step 8427, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:38.749903 #train# step 8428, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:40.249592 #train# step 8429, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:41.814186 #train# step 8430, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:43.362087 #train# step 8431, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:44.920869 #train# step 8432, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:46.474907 #train# step 8433, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:48.042869 #train# step 8434, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:49.613310 #train# step 8435, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:51.148938 #train# step 8436, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:52.761875 #train# step 8437, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:54.338086 #train# step 8438, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:55.927897 #train# step 8439, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:57.520302 #train# step 8440, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:19:59.095487 #train# step 8441, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:00.640529 #train# step 8442, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:02.184732 #train# step 8443, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:03.739551 #train# step 8444, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:05.322512 #train# step 8445, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:06.871280 #train# step 8446, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:08.469605 #train# step 8447, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:10.040081 #train# step 8448, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:11.596440 #train# step 8449, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:13.160670 #train# step 8450, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:14.736757 #train# step 8451, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:16.247572 #train# step 8452, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:17.817314 #train# step 8453, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:19.346120 #train# step 8454, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:20.922100 #train# step 8455, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:22.492360 #train# step 8456, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:24.062245 #train# step 8457, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:25.604337 #train# step 8458, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:27.160757 #train# step 8459, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:28.741908 #train# step 8460, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:30.345469 #train# step 8461, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:31.929822 #train# step 8462, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:33.467185 #train# step 8463, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:35.031514 #train# step 8464, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:36.576571 #train# step 8465, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:38.120441 #train# step 8466, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:39.681716 #train# step 8467, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:41.244098 #train# step 8468, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:42.818716 #train# step 8469, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:44.366052 #train# step 8470, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:45.911525 #train# step 8471, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:47.493683 #train# step 8472, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:49.055497 #train# step 8473, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:50.607062 #train# step 8474, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:52.203408 #train# step 8475, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:53.786474 #train# step 8476, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:55.319292 #train# step 8477, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:56.891699 #train# step 8478, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:20:58.493316 #train# step 8479, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:00.068349 #train# step 8480, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:01.636391 #train# step 8481, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:03.192282 #train# step 8482, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:04.763439 #train# step 8483, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:06.347531 #train# step 8484, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:07.885777 #train# step 8485, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:09.480453 #train# step 8486, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:11.068945 #train# step 8487, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:12.628049 #train# step 8488, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:14.186778 #train# step 8489, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:15.773141 #train# step 8490, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:17.342094 #train# step 8491, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:18.903213 #train# step 8492, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:20.490101 #train# step 8493, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:22.073863 #train# step 8494, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:23.645544 #train# step 8495, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:25.203984 #train# step 8496, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:26.794409 #train# step 8497, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:28.350257 #train# step 8498, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:29.929198 #train# step 8499, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:31.480669 #train# step 8500, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:33.050261 #train# step 8501, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:34.622884 #train# step 8502, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:36.200594 #train# step 8503, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:37.721673 #train# step 8504, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:39.270128 #train# step 8505, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:40.825339 #train# step 8506, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:42.362157 #train# step 8507, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:43.930481 #train# step 8508, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:45.486425 #train# step 8509, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:47.061812 #train# step 8510, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:48.599033 #train# step 8511, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:50.181277 #train# step 8512, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:51.746284 #train# step 8513, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:53.281484 #train# step 8514, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:54.833806 #train# step 8515, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:56.382963 #train# step 8516, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:57.958526 #train# step 8517, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:21:59.496424 #train# step 8518, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:01.066415 #train# step 8519, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:02.655506 #train# step 8520, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:04.218087 #train# step 8521, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:05.778687 #train# step 8522, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:07.347699 #train# step 8523, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:08.934577 #train# step 8524, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:10.514581 #train# step 8525, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:12.054150 #train# step 8526, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:13.636270 #train# step 8527, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:15.201848 #train# step 8528, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:16.769852 #train# step 8529, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:18.319526 #train# step 8530, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:19.870566 #train# step 8531, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:21.469721 #train# step 8532, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:23.058299 #train# step 8533, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:24.621310 #train# step 8534, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:26.177552 #train# step 8535, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:27.713916 #train# step 8536, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:29.285043 #train# step 8537, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:30.825435 #train# step 8538, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:32.393022 #train# step 8539, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:33.973331 #train# step 8540, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:35.569165 #train# step 8541, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:37.111734 #train# step 8542, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:38.682509 #train# step 8543, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:40.238604 #train# step 8544, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:41.817247 #train# step 8545, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:43.373461 #train# step 8546, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:44.972922 #train# step 8547, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:46.527162 #train# step 8548, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:48.139228 #train# step 8549, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:49.688071 #train# step 8550, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:51.257080 #train# step 8551, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:52.850075 #train# step 8552, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:54.420989 #train# step 8553, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:55.954764 #train# step 8554, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:57.530637 #train# step 8555, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:22:59.101078 #train# step 8556, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:00.692797 #train# step 8557, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:02.250691 #train# step 8558, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:03.840691 #train# step 8559, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:05.401250 #train# step 8560, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:06.950919 #train# step 8561, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:08.519684 #train# step 8562, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:10.072695 #train# step 8563, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:11.597795 #train# step 8564, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:13.163547 #train# step 8565, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:14.764283 #train# step 8566, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:16.307434 #train# step 8567, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:17.864984 #train# step 8568, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:19.439428 #train# step 8569, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:21.038380 #train# step 8570, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:22.588215 #train# step 8571, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:24.152387 #train# step 8572, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:25.700595 #train# step 8573, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:27.269636 #train# step 8574, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:28.855223 #train# step 8575, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:30.412848 #train# step 8576, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:31.952936 #train# step 8577, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:33.541356 #train# step 8578, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:35.115483 #train# step 8579, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:36.713683 #train# step 8580, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:38.308009 #train# step 8581, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:39.860447 #train# step 8582, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:41.397151 #train# step 8583, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:42.957475 #train# step 8584, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:44.521447 #train# step 8585, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:46.096823 #train# step 8586, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:47.646041 #train# step 8587, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:49.191253 #train# step 8588, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:50.721829 #train# step 8589, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:52.299330 #train# step 8590, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:53.841328 #train# step 8591, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:55.380937 #train# step 8592, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:56.966596 #train# step 8593, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:23:58.508161 #train# step 8594, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:00.062900 #train# step 8595, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:01.638519 #train# step 8596, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:03.174692 #train# step 8597, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:04.726535 #train# step 8598, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:06.320690 #train# step 8599, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:07.911542 #train# step 8600, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:09.499223 #train# step 8601, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:11.055713 #train# step 8602, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:12.619804 #train# step 8603, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:14.163035 #train# step 8604, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:15.730877 #train# step 8605, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:17.285748 #train# step 8606, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:18.873130 #train# step 8607, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:20.423318 #train# step 8608, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:21.981495 #train# step 8609, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:23.577338 #train# step 8610, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:25.118463 #train# step 8611, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:26.678298 #train# step 8612, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:28.252839 #train# step 8613, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:29.790092 #train# step 8614, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:31.363906 #train# step 8615, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:32.950308 #train# step 8616, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:34.491258 #train# step 8617, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:36.082772 #train# step 8618, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:37.622075 #train# step 8619, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:39.179209 #train# step 8620, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:40.744907 #train# step 8621, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:42.344588 #train# step 8622, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:43.921462 #train# step 8623, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:45.470201 #train# step 8624, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:47.049388 #train# step 8625, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:48.594731 #train# step 8626, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:50.159188 #train# step 8627, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:51.744012 #train# step 8628, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:53.318309 #train# step 8629, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:54.858908 #train# step 8630, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:56.433092 #train# step 8631, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:58.005510 #train# step 8632, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:24:59.545914 #train# step 8633, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:01.121897 #train# step 8634, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:02.669785 #train# step 8635, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:04.233787 #train# step 8636, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:05.809871 #train# step 8637, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:07.343931 #train# step 8638, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:08.892127 #train# step 8639, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:10.460691 #train# step 8640, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:12.076034 #train# step 8641, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:13.664363 #train# step 8642, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:15.268142 #train# step 8643, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:16.844815 #train# step 8644, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:18.402888 #train# step 8645, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:19.948419 #train# step 8646, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:21.521347 #train# step 8647, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:23.105432 #train# step 8648, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:24.703021 #train# step 8649, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:26.276358 #train# step 8650, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:27.863768 #train# step 8651, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:29.430585 #train# step 8652, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:30.990408 #train# step 8653, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:32.587258 #train# step 8654, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:34.125042 #train# step 8655, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:35.726008 #train# step 8656, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:37.298789 #train# step 8657, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:38.871968 #train# step 8658, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:40.442897 #train# step 8659, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:42.027842 #train# step 8660, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:43.603382 #train# step 8661, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:45.160823 #train# step 8662, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:46.743461 #train# step 8663, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:48.294507 #train# step 8664, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:49.829634 #train# step 8665, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:51.400805 #train# step 8666, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:52.982506 #train# step 8667, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:54.517485 #train# step 8668, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:56.059135 #train# step 8669, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:57.637610 #train# step 8670, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:25:59.192430 #train# step 8671, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:00.738558 #train# step 8672, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:02.294841 #train# step 8673, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:03.856778 #train# step 8674, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:05.401010 #train# step 8675, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:06.946245 #train# step 8676, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:08.486103 #train# step 8677, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:10.054617 #train# step 8678, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:11.630637 #train# step 8679, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:13.211294 #train# step 8680, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:14.767331 #train# step 8681, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:16.338300 #train# step 8682, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:17.901517 #train# step 8683, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:19.467404 #train# step 8684, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:21.021752 #train# step 8685, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:22.594338 #train# step 8686, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:24.170887 #train# step 8687, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:25.729328 #train# step 8688, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:27.299733 #train# step 8689, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:28.847608 #train# step 8690, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:30.385079 #train# step 8691, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:31.950762 #train# step 8692, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:33.531487 #train# step 8693, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:35.102577 #train# step 8694, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:36.660069 #train# step 8695, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:38.227691 #train# step 8696, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:39.778560 #train# step 8697, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:41.356605 #train# step 8698, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:42.951161 #train# step 8699, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:44.534793 #train# step 8700, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:46.095358 #train# step 8701, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:47.656979 #train# step 8702, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:49.195560 #train# step 8703, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:50.789043 #train# step 8704, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:52.365657 #train# step 8705, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:53.922165 #train# step 8706, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:55.483615 #train# step 8707, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:57.048058 #train# step 8708, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:26:58.583924 #train# step 8709, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:00.144299 #train# step 8710, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:01.758353 #train# step 8711, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:03.306756 #train# step 8712, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:04.864837 #train# step 8713, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:06.446150 #train# step 8714, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:08.020583 #train# step 8715, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:09.565475 #train# step 8716, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:11.159907 #train# step 8717, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:12.724090 #train# step 8718, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:14.266340 #train# step 8719, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:15.837434 #train# step 8720, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:17.404291 #train# step 8721, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:18.969651 #train# step 8722, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:20.522284 #train# step 8723, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:22.116184 #train# step 8724, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:23.707362 #train# step 8725, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:25.271861 #train# step 8726, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:26.815779 #train# step 8727, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:28.368918 #train# step 8728, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:29.935187 #train# step 8729, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:31.493619 #train# step 8730, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:33.028900 #train# step 8731, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:34.607538 #train# step 8732, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:36.166052 #train# step 8733, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:37.689037 #train# step 8734, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:39.270913 #train# step 8735, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:40.867836 #train# step 8736, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:42.442999 #train# step 8737, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:44.028400 #train# step 8738, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:45.592141 #train# step 8739, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:47.152675 #train# step 8740, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:48.694937 #train# step 8741, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:50.242642 #train# step 8742, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:51.829846 #train# step 8743, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:53.396623 #train# step 8744, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:54.959278 #train# step 8745, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:56.532688 #train# step 8746, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:58.133678 #train# step 8747, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:27:59.670722 #train# step 8748, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:01.222991 #train# step 8749, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:02.760889 #train# step 8750, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:04.340548 #train# step 8751, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:05.911310 #train# step 8752, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:07.449779 #train# step 8753, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:09.014360 #train# step 8754, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:10.596718 #train# step 8755, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:12.189358 #train# step 8756, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:13.762464 #train# step 8757, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:15.362173 #train# step 8758, loss = 0.8846, cross_entropy loss = 0.8846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:16.935562 #train# step 8759, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:18.525217 #train# step 8760, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:20.073566 #train# step 8761, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:21.642844 #train# step 8762, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:23.210346 #train# step 8763, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:24.760073 #train# step 8764, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:26.341803 #train# step 8765, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:27.914511 #train# step 8766, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:29.461981 #train# step 8767, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:30.970055 #train# step 8768, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:32.527102 #train# step 8769, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:34.104122 #train# step 8770, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:35.624532 #train# step 8771, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:37.169499 #train# step 8772, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:38.732730 #train# step 8773, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:40.271307 #train# step 8774, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:41.814803 #train# step 8775, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:43.374241 #train# step 8776, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:44.982053 #train# step 8777, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:46.582469 #train# step 8778, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:48.140655 #train# step 8779, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:49.709857 #train# step 8780, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:51.296233 #train# step 8781, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:52.870740 #train# step 8782, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:54.429746 #train# step 8783, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:55.987067 #train# step 8784, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:57.551822 #train# step 8785, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:28:59.128527 #train# step 8786, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:00.699598 #train# step 8787, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:02.256795 #train# step 8788, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:03.844401 #train# step 8789, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:05.399687 #train# step 8790, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:06.953805 #train# step 8791, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:08.534111 #train# step 8792, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:10.098748 #train# step 8793, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:11.663490 #train# step 8794, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:13.230031 #train# step 8795, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:14.801855 #train# step 8796, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:16.373643 #train# step 8797, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:17.945521 #train# step 8798, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:19.504232 #train# step 8799, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:21.075551 #train# step 8800, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:22.651393 #train# step 8801, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:24.201340 #train# step 8802, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:25.776396 #train# step 8803, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:27.352127 #train# step 8804, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:28.938623 #train# step 8805, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:30.489681 #train# step 8806, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:32.081589 #train# step 8807, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:33.632560 #train# step 8808, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:35.169311 #train# step 8809, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:36.745679 #train# step 8810, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:38.313383 #train# step 8811, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:39.856206 #train# step 8812, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:41.438292 #train# step 8813, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:43.021752 #train# step 8814, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:44.605861 #train# step 8815, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:46.158141 #train# step 8816, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:47.719849 #train# step 8817, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:49.279392 #train# step 8818, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:50.848040 #train# step 8819, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:52.426990 #train# step 8820, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:53.972313 #train# step 8821, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:55.514541 #train# step 8822, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:57.085869 #train# step 8823, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:29:58.666243 #train# step 8824, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:00.278623 #train# step 8825, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:01.847094 #train# step 8826, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:03.416000 #train# step 8827, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:04.997540 #train# step 8828, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:06.556441 #train# step 8829, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:08.116824 #train# step 8830, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:09.671493 #train# step 8831, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:11.228466 #train# step 8832, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:12.803215 #train# step 8833, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:14.366740 #train# step 8834, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:15.916594 #train# step 8835, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:17.489154 #train# step 8836, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:19.068259 #train# step 8837, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:20.623266 #train# step 8838, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:22.159325 #train# step 8839, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:23.759742 #train# step 8840, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:25.314883 #train# step 8841, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:26.849823 #train# step 8842, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:28.409964 #train# step 8843, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:29.983798 #train# step 8844, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:31.546558 #train# step 8845, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:33.128981 #train# step 8846, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:34.710668 #train# step 8847, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:36.288170 #train# step 8848, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:37.898910 #train# step 8849, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:39.469544 #train# step 8850, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:41.033596 #train# step 8851, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:42.582009 #train# step 8852, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:44.116152 #train# step 8853, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:45.659252 #train# step 8854, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:47.215784 #train# step 8855, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:48.778752 #train# step 8856, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:50.353019 #train# step 8857, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:51.911715 #train# step 8858, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:53.484192 #train# step 8859, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:55.049771 #train# step 8860, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:56.620148 #train# step 8861, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:58.176622 #train# step 8862, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:30:59.742295 #train# step 8863, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:01.273700 #train# step 8864, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:02.848707 #train# step 8865, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:04.400317 #train# step 8866, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:05.927884 #train# step 8867, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:07.472785 #train# step 8868, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:09.070055 #train# step 8869, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:10.640455 #train# step 8870, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:12.185297 #train# step 8871, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:13.771540 #train# step 8872, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:15.363238 #train# step 8873, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:16.932792 #train# step 8874, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:18.480263 #train# step 8875, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:20.065003 #train# step 8876, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:21.658544 #train# step 8877, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:23.237056 #train# step 8878, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:24.800229 #train# step 8879, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:26.349971 #train# step 8880, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:27.912645 #train# step 8881, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:29.506131 #train# step 8882, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:31.092722 #train# step 8883, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:32.649932 #train# step 8884, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:34.213845 #train# step 8885, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:35.786803 #train# step 8886, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:37.349062 #train# step 8887, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:38.896614 #train# step 8888, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:40.474532 #train# step 8889, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:42.063412 #train# step 8890, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:43.648258 #train# step 8891, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:45.213058 #train# step 8892, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:46.767945 #train# step 8893, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:48.331035 #train# step 8894, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:49.906172 #train# step 8895, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:51.478856 #train# step 8896, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:53.038208 #train# step 8897, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:54.625917 #train# step 8898, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:56.164529 #train# step 8899, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:57.699696 #train# step 8900, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:31:59.264319 #train# step 8901, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:00.837316 #train# step 8902, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:02.403306 #train# step 8903, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:03.970509 #train# step 8904, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:05.539930 #train# step 8905, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:07.106394 #train# step 8906, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:08.636882 #train# step 8907, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:10.209812 #train# step 8908, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:11.769641 #train# step 8909, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:13.341036 #train# step 8910, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:14.882894 #train# step 8911, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:16.447651 #train# step 8912, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:18.038940 #train# step 8913, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:19.613314 #train# step 8914, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:21.170411 #train# step 8915, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:22.735192 #train# step 8916, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:24.315337 #train# step 8917, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:25.907817 #train# step 8918, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:27.467989 #train# step 8919, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:29.028110 #train# step 8920, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:30.615651 #train# step 8921, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:32.145744 #train# step 8922, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:33.729044 #train# step 8923, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:35.294521 #train# step 8924, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:36.871603 #train# step 8925, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:38.408224 #train# step 8926, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:39.971152 #train# step 8927, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:41.528760 #train# step 8928, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:43.070968 #train# step 8929, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:44.651002 #train# step 8930, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:46.202217 #train# step 8931, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:47.745165 #train# step 8932, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:49.320660 #train# step 8933, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:50.886439 #train# step 8934, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:52.460119 #train# step 8935, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:54.050110 #train# step 8936, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:55.613768 #train# step 8937, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:57.174938 #train# step 8938, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:32:58.723492 #train# step 8939, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:00.292628 #train# step 8940, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:01.874235 #train# step 8941, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:03.427468 #train# step 8942, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:04.975365 #train# step 8943, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:06.525176 #train# step 8944, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:08.115546 #train# step 8945, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:09.666817 #train# step 8946, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:11.243638 #train# step 8947, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:12.828278 #train# step 8948, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:14.359541 #train# step 8949, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:15.943094 #train# step 8950, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:17.536859 #train# step 8951, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:19.111180 #train# step 8952, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:20.682546 #train# step 8953, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:22.261091 #train# step 8954, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:23.830372 #train# step 8955, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:25.378611 #train# step 8956, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:26.958134 #train# step 8957, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:28.488884 #train# step 8958, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:30.035174 #train# step 8959, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:31.630315 #train# step 8960, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:33.224665 #train# step 8961, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:34.817947 #train# step 8962, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:36.370420 #train# step 8963, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:37.953927 #train# step 8964, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:39.537522 #train# step 8965, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:41.095934 #train# step 8966, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:42.652619 #train# step 8967, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:44.230805 #train# step 8968, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:45.780643 #train# step 8969, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:47.330834 #train# step 8970, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:48.911120 #train# step 8971, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:50.494143 #train# step 8972, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:52.027877 #train# step 8973, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:53.610667 #train# step 8974, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:55.164392 #train# step 8975, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:56.724989 #train# step 8976, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:58.266981 #train# step 8977, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:33:59.823354 #train# step 8978, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:01.372562 #train# step 8979, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:02.930917 #train# step 8980, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:04.484634 #train# step 8981, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:06.062128 #train# step 8982, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:07.629357 #train# step 8983, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:09.191100 #train# step 8984, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:10.750440 #train# step 8985, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:12.336729 #train# step 8986, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:13.897191 #train# step 8987, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:15.477341 #train# step 8988, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:17.024841 #train# step 8989, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:18.587009 #train# step 8990, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:20.128194 #train# step 8991, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:21.679104 #train# step 8992, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:23.278867 #train# step 8993, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:24.838356 #train# step 8994, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:26.414300 #train# step 8995, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:27.997060 #train# step 8996, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:29.537275 #train# step 8997, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:31.118350 #train# step 8998, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:32.687234 #train# step 8999, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:34.275763 #train# step 9000, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:35.878615 #train# step 9001, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:37.437376 #train# step 9002, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:39.024060 #train# step 9003, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:40.590021 #train# step 9004, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:42.198260 #train# step 9005, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:43.800082 #train# step 9006, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:45.336682 #train# step 9007, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:46.910476 #train# step 9008, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:48.483010 #train# step 9009, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:50.028388 #train# step 9010, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:51.559881 #train# step 9011, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:53.130690 #train# step 9012, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:54.668272 #train# step 9013, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:56.240573 #train# step 9014, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:57.774307 #train# step 9015, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:34:59.363621 #train# step 9016, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:00.887937 #train# step 9017, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:02.451589 #train# step 9018, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:04.028198 #train# step 9019, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:05.598861 #train# step 9020, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:07.163903 #train# step 9021, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:08.732732 #train# step 9022, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:10.288464 #train# step 9023, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:11.856510 #train# step 9024, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:13.430731 #train# step 9025, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:14.968079 #train# step 9026, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:16.541549 #train# step 9027, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:18.120484 #train# step 9028, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:19.713307 #train# step 9029, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:21.271894 #train# step 9030, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:22.804850 #train# step 9031, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:24.366257 #train# step 9032, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:25.950410 #train# step 9033, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:27.543615 #train# step 9034, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:29.109552 #train# step 9035, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:30.671150 #train# step 9036, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:32.224307 #train# step 9037, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:33.773158 #train# step 9038, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:35.355680 #train# step 9039, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:36.928603 #train# step 9040, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:38.458316 #train# step 9041, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:40.026159 #train# step 9042, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:41.597550 #train# step 9043, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:43.197092 #train# step 9044, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:44.743376 #train# step 9045, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:46.301530 #train# step 9046, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:47.871256 #train# step 9047, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:49.434804 #train# step 9048, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:51.006607 #train# step 9049, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:52.587375 #train# step 9050, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:54.156132 #train# step 9051, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:55.715213 #train# step 9052, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:57.294936 #train# step 9053, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:35:58.869353 #train# step 9054, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:00.401775 #train# step 9055, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:01.981318 #train# step 9056, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:03.594618 #train# step 9057, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:05.166358 #train# step 9058, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:06.754676 #train# step 9059, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:08.310085 #train# step 9060, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:09.856999 #train# step 9061, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:11.446505 #train# step 9062, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:12.991213 #train# step 9063, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:14.600404 #train# step 9064, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:16.141005 #train# step 9065, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:17.683832 #train# step 9066, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:19.223476 #train# step 9067, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:20.801570 #train# step 9068, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:22.349149 #train# step 9069, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:23.915864 #train# step 9070, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:25.474483 #train# step 9071, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:27.063232 #train# step 9072, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:28.612853 #train# step 9073, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:30.185425 #train# step 9074, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:31.761146 #train# step 9075, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:33.297837 #train# step 9076, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:34.883611 #train# step 9077, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:36.462345 #train# step 9078, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:38.040215 #train# step 9079, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:39.597899 #train# step 9080, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:41.152778 #train# step 9081, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:42.718127 #train# step 9082, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:44.291881 #train# step 9083, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:45.877005 #train# step 9084, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:47.414097 #train# step 9085, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:48.973722 #train# step 9086, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:50.513788 #train# step 9087, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:52.087981 #train# step 9088, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:53.653645 #train# step 9089, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:55.228142 #train# step 9090, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:56.785557 #train# step 9091, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:58.336534 #train# step 9092, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:36:59.903476 #train# step 9093, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:01.487245 #train# step 9094, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:03.026396 #train# step 9095, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:04.603472 #train# step 9096, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:06.158123 #train# step 9097, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:07.687688 #train# step 9098, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:09.258347 #train# step 9099, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:10.799440 #train# step 9100, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:12.384610 #train# step 9101, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:13.943753 #train# step 9102, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:15.542460 #train# step 9103, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:17.117765 #train# step 9104, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:18.688942 #train# step 9105, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:20.257086 #train# step 9106, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:21.827386 #train# step 9107, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:23.390805 #train# step 9108, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:24.947132 #train# step 9109, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:26.513405 #train# step 9110, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:28.090160 #train# step 9111, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:29.668250 #train# step 9112, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:31.224800 #train# step 9113, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:32.795251 #train# step 9114, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:34.339143 #train# step 9115, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:35.911456 #train# step 9116, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:37.461807 #train# step 9117, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:39.038660 #train# step 9118, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:40.605441 #train# step 9119, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:42.189788 #train# step 9120, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:43.717705 #train# step 9121, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:45.275781 #train# step 9122, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:46.821920 #train# step 9123, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:48.383771 #train# step 9124, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:49.945590 #train# step 9125, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:51.500520 #train# step 9126, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:53.046181 #train# step 9127, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:54.604232 #train# step 9128, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:56.154266 #train# step 9129, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:57.733821 #train# step 9130, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:37:59.300164 #train# step 9131, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:00.877913 #train# step 9132, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:02.443414 #train# step 9133, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:03.999037 #train# step 9134, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:05.608962 #train# step 9135, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:07.168108 #train# step 9136, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:08.763169 #train# step 9137, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:10.333897 #train# step 9138, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:11.878667 #train# step 9139, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:13.466081 #train# step 9140, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:15.019852 #train# step 9141, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:16.600145 #train# step 9142, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:18.182966 #train# step 9143, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:19.746673 #train# step 9144, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:21.317823 #train# step 9145, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:22.860045 #train# step 9146, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:24.441274 #train# step 9147, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:26.019137 #train# step 9148, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:27.585260 #train# step 9149, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:29.178951 #train# step 9150, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:30.774475 #train# step 9151, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:32.323838 #train# step 9152, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:33.927163 #train# step 9153, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:35.457753 #train# step 9154, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:37.021853 #train# step 9155, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:38.572550 #train# step 9156, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:40.169922 #train# step 9157, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:41.720022 #train# step 9158, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:43.286239 #train# step 9159, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:44.830440 #train# step 9160, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:46.371854 #train# step 9161, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:47.907421 #train# step 9162, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:49.455962 #train# step 9163, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:51.006098 #train# step 9164, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:52.581816 #train# step 9165, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:54.115694 #train# step 9166, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:55.650055 #train# step 9167, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:57.212131 #train# step 9168, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:38:58.792545 #train# step 9169, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:00.377745 #train# step 9170, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:01.921795 #train# step 9171, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:03.530531 #train# step 9172, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:05.104963 #train# step 9173, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:06.668971 #train# step 9174, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:08.216237 #train# step 9175, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:09.770309 #train# step 9176, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:11.318995 #train# step 9177, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:12.887834 #train# step 9178, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:14.462551 #train# step 9179, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:16.034576 #train# step 9180, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:17.591537 #train# step 9181, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:19.163201 #train# step 9182, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:20.745812 #train# step 9183, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:22.337982 #train# step 9184, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:23.889480 #train# step 9185, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:25.444533 #train# step 9186, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:26.989612 #train# step 9187, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:28.541793 #train# step 9188, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:30.111838 #train# step 9189, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:31.698757 #train# step 9190, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:33.259422 #train# step 9191, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:34.824171 #train# step 9192, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:36.349031 #train# step 9193, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:37.915404 #train# step 9194, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:39.500739 #train# step 9195, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:41.062418 #train# step 9196, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:42.623355 #train# step 9197, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:44.157119 #train# step 9198, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:45.707936 #train# step 9199, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:47.267169 #train# step 9200, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:48.857570 #train# step 9201, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:50.424164 #train# step 9202, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:52.007552 #train# step 9203, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:53.615752 #train# step 9204, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:55.176034 #train# step 9205, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:56.743695 #train# step 9206, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:58.290799 #train# step 9207, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:39:59.836087 #train# step 9208, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:01.420481 #train# step 9209, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:02.992132 #train# step 9210, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:04.547607 #train# step 9211, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:06.110988 #train# step 9212, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:07.691666 #train# step 9213, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:09.275167 #train# step 9214, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:10.825831 #train# step 9215, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:12.381662 #train# step 9216, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:13.952576 #train# step 9217, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:15.517623 #train# step 9218, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:17.062965 #train# step 9219, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:18.626614 #train# step 9220, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:20.194803 #train# step 9221, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:21.742750 #train# step 9222, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:23.274044 #train# step 9223, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:24.841945 #train# step 9224, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:26.447375 #train# step 9225, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:28.033033 #train# step 9226, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:29.578673 #train# step 9227, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:31.143380 #train# step 9228, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:32.704895 #train# step 9229, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:34.269722 #train# step 9230, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:35.833083 #train# step 9231, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:37.406280 #train# step 9232, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:38.972191 #train# step 9233, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:40.530742 #train# step 9234, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:42.075187 #train# step 9235, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:43.657728 #train# step 9236, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:45.251203 #train# step 9237, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:46.793148 #train# step 9238, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:48.351730 #train# step 9239, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:49.896945 #train# step 9240, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:51.438952 #train# step 9241, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:52.981862 #train# step 9242, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:54.538226 #train# step 9243, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:56.096405 #train# step 9244, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:57.648991 #train# step 9245, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:40:59.230145 #train# step 9246, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:00.775744 #train# step 9247, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:02.344196 #train# step 9248, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:03.935917 #train# step 9249, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:05.494425 #train# step 9250, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:07.042504 #train# step 9251, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:08.632878 #train# step 9252, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:10.201277 #train# step 9253, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:11.760354 #train# step 9254, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:13.337914 #train# step 9255, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:14.899919 #train# step 9256, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:16.468694 #train# step 9257, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:18.043692 #train# step 9258, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:19.586218 #train# step 9259, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:21.120064 #train# step 9260, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:22.679648 #train# step 9261, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:24.255032 #train# step 9262, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:25.813362 #train# step 9263, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:27.392686 #train# step 9264, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:28.931092 #train# step 9265, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:30.467303 #train# step 9266, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:32.041910 #train# step 9267, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:33.638162 #train# step 9268, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:35.218574 #train# step 9269, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:36.744009 #train# step 9270, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:38.297189 #train# step 9271, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:39.841070 #train# step 9272, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:41.423187 #train# step 9273, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:42.979766 #train# step 9274, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:44.544134 #train# step 9275, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:46.114215 #train# step 9276, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:47.670602 #train# step 9277, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:49.232595 #train# step 9278, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:50.780967 #train# step 9279, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:52.361090 #train# step 9280, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:53.970300 #train# step 9281, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:55.600961 #train# step 9282, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:57.163798 #train# step 9283, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:41:58.704596 #train# step 9284, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:00.300218 #train# step 9285, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:01.851437 #train# step 9286, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:03.417045 #train# step 9287, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:04.969720 #train# step 9288, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:06.538075 #train# step 9289, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:08.104056 #train# step 9290, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:09.661625 #train# step 9291, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:11.255712 #train# step 9292, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:12.798310 #train# step 9293, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:14.319930 #train# step 9294, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:15.887659 #train# step 9295, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:17.460868 #train# step 9296, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:19.022199 #train# step 9297, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:20.571641 #train# step 9298, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:22.126494 #train# step 9299, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:23.700229 #train# step 9300, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:25.287065 #train# step 9301, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:26.861183 #train# step 9302, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:28.391542 #train# step 9303, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:29.986774 #train# step 9304, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:31.524910 #train# step 9305, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:33.103988 #train# step 9306, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:34.670083 #train# step 9307, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:36.210881 #train# step 9308, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:37.792948 #train# step 9309, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:39.422010 #train# step 9310, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:40.994239 #train# step 9311, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:42.565925 #train# step 9312, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:44.137852 #train# step 9313, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:45.730412 #train# step 9314, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:47.288280 #train# step 9315, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:48.832160 #train# step 9316, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:50.410520 #train# step 9317, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:51.984297 #train# step 9318, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:53.563270 #train# step 9319, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:55.140972 #train# step 9320, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:56.689445 #train# step 9321, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:58.250669 #train# step 9322, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:42:59.794788 #train# step 9323, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:01.360898 #train# step 9324, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:02.943801 #train# step 9325, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:04.514183 #train# step 9326, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:06.092748 #train# step 9327, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:07.651033 #train# step 9328, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:09.251713 #train# step 9329, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:10.823289 #train# step 9330, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:12.417893 #train# step 9331, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:14.009333 #train# step 9332, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:15.552923 #train# step 9333, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:17.108516 #train# step 9334, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:18.648933 #train# step 9335, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:20.210886 #train# step 9336, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:21.736168 #train# step 9337, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:23.271342 #train# step 9338, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:24.864251 #train# step 9339, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:26.401273 #train# step 9340, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:27.959550 #train# step 9341, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:29.546351 #train# step 9342, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:31.088999 #train# step 9343, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:32.674586 #train# step 9344, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:34.219727 #train# step 9345, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:35.735813 #train# step 9346, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:37.311388 #train# step 9347, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:38.874654 #train# step 9348, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:40.443723 #train# step 9349, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:42.001214 #train# step 9350, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:43.544932 #train# step 9351, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:45.097301 #train# step 9352, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:46.658436 #train# step 9353, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:48.228623 #train# step 9354, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:49.788756 #train# step 9355, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:51.331191 #train# step 9356, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:52.884230 #train# step 9357, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:54.429226 #train# step 9358, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:55.992186 #train# step 9359, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:57.550747 #train# step 9360, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:43:59.148147 #train# step 9361, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:00.768453 #train# step 9362, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:02.312675 #train# step 9363, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:03.886163 #train# step 9364, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:05.441756 #train# step 9365, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:07.010013 #train# step 9366, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:08.579383 #train# step 9367, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:10.158251 #train# step 9368, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:11.696718 #train# step 9369, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:13.279302 #train# step 9370, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:14.852680 #train# step 9371, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:16.427610 #train# step 9372, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:17.956380 #train# step 9373, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:19.518269 #train# step 9374, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:21.075373 #train# step 9375, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:22.630554 #train# step 9376, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:24.205040 #train# step 9377, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:25.783854 #train# step 9378, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:27.342895 #train# step 9379, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:28.900405 #train# step 9380, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:30.483009 #train# step 9381, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:32.024804 #train# step 9382, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:33.576113 #train# step 9383, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:35.147927 #train# step 9384, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:36.712383 #train# step 9385, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:38.285599 #train# step 9386, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:39.855418 #train# step 9387, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:41.431552 #train# step 9388, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:42.968403 #train# step 9389, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:44.548393 #train# step 9390, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:46.088588 #train# step 9391, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:47.661170 #train# step 9392, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:49.220459 #train# step 9393, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:50.814582 #train# step 9394, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:52.397509 #train# step 9395, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:53.965494 #train# step 9396, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:55.527488 #train# step 9397, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:57.087346 #train# step 9398, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:44:58.651043 #train# step 9399, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:00.198572 #train# step 9400, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:01.787591 #train# step 9401, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:03.350312 #train# step 9402, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:04.930208 #train# step 9403, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:06.468087 #train# step 9404, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:08.026114 #train# step 9405, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:09.611549 #train# step 9406, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:11.156367 #train# step 9407, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:12.683274 #train# step 9408, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:14.248868 #train# step 9409, loss = 0.8872, cross_entropy loss = 0.8872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:15.817848 #train# step 9410, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:17.395664 #train# step 9411, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:18.957109 #train# step 9412, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:20.512030 #train# step 9413, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:22.060082 #train# step 9414, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:23.633716 #train# step 9415, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:25.195832 #train# step 9416, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:26.743973 #train# step 9417, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:28.320603 #train# step 9418, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:29.876744 #train# step 9419, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:31.453709 #train# step 9420, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:33.008430 #train# step 9421, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:34.564691 #train# step 9422, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:36.136367 #train# step 9423, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:37.725810 #train# step 9424, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:39.296036 #train# step 9425, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:40.848402 #train# step 9426, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:42.420219 #train# step 9427, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:43.997599 #train# step 9428, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:45.562796 #train# step 9429, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:47.109330 #train# step 9430, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:48.661050 #train# step 9431, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:50.185343 #train# step 9432, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:51.760009 #train# step 9433, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:53.329687 #train# step 9434, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:54.899091 #train# step 9435, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:56.444689 #train# step 9436, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:58.029999 #train# step 9437, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:45:59.641337 #train# step 9438, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:01.202400 #train# step 9439, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:02.762178 #train# step 9440, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:04.321492 #train# step 9441, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:05.891555 #train# step 9442, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:07.436868 #train# step 9443, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:09.032382 #train# step 9444, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:10.574799 #train# step 9445, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:12.162750 #train# step 9446, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:13.753525 #train# step 9447, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:15.332890 #train# step 9448, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:16.902742 #train# step 9449, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:18.464638 #train# step 9450, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:20.012669 #train# step 9451, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:21.546644 #train# step 9452, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:23.138922 #train# step 9453, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:24.750441 #train# step 9454, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:26.316109 #train# step 9455, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:27.859441 #train# step 9456, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:29.435891 #train# step 9457, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:31.007276 #train# step 9458, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:32.569146 #train# step 9459, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:34.139265 #train# step 9460, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:35.684532 #train# step 9461, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:37.236225 #train# step 9462, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:38.791201 #train# step 9463, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:40.336642 #train# step 9464, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:41.903651 #train# step 9465, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:43.438722 #train# step 9466, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:45.000552 #train# step 9467, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:46.591823 #train# step 9468, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:48.160018 #train# step 9469, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:49.715852 #train# step 9470, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:51.237981 #train# step 9471, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:52.774376 #train# step 9472, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:54.355863 #train# step 9473, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:55.926048 #train# step 9474, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:57.501352 #train# step 9475, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:46:59.058167 #train# step 9476, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:00.641989 #train# step 9477, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:02.223767 #train# step 9478, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:03.776159 #train# step 9479, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:05.360227 #train# step 9480, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:06.925149 #train# step 9481, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:08.506933 #train# step 9482, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:10.072859 #train# step 9483, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:11.647005 #train# step 9484, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:13.214994 #train# step 9485, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:14.768907 #train# step 9486, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:16.318615 #train# step 9487, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:17.879659 #train# step 9488, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:19.461470 #train# step 9489, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:21.047977 #train# step 9490, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:22.634888 #train# step 9491, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:24.171598 #train# step 9492, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:25.751819 #train# step 9493, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:27.292682 #train# step 9494, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:28.858531 #train# step 9495, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:30.433642 #train# step 9496, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:31.985773 #train# step 9497, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:33.566247 #train# step 9498, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:35.153454 #train# step 9499, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:36.724173 #train# step 9500, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:38.294799 #train# step 9501, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:39.844317 #train# step 9502, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:41.396761 #train# step 9503, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:42.962316 #train# step 9504, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:44.536355 #train# step 9505, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:46.104934 #train# step 9506, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:47.678980 #train# step 9507, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:49.235522 #train# step 9508, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:50.818284 #train# step 9509, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:52.373814 #train# step 9510, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:53.928723 #train# step 9511, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:55.489785 #train# step 9512, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:57.032397 #train# step 9513, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:47:58.559865 #train# step 9514, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:00.143138 #train# step 9515, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:01.672839 #train# step 9516, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:03.227433 #train# step 9517, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:04.798947 #train# step 9518, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:06.366493 #train# step 9519, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:07.949459 #train# step 9520, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:09.527888 #train# step 9521, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:11.109919 #train# step 9522, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:12.679171 #train# step 9523, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:14.227842 #train# step 9524, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:15.802367 #train# step 9525, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:17.362944 #train# step 9526, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:18.910886 #train# step 9527, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:20.478416 #train# step 9528, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:22.026981 #train# step 9529, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:23.606970 #train# step 9530, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:25.193897 #train# step 9531, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:26.774720 #train# step 9532, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:28.334565 #train# step 9533, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:29.928801 #train# step 9534, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:31.488293 #train# step 9535, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:33.045160 #train# step 9536, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:34.617047 #train# step 9537, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:36.176571 #train# step 9538, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:37.756180 #train# step 9539, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:39.346906 #train# step 9540, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:40.914890 #train# step 9541, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:42.508512 #train# step 9542, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:44.065788 #train# step 9543, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:45.635886 #train# step 9544, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:47.213423 #train# step 9545, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:48.771600 #train# step 9546, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:50.377844 #train# step 9547, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:51.974469 #train# step 9548, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:53.537655 #train# step 9549, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:55.082119 #train# step 9550, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:56.652219 #train# step 9551, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:58.200582 #train# step 9552, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:48:59.778798 #train# step 9553, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:01.362249 #train# step 9554, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:02.962877 #train# step 9555, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:04.510512 #train# step 9556, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:06.070503 #train# step 9557, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:07.623707 #train# step 9558, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:09.179436 #train# step 9559, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:10.726254 #train# step 9560, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:12.288203 #train# step 9561, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:13.845732 #train# step 9562, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:15.408373 #train# step 9563, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:16.974839 #train# step 9564, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:18.520278 #train# step 9565, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:20.051024 #train# step 9566, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:21.578686 #train# step 9567, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:23.129479 #train# step 9568, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:24.719825 #train# step 9569, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:26.293835 #train# step 9570, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:27.854953 #train# step 9571, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:29.441845 #train# step 9572, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:30.998978 #train# step 9573, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:32.546529 #train# step 9574, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:34.113879 #train# step 9575, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:35.679467 #train# step 9576, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:37.224730 #train# step 9577, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:38.790855 #train# step 9578, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:40.336293 #train# step 9579, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:41.933146 #train# step 9580, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:43.502787 #train# step 9581, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:45.068229 #train# step 9582, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:46.611965 #train# step 9583, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:48.167486 #train# step 9584, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:49.743199 #train# step 9585, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:51.286666 #train# step 9586, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:52.848166 #train# step 9587, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:54.426720 #train# step 9588, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:55.987974 #train# step 9589, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:57.553673 #train# step 9590, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:49:59.096702 #train# step 9591, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:00.665256 #train# step 9592, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:02.232275 #train# step 9593, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:03.799033 #train# step 9594, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:05.355775 #train# step 9595, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:06.933030 #train# step 9596, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:08.479956 #train# step 9597, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:10.069891 #train# step 9598, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:11.655671 #train# step 9599, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:13.236638 #train# step 9600, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:14.801172 #train# step 9601, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:16.360287 #train# step 9602, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:17.939631 #train# step 9603, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:19.479111 #train# step 9604, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:21.036803 #train# step 9605, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:22.599025 #train# step 9606, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:24.174650 #train# step 9607, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:25.752530 #train# step 9608, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:27.305955 #train# step 9609, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:28.872746 #train# step 9610, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:30.414540 #train# step 9611, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:31.992128 #train# step 9612, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:33.567526 #train# step 9613, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:35.131247 #train# step 9614, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:36.732159 #train# step 9615, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:38.271184 #train# step 9616, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:39.848166 #train# step 9617, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:41.411697 #train# step 9618, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:42.980267 #train# step 9619, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:44.562327 #train# step 9620, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:46.103157 #train# step 9621, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:47.664240 #train# step 9622, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:49.236387 #train# step 9623, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:50.784060 #train# step 9624, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:52.332410 #train# step 9625, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:53.878470 #train# step 9626, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:55.452691 #train# step 9627, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:57.016591 #train# step 9628, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:50:58.584724 #train# step 9629, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:00.156978 #train# step 9630, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:01.720720 #train# step 9631, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:03.287415 #train# step 9632, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:04.835204 #train# step 9633, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:06.410981 #train# step 9634, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:07.989378 #train# step 9635, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:09.556882 #train# step 9636, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:11.113400 #train# step 9637, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:12.679705 #train# step 9638, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:14.250561 #train# step 9639, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:15.804726 #train# step 9640, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:17.345549 #train# step 9641, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:18.905785 #train# step 9642, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:20.448984 #train# step 9643, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:22.008569 #train# step 9644, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:23.597747 #train# step 9645, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:25.172880 #train# step 9646, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:26.734536 #train# step 9647, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:28.291282 #train# step 9648, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:29.843475 #train# step 9649, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:31.414745 #train# step 9650, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:32.984616 #train# step 9651, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:34.520938 #train# step 9652, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:36.068927 #train# step 9653, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:37.649908 #train# step 9654, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:39.229739 #train# step 9655, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:40.824601 #train# step 9656, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:42.391352 #train# step 9657, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:43.952869 #train# step 9658, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:45.541979 #train# step 9659, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:47.120400 #train# step 9660, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:48.677560 #train# step 9661, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:50.227588 #train# step 9662, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:51.795655 #train# step 9663, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:53.361437 #train# step 9664, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:54.927450 #train# step 9665, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:56.498924 #train# step 9666, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:58.052368 #train# step 9667, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:51:59.626276 #train# step 9668, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:01.204103 #train# step 9669, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:02.807947 #train# step 9670, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:04.366365 #train# step 9671, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:05.935694 #train# step 9672, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:07.491063 #train# step 9673, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:09.082528 #train# step 9674, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:10.656431 #train# step 9675, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:12.233527 #train# step 9676, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:13.813838 #train# step 9677, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:15.351681 #train# step 9678, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:16.904866 #train# step 9679, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:18.471286 #train# step 9680, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:20.031498 #train# step 9681, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:21.580675 #train# step 9682, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:23.163872 #train# step 9683, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:24.719624 #train# step 9684, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:26.250870 #train# step 9685, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:27.824852 #train# step 9686, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:29.397511 #train# step 9687, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:30.982504 #train# step 9688, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:32.532792 #train# step 9689, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:34.095564 #train# step 9690, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:35.672178 #train# step 9691, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:37.239466 #train# step 9692, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:38.798819 #train# step 9693, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:40.363425 #train# step 9694, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:41.938091 #train# step 9695, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:43.500818 #train# step 9696, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:45.084961 #train# step 9697, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:46.654429 #train# step 9698, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:48.244669 #train# step 9699, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:49.795011 #train# step 9700, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:51.355364 #train# step 9701, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:52.929589 #train# step 9702, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:54.471965 #train# step 9703, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:56.056113 #train# step 9704, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:57.634167 #train# step 9705, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:52:59.200621 #train# step 9706, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:00.747465 #train# step 9707, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:02.298845 #train# step 9708, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:03.889571 #train# step 9709, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:05.464551 #train# step 9710, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:07.026811 #train# step 9711, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:08.593933 #train# step 9712, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:10.162589 #train# step 9713, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:11.718148 #train# step 9714, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:13.272783 #train# step 9715, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:14.806807 #train# step 9716, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:16.379417 #train# step 9717, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:17.947158 #train# step 9718, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:19.521725 #train# step 9719, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:21.067626 #train# step 9720, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:22.660865 #train# step 9721, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:24.216653 #train# step 9722, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:25.762627 #train# step 9723, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:27.368201 #train# step 9724, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:28.918738 #train# step 9725, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:30.473338 #train# step 9726, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:32.034295 #train# step 9727, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:33.611568 #train# step 9728, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:35.152769 #train# step 9729, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:36.705676 #train# step 9730, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:38.299288 #train# step 9731, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:39.848827 #train# step 9732, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:41.419145 #train# step 9733, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:42.982847 #train# step 9734, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:44.540189 #train# step 9735, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:46.139772 #train# step 9736, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:47.661432 #train# step 9737, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:49.281781 #train# step 9738, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:50.830363 #train# step 9739, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:52.416553 #train# step 9740, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:53.992335 #train# step 9741, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:55.574368 #train# step 9742, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:57.109567 #train# step 9743, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:53:58.636845 #train# step 9744, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:00.164665 #train# step 9745, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:01.732207 #train# step 9746, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:03.292796 #train# step 9747, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:04.858022 #train# step 9748, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:06.402767 #train# step 9749, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:07.993540 #train# step 9750, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:09.563196 #train# step 9751, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:11.128679 #train# step 9752, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:12.689868 #train# step 9753, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:14.235689 #train# step 9754, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:15.816898 #train# step 9755, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:17.417395 #train# step 9756, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:18.990302 #train# step 9757, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:20.558967 #train# step 9758, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:22.097935 #train# step 9759, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:23.679581 #train# step 9760, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:25.229565 #train# step 9761, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:26.822121 #train# step 9762, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:28.377908 #train# step 9763, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:29.964676 #train# step 9764, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:31.546698 #train# step 9765, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:33.091417 #train# step 9766, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:34.686745 #train# step 9767, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:36.277580 #train# step 9768, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:37.818794 #train# step 9769, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:39.370148 #train# step 9770, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:40.912001 #train# step 9771, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:42.457374 #train# step 9772, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:44.033435 #train# step 9773, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:45.576016 #train# step 9774, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:47.153011 #train# step 9775, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:48.705326 #train# step 9776, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:50.273224 #train# step 9777, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:51.831247 #train# step 9778, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:53.363048 #train# step 9779, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:54.914201 #train# step 9780, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:56.481908 #train# step 9781, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:58.037613 #train# step 9782, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:54:59.605729 #train# step 9783, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:01.173775 #train# step 9784, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:02.735701 #train# step 9785, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:04.281788 #train# step 9786, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:05.831176 #train# step 9787, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:07.379073 #train# step 9788, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:08.908843 #train# step 9789, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:10.499441 #train# step 9790, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:12.056437 #train# step 9791, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:13.646562 #train# step 9792, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:15.229837 #train# step 9793, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:16.794767 #train# step 9794, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:18.367466 #train# step 9795, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:19.941888 #train# step 9796, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:21.484948 #train# step 9797, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:23.045199 #train# step 9798, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:24.637405 #train# step 9799, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:26.183117 #train# step 9800, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:27.717600 #train# step 9801, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:29.299713 #train# step 9802, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:30.834822 #train# step 9803, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:32.406470 #train# step 9804, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:33.994166 #train# step 9805, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:35.559878 #train# step 9806, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:37.118662 #train# step 9807, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:38.655644 #train# step 9808, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:40.269251 #train# step 9809, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:41.834286 #train# step 9810, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:43.397847 #train# step 9811, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:45.025033 #train# step 9812, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:46.569070 #train# step 9813, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:48.108788 #train# step 9814, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:49.679659 #train# step 9815, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:51.258546 #train# step 9816, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:52.838071 #train# step 9817, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:54.430115 #train# step 9818, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:56.006451 #train# step 9819, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:57.536187 #train# step 9820, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:55:59.119013 #train# step 9821, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:00.655902 #train# step 9822, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:02.235289 #train# step 9823, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:03.834497 #train# step 9824, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:05.397118 #train# step 9825, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:06.971264 #train# step 9826, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:08.522663 #train# step 9827, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:10.093136 #train# step 9828, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:11.650034 #train# step 9829, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:13.238623 #train# step 9830, loss = 0.8894, cross_entropy loss = 0.8894, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:14.798156 #train# step 9831, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:16.348340 #train# step 9832, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:17.945313 #train# step 9833, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:19.495670 #train# step 9834, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:21.019248 #train# step 9835, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:22.611629 #train# step 9836, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:24.218665 #train# step 9837, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:25.801752 #train# step 9838, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:27.364048 #train# step 9839, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:28.905478 #train# step 9840, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:30.452245 #train# step 9841, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:32.050322 #train# step 9842, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:33.595258 #train# step 9843, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:35.170562 #train# step 9844, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:36.733426 #train# step 9845, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:38.264026 #train# step 9846, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:39.831086 #train# step 9847, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:41.385138 #train# step 9848, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:42.986647 #train# step 9849, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:44.567165 #train# step 9850, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:46.101129 #train# step 9851, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:47.677289 #train# step 9852, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:49.230944 #train# step 9853, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:50.807991 #train# step 9854, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:52.365600 #train# step 9855, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:53.916198 #train# step 9856, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:55.467532 #train# step 9857, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:57.019543 #train# step 9858, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:56:58.599959 #train# step 9859, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:00.137845 #train# step 9860, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:01.716305 #train# step 9861, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:03.300022 #train# step 9862, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:04.859460 #train# step 9863, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:06.442928 #train# step 9864, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:07.999344 #train# step 9865, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:09.547847 #train# step 9866, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:11.103466 #train# step 9867, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:12.652716 #train# step 9868, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:14.253914 #train# step 9869, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:15.816136 #train# step 9870, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:17.395753 #train# step 9871, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:18.929094 #train# step 9872, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:20.497863 #train# step 9873, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:22.075822 #train# step 9874, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:23.632910 #train# step 9875, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:25.188410 #train# step 9876, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:26.776813 #train# step 9877, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:28.372406 #train# step 9878, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:29.923250 #train# step 9879, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:31.500189 #train# step 9880, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:33.057690 #train# step 9881, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:34.621884 #train# step 9882, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:36.170836 #train# step 9883, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:37.730000 #train# step 9884, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:39.280487 #train# step 9885, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:40.855783 #train# step 9886, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:42.468357 #train# step 9887, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:44.038595 #train# step 9888, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:45.638228 #train# step 9889, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:47.199875 #train# step 9890, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:48.815223 #train# step 9891, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:50.375157 #train# step 9892, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:51.950735 #train# step 9893, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:53.482440 #train# step 9894, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:55.039977 #train# step 9895, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:56.608437 #train# step 9896, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:58.176573 #train# step 9897, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:57:59.740803 #train# step 9898, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:01.295479 #train# step 9899, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:02.838254 #train# step 9900, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:04.390402 #train# step 9901, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:05.941990 #train# step 9902, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:07.513764 #train# step 9903, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:09.069796 #train# step 9904, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:10.645093 #train# step 9905, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:12.196637 #train# step 9906, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:13.738457 #train# step 9907, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:15.292740 #train# step 9908, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:16.859377 #train# step 9909, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:18.424396 #train# step 9910, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:19.973599 #train# step 9911, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:21.553436 #train# step 9912, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:23.112069 #train# step 9913, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:24.701640 #train# step 9914, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:26.281727 #train# step 9915, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:27.824047 #train# step 9916, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:29.387101 #train# step 9917, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:30.978247 #train# step 9918, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:32.539198 #train# step 9919, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:34.085789 #train# step 9920, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:35.633528 #train# step 9921, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:37.157997 #train# step 9922, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:38.710839 #train# step 9923, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:40.246677 #train# step 9924, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:41.808209 #train# step 9925, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:43.401997 #train# step 9926, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:44.932673 #train# step 9927, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:46.486606 #train# step 9928, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:48.072501 #train# step 9929, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:49.589820 #train# step 9930, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:51.164961 #train# step 9931, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:52.755130 #train# step 9932, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:54.319816 #train# step 9933, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:55.888171 #train# step 9934, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:57.436170 #train# step 9935, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:58:58.983514 #train# step 9936, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:00.543006 #train# step 9937, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:02.121127 #train# step 9938, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:03.697117 #train# step 9939, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:05.281749 #train# step 9940, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:06.840692 #train# step 9941, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:08.441170 #train# step 9942, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:09.996475 #train# step 9943, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:11.548031 #train# step 9944, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:13.102535 #train# step 9945, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:14.705513 #train# step 9946, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:16.251446 #train# step 9947, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:17.843102 #train# step 9948, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:19.418237 #train# step 9949, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:20.970174 #train# step 9950, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:22.528964 #train# step 9951, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:24.085880 #train# step 9952, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:25.663196 #train# step 9953, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:27.232173 #train# step 9954, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:28.775798 #train# step 9955, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:30.361224 #train# step 9956, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:31.951004 #train# step 9957, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:33.506887 #train# step 9958, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:35.089113 #train# step 9959, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:36.657950 #train# step 9960, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:38.206028 #train# step 9961, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:39.802390 #train# step 9962, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:41.388055 #train# step 9963, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:42.950687 #train# step 9964, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:44.531966 #train# step 9965, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:46.057552 #train# step 9966, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:47.615909 #train# step 9967, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:49.159036 #train# step 9968, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:50.709251 #train# step 9969, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:52.286900 #train# step 9970, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:53.819823 #train# step 9971, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:55.374721 #train# step 9972, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:56.945940 #train# step 9973, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 17:59:58.506803 #train# step 9974, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:00.069510 #train# step 9975, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:01.622647 #train# step 9976, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:03.173521 #train# step 9977, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:04.783753 #train# step 9978, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:06.328342 #train# step 9979, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:07.882896 #train# step 9980, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:09.492330 #train# step 9981, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:11.042114 #train# step 9982, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:12.595731 #train# step 9983, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:14.176938 #train# step 9984, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:15.759894 #train# step 9985, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:17.342744 #train# step 9986, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:18.904488 #train# step 9987, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:20.486730 #train# step 9988, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:22.029648 #train# step 9989, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:23.620215 #train# step 9990, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:25.206002 #train# step 9991, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:26.746132 #train# step 9992, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:28.347571 #train# step 9993, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:29.891375 #train# step 9994, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:31.466516 #train# step 9995, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:33.046911 #train# step 9996, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:34.596052 #train# step 9997, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:36.155757 #train# step 9998, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:37.721985 #train# step 9999, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-22 18:00:39.316380 #train# step 10000, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
2021-01-22 18:00:39.316660 #traing# finish training
saving model to ./models/lr_5e-05_cqlambda_0.0_alpha_10.0_dataset_VeRi_hashbit_256.npy
model saved
{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 256,
 'save_dir': './models/',
 'val_batch_size': 100}
