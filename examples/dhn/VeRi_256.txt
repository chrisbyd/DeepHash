{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 256,
 'save_dir': './models/',
 'val_batch_size': 100}
initializing
launching session
loading img model from ../../architecture/pretrained_model/reference_pretrain.npy
['hash_layer', 'fc6', 'fc7', 'conv3', 'conv2', 'conv1', 'conv5', 'conv4']
img model loading finished
Initializing Dataset
Dataset already
2021-01-20 20:52:55.423989 #train# start training
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:13.121001 #train# step    1, loss = 2.1508, cross_entropy loss = 2.1508, 12.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:14.785245 #train# step    2, loss = 2.0238, cross_entropy loss = 2.0238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:16.399979 #train# step    3, loss = 1.8587, cross_entropy loss = 1.8587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:18.026903 #train# step    4, loss = 1.6347, cross_entropy loss = 1.6347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:19.652082 #train# step    5, loss = 1.4213, cross_entropy loss = 1.4213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:21.296907 #train# step    6, loss = 1.2874, cross_entropy loss = 1.2874, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:22.973709 #train# step    7, loss = 1.2184, cross_entropy loss = 1.2184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:24.588401 #train# step    8, loss = 1.1732, cross_entropy loss = 1.1732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:26.203441 #train# step    9, loss = 1.1548, cross_entropy loss = 1.1548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:27.827538 #train# step   10, loss = 1.1769, cross_entropy loss = 1.1769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:29.448060 #train# step   11, loss = 1.1897, cross_entropy loss = 1.1897, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:31.059941 #train# step   12, loss = 1.2038, cross_entropy loss = 1.2038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:32.691912 #train# step   13, loss = 1.2227, cross_entropy loss = 1.2227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:34.330125 #train# step   14, loss = 1.2671, cross_entropy loss = 1.2671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:35.965479 #train# step   15, loss = 1.2735, cross_entropy loss = 1.2735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:37.653253 #train# step   16, loss = 1.2997, cross_entropy loss = 1.2997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:39.306672 #train# step   17, loss = 1.3020, cross_entropy loss = 1.3020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:40.956144 #train# step   18, loss = 1.2802, cross_entropy loss = 1.2802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:42.585266 #train# step   19, loss = 1.2550, cross_entropy loss = 1.2550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:44.210866 #train# step   20, loss = 1.2307, cross_entropy loss = 1.2307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:45.875840 #train# step   21, loss = 1.2119, cross_entropy loss = 1.2119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:47.533335 #train# step   22, loss = 1.2042, cross_entropy loss = 1.2042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:49.183507 #train# step   23, loss = 1.1715, cross_entropy loss = 1.1715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:50.852637 #train# step   24, loss = 1.1487, cross_entropy loss = 1.1487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:52.517572 #train# step   25, loss = 1.1467, cross_entropy loss = 1.1467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:54.188076 #train# step   26, loss = 1.1154, cross_entropy loss = 1.1154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:55.834882 #train# step   27, loss = 1.1404, cross_entropy loss = 1.1404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:57.456681 #train# step   28, loss = 1.1220, cross_entropy loss = 1.1220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:59.100728 #train# step   29, loss = 1.1373, cross_entropy loss = 1.1373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:00.735126 #train# step   30, loss = 1.1308, cross_entropy loss = 1.1308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:02.375572 #train# step   31, loss = 1.1476, cross_entropy loss = 1.1476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:03.986014 #train# step   32, loss = 1.1353, cross_entropy loss = 1.1353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:05.613983 #train# step   33, loss = 1.1265, cross_entropy loss = 1.1265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:07.279064 #train# step   34, loss = 1.1491, cross_entropy loss = 1.1491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:08.915830 #train# step   35, loss = 1.1362, cross_entropy loss = 1.1362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:10.583690 #train# step   36, loss = 1.1232, cross_entropy loss = 1.1232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:12.231186 #train# step   37, loss = 1.1322, cross_entropy loss = 1.1322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:13.902952 #train# step   38, loss = 1.1501, cross_entropy loss = 1.1501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:15.568146 #train# step   39, loss = 1.1259, cross_entropy loss = 1.1259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:17.230080 #train# step   40, loss = 1.1260, cross_entropy loss = 1.1260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:18.865023 #train# step   41, loss = 1.1374, cross_entropy loss = 1.1374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:20.494380 #train# step   42, loss = 1.1369, cross_entropy loss = 1.1369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:22.158608 #train# step   43, loss = 1.1192, cross_entropy loss = 1.1192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:23.816431 #train# step   44, loss = 1.1290, cross_entropy loss = 1.1290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:25.439558 #train# step   45, loss = 1.1297, cross_entropy loss = 1.1297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:27.085419 #train# step   46, loss = 1.1254, cross_entropy loss = 1.1254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:28.725066 #train# step   47, loss = 1.1194, cross_entropy loss = 1.1194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:30.295239 #train# step   48, loss = 1.1087, cross_entropy loss = 1.1087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:31.864181 #train# step   49, loss = 1.1166, cross_entropy loss = 1.1166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:33.421513 #train# step   50, loss = 1.1052, cross_entropy loss = 1.1052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:34.979998 #train# step   51, loss = 1.0999, cross_entropy loss = 1.0999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:36.535232 #train# step   52, loss = 1.1052, cross_entropy loss = 1.1052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:38.074340 #train# step   53, loss = 1.1132, cross_entropy loss = 1.1132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:39.608004 #train# step   54, loss = 1.1234, cross_entropy loss = 1.1234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:41.142388 #train# step   55, loss = 1.1208, cross_entropy loss = 1.1208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:42.689447 #train# step   56, loss = 1.1243, cross_entropy loss = 1.1243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:44.232917 #train# step   57, loss = 1.1064, cross_entropy loss = 1.1064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:45.748821 #train# step   58, loss = 1.1331, cross_entropy loss = 1.1331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:47.306046 #train# step   59, loss = 1.0823, cross_entropy loss = 1.0823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:48.851712 #train# step   60, loss = 1.0847, cross_entropy loss = 1.0847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:50.401002 #train# step   61, loss = 1.0994, cross_entropy loss = 1.0994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:51.951667 #train# step   62, loss = 1.1046, cross_entropy loss = 1.1046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:53.497317 #train# step   63, loss = 1.0956, cross_entropy loss = 1.0956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:55.026600 #train# step   64, loss = 1.0965, cross_entropy loss = 1.0965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:56.560560 #train# step   65, loss = 1.1000, cross_entropy loss = 1.1000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:58.092557 #train# step   66, loss = 1.1116, cross_entropy loss = 1.1116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:59.728311 #train# step   67, loss = 1.0867, cross_entropy loss = 1.0867, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:01.263135 #train# step   68, loss = 1.1058, cross_entropy loss = 1.1058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:02.823500 #train# step   69, loss = 1.1286, cross_entropy loss = 1.1286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:04.371358 #train# step   70, loss = 1.0939, cross_entropy loss = 1.0939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:05.904434 #train# step   71, loss = 1.1058, cross_entropy loss = 1.1058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:07.466867 #train# step   72, loss = 1.0938, cross_entropy loss = 1.0938, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:09.073628 #train# step   73, loss = 1.0883, cross_entropy loss = 1.0883, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:10.615064 #train# step   74, loss = 1.0870, cross_entropy loss = 1.0870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:12.210126 #train# step   75, loss = 1.0909, cross_entropy loss = 1.0909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:13.739218 #train# step   76, loss = 1.1077, cross_entropy loss = 1.1077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:15.304984 #train# step   77, loss = 1.1067, cross_entropy loss = 1.1067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:16.857260 #train# step   78, loss = 1.1086, cross_entropy loss = 1.1086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:18.412177 #train# step   79, loss = 1.1015, cross_entropy loss = 1.1015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:19.958126 #train# step   80, loss = 1.1003, cross_entropy loss = 1.1003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:21.543293 #train# step   81, loss = 1.0978, cross_entropy loss = 1.0978, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:23.067548 #train# step   82, loss = 1.1063, cross_entropy loss = 1.1063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:24.625163 #train# step   83, loss = 1.0948, cross_entropy loss = 1.0948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:26.189122 #train# step   84, loss = 1.0923, cross_entropy loss = 1.0923, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:27.713518 #train# step   85, loss = 1.0792, cross_entropy loss = 1.0792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:29.268021 #train# step   86, loss = 1.0709, cross_entropy loss = 1.0709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:30.808063 #train# step   87, loss = 1.1072, cross_entropy loss = 1.1072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:32.344621 #train# step   88, loss = 1.1086, cross_entropy loss = 1.1086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:33.897317 #train# step   89, loss = 1.0918, cross_entropy loss = 1.0918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:35.445486 #train# step   90, loss = 1.1001, cross_entropy loss = 1.1001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:36.986342 #train# step   91, loss = 1.0829, cross_entropy loss = 1.0829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:38.543379 #train# step   92, loss = 1.0954, cross_entropy loss = 1.0954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:40.105740 #train# step   93, loss = 1.0814, cross_entropy loss = 1.0814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:41.647649 #train# step   94, loss = 1.0983, cross_entropy loss = 1.0983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:43.208580 #train# step   95, loss = 1.0883, cross_entropy loss = 1.0883, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:44.772350 #train# step   96, loss = 1.0785, cross_entropy loss = 1.0785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:46.288030 #train# step   97, loss = 1.0745, cross_entropy loss = 1.0745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:47.860596 #train# step   98, loss = 1.0732, cross_entropy loss = 1.0732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:49.399905 #train# step   99, loss = 1.1045, cross_entropy loss = 1.1045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:50.936455 #train# step  100, loss = 1.0996, cross_entropy loss = 1.0996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:52.513992 #train# step  101, loss = 1.0670, cross_entropy loss = 1.0670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:54.029913 #train# step  102, loss = 1.0921, cross_entropy loss = 1.0921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:55.589165 #train# step  103, loss = 1.1014, cross_entropy loss = 1.1014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:57.141453 #train# step  104, loss = 1.0791, cross_entropy loss = 1.0791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:58.693885 #train# step  105, loss = 1.0761, cross_entropy loss = 1.0761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:00.254845 #train# step  106, loss = 1.0813, cross_entropy loss = 1.0813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:01.810901 #train# step  107, loss = 1.0921, cross_entropy loss = 1.0921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:03.358287 #train# step  108, loss = 1.0739, cross_entropy loss = 1.0739, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:04.853804 #train# step  109, loss = 1.1024, cross_entropy loss = 1.1024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:06.398855 #train# step  110, loss = 1.0795, cross_entropy loss = 1.0795, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:07.972925 #train# step  111, loss = 1.0727, cross_entropy loss = 1.0727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:09.549350 #train# step  112, loss = 1.0563, cross_entropy loss = 1.0563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:11.069365 #train# step  113, loss = 1.0873, cross_entropy loss = 1.0873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:12.590438 #train# step  114, loss = 1.0669, cross_entropy loss = 1.0669, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:14.127176 #train# step  115, loss = 1.0460, cross_entropy loss = 1.0460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:15.675336 #train# step  116, loss = 1.0721, cross_entropy loss = 1.0721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:17.179136 #train# step  117, loss = 1.0875, cross_entropy loss = 1.0875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:18.726952 #train# step  118, loss = 1.0689, cross_entropy loss = 1.0689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:20.245840 #train# step  119, loss = 1.0973, cross_entropy loss = 1.0973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:21.808133 #train# step  120, loss = 1.0960, cross_entropy loss = 1.0960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:23.299467 #train# step  121, loss = 1.1042, cross_entropy loss = 1.1042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:24.877002 #train# step  122, loss = 1.0810, cross_entropy loss = 1.0810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:26.417185 #train# step  123, loss = 1.0782, cross_entropy loss = 1.0782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:27.971854 #train# step  124, loss = 1.0522, cross_entropy loss = 1.0522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:29.522310 #train# step  125, loss = 1.0680, cross_entropy loss = 1.0680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:31.078941 #train# step  126, loss = 1.0805, cross_entropy loss = 1.0805, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:32.643286 #train# step  127, loss = 1.0722, cross_entropy loss = 1.0722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:34.213917 #train# step  128, loss = 1.0674, cross_entropy loss = 1.0674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:35.748778 #train# step  129, loss = 1.0758, cross_entropy loss = 1.0758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:37.282894 #train# step  130, loss = 1.0647, cross_entropy loss = 1.0647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:38.874562 #train# step  131, loss = 1.0382, cross_entropy loss = 1.0382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:40.412666 #train# step  132, loss = 1.0519, cross_entropy loss = 1.0519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:41.947489 #train# step  133, loss = 1.0730, cross_entropy loss = 1.0730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:43.497894 #train# step  134, loss = 1.0604, cross_entropy loss = 1.0604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:45.031741 #train# step  135, loss = 1.0528, cross_entropy loss = 1.0528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:46.600145 #train# step  136, loss = 1.0523, cross_entropy loss = 1.0523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:48.147885 #train# step  137, loss = 1.0696, cross_entropy loss = 1.0696, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:49.733851 #train# step  138, loss = 1.0576, cross_entropy loss = 1.0576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:51.334606 #train# step  139, loss = 1.0605, cross_entropy loss = 1.0605, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:52.867333 #train# step  140, loss = 1.0486, cross_entropy loss = 1.0486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:54.420056 #train# step  141, loss = 1.0799, cross_entropy loss = 1.0799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:56.048702 #train# step  142, loss = 1.0607, cross_entropy loss = 1.0607, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:57.636700 #train# step  143, loss = 1.0334, cross_entropy loss = 1.0334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:59.206869 #train# step  144, loss = 1.0659, cross_entropy loss = 1.0659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:00.771617 #train# step  145, loss = 1.0552, cross_entropy loss = 1.0552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:02.317123 #train# step  146, loss = 1.0674, cross_entropy loss = 1.0674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:03.845420 #train# step  147, loss = 1.0812, cross_entropy loss = 1.0812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:05.375623 #train# step  148, loss = 1.0640, cross_entropy loss = 1.0640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:06.951659 #train# step  149, loss = 1.0640, cross_entropy loss = 1.0640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:08.503524 #train# step  150, loss = 1.0625, cross_entropy loss = 1.0625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:10.052037 #train# step  151, loss = 1.0590, cross_entropy loss = 1.0590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:11.571605 #train# step  152, loss = 1.0816, cross_entropy loss = 1.0816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:13.136719 #train# step  153, loss = 1.0699, cross_entropy loss = 1.0699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:14.701502 #train# step  154, loss = 1.0587, cross_entropy loss = 1.0587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:16.217390 #train# step  155, loss = 1.0780, cross_entropy loss = 1.0780, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:17.822469 #train# step  156, loss = 1.0614, cross_entropy loss = 1.0614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:19.396973 #train# step  157, loss = 1.0568, cross_entropy loss = 1.0568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:20.970015 #train# step  158, loss = 1.0638, cross_entropy loss = 1.0638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:22.516691 #train# step  159, loss = 1.0638, cross_entropy loss = 1.0638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:24.046836 #train# step  160, loss = 1.0660, cross_entropy loss = 1.0660, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:25.633882 #train# step  161, loss = 1.0625, cross_entropy loss = 1.0625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:27.188805 #train# step  162, loss = 1.0621, cross_entropy loss = 1.0621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:28.736174 #train# step  163, loss = 1.0483, cross_entropy loss = 1.0483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:30.319293 #train# step  164, loss = 1.0652, cross_entropy loss = 1.0652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:31.891354 #train# step  165, loss = 1.0511, cross_entropy loss = 1.0511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:33.483726 #train# step  166, loss = 1.0548, cross_entropy loss = 1.0548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:35.036200 #train# step  167, loss = 1.0593, cross_entropy loss = 1.0593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:36.579411 #train# step  168, loss = 1.0663, cross_entropy loss = 1.0663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:38.122909 #train# step  169, loss = 1.0446, cross_entropy loss = 1.0446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:39.757542 #train# step  170, loss = 1.0566, cross_entropy loss = 1.0566, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:41.370794 #train# step  171, loss = 1.0415, cross_entropy loss = 1.0415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:42.962444 #train# step  172, loss = 1.0370, cross_entropy loss = 1.0370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:44.527924 #train# step  173, loss = 1.0752, cross_entropy loss = 1.0752, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:46.086433 #train# step  174, loss = 1.0266, cross_entropy loss = 1.0266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:47.636186 #train# step  175, loss = 1.0554, cross_entropy loss = 1.0554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:49.187463 #train# step  176, loss = 1.0591, cross_entropy loss = 1.0591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:50.721885 #train# step  177, loss = 1.0648, cross_entropy loss = 1.0648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:52.267205 #train# step  178, loss = 1.0398, cross_entropy loss = 1.0398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:53.804005 #train# step  179, loss = 1.0349, cross_entropy loss = 1.0349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:55.337439 #train# step  180, loss = 1.0602, cross_entropy loss = 1.0602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:56.879386 #train# step  181, loss = 1.0433, cross_entropy loss = 1.0433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:58.406101 #train# step  182, loss = 1.0403, cross_entropy loss = 1.0403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:59.969104 #train# step  183, loss = 1.0350, cross_entropy loss = 1.0350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:01.501257 #train# step  184, loss = 1.0473, cross_entropy loss = 1.0473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:03.039990 #train# step  185, loss = 1.0499, cross_entropy loss = 1.0499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:04.593896 #train# step  186, loss = 1.0509, cross_entropy loss = 1.0509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:06.183557 #train# step  187, loss = 1.0518, cross_entropy loss = 1.0518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:07.798919 #train# step  188, loss = 1.0461, cross_entropy loss = 1.0461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:09.356757 #train# step  189, loss = 1.0533, cross_entropy loss = 1.0533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:10.919654 #train# step  190, loss = 1.0346, cross_entropy loss = 1.0346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:12.475804 #train# step  191, loss = 1.0483, cross_entropy loss = 1.0483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:14.071687 #train# step  192, loss = 1.0547, cross_entropy loss = 1.0547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:15.620633 #train# step  193, loss = 1.0377, cross_entropy loss = 1.0377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:17.185141 #train# step  194, loss = 1.0400, cross_entropy loss = 1.0400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:18.741654 #train# step  195, loss = 1.0498, cross_entropy loss = 1.0498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:20.284070 #train# step  196, loss = 1.0597, cross_entropy loss = 1.0597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:21.850416 #train# step  197, loss = 1.0655, cross_entropy loss = 1.0655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:23.404557 #train# step  198, loss = 1.0286, cross_entropy loss = 1.0286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:24.953680 #train# step  199, loss = 1.0459, cross_entropy loss = 1.0459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:26.488943 #train# step  200, loss = 1.0506, cross_entropy loss = 1.0506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:28.074541 #train# step  201, loss = 1.0293, cross_entropy loss = 1.0293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:29.638770 #train# step  202, loss = 1.0499, cross_entropy loss = 1.0499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:31.166450 #train# step  203, loss = 1.0397, cross_entropy loss = 1.0397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:32.715982 #train# step  204, loss = 1.0454, cross_entropy loss = 1.0454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:34.297281 #train# step  205, loss = 1.0374, cross_entropy loss = 1.0374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:35.853699 #train# step  206, loss = 1.0549, cross_entropy loss = 1.0549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:37.421842 #train# step  207, loss = 1.0391, cross_entropy loss = 1.0391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:38.949357 #train# step  208, loss = 1.0278, cross_entropy loss = 1.0278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:40.474348 #train# step  209, loss = 1.0526, cross_entropy loss = 1.0526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:42.001357 #train# step  210, loss = 1.0341, cross_entropy loss = 1.0341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:43.539500 #train# step  211, loss = 1.0541, cross_entropy loss = 1.0541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:45.060523 #train# step  212, loss = 1.0427, cross_entropy loss = 1.0427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:46.588934 #train# step  213, loss = 1.0478, cross_entropy loss = 1.0478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:48.140712 #train# step  214, loss = 1.0295, cross_entropy loss = 1.0295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:49.688392 #train# step  215, loss = 1.0587, cross_entropy loss = 1.0587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:51.219461 #train# step  216, loss = 1.0345, cross_entropy loss = 1.0345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:52.772347 #train# step  217, loss = 1.0648, cross_entropy loss = 1.0648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:54.290209 #train# step  218, loss = 1.0345, cross_entropy loss = 1.0345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:55.816464 #train# step  219, loss = 1.0333, cross_entropy loss = 1.0333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:57.417625 #train# step  220, loss = 1.0144, cross_entropy loss = 1.0144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:58.945414 #train# step  221, loss = 1.0554, cross_entropy loss = 1.0554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:00.505810 #train# step  222, loss = 1.0318, cross_entropy loss = 1.0318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:02.046723 #train# step  223, loss = 1.0545, cross_entropy loss = 1.0545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:03.571590 #train# step  224, loss = 1.0343, cross_entropy loss = 1.0343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:05.137665 #train# step  225, loss = 1.0537, cross_entropy loss = 1.0537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:06.722654 #train# step  226, loss = 1.0153, cross_entropy loss = 1.0153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:08.369238 #train# step  227, loss = 1.0430, cross_entropy loss = 1.0430, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:09.916114 #train# step  228, loss = 1.0489, cross_entropy loss = 1.0489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:11.498356 #train# step  229, loss = 1.0327, cross_entropy loss = 1.0327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:13.065464 #train# step  230, loss = 1.0531, cross_entropy loss = 1.0531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:14.602018 #train# step  231, loss = 1.0260, cross_entropy loss = 1.0260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:16.152854 #train# step  232, loss = 1.0427, cross_entropy loss = 1.0427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:17.655645 #train# step  233, loss = 1.0478, cross_entropy loss = 1.0478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:19.214726 #train# step  234, loss = 1.0550, cross_entropy loss = 1.0550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:20.763445 #train# step  235, loss = 1.0317, cross_entropy loss = 1.0317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:22.321121 #train# step  236, loss = 1.0566, cross_entropy loss = 1.0566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:23.872275 #train# step  237, loss = 1.0326, cross_entropy loss = 1.0326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:25.441995 #train# step  238, loss = 1.0155, cross_entropy loss = 1.0155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:26.992716 #train# step  239, loss = 1.0286, cross_entropy loss = 1.0286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:28.539168 #train# step  240, loss = 1.0256, cross_entropy loss = 1.0256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:30.108893 #train# step  241, loss = 1.0289, cross_entropy loss = 1.0289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:31.686042 #train# step  242, loss = 1.0378, cross_entropy loss = 1.0378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:33.229281 #train# step  243, loss = 1.0267, cross_entropy loss = 1.0267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:34.783870 #train# step  244, loss = 1.0282, cross_entropy loss = 1.0282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:36.346401 #train# step  245, loss = 1.0529, cross_entropy loss = 1.0529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:37.889167 #train# step  246, loss = 1.0528, cross_entropy loss = 1.0528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:39.442991 #train# step  247, loss = 1.0332, cross_entropy loss = 1.0332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:40.972765 #train# step  248, loss = 1.0434, cross_entropy loss = 1.0434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:42.517290 #train# step  249, loss = 1.0230, cross_entropy loss = 1.0230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:44.060552 #train# step  250, loss = 1.0402, cross_entropy loss = 1.0402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:45.627737 #train# step  251, loss = 1.0403, cross_entropy loss = 1.0403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:47.181831 #train# step  252, loss = 1.0284, cross_entropy loss = 1.0284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:48.730997 #train# step  253, loss = 1.0276, cross_entropy loss = 1.0276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:50.342091 #train# step  254, loss = 1.0322, cross_entropy loss = 1.0322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:51.916345 #train# step  255, loss = 1.0271, cross_entropy loss = 1.0271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:53.497319 #train# step  256, loss = 1.0274, cross_entropy loss = 1.0274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:55.063380 #train# step  257, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:56.618726 #train# step  258, loss = 1.0345, cross_entropy loss = 1.0345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:58.132405 #train# step  259, loss = 1.0362, cross_entropy loss = 1.0362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:59.703791 #train# step  260, loss = 1.0509, cross_entropy loss = 1.0509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:01.244497 #train# step  261, loss = 1.0183, cross_entropy loss = 1.0183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:02.814198 #train# step  262, loss = 1.0197, cross_entropy loss = 1.0197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:04.347399 #train# step  263, loss = 1.0477, cross_entropy loss = 1.0477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:05.897481 #train# step  264, loss = 1.0309, cross_entropy loss = 1.0309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:07.437922 #train# step  265, loss = 1.0151, cross_entropy loss = 1.0151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:08.974242 #train# step  266, loss = 1.0153, cross_entropy loss = 1.0153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:10.496277 #train# step  267, loss = 1.0129, cross_entropy loss = 1.0129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:11.996442 #train# step  268, loss = 1.0434, cross_entropy loss = 1.0434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:13.550908 #train# step  269, loss = 1.0548, cross_entropy loss = 1.0548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:15.084314 #train# step  270, loss = 1.0340, cross_entropy loss = 1.0340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:16.607585 #train# step  271, loss = 1.0399, cross_entropy loss = 1.0399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:18.161045 #train# step  272, loss = 1.0269, cross_entropy loss = 1.0269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:19.707830 #train# step  273, loss = 1.0236, cross_entropy loss = 1.0236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:21.261501 #train# step  274, loss = 1.0505, cross_entropy loss = 1.0505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:22.819773 #train# step  275, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:24.362231 #train# step  276, loss = 1.0289, cross_entropy loss = 1.0289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:25.981439 #train# step  277, loss = 1.0294, cross_entropy loss = 1.0294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:27.547446 #train# step  278, loss = 1.0272, cross_entropy loss = 1.0272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:29.102794 #train# step  279, loss = 1.0371, cross_entropy loss = 1.0371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:30.654137 #train# step  280, loss = 1.0189, cross_entropy loss = 1.0189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:32.221737 #train# step  281, loss = 1.0388, cross_entropy loss = 1.0388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:33.777317 #train# step  282, loss = 1.0322, cross_entropy loss = 1.0322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:35.339688 #train# step  283, loss = 1.0393, cross_entropy loss = 1.0393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:36.890781 #train# step  284, loss = 1.0089, cross_entropy loss = 1.0089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:38.464966 #train# step  285, loss = 1.0275, cross_entropy loss = 1.0275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:39.992535 #train# step  286, loss = 1.0471, cross_entropy loss = 1.0471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:41.523632 #train# step  287, loss = 1.0348, cross_entropy loss = 1.0348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:43.092848 #train# step  288, loss = 1.0469, cross_entropy loss = 1.0469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:44.639280 #train# step  289, loss = 1.0244, cross_entropy loss = 1.0244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:46.234622 #train# step  290, loss = 1.0207, cross_entropy loss = 1.0207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:47.758421 #train# step  291, loss = 1.0209, cross_entropy loss = 1.0209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:49.299993 #train# step  292, loss = 1.0227, cross_entropy loss = 1.0227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:50.845358 #train# step  293, loss = 1.0189, cross_entropy loss = 1.0189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:52.406926 #train# step  294, loss = 1.0274, cross_entropy loss = 1.0274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:53.940744 #train# step  295, loss = 1.0192, cross_entropy loss = 1.0192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:55.470660 #train# step  296, loss = 1.0323, cross_entropy loss = 1.0323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:57.034660 #train# step  297, loss = 1.0385, cross_entropy loss = 1.0385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:58.596684 #train# step  298, loss = 1.0344, cross_entropy loss = 1.0344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:00.126916 #train# step  299, loss = 1.0253, cross_entropy loss = 1.0253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:01.652753 #train# step  300, loss = 1.0244, cross_entropy loss = 1.0244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:03.192643 #train# step  301, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:04.764045 #train# step  302, loss = 1.0176, cross_entropy loss = 1.0176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:06.336858 #train# step  303, loss = 1.0413, cross_entropy loss = 1.0413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:07.908843 #train# step  304, loss = 1.0262, cross_entropy loss = 1.0262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:09.465726 #train# step  305, loss = 1.0212, cross_entropy loss = 1.0212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:10.999779 #train# step  306, loss = 1.0252, cross_entropy loss = 1.0252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:12.533875 #train# step  307, loss = 1.0201, cross_entropy loss = 1.0201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:14.041701 #train# step  308, loss = 1.0101, cross_entropy loss = 1.0101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:15.584184 #train# step  309, loss = 1.0263, cross_entropy loss = 1.0263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:17.153115 #train# step  310, loss = 1.0254, cross_entropy loss = 1.0254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:18.724696 #train# step  311, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:20.283813 #train# step  312, loss = 1.0243, cross_entropy loss = 1.0243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:21.834730 #train# step  313, loss = 1.0333, cross_entropy loss = 1.0333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:23.394433 #train# step  314, loss = 1.0045, cross_entropy loss = 1.0045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:24.974686 #train# step  315, loss = 1.0213, cross_entropy loss = 1.0213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:26.566783 #train# step  316, loss = 1.0233, cross_entropy loss = 1.0233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:28.114055 #train# step  317, loss = 1.0315, cross_entropy loss = 1.0315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:29.690022 #train# step  318, loss = 1.0277, cross_entropy loss = 1.0277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:31.244497 #train# step  319, loss = 1.0289, cross_entropy loss = 1.0289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:32.772359 #train# step  320, loss = 1.0202, cross_entropy loss = 1.0202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:34.348121 #train# step  321, loss = 1.0337, cross_entropy loss = 1.0337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:35.867072 #train# step  322, loss = 1.0432, cross_entropy loss = 1.0432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:37.385611 #train# step  323, loss = 1.0310, cross_entropy loss = 1.0310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:38.917002 #train# step  324, loss = 1.0246, cross_entropy loss = 1.0246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:40.470054 #train# step  325, loss = 1.0462, cross_entropy loss = 1.0462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:42.026121 #train# step  326, loss = 1.0153, cross_entropy loss = 1.0153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:43.557241 #train# step  327, loss = 1.0187, cross_entropy loss = 1.0187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:45.113926 #train# step  328, loss = 0.9998, cross_entropy loss = 0.9998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:46.685433 #train# step  329, loss = 1.0179, cross_entropy loss = 1.0179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:48.231446 #train# step  330, loss = 1.0031, cross_entropy loss = 1.0031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:49.809125 #train# step  331, loss = 1.0267, cross_entropy loss = 1.0267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:51.362106 #train# step  332, loss = 1.0218, cross_entropy loss = 1.0218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:52.887903 #train# step  333, loss = 1.0395, cross_entropy loss = 1.0395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:54.430992 #train# step  334, loss = 1.0478, cross_entropy loss = 1.0478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:55.995631 #train# step  335, loss = 1.0202, cross_entropy loss = 1.0202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:57.551942 #train# step  336, loss = 1.0176, cross_entropy loss = 1.0176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:59.057578 #train# step  337, loss = 1.0344, cross_entropy loss = 1.0344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:00.615649 #train# step  338, loss = 1.0185, cross_entropy loss = 1.0185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:02.176457 #train# step  339, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:03.722476 #train# step  340, loss = 1.0114, cross_entropy loss = 1.0114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:05.273912 #train# step  341, loss = 1.0416, cross_entropy loss = 1.0416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:06.802042 #train# step  342, loss = 1.0228, cross_entropy loss = 1.0228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:08.374275 #train# step  343, loss = 1.0079, cross_entropy loss = 1.0079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:09.920210 #train# step  344, loss = 1.0446, cross_entropy loss = 1.0446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:11.487137 #train# step  345, loss = 1.0333, cross_entropy loss = 1.0333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:13.048773 #train# step  346, loss = 1.0248, cross_entropy loss = 1.0248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:14.575779 #train# step  347, loss = 1.0333, cross_entropy loss = 1.0333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:16.127361 #train# step  348, loss = 1.0009, cross_entropy loss = 1.0009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:17.689247 #train# step  349, loss = 1.0312, cross_entropy loss = 1.0312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:19.184674 #train# step  350, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:20.745878 #train# step  351, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:22.317914 #train# step  352, loss = 1.0173, cross_entropy loss = 1.0173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:23.881266 #train# step  353, loss = 1.0167, cross_entropy loss = 1.0167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:25.437622 #train# step  354, loss = 1.0257, cross_entropy loss = 1.0257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:26.975006 #train# step  355, loss = 1.0083, cross_entropy loss = 1.0083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:28.520738 #train# step  356, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:30.083563 #train# step  357, loss = 1.0110, cross_entropy loss = 1.0110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:31.627743 #train# step  358, loss = 1.0234, cross_entropy loss = 1.0234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:33.138914 #train# step  359, loss = 1.0352, cross_entropy loss = 1.0352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:34.699375 #train# step  360, loss = 1.0132, cross_entropy loss = 1.0132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:36.236809 #train# step  361, loss = 1.0176, cross_entropy loss = 1.0176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:37.802810 #train# step  362, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:39.361599 #train# step  363, loss = 1.0228, cross_entropy loss = 1.0228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:40.888558 #train# step  364, loss = 1.0227, cross_entropy loss = 1.0227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:42.442881 #train# step  365, loss = 1.0138, cross_entropy loss = 1.0138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:44.001256 #train# step  366, loss = 1.0146, cross_entropy loss = 1.0146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:45.591083 #train# step  367, loss = 1.0211, cross_entropy loss = 1.0211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:47.155378 #train# step  368, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:48.685723 #train# step  369, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:50.236832 #train# step  370, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:51.798134 #train# step  371, loss = 1.0187, cross_entropy loss = 1.0187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:53.351039 #train# step  372, loss = 1.0419, cross_entropy loss = 1.0419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:54.896267 #train# step  373, loss = 1.0198, cross_entropy loss = 1.0198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:56.462714 #train# step  374, loss = 1.0022, cross_entropy loss = 1.0022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:57.961758 #train# step  375, loss = 1.0179, cross_entropy loss = 1.0179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:59.540710 #train# step  376, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:01.108543 #train# step  377, loss = 1.0140, cross_entropy loss = 1.0140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:02.651716 #train# step  378, loss = 1.0082, cross_entropy loss = 1.0082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:04.202395 #train# step  379, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:05.761762 #train# step  380, loss = 1.0199, cross_entropy loss = 1.0199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:07.302089 #train# step  381, loss = 1.0163, cross_entropy loss = 1.0163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:08.832296 #train# step  382, loss = 1.0473, cross_entropy loss = 1.0473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:10.376941 #train# step  383, loss = 1.0470, cross_entropy loss = 1.0470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:11.910882 #train# step  384, loss = 1.0273, cross_entropy loss = 1.0273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:13.444123 #train# step  385, loss = 1.0327, cross_entropy loss = 1.0327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:14.982659 #train# step  386, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:16.524056 #train# step  387, loss = 1.0065, cross_entropy loss = 1.0065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:18.068560 #train# step  388, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:19.617948 #train# step  389, loss = 1.0316, cross_entropy loss = 1.0316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:21.171651 #train# step  390, loss = 1.0240, cross_entropy loss = 1.0240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:22.730923 #train# step  391, loss = 1.0184, cross_entropy loss = 1.0184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:24.297526 #train# step  392, loss = 0.9979, cross_entropy loss = 0.9979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:25.872645 #train# step  393, loss = 1.0165, cross_entropy loss = 1.0165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:27.412845 #train# step  394, loss = 1.0290, cross_entropy loss = 1.0290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:28.954116 #train# step  395, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:30.521444 #train# step  396, loss = 1.0309, cross_entropy loss = 1.0309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:32.060308 #train# step  397, loss = 1.0131, cross_entropy loss = 1.0131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:33.631518 #train# step  398, loss = 1.0291, cross_entropy loss = 1.0291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:35.184677 #train# step  399, loss = 1.0247, cross_entropy loss = 1.0247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:36.726860 #train# step  400, loss = 1.0295, cross_entropy loss = 1.0295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:38.299831 #train# step  401, loss = 1.0034, cross_entropy loss = 1.0034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:39.868434 #train# step  402, loss = 1.0141, cross_entropy loss = 1.0141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:41.408909 #train# step  403, loss = 1.0415, cross_entropy loss = 1.0415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:42.955720 #train# step  404, loss = 1.0167, cross_entropy loss = 1.0167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:44.522716 #train# step  405, loss = 1.0075, cross_entropy loss = 1.0075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:46.042977 #train# step  406, loss = 1.0249, cross_entropy loss = 1.0249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:47.588438 #train# step  407, loss = 1.0025, cross_entropy loss = 1.0025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:49.177605 #train# step  408, loss = 1.0147, cross_entropy loss = 1.0147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:50.735904 #train# step  409, loss = 1.0250, cross_entropy loss = 1.0250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:52.288451 #train# step  410, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:53.810768 #train# step  411, loss = 1.0098, cross_entropy loss = 1.0098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:55.347111 #train# step  412, loss = 1.0166, cross_entropy loss = 1.0166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:56.893750 #train# step  413, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:58.398241 #train# step  414, loss = 1.0257, cross_entropy loss = 1.0257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:59.976102 #train# step  415, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:01.517107 #train# step  416, loss = 1.0067, cross_entropy loss = 1.0067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:03.053519 #train# step  417, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:04.597413 #train# step  418, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:06.137637 #train# step  419, loss = 1.0182, cross_entropy loss = 1.0182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:07.687297 #train# step  420, loss = 1.0141, cross_entropy loss = 1.0141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:09.243819 #train# step  421, loss = 1.0021, cross_entropy loss = 1.0021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:10.785422 #train# step  422, loss = 1.0146, cross_entropy loss = 1.0146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:12.372125 #train# step  423, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:13.939513 #train# step  424, loss = 1.0087, cross_entropy loss = 1.0087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:15.536620 #train# step  425, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:17.062834 #train# step  426, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:18.610423 #train# step  427, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:20.172793 #train# step  428, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:21.727310 #train# step  429, loss = 1.0206, cross_entropy loss = 1.0206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:23.301787 #train# step  430, loss = 1.0048, cross_entropy loss = 1.0048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:24.863260 #train# step  431, loss = 1.0000, cross_entropy loss = 1.0000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:26.411165 #train# step  432, loss = 1.0159, cross_entropy loss = 1.0159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:27.936840 #train# step  433, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:29.512632 #train# step  434, loss = 1.0081, cross_entropy loss = 1.0081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:31.096084 #train# step  435, loss = 1.0080, cross_entropy loss = 1.0080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:32.634191 #train# step  436, loss = 1.0159, cross_entropy loss = 1.0159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:34.128389 #train# step  437, loss = 1.0223, cross_entropy loss = 1.0223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:35.649318 #train# step  438, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:37.214640 #train# step  439, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:38.773255 #train# step  440, loss = 1.0312, cross_entropy loss = 1.0312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:40.364986 #train# step  441, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:41.927567 #train# step  442, loss = 1.0042, cross_entropy loss = 1.0042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:43.469668 #train# step  443, loss = 1.0290, cross_entropy loss = 1.0290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:45.010300 #train# step  444, loss = 1.0106, cross_entropy loss = 1.0106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:46.569170 #train# step  445, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:48.117944 #train# step  446, loss = 1.0222, cross_entropy loss = 1.0222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:49.641486 #train# step  447, loss = 1.0295, cross_entropy loss = 1.0295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:51.216928 #train# step  448, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:52.727153 #train# step  449, loss = 1.0090, cross_entropy loss = 1.0090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:54.302966 #train# step  450, loss = 1.0209, cross_entropy loss = 1.0209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:55.854191 #train# step  451, loss = 1.0081, cross_entropy loss = 1.0081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:57.412937 #train# step  452, loss = 1.0137, cross_entropy loss = 1.0137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:58.908657 #train# step  453, loss = 1.0142, cross_entropy loss = 1.0142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:00.467984 #train# step  454, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:02.029846 #train# step  455, loss = 1.0073, cross_entropy loss = 1.0073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:03.557808 #train# step  456, loss = 1.0165, cross_entropy loss = 1.0165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:05.108530 #train# step  457, loss = 1.0146, cross_entropy loss = 1.0146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:06.645953 #train# step  458, loss = 1.0160, cross_entropy loss = 1.0160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:08.162905 #train# step  459, loss = 1.0220, cross_entropy loss = 1.0220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:09.747377 #train# step  460, loss = 1.0102, cross_entropy loss = 1.0102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:11.271676 #train# step  461, loss = 0.9992, cross_entropy loss = 0.9992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:12.827636 #train# step  462, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:14.374328 #train# step  463, loss = 1.0163, cross_entropy loss = 1.0163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:15.942710 #train# step  464, loss = 1.0201, cross_entropy loss = 1.0201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:17.519248 #train# step  465, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:19.054937 #train# step  466, loss = 1.0115, cross_entropy loss = 1.0115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:20.603381 #train# step  467, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:22.139213 #train# step  468, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:23.688285 #train# step  469, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:25.281111 #train# step  470, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:26.819961 #train# step  471, loss = 1.0179, cross_entropy loss = 1.0179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:28.411577 #train# step  472, loss = 1.0160, cross_entropy loss = 1.0160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:29.986492 #train# step  473, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:31.532625 #train# step  474, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:33.070535 #train# step  475, loss = 1.0095, cross_entropy loss = 1.0095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:34.615260 #train# step  476, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:36.171447 #train# step  477, loss = 1.0115, cross_entropy loss = 1.0115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:37.739353 #train# step  478, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:39.295598 #train# step  479, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:40.865009 #train# step  480, loss = 1.0178, cross_entropy loss = 1.0178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:42.420054 #train# step  481, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:43.995490 #train# step  482, loss = 1.0078, cross_entropy loss = 1.0078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:45.504090 #train# step  483, loss = 1.0171, cross_entropy loss = 1.0171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:47.086124 #train# step  484, loss = 1.0087, cross_entropy loss = 1.0087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:48.625727 #train# step  485, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:50.219782 #train# step  486, loss = 1.0073, cross_entropy loss = 1.0073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:51.754954 #train# step  487, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:53.281958 #train# step  488, loss = 1.0288, cross_entropy loss = 1.0288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:54.825107 #train# step  489, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:56.371189 #train# step  490, loss = 1.0126, cross_entropy loss = 1.0126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:57.902839 #train# step  491, loss = 1.0068, cross_entropy loss = 1.0068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:59.473219 #train# step  492, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:01.002707 #train# step  493, loss = 1.0213, cross_entropy loss = 1.0213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:02.559207 #train# step  494, loss = 1.0021, cross_entropy loss = 1.0021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:04.257685 #train# step  495, loss = 1.0050, cross_entropy loss = 1.0050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:05.817002 #train# step  496, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:07.357094 #train# step  497, loss = 1.0059, cross_entropy loss = 1.0059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:08.905725 #train# step  498, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:10.453182 #train# step  499, loss = 1.0024, cross_entropy loss = 1.0024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:11.968338 #train# step  500, loss = 1.0051, cross_entropy loss = 1.0051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:13.532479 #train# step  501, loss = 0.9943, cross_entropy loss = 0.9943, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:15.081951 #train# step  502, loss = 1.0035, cross_entropy loss = 1.0035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:16.616175 #train# step  503, loss = 1.0045, cross_entropy loss = 1.0045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:18.151637 #train# step  504, loss = 1.0198, cross_entropy loss = 1.0198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:19.705485 #train# step  505, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:21.243129 #train# step  506, loss = 1.0155, cross_entropy loss = 1.0155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:22.800744 #train# step  507, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:24.360965 #train# step  508, loss = 1.0101, cross_entropy loss = 1.0101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:25.889247 #train# step  509, loss = 1.0006, cross_entropy loss = 1.0006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:27.443693 #train# step  510, loss = 1.0099, cross_entropy loss = 1.0099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:28.970220 #train# step  511, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:30.534582 #train# step  512, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:32.115887 #train# step  513, loss = 1.0056, cross_entropy loss = 1.0056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:33.661402 #train# step  514, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:35.223553 #train# step  515, loss = 1.0036, cross_entropy loss = 1.0036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:36.751987 #train# step  516, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:38.306216 #train# step  517, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:39.888627 #train# step  518, loss = 1.0269, cross_entropy loss = 1.0269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:41.462644 #train# step  519, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:43.011994 #train# step  520, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:44.566917 #train# step  521, loss = 1.0204, cross_entropy loss = 1.0204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:46.129538 #train# step  522, loss = 0.9940, cross_entropy loss = 0.9940, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:47.675053 #train# step  523, loss = 1.0149, cross_entropy loss = 1.0149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:49.249140 #train# step  524, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:50.811648 #train# step  525, loss = 1.0106, cross_entropy loss = 1.0106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:52.358239 #train# step  526, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:53.900589 #train# step  527, loss = 1.0061, cross_entropy loss = 1.0061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:55.456076 #train# step  528, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:56.997005 #train# step  529, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:58.563970 #train# step  530, loss = 0.9995, cross_entropy loss = 0.9995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:00.139848 #train# step  531, loss = 0.9990, cross_entropy loss = 0.9990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:01.686194 #train# step  532, loss = 1.0058, cross_entropy loss = 1.0058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:03.239127 #train# step  533, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:04.799307 #train# step  534, loss = 1.0030, cross_entropy loss = 1.0030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:06.344632 #train# step  535, loss = 1.0005, cross_entropy loss = 1.0005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:07.871803 #train# step  536, loss = 1.0067, cross_entropy loss = 1.0067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:09.405220 #train# step  537, loss = 1.0293, cross_entropy loss = 1.0293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:10.920850 #train# step  538, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:12.416064 #train# step  539, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:13.971135 #train# step  540, loss = 1.0141, cross_entropy loss = 1.0141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:15.532994 #train# step  541, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:17.048376 #train# step  542, loss = 1.0180, cross_entropy loss = 1.0180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:18.627981 #train# step  543, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:20.148470 #train# step  544, loss = 1.0062, cross_entropy loss = 1.0062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:21.716519 #train# step  545, loss = 1.0104, cross_entropy loss = 1.0104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:23.249266 #train# step  546, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:24.788387 #train# step  547, loss = 1.0101, cross_entropy loss = 1.0101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:26.322667 #train# step  548, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:27.867864 #train# step  549, loss = 0.9924, cross_entropy loss = 0.9924, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:29.397092 #train# step  550, loss = 1.0131, cross_entropy loss = 1.0131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:30.941676 #train# step  551, loss = 1.0162, cross_entropy loss = 1.0162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:32.466009 #train# step  552, loss = 1.0172, cross_entropy loss = 1.0172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:34.000634 #train# step  553, loss = 1.0195, cross_entropy loss = 1.0195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:35.568958 #train# step  554, loss = 1.0033, cross_entropy loss = 1.0033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:37.115502 #train# step  555, loss = 1.0054, cross_entropy loss = 1.0054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:38.705844 #train# step  556, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:40.262750 #train# step  557, loss = 1.0081, cross_entropy loss = 1.0081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:41.804249 #train# step  558, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:43.390042 #train# step  559, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:44.963888 #train# step  560, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:46.486261 #train# step  561, loss = 1.0016, cross_entropy loss = 1.0016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:48.038656 #train# step  562, loss = 1.0107, cross_entropy loss = 1.0107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:49.579291 #train# step  563, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:51.155094 #train# step  564, loss = 1.0061, cross_entropy loss = 1.0061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:52.709944 #train# step  565, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:54.265833 #train# step  566, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:55.821752 #train# step  567, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:57.370160 #train# step  568, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:58.915533 #train# step  569, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:00.448196 #train# step  570, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:02.060911 #train# step  571, loss = 0.9974, cross_entropy loss = 0.9974, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:03.658373 #train# step  572, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:05.232963 #train# step  573, loss = 0.9978, cross_entropy loss = 0.9978, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:06.737257 #train# step  574, loss = 1.0177, cross_entropy loss = 1.0177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:08.315025 #train# step  575, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:09.901543 #train# step  576, loss = 1.0111, cross_entropy loss = 1.0111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:11.591626 #train# step  577, loss = 1.0165, cross_entropy loss = 1.0165, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:13.130470 #train# step  578, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:14.714648 #train# step  579, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:16.278911 #train# step  580, loss = 0.9974, cross_entropy loss = 0.9974, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:17.835031 #train# step  581, loss = 1.0076, cross_entropy loss = 1.0076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:19.356236 #train# step  582, loss = 1.0005, cross_entropy loss = 1.0005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:20.926010 #train# step  583, loss = 1.0048, cross_entropy loss = 1.0048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:22.570624 #train# step  584, loss = 1.0047, cross_entropy loss = 1.0047, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:24.165745 #train# step  585, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:25.727692 #train# step  586, loss = 1.0276, cross_entropy loss = 1.0276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:27.341631 #train# step  587, loss = 1.0073, cross_entropy loss = 1.0073, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:28.903529 #train# step  588, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:30.461023 #train# step  589, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:32.001613 #train# step  590, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:33.596899 #train# step  591, loss = 1.0020, cross_entropy loss = 1.0020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:35.158925 #train# step  592, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:36.726507 #train# step  593, loss = 1.0042, cross_entropy loss = 1.0042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:38.300957 #train# step  594, loss = 1.0026, cross_entropy loss = 1.0026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:39.874148 #train# step  595, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:41.399337 #train# step  596, loss = 1.0097, cross_entropy loss = 1.0097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:42.948231 #train# step  597, loss = 1.0092, cross_entropy loss = 1.0092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:44.495827 #train# step  598, loss = 1.0072, cross_entropy loss = 1.0072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:46.023388 #train# step  599, loss = 0.9969, cross_entropy loss = 0.9969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:47.589987 #train# step  600, loss = 0.9918, cross_entropy loss = 0.9918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:49.151423 #train# step  601, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:50.721368 #train# step  602, loss = 1.0221, cross_entropy loss = 1.0221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:52.285647 #train# step  603, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:53.840617 #train# step  604, loss = 1.0001, cross_entropy loss = 1.0001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:55.387614 #train# step  605, loss = 1.0076, cross_entropy loss = 1.0076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:56.934368 #train# step  606, loss = 1.0179, cross_entropy loss = 1.0179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:58.486658 #train# step  607, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:00.042116 #train# step  608, loss = 0.9811, cross_entropy loss = 0.9811, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:01.580009 #train# step  609, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:03.099484 #train# step  610, loss = 1.0057, cross_entropy loss = 1.0057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:04.634779 #train# step  611, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:06.149436 #train# step  612, loss = 1.0098, cross_entropy loss = 1.0098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:07.695350 #train# step  613, loss = 1.0132, cross_entropy loss = 1.0132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:09.233302 #train# step  614, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:10.808253 #train# step  615, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:12.371614 #train# step  616, loss = 1.0194, cross_entropy loss = 1.0194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:13.908439 #train# step  617, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:15.449277 #train# step  618, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:17.021346 #train# step  619, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:18.551813 #train# step  620, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:20.047141 #train# step  621, loss = 1.0383, cross_entropy loss = 1.0383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:21.591624 #train# step  622, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:23.155745 #train# step  623, loss = 0.9979, cross_entropy loss = 0.9979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:24.708592 #train# step  624, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:26.265023 #train# step  625, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:27.792215 #train# step  626, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:29.323195 #train# step  627, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:30.905938 #train# step  628, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:32.465662 #train# step  629, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:34.041323 #train# step  630, loss = 1.0127, cross_entropy loss = 1.0127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:35.585277 #train# step  631, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:37.112948 #train# step  632, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:38.666026 #train# step  633, loss = 0.9942, cross_entropy loss = 0.9942, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:40.207276 #train# step  634, loss = 1.0047, cross_entropy loss = 1.0047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:41.757572 #train# step  635, loss = 1.0089, cross_entropy loss = 1.0089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:43.318520 #train# step  636, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:44.857531 #train# step  637, loss = 1.0025, cross_entropy loss = 1.0025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:46.400078 #train# step  638, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:47.956280 #train# step  639, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:49.486863 #train# step  640, loss = 0.9985, cross_entropy loss = 0.9985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:51.049781 #train# step  641, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:52.604560 #train# step  642, loss = 1.0115, cross_entropy loss = 1.0115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:54.147524 #train# step  643, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:55.708667 #train# step  644, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:57.270201 #train# step  645, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:58.799165 #train# step  646, loss = 1.0061, cross_entropy loss = 1.0061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:00.381369 #train# step  647, loss = 1.0082, cross_entropy loss = 1.0082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:01.915834 #train# step  648, loss = 0.9976, cross_entropy loss = 0.9976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:03.511298 #train# step  649, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:05.042304 #train# step  650, loss = 1.0182, cross_entropy loss = 1.0182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:06.577866 #train# step  651, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:08.144234 #train# step  652, loss = 0.9993, cross_entropy loss = 0.9993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:09.713010 #train# step  653, loss = 1.0086, cross_entropy loss = 1.0086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:11.280165 #train# step  654, loss = 1.0044, cross_entropy loss = 1.0044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:12.845080 #train# step  655, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:14.390614 #train# step  656, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:15.940323 #train# step  657, loss = 0.9946, cross_entropy loss = 0.9946, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:17.484535 #train# step  658, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:19.052673 #train# step  659, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:20.608125 #train# step  660, loss = 1.0060, cross_entropy loss = 1.0060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:22.150542 #train# step  661, loss = 1.0103, cross_entropy loss = 1.0103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:23.705913 #train# step  662, loss = 1.0138, cross_entropy loss = 1.0138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:25.263900 #train# step  663, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:26.842029 #train# step  664, loss = 0.9920, cross_entropy loss = 0.9920, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:28.372592 #train# step  665, loss = 0.9919, cross_entropy loss = 0.9919, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:29.918550 #train# step  666, loss = 1.0070, cross_entropy loss = 1.0070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:31.459976 #train# step  667, loss = 1.0008, cross_entropy loss = 1.0008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:33.011895 #train# step  668, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:34.607683 #train# step  669, loss = 1.0137, cross_entropy loss = 1.0137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:36.168531 #train# step  670, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:37.740365 #train# step  671, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:39.284257 #train# step  672, loss = 0.9833, cross_entropy loss = 0.9833, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:40.857881 #train# step  673, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:42.391292 #train# step  674, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:43.921222 #train# step  675, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:45.435711 #train# step  676, loss = 1.0026, cross_entropy loss = 1.0026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:46.977105 #train# step  677, loss = 1.0074, cross_entropy loss = 1.0074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:48.516888 #train# step  678, loss = 0.9943, cross_entropy loss = 0.9943, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:50.067869 #train# step  679, loss = 1.0069, cross_entropy loss = 1.0069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:51.610074 #train# step  680, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:53.139591 #train# step  681, loss = 1.0104, cross_entropy loss = 1.0104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:54.674918 #train# step  682, loss = 1.0059, cross_entropy loss = 1.0059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:56.233396 #train# step  683, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:57.803253 #train# step  684, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:59.325941 #train# step  685, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:00.845106 #train# step  686, loss = 1.0130, cross_entropy loss = 1.0130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:02.384380 #train# step  687, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:03.900528 #train# step  688, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:05.451244 #train# step  689, loss = 0.9914, cross_entropy loss = 0.9914, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:07.008134 #train# step  690, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:08.560101 #train# step  691, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:10.114022 #train# step  692, loss = 1.0002, cross_entropy loss = 1.0002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:11.677562 #train# step  693, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:13.236406 #train# step  694, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:14.777204 #train# step  695, loss = 1.0021, cross_entropy loss = 1.0021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:16.354598 #train# step  696, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:17.915188 #train# step  697, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:19.480140 #train# step  698, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:20.997521 #train# step  699, loss = 1.0079, cross_entropy loss = 1.0079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:22.549041 #train# step  700, loss = 1.0095, cross_entropy loss = 1.0095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:24.123838 #train# step  701, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:25.661612 #train# step  702, loss = 1.0051, cross_entropy loss = 1.0051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:27.194507 #train# step  703, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:28.734980 #train# step  704, loss = 1.0017, cross_entropy loss = 1.0017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:30.289590 #train# step  705, loss = 0.9898, cross_entropy loss = 0.9898, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:31.841653 #train# step  706, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:33.437416 #train# step  707, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:35.006752 #train# step  708, loss = 0.9874, cross_entropy loss = 0.9874, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:36.577643 #train# step  709, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:38.103175 #train# step  710, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:39.660512 #train# step  711, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:41.191525 #train# step  712, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:42.736045 #train# step  713, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:44.306486 #train# step  714, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:45.825381 #train# step  715, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:47.391277 #train# step  716, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:48.937658 #train# step  717, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:50.477491 #train# step  718, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:52.010754 #train# step  719, loss = 1.0065, cross_entropy loss = 1.0065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:53.561059 #train# step  720, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:55.127663 #train# step  721, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:56.678119 #train# step  722, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:58.220763 #train# step  723, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:59.756012 #train# step  724, loss = 0.9914, cross_entropy loss = 0.9914, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:01.296141 #train# step  725, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:02.838112 #train# step  726, loss = 1.0070, cross_entropy loss = 1.0070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:04.379962 #train# step  727, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:05.920649 #train# step  728, loss = 0.9888, cross_entropy loss = 0.9888, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:07.447298 #train# step  729, loss = 1.0026, cross_entropy loss = 1.0026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:09.027618 #train# step  730, loss = 1.0062, cross_entropy loss = 1.0062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:10.562119 #train# step  731, loss = 1.0072, cross_entropy loss = 1.0072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:12.125938 #train# step  732, loss = 0.9967, cross_entropy loss = 0.9967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:13.651049 #train# step  733, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:15.201829 #train# step  734, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:16.768996 #train# step  735, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:18.309247 #train# step  736, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:19.870247 #train# step  737, loss = 1.0000, cross_entropy loss = 1.0000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:21.425213 #train# step  738, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:22.969597 #train# step  739, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:24.512491 #train# step  740, loss = 1.0054, cross_entropy loss = 1.0054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:26.071040 #train# step  741, loss = 0.9967, cross_entropy loss = 0.9967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:27.661128 #train# step  742, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:29.209858 #train# step  743, loss = 0.9927, cross_entropy loss = 0.9927, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:30.763126 #train# step  744, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:32.326731 #train# step  745, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:33.864993 #train# step  746, loss = 1.0223, cross_entropy loss = 1.0223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:35.421108 #train# step  747, loss = 1.0211, cross_entropy loss = 1.0211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:36.973831 #train# step  748, loss = 0.9993, cross_entropy loss = 0.9993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:38.543736 #train# step  749, loss = 0.9888, cross_entropy loss = 0.9888, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:40.109489 #train# step  750, loss = 1.0034, cross_entropy loss = 1.0034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:41.673386 #train# step  751, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:43.211796 #train# step  752, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:44.795830 #train# step  753, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:46.335783 #train# step  754, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:47.913176 #train# step  755, loss = 0.9968, cross_entropy loss = 0.9968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:49.465449 #train# step  756, loss = 0.9937, cross_entropy loss = 0.9937, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:51.014658 #train# step  757, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:52.577855 #train# step  758, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:54.150590 #train# step  759, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:55.705552 #train# step  760, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:57.279994 #train# step  761, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:58.797784 #train# step  762, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:00.361121 #train# step  763, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:01.907749 #train# step  764, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:03.446595 #train# step  765, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:05.011860 #train# step  766, loss = 1.0113, cross_entropy loss = 1.0113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:06.576563 #train# step  767, loss = 0.9894, cross_entropy loss = 0.9894, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:08.120742 #train# step  768, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:09.665736 #train# step  769, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:11.211365 #train# step  770, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:12.748320 #train# step  771, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:14.303999 #train# step  772, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:15.844915 #train# step  773, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:17.428957 #train# step  774, loss = 0.9940, cross_entropy loss = 0.9940, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:18.981161 #train# step  775, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:20.542466 #train# step  776, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:22.097003 #train# step  777, loss = 1.0120, cross_entropy loss = 1.0120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:23.596113 #train# step  778, loss = 0.9957, cross_entropy loss = 0.9957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:25.142289 #train# step  779, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:26.660905 #train# step  780, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:28.254152 #train# step  781, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:29.792109 #train# step  782, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:31.364929 #train# step  783, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:32.906021 #train# step  784, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:34.437279 #train# step  785, loss = 0.9813, cross_entropy loss = 0.9813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:36.005973 #train# step  786, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:37.525612 #train# step  787, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:39.087494 #train# step  788, loss = 0.9924, cross_entropy loss = 0.9924, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:40.655314 #train# step  789, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:42.256260 #train# step  790, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:43.781480 #train# step  791, loss = 1.0147, cross_entropy loss = 1.0147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:45.294671 #train# step  792, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:46.829665 #train# step  793, loss = 1.0031, cross_entropy loss = 1.0031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:48.372865 #train# step  794, loss = 1.0075, cross_entropy loss = 1.0075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:49.918254 #train# step  795, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:51.460744 #train# step  796, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:53.023869 #train# step  797, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:54.604446 #train# step  798, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:56.108079 #train# step  799, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:57.641513 #train# step  800, loss = 0.9945, cross_entropy loss = 0.9945, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:59.179515 #train# step  801, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:00.714284 #train# step  802, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:02.258396 #train# step  803, loss = 1.0080, cross_entropy loss = 1.0080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:03.829863 #train# step  804, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:05.376489 #train# step  805, loss = 0.9983, cross_entropy loss = 0.9983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:06.911442 #train# step  806, loss = 0.9942, cross_entropy loss = 0.9942, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:08.454115 #train# step  807, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:10.008604 #train# step  808, loss = 1.0003, cross_entropy loss = 1.0003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:11.593573 #train# step  809, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:13.149203 #train# step  810, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:14.664163 #train# step  811, loss = 0.9917, cross_entropy loss = 0.9917, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:16.243315 #train# step  812, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:17.814121 #train# step  813, loss = 0.9811, cross_entropy loss = 0.9811, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:19.356638 #train# step  814, loss = 1.0070, cross_entropy loss = 1.0070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:20.929842 #train# step  815, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:22.498525 #train# step  816, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:24.009560 #train# step  817, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:25.563721 #train# step  818, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:27.139833 #train# step  819, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:28.694591 #train# step  820, loss = 1.0003, cross_entropy loss = 1.0003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:30.240493 #train# step  821, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:31.831693 #train# step  822, loss = 0.9919, cross_entropy loss = 0.9919, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:33.393706 #train# step  823, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:34.929256 #train# step  824, loss = 1.0047, cross_entropy loss = 1.0047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:36.483434 #train# step  825, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:38.047418 #train# step  826, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:39.614062 #train# step  827, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:41.167928 #train# step  828, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:42.739367 #train# step  829, loss = 0.9895, cross_entropy loss = 0.9895, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:44.279001 #train# step  830, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:45.806295 #train# step  831, loss = 0.9920, cross_entropy loss = 0.9920, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:47.334881 #train# step  832, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:48.907809 #train# step  833, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:50.445230 #train# step  834, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:52.020738 #train# step  835, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:53.581385 #train# step  836, loss = 0.9898, cross_entropy loss = 0.9898, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:55.120874 #train# step  837, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:56.681801 #train# step  838, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:58.215315 #train# step  839, loss = 1.0024, cross_entropy loss = 1.0024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:59.738641 #train# step  840, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:01.283236 #train# step  841, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:02.834897 #train# step  842, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:04.400577 #train# step  843, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:05.943883 #train# step  844, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:07.502890 #train# step  845, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:09.036528 #train# step  846, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:10.574653 #train# step  847, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:12.104582 #train# step  848, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:13.661266 #train# step  849, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:15.183765 #train# step  850, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:16.751424 #train# step  851, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:18.280852 #train# step  852, loss = 0.9931, cross_entropy loss = 0.9931, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:19.824993 #train# step  853, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:21.435492 #train# step  854, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:22.974395 #train# step  855, loss = 1.0076, cross_entropy loss = 1.0076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:24.508938 #train# step  856, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:26.056211 #train# step  857, loss = 1.0092, cross_entropy loss = 1.0092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:27.591194 #train# step  858, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:29.132149 #train# step  859, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:30.676545 #train# step  860, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:32.250751 #train# step  861, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:33.793007 #train# step  862, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:35.382236 #train# step  863, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:37.002059 #train# step  864, loss = 0.9937, cross_entropy loss = 0.9937, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:38.771715 #train# step  865, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:40.324841 #train# step  866, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:41.880780 #train# step  867, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:43.443036 #train# step  868, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:45.007464 #train# step  869, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:46.574773 #train# step  870, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:48.255566 #train# step  871, loss = 0.9842, cross_entropy loss = 0.9842, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:49.879327 #train# step  872, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:51.427659 #train# step  873, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:53.131429 #train# step  874, loss = 1.0002, cross_entropy loss = 1.0002, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:54.734917 #train# step  875, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:56.473718 #train# step  876, loss = 1.0017, cross_entropy loss = 1.0017, 1.0 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:57.998687 #train# step  877, loss = 0.9979, cross_entropy loss = 0.9979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:59.567650 #train# step  878, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:01.118399 #train# step  879, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:02.697331 #train# step  880, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:04.241088 #train# step  881, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:05.792295 #train# step  882, loss = 0.9929, cross_entropy loss = 0.9929, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:07.367501 #train# step  883, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:08.961010 #train# step  884, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:10.533759 #train# step  885, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:12.054100 #train# step  886, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:13.632654 #train# step  887, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:15.195220 #train# step  888, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:16.731176 #train# step  889, loss = 0.9933, cross_entropy loss = 0.9933, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:18.301421 #train# step  890, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:19.846606 #train# step  891, loss = 0.9934, cross_entropy loss = 0.9934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:21.411828 #train# step  892, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:22.987353 #train# step  893, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:24.536992 #train# step  894, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:26.069588 #train# step  895, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:27.625851 #train# step  896, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:29.151512 #train# step  897, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:30.714733 #train# step  898, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:32.252283 #train# step  899, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:33.782356 #train# step  900, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:35.344265 #train# step  901, loss = 0.9995, cross_entropy loss = 0.9995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:36.898986 #train# step  902, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:38.435946 #train# step  903, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:40.022194 #train# step  904, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:41.571381 #train# step  905, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:43.112607 #train# step  906, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:44.666321 #train# step  907, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:46.247426 #train# step  908, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:47.783152 #train# step  909, loss = 0.9987, cross_entropy loss = 0.9987, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:49.291700 #train# step  910, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:50.819986 #train# step  911, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:52.365613 #train# step  912, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:53.895977 #train# step  913, loss = 0.9913, cross_entropy loss = 0.9913, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:55.470953 #train# step  914, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:57.019032 #train# step  915, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:58.582575 #train# step  916, loss = 0.9927, cross_entropy loss = 0.9927, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:00.148470 #train# step  917, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:01.716506 #train# step  918, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:03.281600 #train# step  919, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:04.809602 #train# step  920, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:06.350397 #train# step  921, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:07.918881 #train# step  922, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:09.479953 #train# step  923, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:11.032244 #train# step  924, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:12.595321 #train# step  925, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:14.172786 #train# step  926, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:15.707744 #train# step  927, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:17.281720 #train# step  928, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:18.852453 #train# step  929, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:20.437992 #train# step  930, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:21.951752 #train# step  931, loss = 0.9940, cross_entropy loss = 0.9940, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:23.544278 #train# step  932, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:25.094590 #train# step  933, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:26.647491 #train# step  934, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:28.188460 #train# step  935, loss = 1.0037, cross_entropy loss = 1.0037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:29.741156 #train# step  936, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:31.292193 #train# step  937, loss = 1.0065, cross_entropy loss = 1.0065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:32.836039 #train# step  938, loss = 1.0080, cross_entropy loss = 1.0080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:34.378006 #train# step  939, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:35.921152 #train# step  940, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:37.467964 #train# step  941, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:39.007617 #train# step  942, loss = 0.9935, cross_entropy loss = 0.9935, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:40.535965 #train# step  943, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:42.097451 #train# step  944, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:43.634802 #train# step  945, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:45.184420 #train# step  946, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:46.703942 #train# step  947, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:48.261716 #train# step  948, loss = 1.0032, cross_entropy loss = 1.0032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:49.797709 #train# step  949, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:51.346781 #train# step  950, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:52.872755 #train# step  951, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:54.436780 #train# step  952, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:55.975444 #train# step  953, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:57.511290 #train# step  954, loss = 0.9895, cross_entropy loss = 0.9895, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:59.078698 #train# step  955, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:00.605700 #train# step  956, loss = 0.9888, cross_entropy loss = 0.9888, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:02.166054 #train# step  957, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:03.718390 #train# step  958, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:05.267899 #train# step  959, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:06.829216 #train# step  960, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:08.390902 #train# step  961, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:09.968201 #train# step  962, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:11.505285 #train# step  963, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:13.034610 #train# step  964, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:14.585657 #train# step  965, loss = 0.9977, cross_entropy loss = 0.9977, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:16.156277 #train# step  966, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:17.742823 #train# step  967, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:19.295298 #train# step  968, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:20.862929 #train# step  969, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:22.423441 #train# step  970, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:23.968230 #train# step  971, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:25.553501 #train# step  972, loss = 0.9933, cross_entropy loss = 0.9933, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:27.080968 #train# step  973, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:28.887913 #train# step  974, loss = 0.9819, cross_entropy loss = 0.9819, 1.0 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:30.456607 #train# step  975, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:31.998128 #train# step  976, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:33.721273 #train# step  977, loss = 0.9857, cross_entropy loss = 0.9857, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:35.390440 #train# step  978, loss = 0.9962, cross_entropy loss = 0.9962, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:37.053540 #train# step  979, loss = 0.9854, cross_entropy loss = 0.9854, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:38.629641 #train# step  980, loss = 1.0111, cross_entropy loss = 1.0111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:40.188575 #train# step  981, loss = 1.0026, cross_entropy loss = 1.0026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:41.785889 #train# step  982, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:43.370842 #train# step  983, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:44.957987 #train# step  984, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:46.514968 #train# step  985, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:48.112312 #train# step  986, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:49.666271 #train# step  987, loss = 0.9863, cross_entropy loss = 0.9863, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:51.218552 #train# step  988, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:52.742069 #train# step  989, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:54.317302 #train# step  990, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:55.860352 #train# step  991, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:57.406309 #train# step  992, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:58.977595 #train# step  993, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:00.520971 #train# step  994, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:02.100434 #train# step  995, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:03.633958 #train# step  996, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:05.199651 #train# step  997, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:06.724654 #train# step  998, loss = 1.0126, cross_entropy loss = 1.0126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:08.254479 #train# step  999, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:09.790231 #train# step 1000, loss = 0.9795, cross_entropy loss = 0.9795, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:11.333910 #train# step 1001, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:12.854558 #train# step 1002, loss = 0.9928, cross_entropy loss = 0.9928, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:14.420491 #train# step 1003, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:15.942033 #train# step 1004, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:17.511874 #train# step 1005, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:19.040510 #train# step 1006, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:20.579474 #train# step 1007, loss = 1.0109, cross_entropy loss = 1.0109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:22.133092 #train# step 1008, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:23.693451 #train# step 1009, loss = 0.9824, cross_entropy loss = 0.9824, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:25.256901 #train# step 1010, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:26.840771 #train# step 1011, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:28.410838 #train# step 1012, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:29.943727 #train# step 1013, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:31.494441 #train# step 1014, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:33.050435 #train# step 1015, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:34.599744 #train# step 1016, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:36.144159 #train# step 1017, loss = 0.9961, cross_entropy loss = 0.9961, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:37.674670 #train# step 1018, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:39.243721 #train# step 1019, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:40.820270 #train# step 1020, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:42.367143 #train# step 1021, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:43.943914 #train# step 1022, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:45.486787 #train# step 1023, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:47.023696 #train# step 1024, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:48.618266 #train# step 1025, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:50.200529 #train# step 1026, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:51.771092 #train# step 1027, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:53.309009 #train# step 1028, loss = 0.9894, cross_entropy loss = 0.9894, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:54.851697 #train# step 1029, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:56.372994 #train# step 1030, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:57.897476 #train# step 1031, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:59.420408 #train# step 1032, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:01.014542 #train# step 1033, loss = 1.0001, cross_entropy loss = 1.0001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:02.538891 #train# step 1034, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:04.096842 #train# step 1035, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:05.656977 #train# step 1036, loss = 0.9820, cross_entropy loss = 0.9820, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:07.178254 #train# step 1037, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:08.702671 #train# step 1038, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:10.257496 #train# step 1039, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:11.820105 #train# step 1040, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:13.380176 #train# step 1041, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:14.947198 #train# step 1042, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:16.529998 #train# step 1043, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:18.069245 #train# step 1044, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:19.630305 #train# step 1045, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:21.180893 #train# step 1046, loss = 0.9820, cross_entropy loss = 0.9820, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:22.740781 #train# step 1047, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:24.320424 #train# step 1048, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:25.911653 #train# step 1049, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:27.438082 #train# step 1050, loss = 0.9897, cross_entropy loss = 0.9897, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:28.972014 #train# step 1051, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:30.543209 #train# step 1052, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:32.088585 #train# step 1053, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:33.614370 #train# step 1054, loss = 1.0006, cross_entropy loss = 1.0006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:35.178870 #train# step 1055, loss = 0.9890, cross_entropy loss = 0.9890, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:36.712446 #train# step 1056, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:38.256452 #train# step 1057, loss = 0.9881, cross_entropy loss = 0.9881, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:39.825683 #train# step 1058, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:41.371108 #train# step 1059, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:42.928698 #train# step 1060, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:44.478115 #train# step 1061, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:46.012641 #train# step 1062, loss = 0.9875, cross_entropy loss = 0.9875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:47.544028 #train# step 1063, loss = 0.9976, cross_entropy loss = 0.9976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:49.108731 #train# step 1064, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:50.657803 #train# step 1065, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:52.212911 #train# step 1066, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:53.749319 #train# step 1067, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:55.290934 #train# step 1068, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:56.871019 #train# step 1069, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:58.445834 #train# step 1070, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:59.995607 #train# step 1071, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:01.527623 #train# step 1072, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:03.072129 #train# step 1073, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:04.645792 #train# step 1074, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:06.198539 #train# step 1075, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:07.773999 #train# step 1076, loss = 0.9824, cross_entropy loss = 0.9824, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:09.342660 #train# step 1077, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:10.868753 #train# step 1078, loss = 0.9957, cross_entropy loss = 0.9957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:12.411244 #train# step 1079, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:13.942136 #train# step 1080, loss = 0.9877, cross_entropy loss = 0.9877, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:15.459670 #train# step 1081, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:16.990130 #train# step 1082, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:18.557705 #train# step 1083, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:20.083105 #train# step 1084, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:21.599353 #train# step 1085, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:23.159232 #train# step 1086, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:24.731481 #train# step 1087, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:26.276755 #train# step 1088, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:27.843739 #train# step 1089, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:29.394047 #train# step 1090, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:30.962184 #train# step 1091, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:32.520852 #train# step 1092, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:34.102230 #train# step 1093, loss = 0.9796, cross_entropy loss = 0.9796, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:35.659778 #train# step 1094, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:37.180430 #train# step 1095, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:38.732657 #train# step 1096, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:40.248273 #train# step 1097, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:41.789295 #train# step 1098, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:43.362675 #train# step 1099, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:44.909363 #train# step 1100, loss = 0.9660, cross_entropy loss = 0.9660, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:46.474990 #train# step 1101, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:48.014359 #train# step 1102, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:49.566332 #train# step 1103, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:51.087198 #train# step 1104, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:52.655051 #train# step 1105, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:54.198826 #train# step 1106, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:55.778346 #train# step 1107, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:57.309964 #train# step 1108, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:58.852813 #train# step 1109, loss = 0.9874, cross_entropy loss = 0.9874, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:00.414725 #train# step 1110, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:01.965773 #train# step 1111, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:03.506539 #train# step 1112, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:05.074097 #train# step 1113, loss = 0.9925, cross_entropy loss = 0.9925, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:06.641993 #train# step 1114, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:08.230395 #train# step 1115, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:09.763865 #train# step 1116, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:11.307963 #train# step 1117, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:12.965094 #train# step 1118, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:14.549532 #train# step 1119, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:16.119368 #train# step 1120, loss = 0.9974, cross_entropy loss = 0.9974, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:17.671276 #train# step 1121, loss = 0.9945, cross_entropy loss = 0.9945, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:19.227541 #train# step 1122, loss = 0.9885, cross_entropy loss = 0.9885, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:20.768110 #train# step 1123, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:22.312531 #train# step 1124, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:23.866705 #train# step 1125, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:25.433858 #train# step 1126, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:27.010984 #train# step 1127, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:28.552696 #train# step 1128, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:30.070067 #train# step 1129, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:31.647658 #train# step 1130, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:33.231805 #train# step 1131, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:34.762096 #train# step 1132, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:36.344287 #train# step 1133, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:37.885312 #train# step 1134, loss = 0.9934, cross_entropy loss = 0.9934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:39.416604 #train# step 1135, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:40.974024 #train# step 1136, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:42.512720 #train# step 1137, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:44.085190 #train# step 1138, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:45.609704 #train# step 1139, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:47.127227 #train# step 1140, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:48.689686 #train# step 1141, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:50.227048 #train# step 1142, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:51.818650 #train# step 1143, loss = 0.9865, cross_entropy loss = 0.9865, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:53.402049 #train# step 1144, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:54.969575 #train# step 1145, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:56.531515 #train# step 1146, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:58.109113 #train# step 1147, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:59.631984 #train# step 1148, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:01.166305 #train# step 1149, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:02.671828 #train# step 1150, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:04.209397 #train# step 1151, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:05.750175 #train# step 1152, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:07.311913 #train# step 1153, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:08.864333 #train# step 1154, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:10.424085 #train# step 1155, loss = 1.0074, cross_entropy loss = 1.0074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:12.007425 #train# step 1156, loss = 0.9875, cross_entropy loss = 0.9875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:13.585943 #train# step 1157, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:15.129207 #train# step 1158, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:16.665693 #train# step 1159, loss = 0.9957, cross_entropy loss = 0.9957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:18.229284 #train# step 1160, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:19.783070 #train# step 1161, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:21.378263 #train# step 1162, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:22.920488 #train# step 1163, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:24.453816 #train# step 1164, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:26.010772 #train# step 1165, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:27.544001 #train# step 1166, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:29.085372 #train# step 1167, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:30.624188 #train# step 1168, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:32.171540 #train# step 1169, loss = 1.0045, cross_entropy loss = 1.0045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:33.715441 #train# step 1170, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:35.269789 #train# step 1171, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:36.832682 #train# step 1172, loss = 0.9775, cross_entropy loss = 0.9775, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:38.333329 #train# step 1173, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:39.868135 #train# step 1174, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:41.424445 #train# step 1175, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:42.975487 #train# step 1176, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:44.528202 #train# step 1177, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:46.053655 #train# step 1178, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:47.587715 #train# step 1179, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:49.138715 #train# step 1180, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:50.711145 #train# step 1181, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:52.262398 #train# step 1182, loss = 0.9833, cross_entropy loss = 0.9833, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:53.831910 #train# step 1183, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:55.360446 #train# step 1184, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:56.903323 #train# step 1185, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:58.453254 #train# step 1186, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:59.998646 #train# step 1187, loss = 0.9990, cross_entropy loss = 0.9990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:01.548409 #train# step 1188, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:03.093564 #train# step 1189, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:04.638666 #train# step 1190, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:06.239516 #train# step 1191, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:07.831991 #train# step 1192, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:09.380174 #train# step 1193, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:10.909950 #train# step 1194, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:12.469824 #train# step 1195, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:14.011133 #train# step 1196, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:15.555574 #train# step 1197, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:17.129149 #train# step 1198, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:18.696901 #train# step 1199, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:20.251131 #train# step 1200, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:21.802081 #train# step 1201, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:23.342772 #train# step 1202, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:24.889146 #train# step 1203, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:26.435879 #train# step 1204, loss = 0.9765, cross_entropy loss = 0.9765, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:27.983512 #train# step 1205, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:29.542826 #train# step 1206, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:31.064422 #train# step 1207, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:32.612211 #train# step 1208, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:34.155843 #train# step 1209, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:35.688146 #train# step 1210, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:37.244200 #train# step 1211, loss = 0.9881, cross_entropy loss = 0.9881, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:38.785914 #train# step 1212, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:40.370345 #train# step 1213, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:41.887382 #train# step 1214, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:43.443412 #train# step 1215, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:44.969834 #train# step 1216, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:46.533096 #train# step 1217, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:48.103644 #train# step 1218, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:49.654107 #train# step 1219, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:51.204761 #train# step 1220, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:52.784297 #train# step 1221, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:54.355199 #train# step 1222, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:55.937270 #train# step 1223, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:57.487591 #train# step 1224, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:59.033059 #train# step 1225, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:00.587421 #train# step 1226, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:02.137693 #train# step 1227, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:03.675599 #train# step 1228, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:05.214761 #train# step 1229, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:06.745819 #train# step 1230, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:08.310373 #train# step 1231, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:09.823017 #train# step 1232, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:11.356285 #train# step 1233, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:12.884726 #train# step 1234, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:14.420367 #train# step 1235, loss = 0.9796, cross_entropy loss = 0.9796, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:15.974700 #train# step 1236, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:17.514231 #train# step 1237, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:19.066342 #train# step 1238, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:20.604616 #train# step 1239, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:22.165757 #train# step 1240, loss = 0.9875, cross_entropy loss = 0.9875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:23.708229 #train# step 1241, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:25.270557 #train# step 1242, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:26.838394 #train# step 1243, loss = 0.9918, cross_entropy loss = 0.9918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:28.382055 #train# step 1244, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:29.969880 #train# step 1245, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:31.573556 #train# step 1246, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:33.085063 #train# step 1247, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:34.667736 #train# step 1248, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:36.202927 #train# step 1249, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:37.811005 #train# step 1250, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:39.386020 #train# step 1251, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:40.941985 #train# step 1252, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:42.474734 #train# step 1253, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:44.040196 #train# step 1254, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:45.599715 #train# step 1255, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:47.165477 #train# step 1256, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:48.677713 #train# step 1257, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:50.201146 #train# step 1258, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:51.759777 #train# step 1259, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:53.308132 #train# step 1260, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:54.830636 #train# step 1261, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:56.435292 #train# step 1262, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:58.005088 #train# step 1263, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:59.581169 #train# step 1264, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:01.127135 #train# step 1265, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:02.671150 #train# step 1266, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:04.211619 #train# step 1267, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:05.748557 #train# step 1268, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:07.320587 #train# step 1269, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:08.872479 #train# step 1270, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:10.407306 #train# step 1271, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:11.948935 #train# step 1272, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:13.510413 #train# step 1273, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:15.050695 #train# step 1274, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:16.590198 #train# step 1275, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:18.156546 #train# step 1276, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:19.719984 #train# step 1277, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:21.240288 #train# step 1278, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:22.796452 #train# step 1279, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:24.380567 #train# step 1280, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:25.909221 #train# step 1281, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:27.484142 #train# step 1282, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:28.993599 #train# step 1283, loss = 0.9922, cross_entropy loss = 0.9922, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:30.534314 #train# step 1284, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:32.061147 #train# step 1285, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:33.612191 #train# step 1286, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:35.218940 #train# step 1287, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:36.766345 #train# step 1288, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:38.344557 #train# step 1289, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:39.891499 #train# step 1290, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:41.473877 #train# step 1291, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:43.023967 #train# step 1292, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:44.586302 #train# step 1293, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:46.141609 #train# step 1294, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:47.708277 #train# step 1295, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:49.274217 #train# step 1296, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:50.855003 #train# step 1297, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:52.387821 #train# step 1298, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:53.942130 #train# step 1299, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:55.491148 #train# step 1300, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:57.009987 #train# step 1301, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:58.573502 #train# step 1302, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:00.136178 #train# step 1303, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:01.708972 #train# step 1304, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:03.255011 #train# step 1305, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:04.791808 #train# step 1306, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:06.327723 #train# step 1307, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:07.868702 #train# step 1308, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:09.393534 #train# step 1309, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:10.912533 #train# step 1310, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:12.481720 #train# step 1311, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:14.022512 #train# step 1312, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:15.576156 #train# step 1313, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:17.122962 #train# step 1314, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:18.675661 #train# step 1315, loss = 1.0036, cross_entropy loss = 1.0036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:20.226258 #train# step 1316, loss = 0.9765, cross_entropy loss = 0.9765, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:21.792385 #train# step 1317, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:23.365330 #train# step 1318, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:24.940061 #train# step 1319, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:26.481916 #train# step 1320, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:28.031049 #train# step 1321, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:29.596628 #train# step 1322, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:31.159178 #train# step 1323, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:32.709754 #train# step 1324, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:34.255473 #train# step 1325, loss = 0.9903, cross_entropy loss = 0.9903, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:35.826119 #train# step 1326, loss = 0.9813, cross_entropy loss = 0.9813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:37.441308 #train# step 1327, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:38.990540 #train# step 1328, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:40.556834 #train# step 1329, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:42.116806 #train# step 1330, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:43.664417 #train# step 1331, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:45.209584 #train# step 1332, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:46.762674 #train# step 1333, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:48.305430 #train# step 1334, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:49.843545 #train# step 1335, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:51.415799 #train# step 1336, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:52.946211 #train# step 1337, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:54.495898 #train# step 1338, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:56.023781 #train# step 1339, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:57.586844 #train# step 1340, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:59.125605 #train# step 1341, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:00.666015 #train# step 1342, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:02.211570 #train# step 1343, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:03.757399 #train# step 1344, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:05.292272 #train# step 1345, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:06.825501 #train# step 1346, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:08.369332 #train# step 1347, loss = 1.0103, cross_entropy loss = 1.0103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:09.925710 #train# step 1348, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:11.476164 #train# step 1349, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:13.025358 #train# step 1350, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:14.603447 #train# step 1351, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:16.147897 #train# step 1352, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:17.690267 #train# step 1353, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:19.269317 #train# step 1354, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:20.840839 #train# step 1355, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:22.431348 #train# step 1356, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:23.998038 #train# step 1357, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:25.520632 #train# step 1358, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:27.072384 #train# step 1359, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:28.597558 #train# step 1360, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:30.145545 #train# step 1361, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:31.706931 #train# step 1362, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:33.253361 #train# step 1363, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:34.808068 #train# step 1364, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:36.356976 #train# step 1365, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:37.887062 #train# step 1366, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:39.447088 #train# step 1367, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:40.970077 #train# step 1368, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:42.514440 #train# step 1369, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:44.101533 #train# step 1370, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:45.681642 #train# step 1371, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:47.193820 #train# step 1372, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:48.741300 #train# step 1373, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:50.272927 #train# step 1374, loss = 0.9946, cross_entropy loss = 0.9946, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:51.857505 #train# step 1375, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:53.395564 #train# step 1376, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:54.948011 #train# step 1377, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:56.488323 #train# step 1378, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:58.042651 #train# step 1379, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:59.605738 #train# step 1380, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:01.182041 #train# step 1381, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:02.783144 #train# step 1382, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:04.317072 #train# step 1383, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:05.879327 #train# step 1384, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:07.413432 #train# step 1385, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:08.973017 #train# step 1386, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:10.523938 #train# step 1387, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:12.078197 #train# step 1388, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:13.654831 #train# step 1389, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:15.192002 #train# step 1390, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:16.812689 #train# step 1391, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:18.376611 #train# step 1392, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:19.906600 #train# step 1393, loss = 0.9895, cross_entropy loss = 0.9895, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:21.471603 #train# step 1394, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:23.033102 #train# step 1395, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:24.580195 #train# step 1396, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:26.143875 #train# step 1397, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:27.710323 #train# step 1398, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:29.229177 #train# step 1399, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:30.768129 #train# step 1400, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:32.334429 #train# step 1401, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:33.877091 #train# step 1402, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:35.409292 #train# step 1403, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:36.940825 #train# step 1404, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:38.476092 #train# step 1405, loss = 0.9920, cross_entropy loss = 0.9920, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:40.049156 #train# step 1406, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:41.588937 #train# step 1407, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:43.150825 #train# step 1408, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:44.682351 #train# step 1409, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:46.228190 #train# step 1410, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:47.763632 #train# step 1411, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:49.310681 #train# step 1412, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:50.865789 #train# step 1413, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:52.418810 #train# step 1414, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:53.962736 #train# step 1415, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:55.529005 #train# step 1416, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:57.076144 #train# step 1417, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:58.613564 #train# step 1418, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:00.173433 #train# step 1419, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:01.731842 #train# step 1420, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:03.311158 #train# step 1421, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:04.862211 #train# step 1422, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:06.418809 #train# step 1423, loss = 0.9748, cross_entropy loss = 0.9748, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:07.983963 #train# step 1424, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:09.558320 #train# step 1425, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:11.134033 #train# step 1426, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:12.675774 #train# step 1427, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:14.219971 #train# step 1428, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:15.749133 #train# step 1429, loss = 0.9881, cross_entropy loss = 0.9881, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:17.316713 #train# step 1430, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:18.870612 #train# step 1431, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:20.451780 #train# step 1432, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:21.993644 #train# step 1433, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:23.543732 #train# step 1434, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:25.089661 #train# step 1435, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:26.640980 #train# step 1436, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:28.201455 #train# step 1437, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:29.770068 #train# step 1438, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:31.321330 #train# step 1439, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:32.861858 #train# step 1440, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:34.394260 #train# step 1441, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:35.954231 #train# step 1442, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:37.518050 #train# step 1443, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:39.097491 #train# step 1444, loss = 0.9660, cross_entropy loss = 0.9660, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:40.647574 #train# step 1445, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:42.187403 #train# step 1446, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:43.715688 #train# step 1447, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:45.245407 #train# step 1448, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:46.792606 #train# step 1449, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:48.383394 #train# step 1450, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:49.921063 #train# step 1451, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:51.460285 #train# step 1452, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:53.000854 #train# step 1453, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:54.583631 #train# step 1454, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:56.162264 #train# step 1455, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:57.704727 #train# step 1456, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:59.271144 #train# step 1457, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:00.835575 #train# step 1458, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:02.353848 #train# step 1459, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:03.879478 #train# step 1460, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:05.420895 #train# step 1461, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:06.986402 #train# step 1462, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:08.552944 #train# step 1463, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:10.100563 #train# step 1464, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:11.655227 #train# step 1465, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:13.211848 #train# step 1466, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:14.789816 #train# step 1467, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:16.332570 #train# step 1468, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:17.860368 #train# step 1469, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:19.480361 #train# step 1470, loss = 0.9697, cross_entropy loss = 0.9697, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:21.050409 #train# step 1471, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:22.592267 #train# step 1472, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:24.143822 #train# step 1473, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:25.672723 #train# step 1474, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:27.237348 #train# step 1475, loss = 0.9796, cross_entropy loss = 0.9796, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:28.782116 #train# step 1476, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:30.345471 #train# step 1477, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:31.895210 #train# step 1478, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:33.486807 #train# step 1479, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:35.031542 #train# step 1480, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:36.605970 #train# step 1481, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:38.151941 #train# step 1482, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:39.711681 #train# step 1483, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:41.221923 #train# step 1484, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:42.779273 #train# step 1485, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:44.327935 #train# step 1486, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:45.897519 #train# step 1487, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:47.464034 #train# step 1488, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:49.023817 #train# step 1489, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:50.562547 #train# step 1490, loss = 0.9845, cross_entropy loss = 0.9845, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:52.102516 #train# step 1491, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:53.645441 #train# step 1492, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:55.191106 #train# step 1493, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:56.773203 #train# step 1494, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:58.321372 #train# step 1495, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:59.855768 #train# step 1496, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:01.387950 #train# step 1497, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:02.932090 #train# step 1498, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:04.487402 #train# step 1499, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:06.032450 #train# step 1500, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:07.580592 #train# step 1501, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:09.128012 #train# step 1502, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:10.653035 #train# step 1503, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:12.238530 #train# step 1504, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:13.810549 #train# step 1505, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:15.355301 #train# step 1506, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:16.937862 #train# step 1507, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:18.478446 #train# step 1508, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:20.062038 #train# step 1509, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:21.627757 #train# step 1510, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:23.170889 #train# step 1511, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:24.719762 #train# step 1512, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:26.260506 #train# step 1513, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:27.809689 #train# step 1514, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:29.366618 #train# step 1515, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:30.924128 #train# step 1516, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:32.479906 #train# step 1517, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:34.038746 #train# step 1518, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:35.582096 #train# step 1519, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:37.134525 #train# step 1520, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:38.665694 #train# step 1521, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:40.205910 #train# step 1522, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:41.762842 #train# step 1523, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:43.312029 #train# step 1524, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:44.856397 #train# step 1525, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:46.397222 #train# step 1526, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:47.972374 #train# step 1527, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:49.510724 #train# step 1528, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:51.070573 #train# step 1529, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:52.611173 #train# step 1530, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:54.147795 #train# step 1531, loss = 0.9909, cross_entropy loss = 0.9909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:55.675536 #train# step 1532, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:57.216960 #train# step 1533, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:58.808392 #train# step 1534, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:00.351323 #train# step 1535, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:01.910474 #train# step 1536, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:03.477872 #train# step 1537, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:05.057462 #train# step 1538, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:06.605091 #train# step 1539, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:08.144451 #train# step 1540, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:09.707624 #train# step 1541, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:11.276727 #train# step 1542, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:12.853677 #train# step 1543, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:14.394689 #train# step 1544, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:15.940212 #train# step 1545, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:17.499289 #train# step 1546, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:19.076240 #train# step 1547, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:20.651688 #train# step 1548, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:22.213997 #train# step 1549, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:23.743598 #train# step 1550, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:25.300136 #train# step 1551, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:26.863362 #train# step 1552, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:28.422991 #train# step 1553, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:29.995304 #train# step 1554, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:31.557262 #train# step 1555, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:33.125123 #train# step 1556, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:34.665606 #train# step 1557, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:36.247207 #train# step 1558, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:37.826277 #train# step 1559, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:39.395098 #train# step 1560, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:40.935855 #train# step 1561, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:42.456351 #train# step 1562, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:44.039327 #train# step 1563, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:45.559855 #train# step 1564, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:47.091435 #train# step 1565, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:48.616269 #train# step 1566, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:50.151084 #train# step 1567, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:51.683975 #train# step 1568, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:53.265170 #train# step 1569, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:54.805307 #train# step 1570, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:56.336074 #train# step 1571, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:57.915660 #train# step 1572, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:59.459676 #train# step 1573, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:01.018019 #train# step 1574, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:02.571981 #train# step 1575, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:04.133811 #train# step 1576, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:05.696941 #train# step 1577, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:07.261741 #train# step 1578, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:08.853862 #train# step 1579, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:10.393158 #train# step 1580, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:11.943196 #train# step 1581, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:13.519318 #train# step 1582, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:15.064105 #train# step 1583, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:16.610787 #train# step 1584, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:18.144635 #train# step 1585, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:19.701403 #train# step 1586, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:21.259588 #train# step 1587, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:22.814904 #train# step 1588, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:24.336191 #train# step 1589, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:25.854726 #train# step 1590, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:27.451900 #train# step 1591, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:28.997610 #train# step 1592, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:30.551183 #train# step 1593, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:32.103341 #train# step 1594, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:33.650045 #train# step 1595, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:35.204142 #train# step 1596, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:36.797263 #train# step 1597, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:38.357486 #train# step 1598, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:39.917293 #train# step 1599, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:41.454709 #train# step 1600, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:43.004044 #train# step 1601, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:44.574999 #train# step 1602, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:46.122437 #train# step 1603, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:47.699187 #train# step 1604, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:49.275890 #train# step 1605, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:50.796741 #train# step 1606, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:52.323353 #train# step 1607, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:53.857651 #train# step 1608, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:55.421910 #train# step 1609, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:56.967708 #train# step 1610, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:58.536895 #train# step 1611, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:00.080858 #train# step 1612, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:01.642325 #train# step 1613, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:03.219610 #train# step 1614, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:04.780730 #train# step 1615, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:06.337190 #train# step 1616, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:07.870155 #train# step 1617, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:09.408348 #train# step 1618, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:10.951744 #train# step 1619, loss = 0.9885, cross_entropy loss = 0.9885, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:12.518729 #train# step 1620, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:14.056977 #train# step 1621, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:15.599867 #train# step 1622, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:17.188646 #train# step 1623, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:18.726525 #train# step 1624, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:20.291862 #train# step 1625, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:21.895042 #train# step 1626, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:23.459659 #train# step 1627, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:25.012461 #train# step 1628, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:26.574625 #train# step 1629, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:28.102931 #train# step 1630, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:29.654461 #train# step 1631, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:31.238859 #train# step 1632, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:32.785259 #train# step 1633, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:34.352674 #train# step 1634, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:35.927562 #train# step 1635, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:37.477612 #train# step 1636, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:39.035584 #train# step 1637, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:40.583053 #train# step 1638, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:42.118705 #train# step 1639, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:43.669091 #train# step 1640, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:45.229615 #train# step 1641, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:46.773066 #train# step 1642, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:48.363400 #train# step 1643, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:49.930111 #train# step 1644, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:51.478714 #train# step 1645, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:53.066640 #train# step 1646, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:54.641649 #train# step 1647, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:56.194860 #train# step 1648, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:57.752619 #train# step 1649, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:59.291358 #train# step 1650, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:00.842143 #train# step 1651, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:02.391365 #train# step 1652, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:03.932002 #train# step 1653, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:05.512783 #train# step 1654, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:07.032212 #train# step 1655, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:08.595111 #train# step 1656, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:10.187237 #train# step 1657, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:11.783660 #train# step 1658, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:13.318715 #train# step 1659, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:14.849781 #train# step 1660, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:16.400878 #train# step 1661, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:17.942657 #train# step 1662, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:19.468265 #train# step 1663, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:21.017519 #train# step 1664, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:22.583069 #train# step 1665, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:24.125217 #train# step 1666, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:25.667850 #train# step 1667, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:27.203042 #train# step 1668, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:28.760638 #train# step 1669, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:30.326576 #train# step 1670, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:31.861645 #train# step 1671, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:33.449995 #train# step 1672, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:34.998684 #train# step 1673, loss = 0.9777, cross_entropy loss = 0.9777, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:36.605517 #train# step 1674, loss = 0.9666, cross_entropy loss = 0.9666, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:38.333806 #train# step 1675, loss = 0.9660, cross_entropy loss = 0.9660, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:39.960371 #train# step 1676, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:41.561722 #train# step 1677, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:43.136481 #train# step 1678, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:44.644054 #train# step 1679, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:46.218936 #train# step 1680, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:47.781455 #train# step 1681, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:49.324096 #train# step 1682, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:50.906524 #train# step 1683, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:52.454179 #train# step 1684, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:53.983018 #train# step 1685, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:55.537193 #train# step 1686, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:57.080617 #train# step 1687, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:58.634902 #train# step 1688, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:00.197792 #train# step 1689, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:01.743136 #train# step 1690, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:03.362562 #train# step 1691, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:04.916899 #train# step 1692, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:06.492940 #train# step 1693, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:08.073059 #train# step 1694, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:09.645290 #train# step 1695, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:11.191374 #train# step 1696, loss = 0.9833, cross_entropy loss = 0.9833, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:12.793960 #train# step 1697, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:14.325918 #train# step 1698, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:15.905273 #train# step 1699, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:17.505061 #train# step 1700, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:19.097317 #train# step 1701, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:20.709253 #train# step 1702, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:22.268618 #train# step 1703, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:23.867640 #train# step 1704, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:25.466909 #train# step 1705, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:27.028217 #train# step 1706, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:28.567913 #train# step 1707, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:30.122332 #train# step 1708, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:31.715997 #train# step 1709, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:33.272213 #train# step 1710, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:34.815685 #train# step 1711, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:36.366491 #train# step 1712, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:37.898548 #train# step 1713, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:39.470506 #train# step 1714, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:41.041595 #train# step 1715, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:42.587109 #train# step 1716, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:44.153571 #train# step 1717, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:45.716201 #train# step 1718, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:47.235615 #train# step 1719, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:48.808827 #train# step 1720, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:50.343288 #train# step 1721, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:51.888613 #train# step 1722, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:53.453272 #train# step 1723, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:55.011793 #train# step 1724, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:56.548117 #train# step 1725, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:58.115980 #train# step 1726, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:59.662054 #train# step 1727, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:01.219795 #train# step 1728, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:02.755672 #train# step 1729, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:04.298407 #train# step 1730, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:05.808150 #train# step 1731, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:07.396212 #train# step 1732, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:08.939516 #train# step 1733, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:10.499648 #train# step 1734, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:12.039388 #train# step 1735, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:13.572284 #train# step 1736, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:15.076150 #train# step 1737, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:16.621489 #train# step 1738, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:18.188572 #train# step 1739, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:19.769068 #train# step 1740, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:21.330114 #train# step 1741, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:22.865004 #train# step 1742, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:24.410204 #train# step 1743, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:25.974886 #train# step 1744, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:27.497447 #train# step 1745, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:29.078228 #train# step 1746, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:30.610143 #train# step 1747, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:32.129262 #train# step 1748, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:33.695853 #train# step 1749, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:35.248854 #train# step 1750, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:36.778821 #train# step 1751, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:38.352118 #train# step 1752, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:39.909940 #train# step 1753, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:41.444828 #train# step 1754, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:43.027296 #train# step 1755, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:44.572046 #train# step 1756, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:46.161422 #train# step 1757, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:47.707453 #train# step 1758, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:49.282264 #train# step 1759, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:50.809909 #train# step 1760, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:52.389561 #train# step 1761, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:53.926239 #train# step 1762, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:55.466086 #train# step 1763, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:57.048850 #train# step 1764, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:58.602064 #train# step 1765, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:00.141346 #train# step 1766, loss = 0.9817, cross_entropy loss = 0.9817, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:01.732278 #train# step 1767, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:03.287998 #train# step 1768, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:04.828856 #train# step 1769, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:06.374996 #train# step 1770, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:07.918360 #train# step 1771, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:09.515090 #train# step 1772, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:11.065413 #train# step 1773, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:12.626855 #train# step 1774, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:14.151548 #train# step 1775, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:15.693338 #train# step 1776, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:17.223998 #train# step 1777, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:18.786445 #train# step 1778, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:20.338520 #train# step 1779, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:21.898112 #train# step 1780, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:23.463484 #train# step 1781, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:25.023478 #train# step 1782, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:26.563679 #train# step 1783, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:28.115804 #train# step 1784, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:29.683136 #train# step 1785, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:31.243703 #train# step 1786, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:32.797833 #train# step 1787, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:34.346762 #train# step 1788, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:35.910312 #train# step 1789, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:37.452040 #train# step 1790, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:39.015960 #train# step 1791, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:40.585732 #train# step 1792, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:42.154616 #train# step 1793, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:43.718565 #train# step 1794, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:45.296129 #train# step 1795, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:46.829371 #train# step 1796, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:48.377733 #train# step 1797, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:49.939650 #train# step 1798, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:51.486840 #train# step 1799, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:53.026795 #train# step 1800, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:54.623824 #train# step 1801, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:56.174629 #train# step 1802, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:57.728877 #train# step 1803, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:59.300717 #train# step 1804, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:00.867735 #train# step 1805, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:02.386023 #train# step 1806, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:03.958265 #train# step 1807, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:05.507369 #train# step 1808, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:07.045495 #train# step 1809, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:08.583041 #train# step 1810, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:10.142430 #train# step 1811, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:11.681302 #train# step 1812, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:13.237864 #train# step 1813, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:14.791100 #train# step 1814, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:16.340732 #train# step 1815, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:17.922033 #train# step 1816, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:19.473047 #train# step 1817, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:21.006485 #train# step 1818, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:22.550201 #train# step 1819, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:24.101691 #train# step 1820, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:25.692602 #train# step 1821, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:27.240749 #train# step 1822, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:28.770695 #train# step 1823, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:30.338526 #train# step 1824, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:31.909954 #train# step 1825, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:33.470044 #train# step 1826, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:35.024219 #train# step 1827, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:36.560582 #train# step 1828, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:38.127706 #train# step 1829, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:39.712374 #train# step 1830, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:41.254456 #train# step 1831, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:42.811319 #train# step 1832, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:44.344240 #train# step 1833, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:45.911145 #train# step 1834, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:47.483834 #train# step 1835, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:49.059468 #train# step 1836, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:50.624045 #train# step 1837, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:52.165266 #train# step 1838, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:53.736307 #train# step 1839, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:55.312206 #train# step 1840, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:56.860937 #train# step 1841, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:58.418358 #train# step 1842, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:59.944064 #train# step 1843, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:01.503602 #train# step 1844, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:03.046443 #train# step 1845, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:04.603902 #train# step 1846, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:06.155692 #train# step 1847, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:07.710999 #train# step 1848, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:09.264498 #train# step 1849, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:10.822969 #train# step 1850, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:12.366555 #train# step 1851, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:13.924395 #train# step 1852, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:15.473838 #train# step 1853, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:17.074884 #train# step 1854, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:18.621289 #train# step 1855, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:20.150750 #train# step 1856, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:21.723274 #train# step 1857, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:23.280036 #train# step 1858, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:24.850107 #train# step 1859, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:26.392461 #train# step 1860, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:27.947920 #train# step 1861, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:29.501467 #train# step 1862, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:31.058138 #train# step 1863, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:32.611096 #train# step 1864, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:34.161649 #train# step 1865, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:35.713784 #train# step 1866, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:37.259704 #train# step 1867, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:38.837550 #train# step 1868, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:40.379930 #train# step 1869, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:41.901980 #train# step 1870, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:43.468043 #train# step 1871, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:45.012718 #train# step 1872, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:46.591627 #train# step 1873, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:48.205687 #train# step 1874, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:49.746352 #train# step 1875, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:51.372123 #train# step 1876, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:52.932181 #train# step 1877, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:54.482680 #train# step 1878, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:56.026318 #train# step 1879, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:57.577615 #train# step 1880, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:59.202658 #train# step 1881, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:00.750305 #train# step 1882, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:02.310548 #train# step 1883, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:03.909450 #train# step 1884, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:05.476366 #train# step 1885, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:07.076477 #train# step 1886, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:08.686807 #train# step 1887, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:10.278220 #train# step 1888, loss = 0.9827, cross_entropy loss = 0.9827, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:11.876784 #train# step 1889, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:13.415120 #train# step 1890, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:14.965403 #train# step 1891, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:16.542827 #train# step 1892, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:18.079622 #train# step 1893, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:19.642826 #train# step 1894, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:21.228257 #train# step 1895, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:22.807351 #train# step 1896, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:24.390715 #train# step 1897, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:25.926225 #train# step 1898, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:27.502512 #train# step 1899, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:29.052590 #train# step 1900, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:30.640040 #train# step 1901, loss = 0.9697, cross_entropy loss = 0.9697, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:32.216809 #train# step 1902, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:33.847537 #train# step 1903, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:35.410065 #train# step 1904, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:36.961879 #train# step 1905, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:38.528528 #train# step 1906, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:40.095463 #train# step 1907, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:41.660067 #train# step 1908, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:43.204092 #train# step 1909, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:44.736733 #train# step 1910, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:46.328748 #train# step 1911, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:47.918069 #train# step 1912, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:49.482665 #train# step 1913, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:51.058372 #train# step 1914, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:52.629635 #train# step 1915, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:54.143245 #train# step 1916, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:55.694672 #train# step 1917, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:57.214107 #train# step 1918, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:58.774828 #train# step 1919, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:00.413279 #train# step 1920, loss = 0.9787, cross_entropy loss = 0.9787, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:02.024810 #train# step 1921, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:03.608151 #train# step 1922, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:05.187321 #train# step 1923, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:06.759568 #train# step 1924, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:08.513200 #train# step 1925, loss = 0.9622, cross_entropy loss = 0.9622, 1.0 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:10.276749 #train# step 1926, loss = 0.9719, cross_entropy loss = 0.9719, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:11.972863 #train# step 1927, loss = 0.9648, cross_entropy loss = 0.9648, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:13.562235 #train# step 1928, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:15.255428 #train# step 1929, loss = 0.9646, cross_entropy loss = 0.9646, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:16.890571 #train# step 1930, loss = 0.9553, cross_entropy loss = 0.9553, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:18.536877 #train# step 1931, loss = 0.9513, cross_entropy loss = 0.9513, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:20.229668 #train# step 1932, loss = 0.9768, cross_entropy loss = 0.9768, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:21.892693 #train# step 1933, loss = 0.9591, cross_entropy loss = 0.9591, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:23.635792 #train# step 1934, loss = 0.9538, cross_entropy loss = 0.9538, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:25.401631 #train# step 1935, loss = 0.9523, cross_entropy loss = 0.9523, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:27.076145 #train# step 1936, loss = 0.9513, cross_entropy loss = 0.9513, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:28.816432 #train# step 1937, loss = 0.9660, cross_entropy loss = 0.9660, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:30.448508 #train# step 1938, loss = 0.9821, cross_entropy loss = 0.9821, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:32.081227 #train# step 1939, loss = 0.9452, cross_entropy loss = 0.9452, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:33.683866 #train# step 1940, loss = 0.9705, cross_entropy loss = 0.9705, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:35.321183 #train# step 1941, loss = 0.9566, cross_entropy loss = 0.9566, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:36.921972 #train# step 1942, loss = 0.9765, cross_entropy loss = 0.9765, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:38.582844 #train# step 1943, loss = 0.9693, cross_entropy loss = 0.9693, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:40.245751 #train# step 1944, loss = 0.9623, cross_entropy loss = 0.9623, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:41.849809 #train# step 1945, loss = 0.9645, cross_entropy loss = 0.9645, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:43.480276 #train# step 1946, loss = 0.9833, cross_entropy loss = 0.9833, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:45.090181 #train# step 1947, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:46.757142 #train# step 1948, loss = 0.9593, cross_entropy loss = 0.9593, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:48.505870 #train# step 1949, loss = 0.9589, cross_entropy loss = 0.9589, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:50.136785 #train# step 1950, loss = 0.9600, cross_entropy loss = 0.9600, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:51.731562 #train# step 1951, loss = 0.9600, cross_entropy loss = 0.9600, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:53.358602 #train# step 1952, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:55.011672 #train# step 1953, loss = 0.9655, cross_entropy loss = 0.9655, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:56.604212 #train# step 1954, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:58.209594 #train# step 1955, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:59.796815 #train# step 1956, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:01.372262 #train# step 1957, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:03.010506 #train# step 1958, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:04.678487 #train# step 1959, loss = 0.9573, cross_entropy loss = 0.9573, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:06.315598 #train# step 1960, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:07.894593 #train# step 1961, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:09.521305 #train# step 1962, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:11.171272 #train# step 1963, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:12.734535 #train# step 1964, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:14.298104 #train# step 1965, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:15.913108 #train# step 1966, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:17.528667 #train# step 1967, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:19.103328 #train# step 1968, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:20.652852 #train# step 1969, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:22.243536 #train# step 1970, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:23.815407 #train# step 1971, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:25.428394 #train# step 1972, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:27.006864 #train# step 1973, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:28.655891 #train# step 1974, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:30.284463 #train# step 1975, loss = 0.9474, cross_entropy loss = 0.9474, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:31.916322 #train# step 1976, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:33.574341 #train# step 1977, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:35.147902 #train# step 1978, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:36.724975 #train# step 1979, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:38.316472 #train# step 1980, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:39.900124 #train# step 1981, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:41.486138 #train# step 1982, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:43.037985 #train# step 1983, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:44.643996 #train# step 1984, loss = 0.9635, cross_entropy loss = 0.9635, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:46.227006 #train# step 1985, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:47.839636 #train# step 1986, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:49.388812 #train# step 1987, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:51.055426 #train# step 1988, loss = 0.9640, cross_entropy loss = 0.9640, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:52.640027 #train# step 1989, loss = 0.9637, cross_entropy loss = 0.9637, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:54.204560 #train# step 1990, loss = 0.9664, cross_entropy loss = 0.9664, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:55.839631 #train# step 1991, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:57.449073 #train# step 1992, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:59.091757 #train# step 1993, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:00.755479 #train# step 1994, loss = 0.9682, cross_entropy loss = 0.9682, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:02.392734 #train# step 1995, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:04.036165 #train# step 1996, loss = 0.9430, cross_entropy loss = 0.9430, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:05.660295 #train# step 1997, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:07.298700 #train# step 1998, loss = 0.9715, cross_entropy loss = 0.9715, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:08.995724 #train# step 1999, loss = 0.9537, cross_entropy loss = 0.9537, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:10.688675 #train# step 2000, loss = 0.9617, cross_entropy loss = 0.9617, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:12.311425 #train# step 2001, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:14.082164 #train# step 2002, loss = 0.9502, cross_entropy loss = 0.9502, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:15.709828 #train# step 2003, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:17.299211 #train# step 2004, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:18.898068 #train# step 2005, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:20.447556 #train# step 2006, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:22.020426 #train# step 2007, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:23.702851 #train# step 2008, loss = 0.9459, cross_entropy loss = 0.9459, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:25.220324 #train# step 2009, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:26.852776 #train# step 2010, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:28.413395 #train# step 2011, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:30.005474 #train# step 2012, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:31.623344 #train# step 2013, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:33.209925 #train# step 2014, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:34.779209 #train# step 2015, loss = 0.9797, cross_entropy loss = 0.9797, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:36.383852 #train# step 2016, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:37.984246 #train# step 2017, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:39.561621 #train# step 2018, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:41.165240 #train# step 2019, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:42.682190 #train# step 2020, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:44.195979 #train# step 2021, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:45.848294 #train# step 2022, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:47.490383 #train# step 2023, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:49.086670 #train# step 2024, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:50.682775 #train# step 2025, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:52.237323 #train# step 2026, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:53.831409 #train# step 2027, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:55.409300 #train# step 2028, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:56.960153 #train# step 2029, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:58.548095 #train# step 2030, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:00.078281 #train# step 2031, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:01.658876 #train# step 2032, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:03.233763 #train# step 2033, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:04.780108 #train# step 2034, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:06.361657 #train# step 2035, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:07.922624 #train# step 2036, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:09.466808 #train# step 2037, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:10.988226 #train# step 2038, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:12.516959 #train# step 2039, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:14.034253 #train# step 2040, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:15.573904 #train# step 2041, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:17.116239 #train# step 2042, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:18.674601 #train# step 2043, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:20.250518 #train# step 2044, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:21.834852 #train# step 2045, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:23.369858 #train# step 2046, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:24.942528 #train# step 2047, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:26.495658 #train# step 2048, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:28.064491 #train# step 2049, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:29.614090 #train# step 2050, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:31.169075 #train# step 2051, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:32.720701 #train# step 2052, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:34.252459 #train# step 2053, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:35.797438 #train# step 2054, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:37.374641 #train# step 2055, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:38.913172 #train# step 2056, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:40.433473 #train# step 2057, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:41.974526 #train# step 2058, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:43.502181 #train# step 2059, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:45.031485 #train# step 2060, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:46.551160 #train# step 2061, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:48.076348 #train# step 2062, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:49.656831 #train# step 2063, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:51.238581 #train# step 2064, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:52.768612 #train# step 2065, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:54.312040 #train# step 2066, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:55.863525 #train# step 2067, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:57.428201 #train# step 2068, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:58.951388 #train# step 2069, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:00.486713 #train# step 2070, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:02.038539 #train# step 2071, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:03.536719 #train# step 2072, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:05.043745 #train# step 2073, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:06.571857 #train# step 2074, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:08.147177 #train# step 2075, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:09.668312 #train# step 2076, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:11.229936 #train# step 2077, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:12.789782 #train# step 2078, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:14.339721 #train# step 2079, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:15.889448 #train# step 2080, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:17.447737 #train# step 2081, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:19.011156 #train# step 2082, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:20.549794 #train# step 2083, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:22.089036 #train# step 2084, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:23.640927 #train# step 2085, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:25.189471 #train# step 2086, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:26.754614 #train# step 2087, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:28.289961 #train# step 2088, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:29.835228 #train# step 2089, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:31.374515 #train# step 2090, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:32.933720 #train# step 2091, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:34.508471 #train# step 2092, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:36.061937 #train# step 2093, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:37.607279 #train# step 2094, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:39.193620 #train# step 2095, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:40.746792 #train# step 2096, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:42.279749 #train# step 2097, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:43.815824 #train# step 2098, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:45.379645 #train# step 2099, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:46.899616 #train# step 2100, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:48.467651 #train# step 2101, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:50.038684 #train# step 2102, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:51.588740 #train# step 2103, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:53.173964 #train# step 2104, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:54.755225 #train# step 2105, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:56.308152 #train# step 2106, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:57.824617 #train# step 2107, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:59.357918 #train# step 2108, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:00.922129 #train# step 2109, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:02.468498 #train# step 2110, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:04.008212 #train# step 2111, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:05.574278 #train# step 2112, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:07.095949 #train# step 2113, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:08.640436 #train# step 2114, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:10.207094 #train# step 2115, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:11.759822 #train# step 2116, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:13.322016 #train# step 2117, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:14.880517 #train# step 2118, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:16.443808 #train# step 2119, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:17.990433 #train# step 2120, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:19.540267 #train# step 2121, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:21.106896 #train# step 2122, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:22.656079 #train# step 2123, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:24.228992 #train# step 2124, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:25.785445 #train# step 2125, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:27.330043 #train# step 2126, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:28.854164 #train# step 2127, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:30.380194 #train# step 2128, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:31.931324 #train# step 2129, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:33.477343 #train# step 2130, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:35.017911 #train# step 2131, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:36.593857 #train# step 2132, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:38.137384 #train# step 2133, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:39.686550 #train# step 2134, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:41.236467 #train# step 2135, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:42.769822 #train# step 2136, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:44.347325 #train# step 2137, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:45.879935 #train# step 2138, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:47.428437 #train# step 2139, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:48.961965 #train# step 2140, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:50.514678 #train# step 2141, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:52.112586 #train# step 2142, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:53.662231 #train# step 2143, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:55.217864 #train# step 2144, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:56.736223 #train# step 2145, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:58.288848 #train# step 2146, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:59.863366 #train# step 2147, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:01.437967 #train# step 2148, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:02.962750 #train# step 2149, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:04.515055 #train# step 2150, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:06.060934 #train# step 2151, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:07.594331 #train# step 2152, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:09.103431 #train# step 2153, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:10.678440 #train# step 2154, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:12.212531 #train# step 2155, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:13.750104 #train# step 2156, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:15.285750 #train# step 2157, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:16.844082 #train# step 2158, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:18.398959 #train# step 2159, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:20.041075 #train# step 2160, loss = 0.9550, cross_entropy loss = 0.9550, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:21.646695 #train# step 2161, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:23.216387 #train# step 2162, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:24.785242 #train# step 2163, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:26.327618 #train# step 2164, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:27.876713 #train# step 2165, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:29.413186 #train# step 2166, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:30.991329 #train# step 2167, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:32.523891 #train# step 2168, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:34.044157 #train# step 2169, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:35.611363 #train# step 2170, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:37.222994 #train# step 2171, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:38.749482 #train# step 2172, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:40.368539 #train# step 2173, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:41.933835 #train# step 2174, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:43.514147 #train# step 2175, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:45.078302 #train# step 2176, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:46.611474 #train# step 2177, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:48.179092 #train# step 2178, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:49.730958 #train# step 2179, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:51.313489 #train# step 2180, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:52.818571 #train# step 2181, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:54.353401 #train# step 2182, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:55.915371 #train# step 2183, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:57.449726 #train# step 2184, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:58.998962 #train# step 2185, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:00.595503 #train# step 2186, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:02.166580 #train# step 2187, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:03.733343 #train# step 2188, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:05.292114 #train# step 2189, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:06.850871 #train# step 2190, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:08.381550 #train# step 2191, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:09.921475 #train# step 2192, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:11.461916 #train# step 2193, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:13.035089 #train# step 2194, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:14.598219 #train# step 2195, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:16.191037 #train# step 2196, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:17.749581 #train# step 2197, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:19.351800 #train# step 2198, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:20.939497 #train# step 2199, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:22.489808 #train# step 2200, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:24.072516 #train# step 2201, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:25.620064 #train# step 2202, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:27.166482 #train# step 2203, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:28.763386 #train# step 2204, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:30.372031 #train# step 2205, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:31.989758 #train# step 2206, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:33.618522 #train# step 2207, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:35.168361 #train# step 2208, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:36.734636 #train# step 2209, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:38.335103 #train# step 2210, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:39.876630 #train# step 2211, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:41.431429 #train# step 2212, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:42.969290 #train# step 2213, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:44.511809 #train# step 2214, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:46.097648 #train# step 2215, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:47.663512 #train# step 2216, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:49.203193 #train# step 2217, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:50.771478 #train# step 2218, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:52.337952 #train# step 2219, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:53.880637 #train# step 2220, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:55.388803 #train# step 2221, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:56.945994 #train# step 2222, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:58.505386 #train# step 2223, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:00.077789 #train# step 2224, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:01.664095 #train# step 2225, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:03.206717 #train# step 2226, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:04.741021 #train# step 2227, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:06.286652 #train# step 2228, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:07.836555 #train# step 2229, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:09.403054 #train# step 2230, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:10.948637 #train# step 2231, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:12.494924 #train# step 2232, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:14.051751 #train# step 2233, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:15.611881 #train# step 2234, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:17.161962 #train# step 2235, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:18.703372 #train# step 2236, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:20.266042 #train# step 2237, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:21.822061 #train# step 2238, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:23.374106 #train# step 2239, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:24.929418 #train# step 2240, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:26.471807 #train# step 2241, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:27.995597 #train# step 2242, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:29.558807 #train# step 2243, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:31.111691 #train# step 2244, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:32.693618 #train# step 2245, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:34.241956 #train# step 2246, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:35.768444 #train# step 2247, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:37.356603 #train# step 2248, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:38.888501 #train# step 2249, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:40.434959 #train# step 2250, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:41.990969 #train# step 2251, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:43.566369 #train# step 2252, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:45.138278 #train# step 2253, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:46.671281 #train# step 2254, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:48.207241 #train# step 2255, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:49.769569 #train# step 2256, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:51.325902 #train# step 2257, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:52.908884 #train# step 2258, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:54.464551 #train# step 2259, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:56.007004 #train# step 2260, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:57.569209 #train# step 2261, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:59.093179 #train# step 2262, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:00.645754 #train# step 2263, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:02.197274 #train# step 2264, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:03.710834 #train# step 2265, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:05.224705 #train# step 2266, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:06.726653 #train# step 2267, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:08.307497 #train# step 2268, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:09.851819 #train# step 2269, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:11.400936 #train# step 2270, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:12.974329 #train# step 2271, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:14.528316 #train# step 2272, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:16.111678 #train# step 2273, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:17.689498 #train# step 2274, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:19.228358 #train# step 2275, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:20.765922 #train# step 2276, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:22.293035 #train# step 2277, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:23.814778 #train# step 2278, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:25.386617 #train# step 2279, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:26.927124 #train# step 2280, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:28.516306 #train# step 2281, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:30.050174 #train# step 2282, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:31.582880 #train# step 2283, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:33.149327 #train# step 2284, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:34.716032 #train# step 2285, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:36.261846 #train# step 2286, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:37.810639 #train# step 2287, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:39.350010 #train# step 2288, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:40.922540 #train# step 2289, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:42.478419 #train# step 2290, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:44.017993 #train# step 2291, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:45.569757 #train# step 2292, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:47.128800 #train# step 2293, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:48.696706 #train# step 2294, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:50.253610 #train# step 2295, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:51.792340 #train# step 2296, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:53.350761 #train# step 2297, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:54.891975 #train# step 2298, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:56.412485 #train# step 2299, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:57.983237 #train# step 2300, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:59.535011 #train# step 2301, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:01.110284 #train# step 2302, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:02.691161 #train# step 2303, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:04.248215 #train# step 2304, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:05.790359 #train# step 2305, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:07.306938 #train# step 2306, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:08.854333 #train# step 2307, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:10.412208 #train# step 2308, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:11.956979 #train# step 2309, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:13.511888 #train# step 2310, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:15.080643 #train# step 2311, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:16.644380 #train# step 2312, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:18.219084 #train# step 2313, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:19.775306 #train# step 2314, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:21.348291 #train# step 2315, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:22.901134 #train# step 2316, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:24.472859 #train# step 2317, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:25.995903 #train# step 2318, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:27.527037 #train# step 2319, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:29.093604 #train# step 2320, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:30.665110 #train# step 2321, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:32.231384 #train# step 2322, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:33.802334 #train# step 2323, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:35.405629 #train# step 2324, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:36.958019 #train# step 2325, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:38.478244 #train# step 2326, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:40.015433 #train# step 2327, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:41.544286 #train# step 2328, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:43.083450 #train# step 2329, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:44.651989 #train# step 2330, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:46.195707 #train# step 2331, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:47.774044 #train# step 2332, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:49.317850 #train# step 2333, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:50.848766 #train# step 2334, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:52.397785 #train# step 2335, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:53.959017 #train# step 2336, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:55.517538 #train# step 2337, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:57.048106 #train# step 2338, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:58.618826 #train# step 2339, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:00.172039 #train# step 2340, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:01.725406 #train# step 2341, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:03.289245 #train# step 2342, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:04.838978 #train# step 2343, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:06.377079 #train# step 2344, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:07.912315 #train# step 2345, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:09.447054 #train# step 2346, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:10.967194 #train# step 2347, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:12.534889 #train# step 2348, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:14.086074 #train# step 2349, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:15.627617 #train# step 2350, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:17.196264 #train# step 2351, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:18.762316 #train# step 2352, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:20.295058 #train# step 2353, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:21.839113 #train# step 2354, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:23.375502 #train# step 2355, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:24.936853 #train# step 2356, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:26.499807 #train# step 2357, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:28.053300 #train# step 2358, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:29.616888 #train# step 2359, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:31.149868 #train# step 2360, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:32.667310 #train# step 2361, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:34.212378 #train# step 2362, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:35.776355 #train# step 2363, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:37.321184 #train# step 2364, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:38.841177 #train# step 2365, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:40.350261 #train# step 2366, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:41.866259 #train# step 2367, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:43.428742 #train# step 2368, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:45.020904 #train# step 2369, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:46.578192 #train# step 2370, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:48.172374 #train# step 2371, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:49.728337 #train# step 2372, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:51.263069 #train# step 2373, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:52.802721 #train# step 2374, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:54.378193 #train# step 2375, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:55.918405 #train# step 2376, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:57.470903 #train# step 2377, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:59.034493 #train# step 2378, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:00.579502 #train# step 2379, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:02.135328 #train# step 2380, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:03.700792 #train# step 2381, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:05.247599 #train# step 2382, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:06.813927 #train# step 2383, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:08.371226 #train# step 2384, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:09.952948 #train# step 2385, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:11.495452 #train# step 2386, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:13.050395 #train# step 2387, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:14.569271 #train# step 2388, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:16.139186 #train# step 2389, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:17.706760 #train# step 2390, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:19.253266 #train# step 2391, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:20.799851 #train# step 2392, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:22.343686 #train# step 2393, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:23.869384 #train# step 2394, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:25.414859 #train# step 2395, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:26.994657 #train# step 2396, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:28.582819 #train# step 2397, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:30.126069 #train# step 2398, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:31.655367 #train# step 2399, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:33.160115 #train# step 2400, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:34.704354 #train# step 2401, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:36.272440 #train# step 2402, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:37.834144 #train# step 2403, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:39.399408 #train# step 2404, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:40.977362 #train# step 2405, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:42.561417 #train# step 2406, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:44.105137 #train# step 2407, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:45.632291 #train# step 2408, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:47.203591 #train# step 2409, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:48.737461 #train# step 2410, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:50.276555 #train# step 2411, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:51.836303 #train# step 2412, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:53.371785 #train# step 2413, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:54.896973 #train# step 2414, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:56.450961 #train# step 2415, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:58.002465 #train# step 2416, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:59.579894 #train# step 2417, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:01.115844 #train# step 2418, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:02.733795 #train# step 2419, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:04.361225 #train# step 2420, loss = 0.9525, cross_entropy loss = 0.9525, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:05.930746 #train# step 2421, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:07.473866 #train# step 2422, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:09.016934 #train# step 2423, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:10.578706 #train# step 2424, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:12.153042 #train# step 2425, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:13.738451 #train# step 2426, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:15.291250 #train# step 2427, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:16.867401 #train# step 2428, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:18.444190 #train# step 2429, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:20.018122 #train# step 2430, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:21.604101 #train# step 2431, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:23.170359 #train# step 2432, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:24.772443 #train# step 2433, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:26.319948 #train# step 2434, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:27.875820 #train# step 2435, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:29.454525 #train# step 2436, loss = 0.9466, cross_entropy loss = 0.9466, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:31.052419 #train# step 2437, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:32.623399 #train# step 2438, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:34.188802 #train# step 2439, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:35.763992 #train# step 2440, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:37.344975 #train# step 2441, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:38.969019 #train# step 2442, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:40.648103 #train# step 2443, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:42.231209 #train# step 2444, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:43.820665 #train# step 2445, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:45.384074 #train# step 2446, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:47.064615 #train# step 2447, loss = 0.9460, cross_entropy loss = 0.9460, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:48.647494 #train# step 2448, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:50.211396 #train# step 2449, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:51.743218 #train# step 2450, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:53.279889 #train# step 2451, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:54.845554 #train# step 2452, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:56.404396 #train# step 2453, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:57.971108 #train# step 2454, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:59.527446 #train# step 2455, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:01.123175 #train# step 2456, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:02.702628 #train# step 2457, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:04.279707 #train# step 2458, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:05.841901 #train# step 2459, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:07.430599 #train# step 2460, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:09.010766 #train# step 2461, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:10.563307 #train# step 2462, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:12.142829 #train# step 2463, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:13.759096 #train# step 2464, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:15.316256 #train# step 2465, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:16.929409 #train# step 2466, loss = 0.9663, cross_entropy loss = 0.9663, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:18.499539 #train# step 2467, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:20.079404 #train# step 2468, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:21.668497 #train# step 2469, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:23.248110 #train# step 2470, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:24.837496 #train# step 2471, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:26.385916 #train# step 2472, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:27.977507 #train# step 2473, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:29.562708 #train# step 2474, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:31.135974 #train# step 2475, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:32.680998 #train# step 2476, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:34.197587 #train# step 2477, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:35.796567 #train# step 2478, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:37.352072 #train# step 2479, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:38.935864 #train# step 2480, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:40.477363 #train# step 2481, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:42.012678 #train# step 2482, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:43.556789 #train# step 2483, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:45.077203 #train# step 2484, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:46.629583 #train# step 2485, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:48.185992 #train# step 2486, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:49.748119 #train# step 2487, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:51.323341 #train# step 2488, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:52.863645 #train# step 2489, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:54.446985 #train# step 2490, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:55.996852 #train# step 2491, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:57.530071 #train# step 2492, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:59.097613 #train# step 2493, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:00.654808 #train# step 2494, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:02.215745 #train# step 2495, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:03.784384 #train# step 2496, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:05.330385 #train# step 2497, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:06.865491 #train# step 2498, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:08.441393 #train# step 2499, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:09.989841 #train# step 2500, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:11.531367 #train# step 2501, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:13.089010 #train# step 2502, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:14.637011 #train# step 2503, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:16.216276 #train# step 2504, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:17.766938 #train# step 2505, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:19.330573 #train# step 2506, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:20.888960 #train# step 2507, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:22.425561 #train# step 2508, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:23.975352 #train# step 2509, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:25.515504 #train# step 2510, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:27.064614 #train# step 2511, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:28.635007 #train# step 2512, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:30.216670 #train# step 2513, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:31.779338 #train# step 2514, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:33.325543 #train# step 2515, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:34.863705 #train# step 2516, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:36.430966 #train# step 2517, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:37.997403 #train# step 2518, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:39.554821 #train# step 2519, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:41.130999 #train# step 2520, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:42.709020 #train# step 2521, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:44.273792 #train# step 2522, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:45.833817 #train# step 2523, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:47.399539 #train# step 2524, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:48.951174 #train# step 2525, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:50.507503 #train# step 2526, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:52.042783 #train# step 2527, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:53.583681 #train# step 2528, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:55.102930 #train# step 2529, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:56.625685 #train# step 2530, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:58.146566 #train# step 2531, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:59.698608 #train# step 2532, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:01.248455 #train# step 2533, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:02.812092 #train# step 2534, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:04.337964 #train# step 2535, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:05.845775 #train# step 2536, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:07.399822 #train# step 2537, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:08.987013 #train# step 2538, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:10.545340 #train# step 2539, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:12.083871 #train# step 2540, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:13.646679 #train# step 2541, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:15.167799 #train# step 2542, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:16.767448 #train# step 2543, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:18.336043 #train# step 2544, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:19.859513 #train# step 2545, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:21.379220 #train# step 2546, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:22.949050 #train# step 2547, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:24.499765 #train# step 2548, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:26.079593 #train# step 2549, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:27.636541 #train# step 2550, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:29.199598 #train# step 2551, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:30.761930 #train# step 2552, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:32.322829 #train# step 2553, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:33.867501 #train# step 2554, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:35.486514 #train# step 2555, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:37.026027 #train# step 2556, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:38.624052 #train# step 2557, loss = 0.9619, cross_entropy loss = 0.9619, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:40.190008 #train# step 2558, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:41.820396 #train# step 2559, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:43.355182 #train# step 2560, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:44.928679 #train# step 2561, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:46.503292 #train# step 2562, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:48.076206 #train# step 2563, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:49.652885 #train# step 2564, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:51.203835 #train# step 2565, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:52.801895 #train# step 2566, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:54.359665 #train# step 2567, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:55.893554 #train# step 2568, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:57.451322 #train# step 2569, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:59.024495 #train# step 2570, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:00.603561 #train# step 2571, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:02.192168 #train# step 2572, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:03.754112 #train# step 2573, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:05.319619 #train# step 2574, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:06.871916 #train# step 2575, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:08.438625 #train# step 2576, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:09.999546 #train# step 2577, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:11.584156 #train# step 2578, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:13.162479 #train# step 2579, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:14.704978 #train# step 2580, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:16.272419 #train# step 2581, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:17.799732 #train# step 2582, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:19.369429 #train# step 2583, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:20.920389 #train# step 2584, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:22.470891 #train# step 2585, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:24.041226 #train# step 2586, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:25.616929 #train# step 2587, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:27.207028 #train# step 2588, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:28.772947 #train# step 2589, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:30.353238 #train# step 2590, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:31.882779 #train# step 2591, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:33.436808 #train# step 2592, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:34.972470 #train# step 2593, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:36.518822 #train# step 2594, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:38.051435 #train# step 2595, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:39.607980 #train# step 2596, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:41.187741 #train# step 2597, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:42.737704 #train# step 2598, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:44.323775 #train# step 2599, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:45.880764 #train# step 2600, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:47.465684 #train# step 2601, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:49.065081 #train# step 2602, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:50.605682 #train# step 2603, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:52.176173 #train# step 2604, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:53.717806 #train# step 2605, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:55.253603 #train# step 2606, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:56.811737 #train# step 2607, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:58.313289 #train# step 2608, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:59.857552 #train# step 2609, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:01.421038 #train# step 2610, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:02.969903 #train# step 2611, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:04.512770 #train# step 2612, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:06.061511 #train# step 2613, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:07.622179 #train# step 2614, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:09.208244 #train# step 2615, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:10.764922 #train# step 2616, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:12.309990 #train# step 2617, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:13.877152 #train# step 2618, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:15.394458 #train# step 2619, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:16.915604 #train# step 2620, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:18.469035 #train# step 2621, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:20.035008 #train# step 2622, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:21.604772 #train# step 2623, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:23.155117 #train# step 2624, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:24.738869 #train# step 2625, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:26.281390 #train# step 2626, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:27.857820 #train# step 2627, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:29.406902 #train# step 2628, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:30.957194 #train# step 2629, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:32.504256 #train# step 2630, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:34.041701 #train# step 2631, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:35.604291 #train# step 2632, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:37.172230 #train# step 2633, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:38.724624 #train# step 2634, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:40.291967 #train# step 2635, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:41.886336 #train# step 2636, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:43.450931 #train# step 2637, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:45.023243 #train# step 2638, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:46.599053 #train# step 2639, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:48.173820 #train# step 2640, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:49.733186 #train# step 2641, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:51.270472 #train# step 2642, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:52.790371 #train# step 2643, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:54.360251 #train# step 2644, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:55.920211 #train# step 2645, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:57.468738 #train# step 2646, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:59.042775 #train# step 2647, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:00.620791 #train# step 2648, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:02.190409 #train# step 2649, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:03.745658 #train# step 2650, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:05.318364 #train# step 2651, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:06.863911 #train# step 2652, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:08.395510 #train# step 2653, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:09.951898 #train# step 2654, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:11.473903 #train# step 2655, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:13.012111 #train# step 2656, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:14.603728 #train# step 2657, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:16.123762 #train# step 2658, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:17.655946 #train# step 2659, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:19.210586 #train# step 2660, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:20.777538 #train# step 2661, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:22.348867 #train# step 2662, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:23.912840 #train# step 2663, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:25.472675 #train# step 2664, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:27.021815 #train# step 2665, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:28.549033 #train# step 2666, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:30.123046 #train# step 2667, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:31.673056 #train# step 2668, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:33.196997 #train# step 2669, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:34.741017 #train# step 2670, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:36.333034 #train# step 2671, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:37.870509 #train# step 2672, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:39.404911 #train# step 2673, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:40.963041 #train# step 2674, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:42.515843 #train# step 2675, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:44.043637 #train# step 2676, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:45.621814 #train# step 2677, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:47.164025 #train# step 2678, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:48.708349 #train# step 2679, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:50.278437 #train# step 2680, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:51.825119 #train# step 2681, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:53.415569 #train# step 2682, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:54.968614 #train# step 2683, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:56.496064 #train# step 2684, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:58.048548 #train# step 2685, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:59.594529 #train# step 2686, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:01.161499 #train# step 2687, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:02.736375 #train# step 2688, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:04.289635 #train# step 2689, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:05.843388 #train# step 2690, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:07.369926 #train# step 2691, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:08.926208 #train# step 2692, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:10.508166 #train# step 2693, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:12.071171 #train# step 2694, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:13.636903 #train# step 2695, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:15.172038 #train# step 2696, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:16.714531 #train# step 2697, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:18.291339 #train# step 2698, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:19.844537 #train# step 2699, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:21.366035 #train# step 2700, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:22.934892 #train# step 2701, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:24.483004 #train# step 2702, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:25.998359 #train# step 2703, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:27.566712 #train# step 2704, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:29.131855 #train# step 2705, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:30.700428 #train# step 2706, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:32.236792 #train# step 2707, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:33.781603 #train# step 2708, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:35.323664 #train# step 2709, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:36.897026 #train# step 2710, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:38.450728 #train# step 2711, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:40.014342 #train# step 2712, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:41.585582 #train# step 2713, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:43.147559 #train# step 2714, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:44.673507 #train# step 2715, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:46.253092 #train# step 2716, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:47.805117 #train# step 2717, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:49.375747 #train# step 2718, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:50.912565 #train# step 2719, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:52.486570 #train# step 2720, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:54.062776 #train# step 2721, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:55.659931 #train# step 2722, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:57.178403 #train# step 2723, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:58.732722 #train# step 2724, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:00.312410 #train# step 2725, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:01.879631 #train# step 2726, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:03.470791 #train# step 2727, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:05.023136 #train# step 2728, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:06.590531 #train# step 2729, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:08.135700 #train# step 2730, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:09.695999 #train# step 2731, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:11.259841 #train# step 2732, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:12.799527 #train# step 2733, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:14.368689 #train# step 2734, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:15.933202 #train# step 2735, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:17.467000 #train# step 2736, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:19.035273 #train# step 2737, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:20.603170 #train# step 2738, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:22.168436 #train# step 2739, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:23.719218 #train# step 2740, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:25.268792 #train# step 2741, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:26.846928 #train# step 2742, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:28.387024 #train# step 2743, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:29.931314 #train# step 2744, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:31.498992 #train# step 2745, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:33.062227 #train# step 2746, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:34.644123 #train# step 2747, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:36.208522 #train# step 2748, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:37.778166 #train# step 2749, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:39.332196 #train# step 2750, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:40.882553 #train# step 2751, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:42.468854 #train# step 2752, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:44.021965 #train# step 2753, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:45.582026 #train# step 2754, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:47.138753 #train# step 2755, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:48.682660 #train# step 2756, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:50.222192 #train# step 2757, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:51.788794 #train# step 2758, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:53.331392 #train# step 2759, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:54.881531 #train# step 2760, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:56.448752 #train# step 2761, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:57.988108 #train# step 2762, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:59.518990 #train# step 2763, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:01.071210 #train# step 2764, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:02.586612 #train# step 2765, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:04.184334 #train# step 2766, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:05.750240 #train# step 2767, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:07.284331 #train# step 2768, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:08.848746 #train# step 2769, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:10.386780 #train# step 2770, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:11.949781 #train# step 2771, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:13.487403 #train# step 2772, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:15.046455 #train# step 2773, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:16.605608 #train# step 2774, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:18.155659 #train# step 2775, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:19.701240 #train# step 2776, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:21.272325 #train# step 2777, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:22.789972 #train# step 2778, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:24.329417 #train# step 2779, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:25.900661 #train# step 2780, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:27.448229 #train# step 2781, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:28.991045 #train# step 2782, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:30.564702 #train# step 2783, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:32.114604 #train# step 2784, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:33.635495 #train# step 2785, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:35.192489 #train# step 2786, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:36.759384 #train# step 2787, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:38.295553 #train# step 2788, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:39.849785 #train# step 2789, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:41.418006 #train# step 2790, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:43.024594 #train# step 2791, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:44.544051 #train# step 2792, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:46.087449 #train# step 2793, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:47.632586 #train# step 2794, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:49.220147 #train# step 2795, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:50.767947 #train# step 2796, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:52.322251 #train# step 2797, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:53.868718 #train# step 2798, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:55.416322 #train# step 2799, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:56.956475 #train# step 2800, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:58.571685 #train# step 2801, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:00.126230 #train# step 2802, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:01.695683 #train# step 2803, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:03.248206 #train# step 2804, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:04.812746 #train# step 2805, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:06.372478 #train# step 2806, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:07.976098 #train# step 2807, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:09.560644 #train# step 2808, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:11.080338 #train# step 2809, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:12.630170 #train# step 2810, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:14.192052 #train# step 2811, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:15.766840 #train# step 2812, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:17.316312 #train# step 2813, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:18.889390 #train# step 2814, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:20.471385 #train# step 2815, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:22.032002 #train# step 2816, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:23.583453 #train# step 2817, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:25.143138 #train# step 2818, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:26.707356 #train# step 2819, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:28.269249 #train# step 2820, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:29.808055 #train# step 2821, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:31.341418 #train# step 2822, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:32.920103 #train# step 2823, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:34.495755 #train# step 2824, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:36.050749 #train# step 2825, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:37.639634 #train# step 2826, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:39.181232 #train# step 2827, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:40.743446 #train# step 2828, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:42.286925 #train# step 2829, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:43.846735 #train# step 2830, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:45.414716 #train# step 2831, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:46.992901 #train# step 2832, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:48.545110 #train# step 2833, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:50.129143 #train# step 2834, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:51.686887 #train# step 2835, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:53.224337 #train# step 2836, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:54.778083 #train# step 2837, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:56.302377 #train# step 2838, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:57.855725 #train# step 2839, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:59.412588 #train# step 2840, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:01.004891 #train# step 2841, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:02.537901 #train# step 2842, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:04.103744 #train# step 2843, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:05.672170 #train# step 2844, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:07.212459 #train# step 2845, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:08.803509 #train# step 2846, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:10.348297 #train# step 2847, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:11.860614 #train# step 2848, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:13.418900 #train# step 2849, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:14.987897 #train# step 2850, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:16.535563 #train# step 2851, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:18.109216 #train# step 2852, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:19.630296 #train# step 2853, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:21.218677 #train# step 2854, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:22.783086 #train# step 2855, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:24.333951 #train# step 2856, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:25.878180 #train# step 2857, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:27.471382 #train# step 2858, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:29.011947 #train# step 2859, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:30.553889 #train# step 2860, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:32.108486 #train# step 2861, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:33.625944 #train# step 2862, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:35.175103 #train# step 2863, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:36.713864 #train# step 2864, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:38.284113 #train# step 2865, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:39.862961 #train# step 2866, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:41.420996 #train# step 2867, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:42.953384 #train# step 2868, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:44.469120 #train# step 2869, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:46.034345 #train# step 2870, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:47.586569 #train# step 2871, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:49.143663 #train# step 2872, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:50.696694 #train# step 2873, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:52.286832 #train# step 2874, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:53.847958 #train# step 2875, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:55.432534 #train# step 2876, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:57.011204 #train# step 2877, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:58.587969 #train# step 2878, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:00.143413 #train# step 2879, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:01.695663 #train# step 2880, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:03.248518 #train# step 2881, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:04.840020 #train# step 2882, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:06.370038 #train# step 2883, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:07.914331 #train# step 2884, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:09.461314 #train# step 2885, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:11.007575 #train# step 2886, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:12.574384 #train# step 2887, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:14.134000 #train# step 2888, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:15.689168 #train# step 2889, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:17.253667 #train# step 2890, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:18.840946 #train# step 2891, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:20.382347 #train# step 2892, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:21.916248 #train# step 2893, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:23.446045 #train# step 2894, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:24.971960 #train# step 2895, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:26.536248 #train# step 2896, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:28.054782 #train# step 2897, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:29.610445 #train# step 2898, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:31.179181 #train# step 2899, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:32.740986 #train# step 2900, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:34.314304 #train# step 2901, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:35.876366 #train# step 2902, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:37.405969 #train# step 2903, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:38.949944 #train# step 2904, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:40.505466 #train# step 2905, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:42.075523 #train# step 2906, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:43.636839 #train# step 2907, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:45.187747 #train# step 2908, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:46.745683 #train# step 2909, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:48.276494 #train# step 2910, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:49.811316 #train# step 2911, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:51.368021 #train# step 2912, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:52.930950 #train# step 2913, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:54.494851 #train# step 2914, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:56.043411 #train# step 2915, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:57.632755 #train# step 2916, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:59.204572 #train# step 2917, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:00.765713 #train# step 2918, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:02.325024 #train# step 2919, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:03.875657 #train# step 2920, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:05.429733 #train# step 2921, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:07.004884 #train# step 2922, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:08.580296 #train# step 2923, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:10.172458 #train# step 2924, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:11.728809 #train# step 2925, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:13.281764 #train# step 2926, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:14.853179 #train# step 2927, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:16.427710 #train# step 2928, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:17.964527 #train# step 2929, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:19.512963 #train# step 2930, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:21.049336 #train# step 2931, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:22.592422 #train# step 2932, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:24.147765 #train# step 2933, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:25.690992 #train# step 2934, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:27.249565 #train# step 2935, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:28.828672 #train# step 2936, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:30.395803 #train# step 2937, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:31.979726 #train# step 2938, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:33.516555 #train# step 2939, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:35.087414 #train# step 2940, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:36.600226 #train# step 2941, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:38.141327 #train# step 2942, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:39.716403 #train# step 2943, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:41.252941 #train# step 2944, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:42.801378 #train# step 2945, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:44.351165 #train# step 2946, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:45.885951 #train# step 2947, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:47.440018 #train# step 2948, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:48.985447 #train# step 2949, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:50.543009 #train# step 2950, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:52.077681 #train# step 2951, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:53.610303 #train# step 2952, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:55.162955 #train# step 2953, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:56.715635 #train# step 2954, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:58.256257 #train# step 2955, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:59.798630 #train# step 2956, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:01.382938 #train# step 2957, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:02.930304 #train# step 2958, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:04.527125 #train# step 2959, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:06.067013 #train# step 2960, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:07.622281 #train# step 2961, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:09.210010 #train# step 2962, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:10.783231 #train# step 2963, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:12.379001 #train# step 2964, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:13.952902 #train# step 2965, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:15.499619 #train# step 2966, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:17.047134 #train# step 2967, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:18.596140 #train# step 2968, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:20.155085 #train# step 2969, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:21.730036 #train# step 2970, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:23.272928 #train# step 2971, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:24.800519 #train# step 2972, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:26.388981 #train# step 2973, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:27.956354 #train# step 2974, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:29.501538 #train# step 2975, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:31.073111 #train# step 2976, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:32.591918 #train# step 2977, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:34.119096 #train# step 2978, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:35.647550 #train# step 2979, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:37.194946 #train# step 2980, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:38.755506 #train# step 2981, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:40.332947 #train# step 2982, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:41.905027 #train# step 2983, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:43.452983 #train# step 2984, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:45.010426 #train# step 2985, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:46.561924 #train# step 2986, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:48.129304 #train# step 2987, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:49.685411 #train# step 2988, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:51.240272 #train# step 2989, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:52.767944 #train# step 2990, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:54.327165 #train# step 2991, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:55.906266 #train# step 2992, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:57.457724 #train# step 2993, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:58.987738 #train# step 2994, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:00.549271 #train# step 2995, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:02.095300 #train# step 2996, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:03.663319 #train# step 2997, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:05.253248 #train# step 2998, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:06.837744 #train# step 2999, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:08.371335 #train# step 3000, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:09.927498 #train# step 3001, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:11.463910 #train# step 3002, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:13.011616 #train# step 3003, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:14.585405 #train# step 3004, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:16.182514 #train# step 3005, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:17.751284 #train# step 3006, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:19.330811 #train# step 3007, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:20.912016 #train# step 3008, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:22.455323 #train# step 3009, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:24.040946 #train# step 3010, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:25.602664 #train# step 3011, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:27.157117 #train# step 3012, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:28.707139 #train# step 3013, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:30.299049 #train# step 3014, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:31.890283 #train# step 3015, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:33.428734 #train# step 3016, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:35.018974 #train# step 3017, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:36.618823 #train# step 3018, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:38.223210 #train# step 3019, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:39.880531 #train# step 3020, loss = 0.9378, cross_entropy loss = 0.9378, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:41.449450 #train# step 3021, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:43.037720 #train# step 3022, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:44.598585 #train# step 3023, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:46.156821 #train# step 3024, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:47.694136 #train# step 3025, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:49.245476 #train# step 3026, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:50.796062 #train# step 3027, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:52.375718 #train# step 3028, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:53.957462 #train# step 3029, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:55.511221 #train# step 3030, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:57.102905 #train# step 3031, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:58.721681 #train# step 3032, loss = 0.9440, cross_entropy loss = 0.9440, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:00.318132 #train# step 3033, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:01.883816 #train# step 3034, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:03.452026 #train# step 3035, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:05.017767 #train# step 3036, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:06.553890 #train# step 3037, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:08.091222 #train# step 3038, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:09.674105 #train# step 3039, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:11.222006 #train# step 3040, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:12.807681 #train# step 3041, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:14.374448 #train# step 3042, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:15.949336 #train# step 3043, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:17.532709 #train# step 3044, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:19.082546 #train# step 3045, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:20.636275 #train# step 3046, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:22.180662 #train# step 3047, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:23.756660 #train# step 3048, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:25.308065 #train# step 3049, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:26.865447 #train# step 3050, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:28.402307 #train# step 3051, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:29.931146 #train# step 3052, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:31.472465 #train# step 3053, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:33.014928 #train# step 3054, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:34.577065 #train# step 3055, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:36.149851 #train# step 3056, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:37.704794 #train# step 3057, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:39.279307 #train# step 3058, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:40.816967 #train# step 3059, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:42.394549 #train# step 3060, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:43.946742 #train# step 3061, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:45.466729 #train# step 3062, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:47.008780 #train# step 3063, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:48.566263 #train# step 3064, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:50.116498 #train# step 3065, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:51.687499 #train# step 3066, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:53.268436 #train# step 3067, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:54.829269 #train# step 3068, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:56.373586 #train# step 3069, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:57.918462 #train# step 3070, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:59.493015 #train# step 3071, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:01.049802 #train# step 3072, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:02.621188 #train# step 3073, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:04.211062 #train# step 3074, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:05.775940 #train# step 3075, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:07.350894 #train# step 3076, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:08.901710 #train# step 3077, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:10.449287 #train# step 3078, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:12.038130 #train# step 3079, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:13.599255 #train# step 3080, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:15.188975 #train# step 3081, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:16.790798 #train# step 3082, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:18.372887 #train# step 3083, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:19.935967 #train# step 3084, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:21.537783 #train# step 3085, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:23.119045 #train# step 3086, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:24.709746 #train# step 3087, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:26.271910 #train# step 3088, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:27.806687 #train# step 3089, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:29.359616 #train# step 3090, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:30.882910 #train# step 3091, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:32.434445 #train# step 3092, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:34.025122 #train# step 3093, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:35.579217 #train# step 3094, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:37.166332 #train# step 3095, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:38.685132 #train# step 3096, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:40.207515 #train# step 3097, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:41.750232 #train# step 3098, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:43.318394 #train# step 3099, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:44.892662 #train# step 3100, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:46.448979 #train# step 3101, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:47.978352 #train# step 3102, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:49.528131 #train# step 3103, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:51.082664 #train# step 3104, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:52.631628 #train# step 3105, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:54.223564 #train# step 3106, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:55.794913 #train# step 3107, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:57.329615 #train# step 3108, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:58.860707 #train# step 3109, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:00.431997 #train# step 3110, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:01.991675 #train# step 3111, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:03.539752 #train# step 3112, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:05.081961 #train# step 3113, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:06.630006 #train# step 3114, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:08.196827 #train# step 3115, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:09.734364 #train# step 3116, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:11.277778 #train# step 3117, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:12.863307 #train# step 3118, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:14.463637 #train# step 3119, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:16.036619 #train# step 3120, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:17.591560 #train# step 3121, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:19.165568 #train# step 3122, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:20.728674 #train# step 3123, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:22.268461 #train# step 3124, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:23.831306 #train# step 3125, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:25.388136 #train# step 3126, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:26.962675 #train# step 3127, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:28.534160 #train# step 3128, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:30.062167 #train# step 3129, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:31.629705 #train# step 3130, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:33.184973 #train# step 3131, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:34.735362 #train# step 3132, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:36.303431 #train# step 3133, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:37.905842 #train# step 3134, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:39.501034 #train# step 3135, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:41.068793 #train# step 3136, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:42.628186 #train# step 3137, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:44.214091 #train# step 3138, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:45.780426 #train# step 3139, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:47.378873 #train# step 3140, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:48.947855 #train# step 3141, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:50.518072 #train# step 3142, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:52.067114 #train# step 3143, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:53.632537 #train# step 3144, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:55.167912 #train# step 3145, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:56.711038 #train# step 3146, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:58.252076 #train# step 3147, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:59.804827 #train# step 3148, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:01.343305 #train# step 3149, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:02.944744 #train# step 3150, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:04.537127 #train# step 3151, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:06.124661 #train# step 3152, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:07.661304 #train# step 3153, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:09.224127 #train# step 3154, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:10.766077 #train# step 3155, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:12.341141 #train# step 3156, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:13.864476 #train# step 3157, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:15.395528 #train# step 3158, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:16.980391 #train# step 3159, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:18.510766 #train# step 3160, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:20.101660 #train# step 3161, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:21.668367 #train# step 3162, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:23.187840 #train# step 3163, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:24.713666 #train# step 3164, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:26.258683 #train# step 3165, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:27.814479 #train# step 3166, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:29.384116 #train# step 3167, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:30.981426 #train# step 3168, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:32.556733 #train# step 3169, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:34.101371 #train# step 3170, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:35.644112 #train# step 3171, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:37.175954 #train# step 3172, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:38.740050 #train# step 3173, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:40.333337 #train# step 3174, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:41.898819 #train# step 3175, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:43.473537 #train# step 3176, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:45.014005 #train# step 3177, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:46.609739 #train# step 3178, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:48.173822 #train# step 3179, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:49.711706 #train# step 3180, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:51.277211 #train# step 3181, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:52.816398 #train# step 3182, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:54.401924 #train# step 3183, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:55.986485 #train# step 3184, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:57.547985 #train# step 3185, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:59.113909 #train# step 3186, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:00.661206 #train# step 3187, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:02.259574 #train# step 3188, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:03.813087 #train# step 3189, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:05.389628 #train# step 3190, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:06.952311 #train# step 3191, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:08.529823 #train# step 3192, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:10.092612 #train# step 3193, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:11.672332 #train# step 3194, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:13.223100 #train# step 3195, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:14.764473 #train# step 3196, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:16.300251 #train# step 3197, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:17.862695 #train# step 3198, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:19.475639 #train# step 3199, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:21.042151 #train# step 3200, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:22.614174 #train# step 3201, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:24.172844 #train# step 3202, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:25.681337 #train# step 3203, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:27.264685 #train# step 3204, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:28.806566 #train# step 3205, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:30.426608 #train# step 3206, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:31.956078 #train# step 3207, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:33.510346 #train# step 3208, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:35.046331 #train# step 3209, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:36.622535 #train# step 3210, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:38.184726 #train# step 3211, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:39.714638 #train# step 3212, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:41.255393 #train# step 3213, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:42.792600 #train# step 3214, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:44.356421 #train# step 3215, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:45.875344 #train# step 3216, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:47.456264 #train# step 3217, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:49.007774 #train# step 3218, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:50.566400 #train# step 3219, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:52.173054 #train# step 3220, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:53.781137 #train# step 3221, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:55.391542 #train# step 3222, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:56.949527 #train# step 3223, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:58.511881 #train# step 3224, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:00.055758 #train# step 3225, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:01.633768 #train# step 3226, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:03.196282 #train# step 3227, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:04.748043 #train# step 3228, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:06.325465 #train# step 3229, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:07.889898 #train# step 3230, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:09.418831 #train# step 3231, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:10.959842 #train# step 3232, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:12.515735 #train# step 3233, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:14.048166 #train# step 3234, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:15.615011 #train# step 3235, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:17.168858 #train# step 3236, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:18.770666 #train# step 3237, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:20.357004 #train# step 3238, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:21.908608 #train# step 3239, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:23.483136 #train# step 3240, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:25.034911 #train# step 3241, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:26.588847 #train# step 3242, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:28.127767 #train# step 3243, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:29.669209 #train# step 3244, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:31.271250 #train# step 3245, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:32.828882 #train# step 3246, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:34.432357 #train# step 3247, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:35.984129 #train# step 3248, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:37.521512 #train# step 3249, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:39.063859 #train# step 3250, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:40.628428 #train# step 3251, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:42.219832 #train# step 3252, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:43.786864 #train# step 3253, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:45.348724 #train# step 3254, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:46.890475 #train# step 3255, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:48.473930 #train# step 3256, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:50.020127 #train# step 3257, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:51.582773 #train# step 3258, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:53.153860 #train# step 3259, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:54.743438 #train# step 3260, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:56.303270 #train# step 3261, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:57.834577 #train# step 3262, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:59.453475 #train# step 3263, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:01.074155 #train# step 3264, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:02.650127 #train# step 3265, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:04.214398 #train# step 3266, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:05.792780 #train# step 3267, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:07.340941 #train# step 3268, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:08.890206 #train# step 3269, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:10.444731 #train# step 3270, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:12.005194 #train# step 3271, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:13.534641 #train# step 3272, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:15.103278 #train# step 3273, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:16.657918 #train# step 3274, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:18.226858 #train# step 3275, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:19.792601 #train# step 3276, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:21.353696 #train# step 3277, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:22.901479 #train# step 3278, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:24.422456 #train# step 3279, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:25.970973 #train# step 3280, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:27.513866 #train# step 3281, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:29.065893 #train# step 3282, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:30.644765 #train# step 3283, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:32.194954 #train# step 3284, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:33.765830 #train# step 3285, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:35.285490 #train# step 3286, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:36.850397 #train# step 3287, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:38.368261 #train# step 3288, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:39.905536 #train# step 3289, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:41.468313 #train# step 3290, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:43.026754 #train# step 3291, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:44.581456 #train# step 3292, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:46.144703 #train# step 3293, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:47.688008 #train# step 3294, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:49.247669 #train# step 3295, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:50.802024 #train# step 3296, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:52.374572 #train# step 3297, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:53.974712 #train# step 3298, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:55.522899 #train# step 3299, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:57.074435 #train# step 3300, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:58.612683 #train# step 3301, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:00.143757 #train# step 3302, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:01.721721 #train# step 3303, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:03.262004 #train# step 3304, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:04.826298 #train# step 3305, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:06.335650 #train# step 3306, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:07.893632 #train# step 3307, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:09.465383 #train# step 3308, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:11.024697 #train# step 3309, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:12.594859 #train# step 3310, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:14.110495 #train# step 3311, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:15.692562 #train# step 3312, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:17.277597 #train# step 3313, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:18.836523 #train# step 3314, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:20.386038 #train# step 3315, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:22.012378 #train# step 3316, loss = 0.9411, cross_entropy loss = 0.9411, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:23.589610 #train# step 3317, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:25.177595 #train# step 3318, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:26.723530 #train# step 3319, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:28.315468 #train# step 3320, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:29.851306 #train# step 3321, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:31.431467 #train# step 3322, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:32.970741 #train# step 3323, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:34.541205 #train# step 3324, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:36.087940 #train# step 3325, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:37.641146 #train# step 3326, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:39.212317 #train# step 3327, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:40.791792 #train# step 3328, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:42.377216 #train# step 3329, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:43.989161 #train# step 3330, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:45.558069 #train# step 3331, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:47.143655 #train# step 3332, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:48.692592 #train# step 3333, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:50.246480 #train# step 3334, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:51.794618 #train# step 3335, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:53.368307 #train# step 3336, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:54.951516 #train# step 3337, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:56.526831 #train# step 3338, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:58.080993 #train# step 3339, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:59.652337 #train# step 3340, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:01.214247 #train# step 3341, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:02.787339 #train# step 3342, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:04.360436 #train# step 3343, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:05.912002 #train# step 3344, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:07.500344 #train# step 3345, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:09.027691 #train# step 3346, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:10.674152 #train# step 3347, loss = 0.9431, cross_entropy loss = 0.9431, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:12.420224 #train# step 3348, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:13.947114 #train# step 3349, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:15.508901 #train# step 3350, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:17.053346 #train# step 3351, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:18.592145 #train# step 3352, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:20.180424 #train# step 3353, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:21.751508 #train# step 3354, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:23.315046 #train# step 3355, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:24.888833 #train# step 3356, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:26.483167 #train# step 3357, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:28.081521 #train# step 3358, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:29.604340 #train# step 3359, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:31.226059 #train# step 3360, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:32.901729 #train# step 3361, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:34.427398 #train# step 3362, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:35.975879 #train# step 3363, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:37.583702 #train# step 3364, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:39.191059 #train# step 3365, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:40.781738 #train# step 3366, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:42.349727 #train# step 3367, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:43.878659 #train# step 3368, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:45.425497 #train# step 3369, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:46.981127 #train# step 3370, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:48.540195 #train# step 3371, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:50.101786 #train# step 3372, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:51.619273 #train# step 3373, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:53.365801 #train# step 3374, loss = 0.9294, cross_entropy loss = 0.9294, 1.0 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:54.941310 #train# step 3375, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:56.495414 #train# step 3376, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:58.121447 #train# step 3377, loss = 0.9355, cross_entropy loss = 0.9355, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:59.664106 #train# step 3378, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:01.232392 #train# step 3379, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:02.804023 #train# step 3380, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:04.359510 #train# step 3381, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:06.002611 #train# step 3382, loss = 0.9389, cross_entropy loss = 0.9389, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:07.594833 #train# step 3383, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:09.150186 #train# step 3384, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:10.739676 #train# step 3385, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:12.294472 #train# step 3386, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:13.866983 #train# step 3387, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:15.432994 #train# step 3388, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:16.968275 #train# step 3389, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:18.517185 #train# step 3390, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:20.070602 #train# step 3391, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:21.631779 #train# step 3392, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:23.196086 #train# step 3393, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:24.813646 #train# step 3394, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:26.538011 #train# step 3395, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:28.225945 #train# step 3396, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:29.806297 #train# step 3397, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:31.340201 #train# step 3398, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:32.915645 #train# step 3399, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:34.467659 #train# step 3400, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:36.056544 #train# step 3401, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:37.613624 #train# step 3402, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:39.168904 #train# step 3403, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:40.703822 #train# step 3404, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:42.279609 #train# step 3405, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:43.851144 #train# step 3406, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:45.408826 #train# step 3407, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:46.968034 #train# step 3408, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:48.506134 #train# step 3409, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:50.045419 #train# step 3410, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:51.602839 #train# step 3411, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:53.175623 #train# step 3412, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:54.750227 #train# step 3413, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:56.318973 #train# step 3414, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:57.861929 #train# step 3415, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:59.395467 #train# step 3416, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:00.913787 #train# step 3417, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:02.451989 #train# step 3418, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:03.996391 #train# step 3419, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:05.539053 #train# step 3420, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:07.110660 #train# step 3421, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:08.638896 #train# step 3422, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:10.238625 #train# step 3423, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:11.822534 #train# step 3424, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:13.373273 #train# step 3425, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:14.972321 #train# step 3426, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:16.538475 #train# step 3427, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:18.110317 #train# step 3428, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:19.637955 #train# step 3429, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:21.176389 #train# step 3430, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:22.787840 #train# step 3431, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:24.333008 #train# step 3432, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:25.893988 #train# step 3433, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:27.430671 #train# step 3434, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:28.994602 #train# step 3435, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:30.560520 #train# step 3436, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:32.124135 #train# step 3437, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:33.650812 #train# step 3438, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:35.214077 #train# step 3439, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:36.782688 #train# step 3440, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:38.321287 #train# step 3441, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:39.862632 #train# step 3442, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:41.396965 #train# step 3443, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:42.965151 #train# step 3444, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:44.509245 #train# step 3445, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:46.075290 #train# step 3446, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:47.640758 #train# step 3447, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:49.197431 #train# step 3448, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:50.745586 #train# step 3449, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:52.309717 #train# step 3450, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:53.878232 #train# step 3451, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:55.409129 #train# step 3452, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:56.957313 #train# step 3453, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:58.564982 #train# step 3454, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:00.131845 #train# step 3455, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:01.713158 #train# step 3456, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:03.269564 #train# step 3457, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:04.853597 #train# step 3458, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:06.425404 #train# step 3459, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:07.952506 #train# step 3460, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:09.497614 #train# step 3461, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:11.057490 #train# step 3462, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:12.657496 #train# step 3463, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:14.225610 #train# step 3464, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:15.785438 #train# step 3465, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:17.329939 #train# step 3466, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:18.875234 #train# step 3467, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:20.437340 #train# step 3468, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:21.983880 #train# step 3469, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:23.547878 #train# step 3470, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:25.123806 #train# step 3471, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:26.680888 #train# step 3472, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:28.203013 #train# step 3473, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:29.759470 #train# step 3474, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:31.292660 #train# step 3475, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:32.837822 #train# step 3476, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:34.393356 #train# step 3477, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:35.963611 #train# step 3478, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:37.514809 #train# step 3479, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:39.083498 #train# step 3480, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:40.664684 #train# step 3481, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:42.221718 #train# step 3482, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:43.785928 #train# step 3483, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:45.332151 #train# step 3484, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:46.918945 #train# step 3485, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:48.509549 #train# step 3486, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:50.050748 #train# step 3487, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:51.612226 #train# step 3488, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:53.181080 #train# step 3489, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:54.737639 #train# step 3490, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:56.292252 #train# step 3491, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:57.851276 #train# step 3492, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:59.423941 #train# step 3493, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:00.949440 #train# step 3494, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:02.466206 #train# step 3495, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:04.020333 #train# step 3496, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:05.566604 #train# step 3497, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:07.132425 #train# step 3498, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:08.701385 #train# step 3499, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:10.280598 #train# step 3500, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:11.842335 #train# step 3501, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:13.376186 #train# step 3502, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:14.945336 #train# step 3503, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:16.496090 #train# step 3504, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:18.060593 #train# step 3505, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:19.609788 #train# step 3506, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:21.181458 #train# step 3507, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:22.776011 #train# step 3508, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:24.378844 #train# step 3509, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:25.916854 #train# step 3510, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:27.470014 #train# step 3511, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:29.022376 #train# step 3512, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:30.581397 #train# step 3513, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:32.162038 #train# step 3514, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:33.693833 #train# step 3515, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:35.272929 #train# step 3516, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:36.792521 #train# step 3517, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:38.349084 #train# step 3518, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:39.898843 #train# step 3519, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:41.473432 #train# step 3520, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:43.048297 #train# step 3521, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:44.601484 #train# step 3522, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:46.144398 #train# step 3523, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:47.687393 #train# step 3524, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:49.281084 #train# step 3525, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:50.828356 #train# step 3526, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:52.349867 #train# step 3527, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:53.891556 #train# step 3528, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:55.436348 #train# step 3529, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:56.999920 #train# step 3530, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:58.570114 #train# step 3531, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:00.128127 #train# step 3532, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:01.671224 #train# step 3533, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:03.250155 #train# step 3534, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:04.787986 #train# step 3535, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:06.348495 #train# step 3536, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:07.912932 #train# step 3537, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:09.481895 #train# step 3538, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:11.046335 #train# step 3539, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:12.604264 #train# step 3540, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:14.145839 #train# step 3541, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:15.704029 #train# step 3542, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:17.258907 #train# step 3543, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:18.849277 #train# step 3544, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:20.390924 #train# step 3545, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:21.932356 #train# step 3546, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:23.487153 #train# step 3547, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:25.041994 #train# step 3548, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:26.572595 #train# step 3549, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:28.109586 #train# step 3550, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:29.642042 #train# step 3551, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:31.207959 #train# step 3552, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:32.758115 #train# step 3553, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:34.333202 #train# step 3554, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:35.910306 #train# step 3555, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:37.468143 #train# step 3556, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:39.045331 #train# step 3557, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:40.589787 #train# step 3558, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:42.139448 #train# step 3559, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:43.685159 #train# step 3560, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:45.257021 #train# step 3561, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:46.779067 #train# step 3562, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:48.371345 #train# step 3563, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:49.938032 #train# step 3564, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:51.476825 #train# step 3565, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:53.040448 #train# step 3566, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:54.583938 #train# step 3567, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:56.136243 #train# step 3568, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:57.708017 #train# step 3569, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:59.264868 #train# step 3570, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:00.837724 #train# step 3571, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:02.413739 #train# step 3572, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:03.971810 #train# step 3573, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:05.523241 #train# step 3574, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:07.077562 #train# step 3575, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:08.631270 #train# step 3576, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:10.199801 #train# step 3577, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:11.756236 #train# step 3578, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:13.308634 #train# step 3579, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:14.858313 #train# step 3580, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:16.421536 #train# step 3581, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:17.975434 #train# step 3582, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:19.553159 #train# step 3583, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:21.115562 #train# step 3584, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:22.701307 #train# step 3585, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:24.255028 #train# step 3586, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:25.836965 #train# step 3587, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:27.377170 #train# step 3588, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:28.941571 #train# step 3589, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:30.487482 #train# step 3590, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:32.045592 #train# step 3591, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:33.596677 #train# step 3592, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:35.129030 #train# step 3593, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:36.664687 #train# step 3594, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:38.208003 #train# step 3595, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:39.778532 #train# step 3596, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:41.372083 #train# step 3597, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:42.928923 #train# step 3598, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:44.451058 #train# step 3599, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:45.997372 #train# step 3600, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:47.551901 #train# step 3601, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:49.122216 #train# step 3602, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:50.667272 #train# step 3603, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:52.237277 #train# step 3604, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:53.783284 #train# step 3605, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:55.322310 #train# step 3606, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:56.859362 #train# step 3607, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:58.438170 #train# step 3608, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:59.980779 #train# step 3609, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:01.550407 #train# step 3610, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:03.115781 #train# step 3611, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:04.665293 #train# step 3612, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:06.239716 #train# step 3613, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:07.784336 #train# step 3614, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:09.342634 #train# step 3615, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:10.911969 #train# step 3616, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:12.456903 #train# step 3617, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:14.002337 #train# step 3618, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:15.629599 #train# step 3619, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:17.216780 #train# step 3620, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:18.768803 #train# step 3621, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:20.343568 #train# step 3622, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:21.883129 #train# step 3623, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:23.397432 #train# step 3624, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:24.935365 #train# step 3625, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:26.491105 #train# step 3626, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:28.035136 #train# step 3627, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:29.629360 #train# step 3628, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:31.193119 #train# step 3629, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:32.740937 #train# step 3630, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:34.286082 #train# step 3631, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:35.826024 #train# step 3632, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:37.364567 #train# step 3633, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:38.925862 #train# step 3634, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:40.444853 #train# step 3635, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:42.022148 #train# step 3636, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:43.612991 #train# step 3637, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:45.182721 #train# step 3638, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:46.746372 #train# step 3639, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:48.331286 #train# step 3640, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:49.891289 #train# step 3641, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:51.445961 #train# step 3642, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:53.030437 #train# step 3643, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:54.585983 #train# step 3644, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:56.137026 #train# step 3645, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:57.679798 #train# step 3646, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:59.252497 #train# step 3647, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:00.788001 #train# step 3648, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:02.337270 #train# step 3649, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:03.932201 #train# step 3650, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:05.537400 #train# step 3651, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:07.100811 #train# step 3652, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:08.673970 #train# step 3653, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:10.244156 #train# step 3654, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:11.787510 #train# step 3655, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:13.349343 #train# step 3656, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:14.911707 #train# step 3657, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:16.435281 #train# step 3658, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:17.977041 #train# step 3659, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:19.536301 #train# step 3660, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:21.063379 #train# step 3661, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:22.629388 #train# step 3662, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:24.170191 #train# step 3663, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:25.708165 #train# step 3664, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:27.277273 #train# step 3665, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:28.808055 #train# step 3666, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:30.354483 #train# step 3667, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:31.917672 #train# step 3668, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:33.540289 #train# step 3669, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:35.106822 #train# step 3670, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:36.667852 #train# step 3671, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:38.219563 #train# step 3672, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:39.770077 #train# step 3673, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:41.323385 #train# step 3674, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:42.868531 #train# step 3675, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:44.432685 #train# step 3676, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:46.003644 #train# step 3677, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:47.586146 #train# step 3678, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:49.139358 #train# step 3679, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:50.685619 #train# step 3680, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:52.270485 #train# step 3681, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:53.841827 #train# step 3682, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:55.410990 #train# step 3683, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:56.937876 #train# step 3684, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:58.531172 #train# step 3685, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:00.085575 #train# step 3686, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:01.639925 #train# step 3687, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:03.180154 #train# step 3688, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:04.743416 #train# step 3689, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:06.289923 #train# step 3690, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:07.850146 #train# step 3691, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:09.413103 #train# step 3692, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:10.990662 #train# step 3693, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:12.543178 #train# step 3694, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:14.103917 #train# step 3695, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:15.636600 #train# step 3696, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:17.211307 #train# step 3697, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:18.784658 #train# step 3698, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:20.340101 #train# step 3699, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:21.928389 #train# step 3700, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:23.488979 #train# step 3701, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:25.055228 #train# step 3702, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:26.607233 #train# step 3703, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:28.176914 #train# step 3704, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:29.739468 #train# step 3705, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:31.287711 #train# step 3706, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:32.854164 #train# step 3707, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:34.423381 #train# step 3708, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:35.992350 #train# step 3709, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:37.565732 #train# step 3710, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:39.164555 #train# step 3711, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:40.742745 #train# step 3712, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:42.271717 #train# step 3713, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:43.817685 #train# step 3714, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:45.391069 #train# step 3715, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:46.977023 #train# step 3716, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:48.532204 #train# step 3717, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:50.110253 #train# step 3718, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:51.668015 #train# step 3719, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:53.199715 #train# step 3720, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:54.770265 #train# step 3721, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:56.374442 #train# step 3722, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:57.944373 #train# step 3723, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:59.532766 #train# step 3724, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:01.048916 #train# step 3725, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:02.650335 #train# step 3726, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:04.195567 #train# step 3727, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:05.728704 #train# step 3728, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:07.269639 #train# step 3729, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:08.807059 #train# step 3730, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:10.363152 #train# step 3731, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:11.910338 #train# step 3732, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:13.461916 #train# step 3733, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:15.030491 #train# step 3734, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:16.580957 #train# step 3735, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:18.106069 #train# step 3736, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:19.660965 #train# step 3737, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:21.212172 #train# step 3738, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:22.762907 #train# step 3739, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:24.335254 #train# step 3740, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:25.886080 #train# step 3741, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:27.473702 #train# step 3742, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:29.007156 #train# step 3743, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:30.543911 #train# step 3744, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:32.107781 #train# step 3745, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:33.688874 #train# step 3746, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:35.230757 #train# step 3747, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:36.792039 #train# step 3748, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:38.328758 #train# step 3749, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:39.927267 #train# step 3750, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:41.522255 #train# step 3751, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:43.089536 #train# step 3752, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:44.642439 #train# step 3753, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:46.202544 #train# step 3754, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:47.771399 #train# step 3755, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:49.346878 #train# step 3756, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:50.911378 #train# step 3757, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:52.476872 #train# step 3758, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:54.032502 #train# step 3759, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:55.580389 #train# step 3760, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:57.122656 #train# step 3761, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:58.691861 #train# step 3762, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:00.257814 #train# step 3763, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:01.845524 #train# step 3764, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:03.374184 #train# step 3765, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:04.909614 #train# step 3766, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:06.457583 #train# step 3767, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:08.013280 #train# step 3768, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:09.594936 #train# step 3769, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:11.163836 #train# step 3770, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:12.715710 #train# step 3771, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:14.290159 #train# step 3772, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:15.864446 #train# step 3773, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:17.406850 #train# step 3774, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:18.951789 #train# step 3775, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:20.482184 #train# step 3776, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:22.045564 #train# step 3777, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:23.615692 #train# step 3778, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:25.184463 #train# step 3779, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:26.772267 #train# step 3780, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:28.300202 #train# step 3781, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:29.853567 #train# step 3782, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:31.401762 #train# step 3783, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:32.953405 #train# step 3784, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:34.523441 #train# step 3785, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:36.109093 #train# step 3786, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:37.628329 #train# step 3787, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:39.229241 #train# step 3788, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:40.807963 #train# step 3789, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:42.380682 #train# step 3790, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:43.928513 #train# step 3791, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:45.507730 #train# step 3792, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:47.085933 #train# step 3793, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:48.612221 #train# step 3794, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:50.167731 #train# step 3795, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:51.720281 #train# step 3796, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:53.303521 #train# step 3797, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:54.855214 #train# step 3798, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:56.417042 #train# step 3799, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:57.961687 #train# step 3800, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:59.521987 #train# step 3801, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:01.089343 #train# step 3802, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:02.648595 #train# step 3803, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:04.217541 #train# step 3804, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:05.785636 #train# step 3805, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:07.331929 #train# step 3806, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:08.882026 #train# step 3807, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:10.467807 #train# step 3808, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:12.004244 #train# step 3809, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:13.567985 #train# step 3810, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:15.125133 #train# step 3811, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:16.726339 #train# step 3812, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:18.282610 #train# step 3813, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:19.840181 #train# step 3814, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:21.420462 #train# step 3815, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:22.969959 #train# step 3816, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:24.511131 #train# step 3817, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:26.064665 #train# step 3818, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:27.631464 #train# step 3819, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:29.174346 #train# step 3820, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:30.728757 #train# step 3821, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:32.294923 #train# step 3822, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:33.800722 #train# step 3823, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:35.369606 #train# step 3824, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:36.905186 #train# step 3825, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:38.492014 #train# step 3826, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:40.034806 #train# step 3827, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:41.585415 #train# step 3828, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:43.172673 #train# step 3829, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:44.723638 #train# step 3830, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:46.302579 #train# step 3831, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:47.835499 #train# step 3832, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:49.376438 #train# step 3833, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:50.919721 #train# step 3834, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:52.472626 #train# step 3835, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:54.045676 #train# step 3836, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:55.612186 #train# step 3837, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:57.157091 #train# step 3838, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:58.722026 #train# step 3839, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:00.286670 #train# step 3840, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:01.829622 #train# step 3841, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:03.348968 #train# step 3842, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:04.904130 #train# step 3843, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:06.418004 #train# step 3844, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:07.999288 #train# step 3845, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:09.577049 #train# step 3846, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:11.133866 #train# step 3847, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:12.691202 #train# step 3848, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:14.257030 #train# step 3849, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:15.843339 #train# step 3850, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:17.408300 #train# step 3851, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:18.961563 #train# step 3852, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:20.508688 #train# step 3853, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:22.070845 #train# step 3854, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:23.621795 #train# step 3855, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:25.173242 #train# step 3856, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:26.719392 #train# step 3857, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:28.288092 #train# step 3858, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:29.878224 #train# step 3859, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:31.448334 #train# step 3860, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:33.038144 #train# step 3861, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:34.592626 #train# step 3862, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:36.140659 #train# step 3863, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:37.715967 #train# step 3864, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:39.277948 #train# step 3865, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:40.826032 #train# step 3866, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:42.394242 #train# step 3867, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:43.936586 #train# step 3868, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:45.494528 #train# step 3869, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:47.048824 #train# step 3870, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:48.589261 #train# step 3871, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:50.133050 #train# step 3872, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:51.698446 #train# step 3873, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:53.276581 #train# step 3874, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:54.849177 #train# step 3875, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:56.410368 #train# step 3876, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:57.959936 #train# step 3877, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:59.509834 #train# step 3878, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:01.051383 #train# step 3879, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:02.610746 #train# step 3880, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:04.146805 #train# step 3881, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:05.710048 #train# step 3882, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:07.273176 #train# step 3883, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:08.808335 #train# step 3884, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:10.365688 #train# step 3885, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:11.924155 #train# step 3886, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:13.458056 #train# step 3887, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:15.033236 #train# step 3888, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:16.628040 #train# step 3889, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:18.199261 #train# step 3890, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:19.780402 #train# step 3891, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:21.309454 #train# step 3892, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:22.868731 #train# step 3893, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:24.432078 #train# step 3894, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:25.968995 #train# step 3895, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:27.528558 #train# step 3896, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:29.056898 #train# step 3897, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:30.628001 #train# step 3898, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:32.192416 #train# step 3899, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:33.726620 #train# step 3900, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:35.305389 #train# step 3901, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:36.862420 #train# step 3902, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:38.415035 #train# step 3903, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:39.994187 #train# step 3904, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:41.546798 #train# step 3905, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:43.102959 #train# step 3906, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:44.668857 #train# step 3907, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:46.208357 #train# step 3908, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:47.775571 #train# step 3909, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:49.336302 #train# step 3910, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:50.920709 #train# step 3911, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:52.500325 #train# step 3912, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:54.058739 #train# step 3913, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:55.596186 #train# step 3914, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:57.144372 #train# step 3915, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:58.741336 #train# step 3916, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:00.275117 #train# step 3917, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:01.830055 #train# step 3918, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:03.511870 #train# step 3919, loss = 0.9326, cross_entropy loss = 0.9326, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:05.064413 #train# step 3920, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:06.646687 #train# step 3921, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:08.226523 #train# step 3922, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:09.834459 #train# step 3923, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:11.397715 #train# step 3924, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:12.970740 #train# step 3925, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:14.527668 #train# step 3926, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:16.096252 #train# step 3927, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:17.645813 #train# step 3928, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:19.197276 #train# step 3929, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:20.784140 #train# step 3930, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:22.345848 #train# step 3931, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:23.879267 #train# step 3932, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:25.433889 #train# step 3933, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:26.992323 #train# step 3934, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:28.587618 #train# step 3935, loss = 0.9425, cross_entropy loss = 0.9425, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:30.152936 #train# step 3936, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:31.715257 #train# step 3937, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:33.334235 #train# step 3938, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:34.897302 #train# step 3939, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:36.481080 #train# step 3940, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:38.057886 #train# step 3941, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:39.614793 #train# step 3942, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:41.171568 #train# step 3943, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:42.733599 #train# step 3944, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:44.301877 #train# step 3945, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:45.862065 #train# step 3946, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:47.413179 #train# step 3947, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:48.969264 #train# step 3948, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:50.558743 #train# step 3949, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:52.138937 #train# step 3950, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:53.739137 #train# step 3951, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:55.317848 #train# step 3952, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:56.889413 #train# step 3953, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:58.464365 #train# step 3954, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:00.018088 #train# step 3955, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:01.585191 #train# step 3956, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:03.166074 #train# step 3957, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:04.728483 #train# step 3958, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:06.289688 #train# step 3959, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:07.851006 #train# step 3960, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:09.483518 #train# step 3961, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:11.139522 #train# step 3962, loss = 0.9347, cross_entropy loss = 0.9347, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:12.732939 #train# step 3963, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:14.370963 #train# step 3964, loss = 0.9269, cross_entropy loss = 0.9269, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:15.992521 #train# step 3965, loss = 0.9487, cross_entropy loss = 0.9487, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:17.645834 #train# step 3966, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:19.245041 #train# step 3967, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:20.899920 #train# step 3968, loss = 0.9270, cross_entropy loss = 0.9270, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:22.541308 #train# step 3969, loss = 0.9392, cross_entropy loss = 0.9392, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:24.168365 #train# step 3970, loss = 0.9422, cross_entropy loss = 0.9422, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:25.749227 #train# step 3971, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:27.286514 #train# step 3972, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:28.865011 #train# step 3973, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:30.469215 #train# step 3974, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:32.039135 #train# step 3975, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:33.595840 #train# step 3976, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:35.129090 #train# step 3977, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:36.671276 #train# step 3978, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:38.273252 #train# step 3979, loss = 0.9318, cross_entropy loss = 0.9318, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:39.813492 #train# step 3980, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:41.367436 #train# step 3981, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:42.899708 #train# step 3982, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:44.433280 #train# step 3983, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:46.014930 #train# step 3984, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:47.601427 #train# step 3985, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:49.158700 #train# step 3986, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:50.704621 #train# step 3987, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:52.250964 #train# step 3988, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:53.829864 #train# step 3989, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:55.393090 #train# step 3990, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:56.965274 #train# step 3991, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:58.489299 #train# step 3992, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:00.108795 #train# step 3993, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:01.707000 #train# step 3994, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:03.309393 #train# step 3995, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:04.876241 #train# step 3996, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:06.441798 #train# step 3997, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:08.036117 #train# step 3998, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:09.623194 #train# step 3999, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:11.252506 #train# step 4000, loss = 0.9323, cross_entropy loss = 0.9323, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:12.884664 #train# step 4001, loss = 0.9301, cross_entropy loss = 0.9301, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:14.419889 #train# step 4002, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:15.974163 #train# step 4003, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:17.527345 #train# step 4004, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:19.090418 #train# step 4005, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:20.650643 #train# step 4006, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:22.203896 #train# step 4007, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:23.770007 #train# step 4008, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:25.319608 #train# step 4009, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:26.899717 #train# step 4010, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:28.421878 #train# step 4011, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:29.936749 #train# step 4012, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:31.545828 #train# step 4013, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:33.095313 #train# step 4014, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:34.676481 #train# step 4015, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:36.252572 #train# step 4016, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:37.820140 #train# step 4017, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:39.357872 #train# step 4018, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:40.907561 #train# step 4019, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:42.474096 #train# step 4020, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:44.042059 #train# step 4021, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:45.573305 #train# step 4022, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:47.141747 #train# step 4023, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:48.702593 #train# step 4024, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:50.270516 #train# step 4025, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:51.839624 #train# step 4026, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:53.420923 #train# step 4027, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:54.969122 #train# step 4028, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:56.487107 #train# step 4029, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:58.051301 #train# step 4030, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:59.641134 #train# step 4031, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:01.190911 #train# step 4032, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:02.769174 #train# step 4033, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:04.344964 #train# step 4034, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:05.961081 #train# step 4035, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:07.547963 #train# step 4036, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:09.195239 #train# step 4037, loss = 0.9245, cross_entropy loss = 0.9245, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:10.871810 #train# step 4038, loss = 0.9238, cross_entropy loss = 0.9238, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:12.522436 #train# step 4039, loss = 0.9238, cross_entropy loss = 0.9238, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:14.167029 #train# step 4040, loss = 0.9249, cross_entropy loss = 0.9249, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:15.816909 #train# step 4041, loss = 0.9257, cross_entropy loss = 0.9257, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:17.419690 #train# step 4042, loss = 0.9325, cross_entropy loss = 0.9325, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:19.070447 #train# step 4043, loss = 0.9474, cross_entropy loss = 0.9474, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:20.687055 #train# step 4044, loss = 0.9517, cross_entropy loss = 0.9517, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:22.320547 #train# step 4045, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:23.848184 #train# step 4046, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:25.387123 #train# step 4047, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:26.938578 #train# step 4048, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:28.504224 #train# step 4049, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:30.121168 #train# step 4050, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:31.761308 #train# step 4051, loss = 0.9273, cross_entropy loss = 0.9273, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:33.347137 #train# step 4052, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:34.939262 #train# step 4053, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:36.529221 #train# step 4054, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:38.124589 #train# step 4055, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:39.685252 #train# step 4056, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:41.230563 #train# step 4057, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:42.799909 #train# step 4058, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:44.347013 #train# step 4059, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:45.882460 #train# step 4060, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:47.462518 #train# step 4061, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:49.005419 #train# step 4062, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:50.585904 #train# step 4063, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:52.161145 #train# step 4064, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:53.736687 #train# step 4065, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:55.278893 #train# step 4066, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:56.851432 #train# step 4067, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:58.405561 #train# step 4068, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:00.008459 #train# step 4069, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:01.543985 #train# step 4070, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:03.182665 #train# step 4071, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:04.730952 #train# step 4072, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:06.304073 #train# step 4073, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:07.867938 #train# step 4074, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:09.424759 #train# step 4075, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:10.999744 #train# step 4076, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:12.557987 #train# step 4077, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:14.107773 #train# step 4078, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:15.714555 #train# step 4079, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:17.259218 #train# step 4080, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:18.814266 #train# step 4081, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:20.357412 #train# step 4082, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:21.923479 #train# step 4083, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:23.458653 #train# step 4084, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:25.037021 #train# step 4085, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:26.596767 #train# step 4086, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:28.155181 #train# step 4087, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:29.760942 #train# step 4088, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:31.341504 #train# step 4089, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:32.916624 #train# step 4090, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:34.497746 #train# step 4091, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:36.021016 #train# step 4092, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:37.582975 #train# step 4093, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:39.174415 #train# step 4094, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:40.743908 #train# step 4095, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:42.353009 #train# step 4096, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:43.934106 #train# step 4097, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:45.498902 #train# step 4098, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:47.071012 #train# step 4099, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:48.602960 #train# step 4100, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:50.180257 #train# step 4101, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:51.733447 #train# step 4102, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:53.281949 #train# step 4103, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:54.823395 #train# step 4104, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:56.392607 #train# step 4105, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:57.962417 #train# step 4106, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:59.545695 #train# step 4107, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:01.150072 #train# step 4108, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:02.683629 #train# step 4109, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:04.252724 #train# step 4110, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:05.836129 #train# step 4111, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:07.369219 #train# step 4112, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:08.934603 #train# step 4113, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:10.496077 #train# step 4114, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:12.046123 #train# step 4115, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:13.599125 #train# step 4116, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:15.179214 #train# step 4117, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:16.754538 #train# step 4118, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:18.319216 #train# step 4119, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:19.853194 #train# step 4120, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:21.420369 #train# step 4121, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:22.956779 #train# step 4122, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:24.522845 #train# step 4123, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:26.088662 #train# step 4124, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:27.657551 #train# step 4125, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:29.237860 #train# step 4126, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:30.771572 #train# step 4127, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:32.340642 #train# step 4128, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:33.919283 #train# step 4129, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:35.465563 #train# step 4130, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:37.036674 #train# step 4131, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:38.650304 #train# step 4132, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:40.235369 #train# step 4133, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:41.775825 #train# step 4134, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:43.368015 #train# step 4135, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:44.957355 #train# step 4136, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:46.507556 #train# step 4137, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:48.070375 #train# step 4138, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:49.633526 #train# step 4139, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:51.185488 #train# step 4140, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:52.740035 #train# step 4141, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:54.316039 #train# step 4142, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:55.897306 #train# step 4143, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:57.439478 #train# step 4144, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:59.023377 #train# step 4145, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:00.577408 #train# step 4146, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:02.137311 #train# step 4147, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:03.691343 #train# step 4148, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:05.256808 #train# step 4149, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:06.835468 #train# step 4150, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:08.412189 #train# step 4151, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:09.964779 #train# step 4152, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:11.499716 #train# step 4153, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:13.050107 #train# step 4154, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:14.614901 #train# step 4155, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:16.224590 #train# step 4156, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:17.801263 #train# step 4157, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:19.381267 #train# step 4158, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:20.902742 #train# step 4159, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:22.454464 #train# step 4160, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:24.023112 #train# step 4161, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:25.587522 #train# step 4162, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:27.160015 #train# step 4163, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:28.746933 #train# step 4164, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:30.293444 #train# step 4165, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:31.882632 #train# step 4166, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:33.409169 #train# step 4167, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:34.976425 #train# step 4168, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:36.547949 #train# step 4169, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:38.129418 #train# step 4170, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:39.669301 #train# step 4171, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:41.242407 #train# step 4172, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:42.804001 #train# step 4173, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:44.375055 #train# step 4174, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:45.954351 #train# step 4175, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:47.531578 #train# step 4176, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:49.076132 #train# step 4177, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:50.655478 #train# step 4178, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:52.202620 #train# step 4179, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:53.743592 #train# step 4180, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:55.299262 #train# step 4181, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:56.888535 #train# step 4182, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:58.424092 #train# step 4183, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:59.995185 #train# step 4184, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:01.558161 #train# step 4185, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:03.120435 #train# step 4186, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:04.688602 #train# step 4187, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:06.252192 #train# step 4188, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:07.804067 #train# step 4189, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:09.372530 #train# step 4190, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:10.955439 #train# step 4191, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:12.519911 #train# step 4192, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:14.072156 #train# step 4193, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:15.635764 #train# step 4194, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:17.222856 #train# step 4195, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:18.791243 #train# step 4196, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:20.355988 #train# step 4197, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:21.927165 #train# step 4198, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:23.495434 #train# step 4199, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:25.057962 #train# step 4200, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:26.624601 #train# step 4201, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:28.248340 #train# step 4202, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:29.797584 #train# step 4203, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:31.398376 #train# step 4204, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:32.924496 #train# step 4205, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:34.458862 #train# step 4206, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:36.003474 #train# step 4207, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:37.541899 #train# step 4208, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:39.125425 #train# step 4209, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:40.700242 #train# step 4210, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:42.249388 #train# step 4211, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:43.807908 #train# step 4212, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:45.384235 #train# step 4213, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:46.905373 #train# step 4214, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:48.453744 #train# step 4215, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:50.004831 #train# step 4216, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:51.549560 #train# step 4217, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:53.125622 #train# step 4218, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:54.724876 #train# step 4219, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:56.315792 #train# step 4220, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:57.872706 #train# step 4221, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:59.416909 #train# step 4222, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:00.972861 #train# step 4223, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:02.544921 #train# step 4224, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:04.097263 #train# step 4225, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:05.674081 #train# step 4226, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:07.232500 #train# step 4227, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:08.755958 #train# step 4228, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:10.294422 #train# step 4229, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:11.845155 #train# step 4230, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:13.414127 #train# step 4231, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:14.972266 #train# step 4232, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:16.555624 #train# step 4233, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:18.079163 #train# step 4234, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:19.685956 #train# step 4235, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:21.234861 #train# step 4236, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:22.786923 #train# step 4237, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:24.358399 #train# step 4238, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:25.945181 #train# step 4239, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:27.514726 #train# step 4240, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:29.058108 #train# step 4241, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:30.613983 #train# step 4242, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:32.168772 #train# step 4243, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:33.738119 #train# step 4244, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:35.318289 #train# step 4245, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:36.870683 #train# step 4246, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:38.433152 #train# step 4247, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:39.999761 #train# step 4248, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:41.590334 #train# step 4249, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:43.118316 #train# step 4250, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:44.672355 #train# step 4251, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:46.227086 #train# step 4252, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:47.809324 #train# step 4253, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:49.382451 #train# step 4254, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:50.911250 #train# step 4255, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:52.450855 #train# step 4256, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:54.046846 #train# step 4257, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:55.611969 #train# step 4258, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:57.152020 #train# step 4259, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:58.700099 #train# step 4260, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:00.281216 #train# step 4261, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:01.851379 #train# step 4262, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:03.424297 #train# step 4263, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:04.984587 #train# step 4264, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:06.542890 #train# step 4265, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:08.105176 #train# step 4266, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:09.652026 #train# step 4267, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:11.249636 #train# step 4268, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:12.810165 #train# step 4269, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:14.384934 #train# step 4270, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:15.922119 #train# step 4271, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:17.466571 #train# step 4272, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:19.014028 #train# step 4273, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:20.558324 #train# step 4274, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:22.131324 #train# step 4275, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:23.692771 #train# step 4276, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:25.287145 #train# step 4277, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:26.843442 #train# step 4278, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:28.374739 #train# step 4279, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:29.941131 #train# step 4280, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:31.509294 #train# step 4281, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:33.110258 #train# step 4282, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:34.650554 #train# step 4283, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:36.231466 #train# step 4284, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:37.823986 #train# step 4285, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:39.384017 #train# step 4286, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:40.929531 #train# step 4287, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:42.505981 #train# step 4288, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:44.041817 #train# step 4289, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:45.606841 #train# step 4290, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:47.161805 #train# step 4291, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:48.708046 #train# step 4292, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:50.293538 #train# step 4293, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:51.868095 #train# step 4294, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:53.449457 #train# step 4295, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:55.055116 #train# step 4296, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:56.609083 #train# step 4297, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:58.194056 #train# step 4298, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:59.747733 #train# step 4299, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:01.299406 #train# step 4300, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:02.863437 #train# step 4301, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:04.438814 #train# step 4302, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:06.020841 #train# step 4303, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:07.575486 #train# step 4304, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:09.125916 #train# step 4305, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:10.660446 #train# step 4306, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:12.176030 #train# step 4307, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:13.743762 #train# step 4308, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:15.281098 #train# step 4309, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:16.844713 #train# step 4310, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:18.411578 #train# step 4311, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:19.986489 #train# step 4312, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:21.557509 #train# step 4313, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:23.099249 #train# step 4314, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:24.631647 #train# step 4315, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:26.172756 #train# step 4316, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:27.723553 #train# step 4317, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:29.308659 #train# step 4318, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:30.909988 #train# step 4319, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:32.484146 #train# step 4320, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:34.016091 #train# step 4321, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:35.609040 #train# step 4322, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:37.173396 #train# step 4323, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:38.713596 #train# step 4324, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:40.277615 #train# step 4325, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:41.808631 #train# step 4326, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:43.360072 #train# step 4327, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:44.925320 #train# step 4328, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:46.458321 #train# step 4329, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:48.007759 #train# step 4330, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:49.574639 #train# step 4331, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:51.117106 #train# step 4332, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:52.672922 #train# step 4333, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:54.223727 #train# step 4334, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:55.771000 #train# step 4335, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:57.304703 #train# step 4336, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:58.881557 #train# step 4337, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:00.442528 #train# step 4338, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:02.029280 #train# step 4339, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:03.607554 #train# step 4340, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:05.171342 #train# step 4341, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:06.683185 #train# step 4342, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:08.224413 #train# step 4343, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:09.790002 #train# step 4344, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:11.358362 #train# step 4345, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:12.917243 #train# step 4346, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:14.468845 #train# step 4347, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:16.058511 #train# step 4348, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:17.635771 #train# step 4349, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:19.180426 #train# step 4350, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:20.736214 #train# step 4351, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:22.294847 #train# step 4352, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:23.860377 #train# step 4353, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:25.422286 #train# step 4354, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:26.998350 #train# step 4355, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:28.611584 #train# step 4356, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:30.194535 #train# step 4357, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:31.745087 #train# step 4358, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:33.274620 #train# step 4359, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:34.860447 #train# step 4360, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:36.428867 #train# step 4361, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:38.008061 #train# step 4362, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:39.571364 #train# step 4363, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:41.157675 #train# step 4364, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:42.750745 #train# step 4365, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:44.326173 #train# step 4366, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:45.894439 #train# step 4367, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:47.455587 #train# step 4368, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:48.997361 #train# step 4369, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:50.575619 #train# step 4370, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:52.161298 #train# step 4371, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:53.721775 #train# step 4372, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:55.275299 #train# step 4373, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:56.842027 #train# step 4374, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:58.383471 #train# step 4375, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:59.961448 #train# step 4376, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:01.526709 #train# step 4377, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:03.096559 #train# step 4378, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:04.668158 #train# step 4379, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:06.257634 #train# step 4380, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:07.830242 #train# step 4381, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:09.405617 #train# step 4382, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:10.979153 #train# step 4383, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:12.574214 #train# step 4384, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:14.158798 #train# step 4385, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:15.691508 #train# step 4386, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:17.245164 #train# step 4387, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:18.842881 #train# step 4388, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:20.401190 #train# step 4389, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:21.946364 #train# step 4390, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:23.491172 #train# step 4391, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:25.077847 #train# step 4392, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:26.648956 #train# step 4393, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:28.194814 #train# step 4394, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:29.752865 #train# step 4395, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:31.304971 #train# step 4396, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:32.873948 #train# step 4397, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:34.410721 #train# step 4398, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:35.943707 #train# step 4399, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:37.544513 #train# step 4400, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:39.098968 #train# step 4401, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:40.691673 #train# step 4402, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:42.281058 #train# step 4403, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:43.838692 #train# step 4404, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:45.394338 #train# step 4405, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:46.942195 #train# step 4406, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:48.503162 #train# step 4407, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:50.052551 #train# step 4408, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:51.636934 #train# step 4409, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:53.228688 #train# step 4410, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:54.754179 #train# step 4411, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:56.311568 #train# step 4412, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:57.864089 #train# step 4413, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:59.413527 #train# step 4414, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:00.968136 #train# step 4415, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:02.527048 #train# step 4416, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:04.089496 #train# step 4417, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:05.646164 #train# step 4418, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:07.216490 #train# step 4419, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:08.744646 #train# step 4420, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:10.310851 #train# step 4421, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:11.901010 #train# step 4422, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:13.448113 #train# step 4423, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:14.959755 #train# step 4424, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:16.493566 #train# step 4425, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:18.058375 #train# step 4426, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:19.646663 #train# step 4427, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:21.196252 #train# step 4428, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:22.777439 #train# step 4429, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:24.336892 #train# step 4430, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:25.888942 #train# step 4431, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:27.473443 #train# step 4432, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:29.041228 #train# step 4433, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:30.615401 #train# step 4434, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:32.162419 #train# step 4435, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:33.712474 #train# step 4436, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:35.285048 #train# step 4437, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:36.889243 #train# step 4438, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:38.430895 #train# step 4439, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:39.994172 #train# step 4440, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:41.575287 #train# step 4441, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:43.143790 #train# step 4442, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:44.692918 #train# step 4443, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:46.250348 #train# step 4444, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:47.808962 #train# step 4445, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:49.364071 #train# step 4446, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:50.938001 #train# step 4447, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:52.537265 #train# step 4448, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:54.120338 #train# step 4449, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:55.671224 #train# step 4450, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:57.250423 #train# step 4451, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:58.814120 #train# step 4452, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:00.368512 #train# step 4453, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:01.918570 #train# step 4454, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:03.464466 #train# step 4455, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:05.013764 #train# step 4456, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:06.594854 #train# step 4457, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:08.157205 #train# step 4458, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:09.703550 #train# step 4459, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:11.279322 #train# step 4460, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:12.843462 #train# step 4461, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:14.428859 #train# step 4462, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:15.992526 #train# step 4463, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:17.559697 #train# step 4464, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:19.115348 #train# step 4465, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:20.691240 #train# step 4466, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:22.278432 #train# step 4467, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:23.837561 #train# step 4468, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:25.391592 #train# step 4469, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:26.957312 #train# step 4470, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:28.530425 #train# step 4471, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:30.103488 #train# step 4472, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:31.674403 #train# step 4473, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:33.256040 #train# step 4474, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:34.822307 #train# step 4475, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:36.334763 #train# step 4476, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:37.911629 #train# step 4477, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:39.515742 #train# step 4478, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:41.080997 #train# step 4479, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:42.642297 #train# step 4480, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:44.201927 #train# step 4481, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:45.748203 #train# step 4482, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:47.261865 #train# step 4483, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:48.828425 #train# step 4484, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:50.393167 #train# step 4485, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:51.950002 #train# step 4486, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:53.528655 #train# step 4487, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:55.109316 #train# step 4488, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:56.677732 #train# step 4489, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:58.205832 #train# step 4490, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:59.780948 #train# step 4491, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:01.344283 #train# step 4492, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:02.890469 #train# step 4493, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:04.464838 #train# step 4494, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:06.011693 #train# step 4495, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:07.601187 #train# step 4496, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:09.157629 #train# step 4497, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:10.708649 #train# step 4498, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:12.288093 #train# step 4499, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:13.849544 #train# step 4500, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:15.417133 #train# step 4501, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:16.970618 #train# step 4502, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:18.540911 #train# step 4503, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:20.134822 #train# step 4504, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:21.687333 #train# step 4505, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:23.221415 #train# step 4506, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:24.785573 #train# step 4507, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:26.331123 #train# step 4508, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:27.880396 #train# step 4509, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:29.409084 #train# step 4510, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:30.968407 #train# step 4511, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:32.535969 #train# step 4512, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:34.129217 #train# step 4513, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:35.718653 #train# step 4514, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:37.279959 #train# step 4515, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:38.833737 #train# step 4516, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:40.382728 #train# step 4517, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:41.927634 #train# step 4518, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:43.494650 #train# step 4519, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:45.034618 #train# step 4520, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:46.587525 #train# step 4521, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:48.166292 #train# step 4522, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:49.734130 #train# step 4523, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:51.301810 #train# step 4524, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:52.888809 #train# step 4525, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:54.467445 #train# step 4526, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:56.034282 #train# step 4527, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:57.576950 #train# step 4528, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:59.133610 #train# step 4529, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:00.695716 #train# step 4530, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:02.276879 #train# step 4531, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:03.854340 #train# step 4532, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:05.383100 #train# step 4533, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:06.937320 #train# step 4534, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:08.497901 #train# step 4535, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:10.068131 #train# step 4536, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:11.610829 #train# step 4537, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:13.168145 #train# step 4538, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:14.732235 #train# step 4539, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:16.283909 #train# step 4540, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:17.811848 #train# step 4541, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:19.354394 #train# step 4542, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:20.934914 #train# step 4543, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:22.497961 #train# step 4544, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:24.093167 #train# step 4545, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:25.666050 #train# step 4546, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:27.211981 #train# step 4547, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:28.771169 #train# step 4548, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:30.330880 #train# step 4549, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:31.910436 #train# step 4550, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:33.462349 #train# step 4551, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:35.039880 #train# step 4552, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:36.609807 #train# step 4553, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:38.176053 #train# step 4554, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:39.745281 #train# step 4555, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:41.303589 #train# step 4556, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:42.883995 #train# step 4557, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:44.451089 #train# step 4558, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:46.020408 #train# step 4559, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:47.573011 #train# step 4560, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:49.118626 #train# step 4561, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:50.664963 #train# step 4562, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:52.205227 #train# step 4563, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:53.764982 #train# step 4564, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:55.344707 #train# step 4565, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:56.885149 #train# step 4566, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:58.422149 #train# step 4567, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:59.964484 #train# step 4568, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:01.533600 #train# step 4569, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:03.106425 #train# step 4570, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:04.665560 #train# step 4571, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:06.227912 #train# step 4572, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:07.798520 #train# step 4573, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:09.352230 #train# step 4574, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:10.971305 #train# step 4575, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:12.550619 #train# step 4576, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:14.101658 #train# step 4577, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:15.663653 #train# step 4578, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:17.209270 #train# step 4579, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:18.757136 #train# step 4580, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:20.357384 #train# step 4581, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:21.938925 #train# step 4582, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:23.488111 #train# step 4583, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:25.021317 #train# step 4584, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:26.582855 #train# step 4585, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:28.168539 #train# step 4586, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:29.721309 #train# step 4587, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:31.301563 #train# step 4588, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:32.864708 #train# step 4589, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:34.411948 #train# step 4590, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:36.002646 #train# step 4591, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:37.565930 #train# step 4592, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:39.135251 #train# step 4593, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:40.674507 #train# step 4594, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:42.233493 #train# step 4595, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:43.770930 #train# step 4596, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:45.327259 #train# step 4597, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:46.886472 #train# step 4598, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:48.434215 #train# step 4599, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:50.010001 #train# step 4600, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:51.560820 #train# step 4601, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:53.163235 #train# step 4602, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:54.749504 #train# step 4603, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:56.308654 #train# step 4604, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:57.838934 #train# step 4605, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:59.400714 #train# step 4606, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:00.942527 #train# step 4607, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:02.463817 #train# step 4608, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:03.981396 #train# step 4609, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:05.537362 #train# step 4610, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:07.132340 #train# step 4611, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:08.681729 #train# step 4612, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:10.275580 #train# step 4613, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:11.831333 #train# step 4614, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:13.347997 #train# step 4615, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:14.921498 #train# step 4616, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:16.479684 #train# step 4617, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:18.082832 #train# step 4618, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:19.677219 #train# step 4619, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:21.215955 #train# step 4620, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:22.783427 #train# step 4621, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:24.334188 #train# step 4622, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:25.884872 #train# step 4623, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:27.488067 #train# step 4624, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:29.024787 #train# step 4625, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:30.612413 #train# step 4626, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:32.193836 #train# step 4627, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:33.742339 #train# step 4628, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:35.303565 #train# step 4629, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:36.931977 #train# step 4630, loss = 0.9085, cross_entropy loss = 0.9085, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:38.606407 #train# step 4631, loss = 0.9317, cross_entropy loss = 0.9317, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:40.255677 #train# step 4632, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:41.853274 #train# step 4633, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:43.457085 #train# step 4634, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:45.090221 #train# step 4635, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:46.638302 #train# step 4636, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:48.234037 #train# step 4637, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:49.842357 #train# step 4638, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:51.427160 #train# step 4639, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:53.060197 #train# step 4640, loss = 0.9292, cross_entropy loss = 0.9292, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:54.687686 #train# step 4641, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:56.256659 #train# step 4642, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:57.874537 #train# step 4643, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:59.455016 #train# step 4644, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:01.019187 #train# step 4645, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:02.631687 #train# step 4646, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:04.259642 #train# step 4647, loss = 0.9268, cross_entropy loss = 0.9268, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:05.917395 #train# step 4648, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:07.529902 #train# step 4649, loss = 0.9225, cross_entropy loss = 0.9225, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:09.110548 #train# step 4650, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:10.693843 #train# step 4651, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:12.202242 #train# step 4652, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:13.730795 #train# step 4653, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:15.276309 #train# step 4654, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:16.854282 #train# step 4655, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:18.387093 #train# step 4656, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:19.935684 #train# step 4657, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:21.483902 #train# step 4658, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:23.059225 #train# step 4659, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:24.602544 #train# step 4660, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:26.172919 #train# step 4661, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:27.734507 #train# step 4662, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:29.275291 #train# step 4663, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:30.810665 #train# step 4664, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:32.359051 #train# step 4665, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:33.896124 #train# step 4666, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:35.492444 #train# step 4667, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:37.064114 #train# step 4668, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:38.641400 #train# step 4669, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:40.215096 #train# step 4670, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:41.789692 #train# step 4671, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:43.357425 #train# step 4672, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:44.906225 #train# step 4673, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:46.441811 #train# step 4674, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:47.981506 #train# step 4675, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:49.558576 #train# step 4676, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:51.169530 #train# step 4677, loss = 0.9220, cross_entropy loss = 0.9220, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:52.762819 #train# step 4678, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:54.328763 #train# step 4679, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:56.009129 #train# step 4680, loss = 0.9185, cross_entropy loss = 0.9185, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:57.653348 #train# step 4681, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:59.277698 #train# step 4682, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:00.876113 #train# step 4683, loss = 0.9356, cross_entropy loss = 0.9356, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:02.461956 #train# step 4684, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:04.032194 #train# step 4685, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:05.661672 #train# step 4686, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:07.230008 #train# step 4687, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:08.794848 #train# step 4688, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:10.373693 #train# step 4689, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:11.926853 #train# step 4690, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:13.521354 #train# step 4691, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:15.091949 #train# step 4692, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:16.655797 #train# step 4693, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:18.216858 #train# step 4694, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:19.793755 #train# step 4695, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:21.349694 #train# step 4696, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:22.965869 #train# step 4697, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:24.552065 #train# step 4698, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:26.151972 #train# step 4699, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:27.712918 #train# step 4700, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:29.281448 #train# step 4701, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:30.873200 #train# step 4702, loss = 0.9272, cross_entropy loss = 0.9272, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:32.415917 #train# step 4703, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:33.989185 #train# step 4704, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:35.546969 #train# step 4705, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:37.087540 #train# step 4706, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:38.644483 #train# step 4707, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:40.230045 #train# step 4708, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:41.770961 #train# step 4709, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:43.326875 #train# step 4710, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:44.893285 #train# step 4711, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:46.457789 #train# step 4712, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:48.033078 #train# step 4713, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:49.629208 #train# step 4714, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:51.183706 #train# step 4715, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:52.738671 #train# step 4716, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:54.279082 #train# step 4717, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:55.843014 #train# step 4718, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:57.390547 #train# step 4719, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:58.930765 #train# step 4720, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:00.477860 #train# step 4721, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:02.026380 #train# step 4722, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:03.597373 #train# step 4723, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:05.139888 #train# step 4724, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:06.712338 #train# step 4725, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:08.266586 #train# step 4726, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:09.829364 #train# step 4727, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:11.419472 #train# step 4728, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:12.969063 #train# step 4729, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:14.518935 #train# step 4730, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:16.074910 #train# step 4731, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:17.599022 #train# step 4732, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:19.160247 #train# step 4733, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:20.725153 #train# step 4734, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:22.300761 #train# step 4735, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:23.890525 #train# step 4736, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:25.458694 #train# step 4737, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:27.000437 #train# step 4738, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:28.574592 #train# step 4739, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:30.147701 #train# step 4740, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:31.679884 #train# step 4741, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:33.245517 #train# step 4742, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:34.797187 #train# step 4743, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:36.344965 #train# step 4744, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:37.931335 #train# step 4745, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:39.497678 #train# step 4746, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:41.046722 #train# step 4747, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:42.606503 #train# step 4748, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:44.131291 #train# step 4749, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:45.674981 #train# step 4750, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:47.238196 #train# step 4751, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:48.850233 #train# step 4752, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:50.418075 #train# step 4753, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:51.967358 #train# step 4754, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:53.540478 #train# step 4755, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:55.084400 #train# step 4756, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:56.655423 #train# step 4757, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:58.194772 #train# step 4758, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:59.753238 #train# step 4759, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:01.316007 #train# step 4760, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:02.873455 #train# step 4761, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:04.428514 #train# step 4762, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:05.997982 #train# step 4763, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:07.541968 #train# step 4764, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:09.117676 #train# step 4765, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:10.669082 #train# step 4766, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:12.217482 #train# step 4767, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:13.784471 #train# step 4768, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:15.346044 #train# step 4769, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:16.910046 #train# step 4770, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:18.479428 #train# step 4771, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:20.027549 #train# step 4772, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:21.585100 #train# step 4773, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:23.157190 #train# step 4774, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:24.731251 #train# step 4775, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:26.254895 #train# step 4776, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:27.817684 #train# step 4777, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:29.339655 #train# step 4778, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:30.930845 #train# step 4779, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:32.483447 #train# step 4780, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:34.063480 #train# step 4781, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:35.601583 #train# step 4782, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:37.156138 #train# step 4783, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:38.686999 #train# step 4784, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:40.252129 #train# step 4785, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:41.801096 #train# step 4786, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:43.351653 #train# step 4787, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:44.899044 #train# step 4788, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:46.479843 #train# step 4789, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:48.049741 #train# step 4790, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:49.620832 #train# step 4791, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:51.167132 #train# step 4792, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:52.725138 #train# step 4793, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:54.279131 #train# step 4794, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:55.865460 #train# step 4795, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:57.414613 #train# step 4796, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:58.983605 #train# step 4797, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:00.552098 #train# step 4798, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:02.127888 #train# step 4799, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:03.664174 #train# step 4800, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:05.212895 #train# step 4801, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:06.784775 #train# step 4802, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:08.350762 #train# step 4803, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:09.908244 #train# step 4804, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:11.428412 #train# step 4805, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:12.982596 #train# step 4806, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:14.551739 #train# step 4807, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:16.125426 #train# step 4808, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:17.672582 #train# step 4809, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:19.245829 #train# step 4810, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:20.792885 #train# step 4811, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:22.372032 #train# step 4812, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:23.906960 #train# step 4813, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:25.507607 #train# step 4814, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:27.131193 #train# step 4815, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:28.723723 #train# step 4816, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:30.332719 #train# step 4817, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:31.906610 #train# step 4818, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:33.547426 #train# step 4819, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:35.147026 #train# step 4820, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:36.717708 #train# step 4821, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:38.292614 #train# step 4822, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:39.871866 #train# step 4823, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:41.451994 #train# step 4824, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:43.042218 #train# step 4825, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:44.658205 #train# step 4826, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:46.248743 #train# step 4827, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:47.786277 #train# step 4828, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:49.363262 #train# step 4829, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:50.900389 #train# step 4830, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:52.518915 #train# step 4831, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:54.112832 #train# step 4832, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:55.724009 #train# step 4833, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:57.282306 #train# step 4834, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:58.863428 #train# step 4835, loss = 0.9269, cross_entropy loss = 0.9269, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:00.428292 #train# step 4836, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:01.983349 #train# step 4837, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:03.560437 #train# step 4838, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:05.146340 #train# step 4839, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:06.692416 #train# step 4840, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:08.364786 #train# step 4841, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:09.984998 #train# step 4842, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:11.582431 #train# step 4843, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:13.145547 #train# step 4844, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:14.703536 #train# step 4845, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:16.279571 #train# step 4846, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:17.924286 #train# step 4847, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:19.525811 #train# step 4848, loss = 0.9259, cross_entropy loss = 0.9259, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:21.100545 #train# step 4849, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:22.646164 #train# step 4850, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:24.207958 #train# step 4851, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:25.770315 #train# step 4852, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:27.359959 #train# step 4853, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:28.954442 #train# step 4854, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:30.541826 #train# step 4855, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:32.079837 #train# step 4856, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:33.640180 #train# step 4857, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:35.241305 #train# step 4858, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:36.917303 #train# step 4859, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:38.473406 #train# step 4860, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:40.042061 #train# step 4861, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:41.598416 #train# step 4862, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:43.159708 #train# step 4863, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:44.730368 #train# step 4864, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:46.300755 #train# step 4865, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:47.864659 #train# step 4866, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:49.412751 #train# step 4867, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:50.987582 #train# step 4868, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:52.574217 #train# step 4869, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:54.205517 #train# step 4870, loss = 0.9185, cross_entropy loss = 0.9185, 0.9 sec/batch