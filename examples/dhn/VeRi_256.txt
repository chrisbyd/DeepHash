{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 256,
 'save_dir': './models/',
 'val_batch_size': 100}
initializing
launching session
loading img model from ../../architecture/pretrained_model/reference_pretrain.npy
['hash_layer', 'fc6', 'fc7', 'conv3', 'conv2', 'conv1', 'conv5', 'conv4']
img model loading finished
Initializing Dataset
Dataset already
2021-01-20 20:52:55.423989 #train# start training
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:13.121001 #train# step    1, loss = 2.1508, cross_entropy loss = 2.1508, 12.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:14.785245 #train# step    2, loss = 2.0238, cross_entropy loss = 2.0238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:16.399979 #train# step    3, loss = 1.8587, cross_entropy loss = 1.8587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:18.026903 #train# step    4, loss = 1.6347, cross_entropy loss = 1.6347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:19.652082 #train# step    5, loss = 1.4213, cross_entropy loss = 1.4213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:21.296907 #train# step    6, loss = 1.2874, cross_entropy loss = 1.2874, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:22.973709 #train# step    7, loss = 1.2184, cross_entropy loss = 1.2184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:24.588401 #train# step    8, loss = 1.1732, cross_entropy loss = 1.1732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:26.203441 #train# step    9, loss = 1.1548, cross_entropy loss = 1.1548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:27.827538 #train# step   10, loss = 1.1769, cross_entropy loss = 1.1769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:29.448060 #train# step   11, loss = 1.1897, cross_entropy loss = 1.1897, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:31.059941 #train# step   12, loss = 1.2038, cross_entropy loss = 1.2038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:32.691912 #train# step   13, loss = 1.2227, cross_entropy loss = 1.2227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:34.330125 #train# step   14, loss = 1.2671, cross_entropy loss = 1.2671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:35.965479 #train# step   15, loss = 1.2735, cross_entropy loss = 1.2735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:37.653253 #train# step   16, loss = 1.2997, cross_entropy loss = 1.2997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:39.306672 #train# step   17, loss = 1.3020, cross_entropy loss = 1.3020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:40.956144 #train# step   18, loss = 1.2802, cross_entropy loss = 1.2802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:42.585266 #train# step   19, loss = 1.2550, cross_entropy loss = 1.2550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:44.210866 #train# step   20, loss = 1.2307, cross_entropy loss = 1.2307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:45.875840 #train# step   21, loss = 1.2119, cross_entropy loss = 1.2119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:47.533335 #train# step   22, loss = 1.2042, cross_entropy loss = 1.2042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:49.183507 #train# step   23, loss = 1.1715, cross_entropy loss = 1.1715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:50.852637 #train# step   24, loss = 1.1487, cross_entropy loss = 1.1487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:52.517572 #train# step   25, loss = 1.1467, cross_entropy loss = 1.1467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:54.188076 #train# step   26, loss = 1.1154, cross_entropy loss = 1.1154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:55.834882 #train# step   27, loss = 1.1404, cross_entropy loss = 1.1404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:57.456681 #train# step   28, loss = 1.1220, cross_entropy loss = 1.1220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:53:59.100728 #train# step   29, loss = 1.1373, cross_entropy loss = 1.1373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:00.735126 #train# step   30, loss = 1.1308, cross_entropy loss = 1.1308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:02.375572 #train# step   31, loss = 1.1476, cross_entropy loss = 1.1476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:03.986014 #train# step   32, loss = 1.1353, cross_entropy loss = 1.1353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:05.613983 #train# step   33, loss = 1.1265, cross_entropy loss = 1.1265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:07.279064 #train# step   34, loss = 1.1491, cross_entropy loss = 1.1491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:08.915830 #train# step   35, loss = 1.1362, cross_entropy loss = 1.1362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:10.583690 #train# step   36, loss = 1.1232, cross_entropy loss = 1.1232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:12.231186 #train# step   37, loss = 1.1322, cross_entropy loss = 1.1322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:13.902952 #train# step   38, loss = 1.1501, cross_entropy loss = 1.1501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:15.568146 #train# step   39, loss = 1.1259, cross_entropy loss = 1.1259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:17.230080 #train# step   40, loss = 1.1260, cross_entropy loss = 1.1260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:18.865023 #train# step   41, loss = 1.1374, cross_entropy loss = 1.1374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:20.494380 #train# step   42, loss = 1.1369, cross_entropy loss = 1.1369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:22.158608 #train# step   43, loss = 1.1192, cross_entropy loss = 1.1192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:23.816431 #train# step   44, loss = 1.1290, cross_entropy loss = 1.1290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:25.439558 #train# step   45, loss = 1.1297, cross_entropy loss = 1.1297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:27.085419 #train# step   46, loss = 1.1254, cross_entropy loss = 1.1254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:28.725066 #train# step   47, loss = 1.1194, cross_entropy loss = 1.1194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:30.295239 #train# step   48, loss = 1.1087, cross_entropy loss = 1.1087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:31.864181 #train# step   49, loss = 1.1166, cross_entropy loss = 1.1166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:33.421513 #train# step   50, loss = 1.1052, cross_entropy loss = 1.1052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:34.979998 #train# step   51, loss = 1.0999, cross_entropy loss = 1.0999, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:36.535232 #train# step   52, loss = 1.1052, cross_entropy loss = 1.1052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:38.074340 #train# step   53, loss = 1.1132, cross_entropy loss = 1.1132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:39.608004 #train# step   54, loss = 1.1234, cross_entropy loss = 1.1234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:41.142388 #train# step   55, loss = 1.1208, cross_entropy loss = 1.1208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:42.689447 #train# step   56, loss = 1.1243, cross_entropy loss = 1.1243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:44.232917 #train# step   57, loss = 1.1064, cross_entropy loss = 1.1064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:45.748821 #train# step   58, loss = 1.1331, cross_entropy loss = 1.1331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:47.306046 #train# step   59, loss = 1.0823, cross_entropy loss = 1.0823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:48.851712 #train# step   60, loss = 1.0847, cross_entropy loss = 1.0847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:50.401002 #train# step   61, loss = 1.0994, cross_entropy loss = 1.0994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:51.951667 #train# step   62, loss = 1.1046, cross_entropy loss = 1.1046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:53.497317 #train# step   63, loss = 1.0956, cross_entropy loss = 1.0956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:55.026600 #train# step   64, loss = 1.0965, cross_entropy loss = 1.0965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:56.560560 #train# step   65, loss = 1.1000, cross_entropy loss = 1.1000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:58.092557 #train# step   66, loss = 1.1116, cross_entropy loss = 1.1116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:54:59.728311 #train# step   67, loss = 1.0867, cross_entropy loss = 1.0867, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:01.263135 #train# step   68, loss = 1.1058, cross_entropy loss = 1.1058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:02.823500 #train# step   69, loss = 1.1286, cross_entropy loss = 1.1286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:04.371358 #train# step   70, loss = 1.0939, cross_entropy loss = 1.0939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:05.904434 #train# step   71, loss = 1.1058, cross_entropy loss = 1.1058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:07.466867 #train# step   72, loss = 1.0938, cross_entropy loss = 1.0938, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:09.073628 #train# step   73, loss = 1.0883, cross_entropy loss = 1.0883, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:10.615064 #train# step   74, loss = 1.0870, cross_entropy loss = 1.0870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:12.210126 #train# step   75, loss = 1.0909, cross_entropy loss = 1.0909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:13.739218 #train# step   76, loss = 1.1077, cross_entropy loss = 1.1077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:15.304984 #train# step   77, loss = 1.1067, cross_entropy loss = 1.1067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:16.857260 #train# step   78, loss = 1.1086, cross_entropy loss = 1.1086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:18.412177 #train# step   79, loss = 1.1015, cross_entropy loss = 1.1015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:19.958126 #train# step   80, loss = 1.1003, cross_entropy loss = 1.1003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:21.543293 #train# step   81, loss = 1.0978, cross_entropy loss = 1.0978, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:23.067548 #train# step   82, loss = 1.1063, cross_entropy loss = 1.1063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:24.625163 #train# step   83, loss = 1.0948, cross_entropy loss = 1.0948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:26.189122 #train# step   84, loss = 1.0923, cross_entropy loss = 1.0923, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:27.713518 #train# step   85, loss = 1.0792, cross_entropy loss = 1.0792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:29.268021 #train# step   86, loss = 1.0709, cross_entropy loss = 1.0709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:30.808063 #train# step   87, loss = 1.1072, cross_entropy loss = 1.1072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:32.344621 #train# step   88, loss = 1.1086, cross_entropy loss = 1.1086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:33.897317 #train# step   89, loss = 1.0918, cross_entropy loss = 1.0918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:35.445486 #train# step   90, loss = 1.1001, cross_entropy loss = 1.1001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:36.986342 #train# step   91, loss = 1.0829, cross_entropy loss = 1.0829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:38.543379 #train# step   92, loss = 1.0954, cross_entropy loss = 1.0954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:40.105740 #train# step   93, loss = 1.0814, cross_entropy loss = 1.0814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:41.647649 #train# step   94, loss = 1.0983, cross_entropy loss = 1.0983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:43.208580 #train# step   95, loss = 1.0883, cross_entropy loss = 1.0883, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:44.772350 #train# step   96, loss = 1.0785, cross_entropy loss = 1.0785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:46.288030 #train# step   97, loss = 1.0745, cross_entropy loss = 1.0745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:47.860596 #train# step   98, loss = 1.0732, cross_entropy loss = 1.0732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:49.399905 #train# step   99, loss = 1.1045, cross_entropy loss = 1.1045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:50.936455 #train# step  100, loss = 1.0996, cross_entropy loss = 1.0996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:52.513992 #train# step  101, loss = 1.0670, cross_entropy loss = 1.0670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:54.029913 #train# step  102, loss = 1.0921, cross_entropy loss = 1.0921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:55.589165 #train# step  103, loss = 1.1014, cross_entropy loss = 1.1014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:57.141453 #train# step  104, loss = 1.0791, cross_entropy loss = 1.0791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:55:58.693885 #train# step  105, loss = 1.0761, cross_entropy loss = 1.0761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:00.254845 #train# step  106, loss = 1.0813, cross_entropy loss = 1.0813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:01.810901 #train# step  107, loss = 1.0921, cross_entropy loss = 1.0921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:03.358287 #train# step  108, loss = 1.0739, cross_entropy loss = 1.0739, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:04.853804 #train# step  109, loss = 1.1024, cross_entropy loss = 1.1024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:06.398855 #train# step  110, loss = 1.0795, cross_entropy loss = 1.0795, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:07.972925 #train# step  111, loss = 1.0727, cross_entropy loss = 1.0727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:09.549350 #train# step  112, loss = 1.0563, cross_entropy loss = 1.0563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:11.069365 #train# step  113, loss = 1.0873, cross_entropy loss = 1.0873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:12.590438 #train# step  114, loss = 1.0669, cross_entropy loss = 1.0669, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:14.127176 #train# step  115, loss = 1.0460, cross_entropy loss = 1.0460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:15.675336 #train# step  116, loss = 1.0721, cross_entropy loss = 1.0721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:17.179136 #train# step  117, loss = 1.0875, cross_entropy loss = 1.0875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:18.726952 #train# step  118, loss = 1.0689, cross_entropy loss = 1.0689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:20.245840 #train# step  119, loss = 1.0973, cross_entropy loss = 1.0973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:21.808133 #train# step  120, loss = 1.0960, cross_entropy loss = 1.0960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:23.299467 #train# step  121, loss = 1.1042, cross_entropy loss = 1.1042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:24.877002 #train# step  122, loss = 1.0810, cross_entropy loss = 1.0810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:26.417185 #train# step  123, loss = 1.0782, cross_entropy loss = 1.0782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:27.971854 #train# step  124, loss = 1.0522, cross_entropy loss = 1.0522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:29.522310 #train# step  125, loss = 1.0680, cross_entropy loss = 1.0680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:31.078941 #train# step  126, loss = 1.0805, cross_entropy loss = 1.0805, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:32.643286 #train# step  127, loss = 1.0722, cross_entropy loss = 1.0722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:34.213917 #train# step  128, loss = 1.0674, cross_entropy loss = 1.0674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:35.748778 #train# step  129, loss = 1.0758, cross_entropy loss = 1.0758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:37.282894 #train# step  130, loss = 1.0647, cross_entropy loss = 1.0647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:38.874562 #train# step  131, loss = 1.0382, cross_entropy loss = 1.0382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:40.412666 #train# step  132, loss = 1.0519, cross_entropy loss = 1.0519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:41.947489 #train# step  133, loss = 1.0730, cross_entropy loss = 1.0730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:43.497894 #train# step  134, loss = 1.0604, cross_entropy loss = 1.0604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:45.031741 #train# step  135, loss = 1.0528, cross_entropy loss = 1.0528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:46.600145 #train# step  136, loss = 1.0523, cross_entropy loss = 1.0523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:48.147885 #train# step  137, loss = 1.0696, cross_entropy loss = 1.0696, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:49.733851 #train# step  138, loss = 1.0576, cross_entropy loss = 1.0576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:51.334606 #train# step  139, loss = 1.0605, cross_entropy loss = 1.0605, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:52.867333 #train# step  140, loss = 1.0486, cross_entropy loss = 1.0486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:54.420056 #train# step  141, loss = 1.0799, cross_entropy loss = 1.0799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:56.048702 #train# step  142, loss = 1.0607, cross_entropy loss = 1.0607, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:57.636700 #train# step  143, loss = 1.0334, cross_entropy loss = 1.0334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:56:59.206869 #train# step  144, loss = 1.0659, cross_entropy loss = 1.0659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:00.771617 #train# step  145, loss = 1.0552, cross_entropy loss = 1.0552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:02.317123 #train# step  146, loss = 1.0674, cross_entropy loss = 1.0674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:03.845420 #train# step  147, loss = 1.0812, cross_entropy loss = 1.0812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:05.375623 #train# step  148, loss = 1.0640, cross_entropy loss = 1.0640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:06.951659 #train# step  149, loss = 1.0640, cross_entropy loss = 1.0640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:08.503524 #train# step  150, loss = 1.0625, cross_entropy loss = 1.0625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:10.052037 #train# step  151, loss = 1.0590, cross_entropy loss = 1.0590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:11.571605 #train# step  152, loss = 1.0816, cross_entropy loss = 1.0816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:13.136719 #train# step  153, loss = 1.0699, cross_entropy loss = 1.0699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:14.701502 #train# step  154, loss = 1.0587, cross_entropy loss = 1.0587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:16.217390 #train# step  155, loss = 1.0780, cross_entropy loss = 1.0780, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:17.822469 #train# step  156, loss = 1.0614, cross_entropy loss = 1.0614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:19.396973 #train# step  157, loss = 1.0568, cross_entropy loss = 1.0568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:20.970015 #train# step  158, loss = 1.0638, cross_entropy loss = 1.0638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:22.516691 #train# step  159, loss = 1.0638, cross_entropy loss = 1.0638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:24.046836 #train# step  160, loss = 1.0660, cross_entropy loss = 1.0660, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:25.633882 #train# step  161, loss = 1.0625, cross_entropy loss = 1.0625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:27.188805 #train# step  162, loss = 1.0621, cross_entropy loss = 1.0621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:28.736174 #train# step  163, loss = 1.0483, cross_entropy loss = 1.0483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:30.319293 #train# step  164, loss = 1.0652, cross_entropy loss = 1.0652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:31.891354 #train# step  165, loss = 1.0511, cross_entropy loss = 1.0511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:33.483726 #train# step  166, loss = 1.0548, cross_entropy loss = 1.0548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:35.036200 #train# step  167, loss = 1.0593, cross_entropy loss = 1.0593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:36.579411 #train# step  168, loss = 1.0663, cross_entropy loss = 1.0663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:38.122909 #train# step  169, loss = 1.0446, cross_entropy loss = 1.0446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:39.757542 #train# step  170, loss = 1.0566, cross_entropy loss = 1.0566, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:41.370794 #train# step  171, loss = 1.0415, cross_entropy loss = 1.0415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:42.962444 #train# step  172, loss = 1.0370, cross_entropy loss = 1.0370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:44.527924 #train# step  173, loss = 1.0752, cross_entropy loss = 1.0752, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:46.086433 #train# step  174, loss = 1.0266, cross_entropy loss = 1.0266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:47.636186 #train# step  175, loss = 1.0554, cross_entropy loss = 1.0554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:49.187463 #train# step  176, loss = 1.0591, cross_entropy loss = 1.0591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:50.721885 #train# step  177, loss = 1.0648, cross_entropy loss = 1.0648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:52.267205 #train# step  178, loss = 1.0398, cross_entropy loss = 1.0398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:53.804005 #train# step  179, loss = 1.0349, cross_entropy loss = 1.0349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:55.337439 #train# step  180, loss = 1.0602, cross_entropy loss = 1.0602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:56.879386 #train# step  181, loss = 1.0433, cross_entropy loss = 1.0433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:58.406101 #train# step  182, loss = 1.0403, cross_entropy loss = 1.0403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:57:59.969104 #train# step  183, loss = 1.0350, cross_entropy loss = 1.0350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:01.501257 #train# step  184, loss = 1.0473, cross_entropy loss = 1.0473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:03.039990 #train# step  185, loss = 1.0499, cross_entropy loss = 1.0499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:04.593896 #train# step  186, loss = 1.0509, cross_entropy loss = 1.0509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:06.183557 #train# step  187, loss = 1.0518, cross_entropy loss = 1.0518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:07.798919 #train# step  188, loss = 1.0461, cross_entropy loss = 1.0461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:09.356757 #train# step  189, loss = 1.0533, cross_entropy loss = 1.0533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:10.919654 #train# step  190, loss = 1.0346, cross_entropy loss = 1.0346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:12.475804 #train# step  191, loss = 1.0483, cross_entropy loss = 1.0483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:14.071687 #train# step  192, loss = 1.0547, cross_entropy loss = 1.0547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:15.620633 #train# step  193, loss = 1.0377, cross_entropy loss = 1.0377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:17.185141 #train# step  194, loss = 1.0400, cross_entropy loss = 1.0400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:18.741654 #train# step  195, loss = 1.0498, cross_entropy loss = 1.0498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:20.284070 #train# step  196, loss = 1.0597, cross_entropy loss = 1.0597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:21.850416 #train# step  197, loss = 1.0655, cross_entropy loss = 1.0655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:23.404557 #train# step  198, loss = 1.0286, cross_entropy loss = 1.0286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:24.953680 #train# step  199, loss = 1.0459, cross_entropy loss = 1.0459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:26.488943 #train# step  200, loss = 1.0506, cross_entropy loss = 1.0506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:28.074541 #train# step  201, loss = 1.0293, cross_entropy loss = 1.0293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:29.638770 #train# step  202, loss = 1.0499, cross_entropy loss = 1.0499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:31.166450 #train# step  203, loss = 1.0397, cross_entropy loss = 1.0397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:32.715982 #train# step  204, loss = 1.0454, cross_entropy loss = 1.0454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:34.297281 #train# step  205, loss = 1.0374, cross_entropy loss = 1.0374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:35.853699 #train# step  206, loss = 1.0549, cross_entropy loss = 1.0549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:37.421842 #train# step  207, loss = 1.0391, cross_entropy loss = 1.0391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:38.949357 #train# step  208, loss = 1.0278, cross_entropy loss = 1.0278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:40.474348 #train# step  209, loss = 1.0526, cross_entropy loss = 1.0526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:42.001357 #train# step  210, loss = 1.0341, cross_entropy loss = 1.0341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:43.539500 #train# step  211, loss = 1.0541, cross_entropy loss = 1.0541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:45.060523 #train# step  212, loss = 1.0427, cross_entropy loss = 1.0427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:46.588934 #train# step  213, loss = 1.0478, cross_entropy loss = 1.0478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:48.140712 #train# step  214, loss = 1.0295, cross_entropy loss = 1.0295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:49.688392 #train# step  215, loss = 1.0587, cross_entropy loss = 1.0587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:51.219461 #train# step  216, loss = 1.0345, cross_entropy loss = 1.0345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:52.772347 #train# step  217, loss = 1.0648, cross_entropy loss = 1.0648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:54.290209 #train# step  218, loss = 1.0345, cross_entropy loss = 1.0345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:55.816464 #train# step  219, loss = 1.0333, cross_entropy loss = 1.0333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:57.417625 #train# step  220, loss = 1.0144, cross_entropy loss = 1.0144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:58:58.945414 #train# step  221, loss = 1.0554, cross_entropy loss = 1.0554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:00.505810 #train# step  222, loss = 1.0318, cross_entropy loss = 1.0318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:02.046723 #train# step  223, loss = 1.0545, cross_entropy loss = 1.0545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:03.571590 #train# step  224, loss = 1.0343, cross_entropy loss = 1.0343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:05.137665 #train# step  225, loss = 1.0537, cross_entropy loss = 1.0537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:06.722654 #train# step  226, loss = 1.0153, cross_entropy loss = 1.0153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:08.369238 #train# step  227, loss = 1.0430, cross_entropy loss = 1.0430, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:09.916114 #train# step  228, loss = 1.0489, cross_entropy loss = 1.0489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:11.498356 #train# step  229, loss = 1.0327, cross_entropy loss = 1.0327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:13.065464 #train# step  230, loss = 1.0531, cross_entropy loss = 1.0531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:14.602018 #train# step  231, loss = 1.0260, cross_entropy loss = 1.0260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:16.152854 #train# step  232, loss = 1.0427, cross_entropy loss = 1.0427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:17.655645 #train# step  233, loss = 1.0478, cross_entropy loss = 1.0478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:19.214726 #train# step  234, loss = 1.0550, cross_entropy loss = 1.0550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:20.763445 #train# step  235, loss = 1.0317, cross_entropy loss = 1.0317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:22.321121 #train# step  236, loss = 1.0566, cross_entropy loss = 1.0566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:23.872275 #train# step  237, loss = 1.0326, cross_entropy loss = 1.0326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:25.441995 #train# step  238, loss = 1.0155, cross_entropy loss = 1.0155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:26.992716 #train# step  239, loss = 1.0286, cross_entropy loss = 1.0286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:28.539168 #train# step  240, loss = 1.0256, cross_entropy loss = 1.0256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:30.108893 #train# step  241, loss = 1.0289, cross_entropy loss = 1.0289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:31.686042 #train# step  242, loss = 1.0378, cross_entropy loss = 1.0378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:33.229281 #train# step  243, loss = 1.0267, cross_entropy loss = 1.0267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:34.783870 #train# step  244, loss = 1.0282, cross_entropy loss = 1.0282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:36.346401 #train# step  245, loss = 1.0529, cross_entropy loss = 1.0529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:37.889167 #train# step  246, loss = 1.0528, cross_entropy loss = 1.0528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:39.442991 #train# step  247, loss = 1.0332, cross_entropy loss = 1.0332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:40.972765 #train# step  248, loss = 1.0434, cross_entropy loss = 1.0434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:42.517290 #train# step  249, loss = 1.0230, cross_entropy loss = 1.0230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:44.060552 #train# step  250, loss = 1.0402, cross_entropy loss = 1.0402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:45.627737 #train# step  251, loss = 1.0403, cross_entropy loss = 1.0403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:47.181831 #train# step  252, loss = 1.0284, cross_entropy loss = 1.0284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:48.730997 #train# step  253, loss = 1.0276, cross_entropy loss = 1.0276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:50.342091 #train# step  254, loss = 1.0322, cross_entropy loss = 1.0322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:51.916345 #train# step  255, loss = 1.0271, cross_entropy loss = 1.0271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:53.497319 #train# step  256, loss = 1.0274, cross_entropy loss = 1.0274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:55.063380 #train# step  257, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:56.618726 #train# step  258, loss = 1.0345, cross_entropy loss = 1.0345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:58.132405 #train# step  259, loss = 1.0362, cross_entropy loss = 1.0362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 20:59:59.703791 #train# step  260, loss = 1.0509, cross_entropy loss = 1.0509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:01.244497 #train# step  261, loss = 1.0183, cross_entropy loss = 1.0183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:02.814198 #train# step  262, loss = 1.0197, cross_entropy loss = 1.0197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:04.347399 #train# step  263, loss = 1.0477, cross_entropy loss = 1.0477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:05.897481 #train# step  264, loss = 1.0309, cross_entropy loss = 1.0309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:07.437922 #train# step  265, loss = 1.0151, cross_entropy loss = 1.0151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:08.974242 #train# step  266, loss = 1.0153, cross_entropy loss = 1.0153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:10.496277 #train# step  267, loss = 1.0129, cross_entropy loss = 1.0129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:11.996442 #train# step  268, loss = 1.0434, cross_entropy loss = 1.0434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:13.550908 #train# step  269, loss = 1.0548, cross_entropy loss = 1.0548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:15.084314 #train# step  270, loss = 1.0340, cross_entropy loss = 1.0340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:16.607585 #train# step  271, loss = 1.0399, cross_entropy loss = 1.0399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:18.161045 #train# step  272, loss = 1.0269, cross_entropy loss = 1.0269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:19.707830 #train# step  273, loss = 1.0236, cross_entropy loss = 1.0236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:21.261501 #train# step  274, loss = 1.0505, cross_entropy loss = 1.0505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:22.819773 #train# step  275, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:24.362231 #train# step  276, loss = 1.0289, cross_entropy loss = 1.0289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:25.981439 #train# step  277, loss = 1.0294, cross_entropy loss = 1.0294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:27.547446 #train# step  278, loss = 1.0272, cross_entropy loss = 1.0272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:29.102794 #train# step  279, loss = 1.0371, cross_entropy loss = 1.0371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:30.654137 #train# step  280, loss = 1.0189, cross_entropy loss = 1.0189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:32.221737 #train# step  281, loss = 1.0388, cross_entropy loss = 1.0388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:33.777317 #train# step  282, loss = 1.0322, cross_entropy loss = 1.0322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:35.339688 #train# step  283, loss = 1.0393, cross_entropy loss = 1.0393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:36.890781 #train# step  284, loss = 1.0089, cross_entropy loss = 1.0089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:38.464966 #train# step  285, loss = 1.0275, cross_entropy loss = 1.0275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:39.992535 #train# step  286, loss = 1.0471, cross_entropy loss = 1.0471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:41.523632 #train# step  287, loss = 1.0348, cross_entropy loss = 1.0348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:43.092848 #train# step  288, loss = 1.0469, cross_entropy loss = 1.0469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:44.639280 #train# step  289, loss = 1.0244, cross_entropy loss = 1.0244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:46.234622 #train# step  290, loss = 1.0207, cross_entropy loss = 1.0207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:47.758421 #train# step  291, loss = 1.0209, cross_entropy loss = 1.0209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:49.299993 #train# step  292, loss = 1.0227, cross_entropy loss = 1.0227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:50.845358 #train# step  293, loss = 1.0189, cross_entropy loss = 1.0189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:52.406926 #train# step  294, loss = 1.0274, cross_entropy loss = 1.0274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:53.940744 #train# step  295, loss = 1.0192, cross_entropy loss = 1.0192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:55.470660 #train# step  296, loss = 1.0323, cross_entropy loss = 1.0323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:57.034660 #train# step  297, loss = 1.0385, cross_entropy loss = 1.0385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:00:58.596684 #train# step  298, loss = 1.0344, cross_entropy loss = 1.0344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:00.126916 #train# step  299, loss = 1.0253, cross_entropy loss = 1.0253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:01.652753 #train# step  300, loss = 1.0244, cross_entropy loss = 1.0244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:03.192643 #train# step  301, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:04.764045 #train# step  302, loss = 1.0176, cross_entropy loss = 1.0176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:06.336858 #train# step  303, loss = 1.0413, cross_entropy loss = 1.0413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:07.908843 #train# step  304, loss = 1.0262, cross_entropy loss = 1.0262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:09.465726 #train# step  305, loss = 1.0212, cross_entropy loss = 1.0212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:10.999779 #train# step  306, loss = 1.0252, cross_entropy loss = 1.0252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:12.533875 #train# step  307, loss = 1.0201, cross_entropy loss = 1.0201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:14.041701 #train# step  308, loss = 1.0101, cross_entropy loss = 1.0101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:15.584184 #train# step  309, loss = 1.0263, cross_entropy loss = 1.0263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:17.153115 #train# step  310, loss = 1.0254, cross_entropy loss = 1.0254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:18.724696 #train# step  311, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:20.283813 #train# step  312, loss = 1.0243, cross_entropy loss = 1.0243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:21.834730 #train# step  313, loss = 1.0333, cross_entropy loss = 1.0333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:23.394433 #train# step  314, loss = 1.0045, cross_entropy loss = 1.0045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:24.974686 #train# step  315, loss = 1.0213, cross_entropy loss = 1.0213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:26.566783 #train# step  316, loss = 1.0233, cross_entropy loss = 1.0233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:28.114055 #train# step  317, loss = 1.0315, cross_entropy loss = 1.0315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:29.690022 #train# step  318, loss = 1.0277, cross_entropy loss = 1.0277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:31.244497 #train# step  319, loss = 1.0289, cross_entropy loss = 1.0289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:32.772359 #train# step  320, loss = 1.0202, cross_entropy loss = 1.0202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:34.348121 #train# step  321, loss = 1.0337, cross_entropy loss = 1.0337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:35.867072 #train# step  322, loss = 1.0432, cross_entropy loss = 1.0432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:37.385611 #train# step  323, loss = 1.0310, cross_entropy loss = 1.0310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:38.917002 #train# step  324, loss = 1.0246, cross_entropy loss = 1.0246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:40.470054 #train# step  325, loss = 1.0462, cross_entropy loss = 1.0462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:42.026121 #train# step  326, loss = 1.0153, cross_entropy loss = 1.0153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:43.557241 #train# step  327, loss = 1.0187, cross_entropy loss = 1.0187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:45.113926 #train# step  328, loss = 0.9998, cross_entropy loss = 0.9998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:46.685433 #train# step  329, loss = 1.0179, cross_entropy loss = 1.0179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:48.231446 #train# step  330, loss = 1.0031, cross_entropy loss = 1.0031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:49.809125 #train# step  331, loss = 1.0267, cross_entropy loss = 1.0267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:51.362106 #train# step  332, loss = 1.0218, cross_entropy loss = 1.0218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:52.887903 #train# step  333, loss = 1.0395, cross_entropy loss = 1.0395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:54.430992 #train# step  334, loss = 1.0478, cross_entropy loss = 1.0478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:55.995631 #train# step  335, loss = 1.0202, cross_entropy loss = 1.0202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:57.551942 #train# step  336, loss = 1.0176, cross_entropy loss = 1.0176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:01:59.057578 #train# step  337, loss = 1.0344, cross_entropy loss = 1.0344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:00.615649 #train# step  338, loss = 1.0185, cross_entropy loss = 1.0185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:02.176457 #train# step  339, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:03.722476 #train# step  340, loss = 1.0114, cross_entropy loss = 1.0114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:05.273912 #train# step  341, loss = 1.0416, cross_entropy loss = 1.0416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:06.802042 #train# step  342, loss = 1.0228, cross_entropy loss = 1.0228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:08.374275 #train# step  343, loss = 1.0079, cross_entropy loss = 1.0079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:09.920210 #train# step  344, loss = 1.0446, cross_entropy loss = 1.0446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:11.487137 #train# step  345, loss = 1.0333, cross_entropy loss = 1.0333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:13.048773 #train# step  346, loss = 1.0248, cross_entropy loss = 1.0248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:14.575779 #train# step  347, loss = 1.0333, cross_entropy loss = 1.0333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:16.127361 #train# step  348, loss = 1.0009, cross_entropy loss = 1.0009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:17.689247 #train# step  349, loss = 1.0312, cross_entropy loss = 1.0312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:19.184674 #train# step  350, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:20.745878 #train# step  351, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:22.317914 #train# step  352, loss = 1.0173, cross_entropy loss = 1.0173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:23.881266 #train# step  353, loss = 1.0167, cross_entropy loss = 1.0167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:25.437622 #train# step  354, loss = 1.0257, cross_entropy loss = 1.0257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:26.975006 #train# step  355, loss = 1.0083, cross_entropy loss = 1.0083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:28.520738 #train# step  356, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:30.083563 #train# step  357, loss = 1.0110, cross_entropy loss = 1.0110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:31.627743 #train# step  358, loss = 1.0234, cross_entropy loss = 1.0234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:33.138914 #train# step  359, loss = 1.0352, cross_entropy loss = 1.0352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:34.699375 #train# step  360, loss = 1.0132, cross_entropy loss = 1.0132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:36.236809 #train# step  361, loss = 1.0176, cross_entropy loss = 1.0176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:37.802810 #train# step  362, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:39.361599 #train# step  363, loss = 1.0228, cross_entropy loss = 1.0228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:40.888558 #train# step  364, loss = 1.0227, cross_entropy loss = 1.0227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:42.442881 #train# step  365, loss = 1.0138, cross_entropy loss = 1.0138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:44.001256 #train# step  366, loss = 1.0146, cross_entropy loss = 1.0146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:45.591083 #train# step  367, loss = 1.0211, cross_entropy loss = 1.0211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:47.155378 #train# step  368, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:48.685723 #train# step  369, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:50.236832 #train# step  370, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:51.798134 #train# step  371, loss = 1.0187, cross_entropy loss = 1.0187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:53.351039 #train# step  372, loss = 1.0419, cross_entropy loss = 1.0419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:54.896267 #train# step  373, loss = 1.0198, cross_entropy loss = 1.0198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:56.462714 #train# step  374, loss = 1.0022, cross_entropy loss = 1.0022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:57.961758 #train# step  375, loss = 1.0179, cross_entropy loss = 1.0179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:02:59.540710 #train# step  376, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:01.108543 #train# step  377, loss = 1.0140, cross_entropy loss = 1.0140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:02.651716 #train# step  378, loss = 1.0082, cross_entropy loss = 1.0082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:04.202395 #train# step  379, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:05.761762 #train# step  380, loss = 1.0199, cross_entropy loss = 1.0199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:07.302089 #train# step  381, loss = 1.0163, cross_entropy loss = 1.0163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:08.832296 #train# step  382, loss = 1.0473, cross_entropy loss = 1.0473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:10.376941 #train# step  383, loss = 1.0470, cross_entropy loss = 1.0470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:11.910882 #train# step  384, loss = 1.0273, cross_entropy loss = 1.0273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:13.444123 #train# step  385, loss = 1.0327, cross_entropy loss = 1.0327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:14.982659 #train# step  386, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:16.524056 #train# step  387, loss = 1.0065, cross_entropy loss = 1.0065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:18.068560 #train# step  388, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:19.617948 #train# step  389, loss = 1.0316, cross_entropy loss = 1.0316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:21.171651 #train# step  390, loss = 1.0240, cross_entropy loss = 1.0240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:22.730923 #train# step  391, loss = 1.0184, cross_entropy loss = 1.0184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:24.297526 #train# step  392, loss = 0.9979, cross_entropy loss = 0.9979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:25.872645 #train# step  393, loss = 1.0165, cross_entropy loss = 1.0165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:27.412845 #train# step  394, loss = 1.0290, cross_entropy loss = 1.0290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:28.954116 #train# step  395, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:30.521444 #train# step  396, loss = 1.0309, cross_entropy loss = 1.0309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:32.060308 #train# step  397, loss = 1.0131, cross_entropy loss = 1.0131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:33.631518 #train# step  398, loss = 1.0291, cross_entropy loss = 1.0291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:35.184677 #train# step  399, loss = 1.0247, cross_entropy loss = 1.0247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:36.726860 #train# step  400, loss = 1.0295, cross_entropy loss = 1.0295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:38.299831 #train# step  401, loss = 1.0034, cross_entropy loss = 1.0034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:39.868434 #train# step  402, loss = 1.0141, cross_entropy loss = 1.0141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:41.408909 #train# step  403, loss = 1.0415, cross_entropy loss = 1.0415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:42.955720 #train# step  404, loss = 1.0167, cross_entropy loss = 1.0167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:44.522716 #train# step  405, loss = 1.0075, cross_entropy loss = 1.0075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:46.042977 #train# step  406, loss = 1.0249, cross_entropy loss = 1.0249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:47.588438 #train# step  407, loss = 1.0025, cross_entropy loss = 1.0025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:49.177605 #train# step  408, loss = 1.0147, cross_entropy loss = 1.0147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:50.735904 #train# step  409, loss = 1.0250, cross_entropy loss = 1.0250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:52.288451 #train# step  410, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:53.810768 #train# step  411, loss = 1.0098, cross_entropy loss = 1.0098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:55.347111 #train# step  412, loss = 1.0166, cross_entropy loss = 1.0166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:56.893750 #train# step  413, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:58.398241 #train# step  414, loss = 1.0257, cross_entropy loss = 1.0257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:03:59.976102 #train# step  415, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:01.517107 #train# step  416, loss = 1.0067, cross_entropy loss = 1.0067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:03.053519 #train# step  417, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:04.597413 #train# step  418, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:06.137637 #train# step  419, loss = 1.0182, cross_entropy loss = 1.0182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:07.687297 #train# step  420, loss = 1.0141, cross_entropy loss = 1.0141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:09.243819 #train# step  421, loss = 1.0021, cross_entropy loss = 1.0021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:10.785422 #train# step  422, loss = 1.0146, cross_entropy loss = 1.0146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:12.372125 #train# step  423, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:13.939513 #train# step  424, loss = 1.0087, cross_entropy loss = 1.0087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:15.536620 #train# step  425, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:17.062834 #train# step  426, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:18.610423 #train# step  427, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:20.172793 #train# step  428, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:21.727310 #train# step  429, loss = 1.0206, cross_entropy loss = 1.0206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:23.301787 #train# step  430, loss = 1.0048, cross_entropy loss = 1.0048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:24.863260 #train# step  431, loss = 1.0000, cross_entropy loss = 1.0000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:26.411165 #train# step  432, loss = 1.0159, cross_entropy loss = 1.0159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:27.936840 #train# step  433, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:29.512632 #train# step  434, loss = 1.0081, cross_entropy loss = 1.0081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:31.096084 #train# step  435, loss = 1.0080, cross_entropy loss = 1.0080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:32.634191 #train# step  436, loss = 1.0159, cross_entropy loss = 1.0159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:34.128389 #train# step  437, loss = 1.0223, cross_entropy loss = 1.0223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:35.649318 #train# step  438, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:37.214640 #train# step  439, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:38.773255 #train# step  440, loss = 1.0312, cross_entropy loss = 1.0312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:40.364986 #train# step  441, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:41.927567 #train# step  442, loss = 1.0042, cross_entropy loss = 1.0042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:43.469668 #train# step  443, loss = 1.0290, cross_entropy loss = 1.0290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:45.010300 #train# step  444, loss = 1.0106, cross_entropy loss = 1.0106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:46.569170 #train# step  445, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:48.117944 #train# step  446, loss = 1.0222, cross_entropy loss = 1.0222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:49.641486 #train# step  447, loss = 1.0295, cross_entropy loss = 1.0295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:51.216928 #train# step  448, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:52.727153 #train# step  449, loss = 1.0090, cross_entropy loss = 1.0090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:54.302966 #train# step  450, loss = 1.0209, cross_entropy loss = 1.0209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:55.854191 #train# step  451, loss = 1.0081, cross_entropy loss = 1.0081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:57.412937 #train# step  452, loss = 1.0137, cross_entropy loss = 1.0137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:04:58.908657 #train# step  453, loss = 1.0142, cross_entropy loss = 1.0142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:00.467984 #train# step  454, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:02.029846 #train# step  455, loss = 1.0073, cross_entropy loss = 1.0073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:03.557808 #train# step  456, loss = 1.0165, cross_entropy loss = 1.0165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:05.108530 #train# step  457, loss = 1.0146, cross_entropy loss = 1.0146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:06.645953 #train# step  458, loss = 1.0160, cross_entropy loss = 1.0160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:08.162905 #train# step  459, loss = 1.0220, cross_entropy loss = 1.0220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:09.747377 #train# step  460, loss = 1.0102, cross_entropy loss = 1.0102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:11.271676 #train# step  461, loss = 0.9992, cross_entropy loss = 0.9992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:12.827636 #train# step  462, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:14.374328 #train# step  463, loss = 1.0163, cross_entropy loss = 1.0163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:15.942710 #train# step  464, loss = 1.0201, cross_entropy loss = 1.0201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:17.519248 #train# step  465, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:19.054937 #train# step  466, loss = 1.0115, cross_entropy loss = 1.0115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:20.603381 #train# step  467, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:22.139213 #train# step  468, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:23.688285 #train# step  469, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:25.281111 #train# step  470, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:26.819961 #train# step  471, loss = 1.0179, cross_entropy loss = 1.0179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:28.411577 #train# step  472, loss = 1.0160, cross_entropy loss = 1.0160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:29.986492 #train# step  473, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:31.532625 #train# step  474, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:33.070535 #train# step  475, loss = 1.0095, cross_entropy loss = 1.0095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:34.615260 #train# step  476, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:36.171447 #train# step  477, loss = 1.0115, cross_entropy loss = 1.0115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:37.739353 #train# step  478, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:39.295598 #train# step  479, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:40.865009 #train# step  480, loss = 1.0178, cross_entropy loss = 1.0178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:42.420054 #train# step  481, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:43.995490 #train# step  482, loss = 1.0078, cross_entropy loss = 1.0078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:45.504090 #train# step  483, loss = 1.0171, cross_entropy loss = 1.0171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:47.086124 #train# step  484, loss = 1.0087, cross_entropy loss = 1.0087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:48.625727 #train# step  485, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:50.219782 #train# step  486, loss = 1.0073, cross_entropy loss = 1.0073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:51.754954 #train# step  487, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:53.281958 #train# step  488, loss = 1.0288, cross_entropy loss = 1.0288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:54.825107 #train# step  489, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:56.371189 #train# step  490, loss = 1.0126, cross_entropy loss = 1.0126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:57.902839 #train# step  491, loss = 1.0068, cross_entropy loss = 1.0068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:05:59.473219 #train# step  492, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:01.002707 #train# step  493, loss = 1.0213, cross_entropy loss = 1.0213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:02.559207 #train# step  494, loss = 1.0021, cross_entropy loss = 1.0021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:04.257685 #train# step  495, loss = 1.0050, cross_entropy loss = 1.0050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:05.817002 #train# step  496, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:07.357094 #train# step  497, loss = 1.0059, cross_entropy loss = 1.0059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:08.905725 #train# step  498, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:10.453182 #train# step  499, loss = 1.0024, cross_entropy loss = 1.0024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:11.968338 #train# step  500, loss = 1.0051, cross_entropy loss = 1.0051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:13.532479 #train# step  501, loss = 0.9943, cross_entropy loss = 0.9943, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:15.081951 #train# step  502, loss = 1.0035, cross_entropy loss = 1.0035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:16.616175 #train# step  503, loss = 1.0045, cross_entropy loss = 1.0045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:18.151637 #train# step  504, loss = 1.0198, cross_entropy loss = 1.0198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:19.705485 #train# step  505, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:21.243129 #train# step  506, loss = 1.0155, cross_entropy loss = 1.0155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:22.800744 #train# step  507, loss = 1.0175, cross_entropy loss = 1.0175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:24.360965 #train# step  508, loss = 1.0101, cross_entropy loss = 1.0101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:25.889247 #train# step  509, loss = 1.0006, cross_entropy loss = 1.0006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:27.443693 #train# step  510, loss = 1.0099, cross_entropy loss = 1.0099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:28.970220 #train# step  511, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:30.534582 #train# step  512, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:32.115887 #train# step  513, loss = 1.0056, cross_entropy loss = 1.0056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:33.661402 #train# step  514, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:35.223553 #train# step  515, loss = 1.0036, cross_entropy loss = 1.0036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:36.751987 #train# step  516, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:38.306216 #train# step  517, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:39.888627 #train# step  518, loss = 1.0269, cross_entropy loss = 1.0269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:41.462644 #train# step  519, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:43.011994 #train# step  520, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:44.566917 #train# step  521, loss = 1.0204, cross_entropy loss = 1.0204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:46.129538 #train# step  522, loss = 0.9940, cross_entropy loss = 0.9940, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:47.675053 #train# step  523, loss = 1.0149, cross_entropy loss = 1.0149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:49.249140 #train# step  524, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:50.811648 #train# step  525, loss = 1.0106, cross_entropy loss = 1.0106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:52.358239 #train# step  526, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:53.900589 #train# step  527, loss = 1.0061, cross_entropy loss = 1.0061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:55.456076 #train# step  528, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:56.997005 #train# step  529, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:06:58.563970 #train# step  530, loss = 0.9995, cross_entropy loss = 0.9995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:00.139848 #train# step  531, loss = 0.9990, cross_entropy loss = 0.9990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:01.686194 #train# step  532, loss = 1.0058, cross_entropy loss = 1.0058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:03.239127 #train# step  533, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:04.799307 #train# step  534, loss = 1.0030, cross_entropy loss = 1.0030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:06.344632 #train# step  535, loss = 1.0005, cross_entropy loss = 1.0005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:07.871803 #train# step  536, loss = 1.0067, cross_entropy loss = 1.0067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:09.405220 #train# step  537, loss = 1.0293, cross_entropy loss = 1.0293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:10.920850 #train# step  538, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:12.416064 #train# step  539, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:13.971135 #train# step  540, loss = 1.0141, cross_entropy loss = 1.0141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:15.532994 #train# step  541, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:17.048376 #train# step  542, loss = 1.0180, cross_entropy loss = 1.0180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:18.627981 #train# step  543, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:20.148470 #train# step  544, loss = 1.0062, cross_entropy loss = 1.0062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:21.716519 #train# step  545, loss = 1.0104, cross_entropy loss = 1.0104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:23.249266 #train# step  546, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:24.788387 #train# step  547, loss = 1.0101, cross_entropy loss = 1.0101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:26.322667 #train# step  548, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:27.867864 #train# step  549, loss = 0.9924, cross_entropy loss = 0.9924, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:29.397092 #train# step  550, loss = 1.0131, cross_entropy loss = 1.0131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:30.941676 #train# step  551, loss = 1.0162, cross_entropy loss = 1.0162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:32.466009 #train# step  552, loss = 1.0172, cross_entropy loss = 1.0172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:34.000634 #train# step  553, loss = 1.0195, cross_entropy loss = 1.0195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:35.568958 #train# step  554, loss = 1.0033, cross_entropy loss = 1.0033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:37.115502 #train# step  555, loss = 1.0054, cross_entropy loss = 1.0054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:38.705844 #train# step  556, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:40.262750 #train# step  557, loss = 1.0081, cross_entropy loss = 1.0081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:41.804249 #train# step  558, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:43.390042 #train# step  559, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:44.963888 #train# step  560, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:46.486261 #train# step  561, loss = 1.0016, cross_entropy loss = 1.0016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:48.038656 #train# step  562, loss = 1.0107, cross_entropy loss = 1.0107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:49.579291 #train# step  563, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:51.155094 #train# step  564, loss = 1.0061, cross_entropy loss = 1.0061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:52.709944 #train# step  565, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:54.265833 #train# step  566, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:55.821752 #train# step  567, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:57.370160 #train# step  568, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:07:58.915533 #train# step  569, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:00.448196 #train# step  570, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:02.060911 #train# step  571, loss = 0.9974, cross_entropy loss = 0.9974, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:03.658373 #train# step  572, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:05.232963 #train# step  573, loss = 0.9978, cross_entropy loss = 0.9978, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:06.737257 #train# step  574, loss = 1.0177, cross_entropy loss = 1.0177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:08.315025 #train# step  575, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:09.901543 #train# step  576, loss = 1.0111, cross_entropy loss = 1.0111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:11.591626 #train# step  577, loss = 1.0165, cross_entropy loss = 1.0165, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:13.130470 #train# step  578, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:14.714648 #train# step  579, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:16.278911 #train# step  580, loss = 0.9974, cross_entropy loss = 0.9974, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:17.835031 #train# step  581, loss = 1.0076, cross_entropy loss = 1.0076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:19.356236 #train# step  582, loss = 1.0005, cross_entropy loss = 1.0005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:20.926010 #train# step  583, loss = 1.0048, cross_entropy loss = 1.0048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:22.570624 #train# step  584, loss = 1.0047, cross_entropy loss = 1.0047, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:24.165745 #train# step  585, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:25.727692 #train# step  586, loss = 1.0276, cross_entropy loss = 1.0276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:27.341631 #train# step  587, loss = 1.0073, cross_entropy loss = 1.0073, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:28.903529 #train# step  588, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:30.461023 #train# step  589, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:32.001613 #train# step  590, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:33.596899 #train# step  591, loss = 1.0020, cross_entropy loss = 1.0020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:35.158925 #train# step  592, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:36.726507 #train# step  593, loss = 1.0042, cross_entropy loss = 1.0042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:38.300957 #train# step  594, loss = 1.0026, cross_entropy loss = 1.0026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:39.874148 #train# step  595, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:41.399337 #train# step  596, loss = 1.0097, cross_entropy loss = 1.0097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:42.948231 #train# step  597, loss = 1.0092, cross_entropy loss = 1.0092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:44.495827 #train# step  598, loss = 1.0072, cross_entropy loss = 1.0072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:46.023388 #train# step  599, loss = 0.9969, cross_entropy loss = 0.9969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:47.589987 #train# step  600, loss = 0.9918, cross_entropy loss = 0.9918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:49.151423 #train# step  601, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:50.721368 #train# step  602, loss = 1.0221, cross_entropy loss = 1.0221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:52.285647 #train# step  603, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:53.840617 #train# step  604, loss = 1.0001, cross_entropy loss = 1.0001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:55.387614 #train# step  605, loss = 1.0076, cross_entropy loss = 1.0076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:56.934368 #train# step  606, loss = 1.0179, cross_entropy loss = 1.0179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:08:58.486658 #train# step  607, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:00.042116 #train# step  608, loss = 0.9811, cross_entropy loss = 0.9811, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:01.580009 #train# step  609, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:03.099484 #train# step  610, loss = 1.0057, cross_entropy loss = 1.0057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:04.634779 #train# step  611, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:06.149436 #train# step  612, loss = 1.0098, cross_entropy loss = 1.0098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:07.695350 #train# step  613, loss = 1.0132, cross_entropy loss = 1.0132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:09.233302 #train# step  614, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:10.808253 #train# step  615, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:12.371614 #train# step  616, loss = 1.0194, cross_entropy loss = 1.0194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:13.908439 #train# step  617, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:15.449277 #train# step  618, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:17.021346 #train# step  619, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:18.551813 #train# step  620, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:20.047141 #train# step  621, loss = 1.0383, cross_entropy loss = 1.0383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:21.591624 #train# step  622, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:23.155745 #train# step  623, loss = 0.9979, cross_entropy loss = 0.9979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:24.708592 #train# step  624, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:26.265023 #train# step  625, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:27.792215 #train# step  626, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:29.323195 #train# step  627, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:30.905938 #train# step  628, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:32.465662 #train# step  629, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:34.041323 #train# step  630, loss = 1.0127, cross_entropy loss = 1.0127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:35.585277 #train# step  631, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:37.112948 #train# step  632, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:38.666026 #train# step  633, loss = 0.9942, cross_entropy loss = 0.9942, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:40.207276 #train# step  634, loss = 1.0047, cross_entropy loss = 1.0047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:41.757572 #train# step  635, loss = 1.0089, cross_entropy loss = 1.0089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:43.318520 #train# step  636, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:44.857531 #train# step  637, loss = 1.0025, cross_entropy loss = 1.0025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:46.400078 #train# step  638, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:47.956280 #train# step  639, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:49.486863 #train# step  640, loss = 0.9985, cross_entropy loss = 0.9985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:51.049781 #train# step  641, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:52.604560 #train# step  642, loss = 1.0115, cross_entropy loss = 1.0115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:54.147524 #train# step  643, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:55.708667 #train# step  644, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:57.270201 #train# step  645, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:09:58.799165 #train# step  646, loss = 1.0061, cross_entropy loss = 1.0061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:00.381369 #train# step  647, loss = 1.0082, cross_entropy loss = 1.0082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:01.915834 #train# step  648, loss = 0.9976, cross_entropy loss = 0.9976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:03.511298 #train# step  649, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:05.042304 #train# step  650, loss = 1.0182, cross_entropy loss = 1.0182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:06.577866 #train# step  651, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:08.144234 #train# step  652, loss = 0.9993, cross_entropy loss = 0.9993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:09.713010 #train# step  653, loss = 1.0086, cross_entropy loss = 1.0086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:11.280165 #train# step  654, loss = 1.0044, cross_entropy loss = 1.0044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:12.845080 #train# step  655, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:14.390614 #train# step  656, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:15.940323 #train# step  657, loss = 0.9946, cross_entropy loss = 0.9946, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:17.484535 #train# step  658, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:19.052673 #train# step  659, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:20.608125 #train# step  660, loss = 1.0060, cross_entropy loss = 1.0060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:22.150542 #train# step  661, loss = 1.0103, cross_entropy loss = 1.0103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:23.705913 #train# step  662, loss = 1.0138, cross_entropy loss = 1.0138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:25.263900 #train# step  663, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:26.842029 #train# step  664, loss = 0.9920, cross_entropy loss = 0.9920, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:28.372592 #train# step  665, loss = 0.9919, cross_entropy loss = 0.9919, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:29.918550 #train# step  666, loss = 1.0070, cross_entropy loss = 1.0070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:31.459976 #train# step  667, loss = 1.0008, cross_entropy loss = 1.0008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:33.011895 #train# step  668, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:34.607683 #train# step  669, loss = 1.0137, cross_entropy loss = 1.0137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:36.168531 #train# step  670, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:37.740365 #train# step  671, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:39.284257 #train# step  672, loss = 0.9833, cross_entropy loss = 0.9833, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:40.857881 #train# step  673, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:42.391292 #train# step  674, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:43.921222 #train# step  675, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:45.435711 #train# step  676, loss = 1.0026, cross_entropy loss = 1.0026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:46.977105 #train# step  677, loss = 1.0074, cross_entropy loss = 1.0074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:48.516888 #train# step  678, loss = 0.9943, cross_entropy loss = 0.9943, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:50.067869 #train# step  679, loss = 1.0069, cross_entropy loss = 1.0069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:51.610074 #train# step  680, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:53.139591 #train# step  681, loss = 1.0104, cross_entropy loss = 1.0104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:54.674918 #train# step  682, loss = 1.0059, cross_entropy loss = 1.0059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:56.233396 #train# step  683, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:57.803253 #train# step  684, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:10:59.325941 #train# step  685, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:00.845106 #train# step  686, loss = 1.0130, cross_entropy loss = 1.0130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:02.384380 #train# step  687, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:03.900528 #train# step  688, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:05.451244 #train# step  689, loss = 0.9914, cross_entropy loss = 0.9914, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:07.008134 #train# step  690, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:08.560101 #train# step  691, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:10.114022 #train# step  692, loss = 1.0002, cross_entropy loss = 1.0002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:11.677562 #train# step  693, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:13.236406 #train# step  694, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:14.777204 #train# step  695, loss = 1.0021, cross_entropy loss = 1.0021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:16.354598 #train# step  696, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:17.915188 #train# step  697, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:19.480140 #train# step  698, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:20.997521 #train# step  699, loss = 1.0079, cross_entropy loss = 1.0079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:22.549041 #train# step  700, loss = 1.0095, cross_entropy loss = 1.0095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:24.123838 #train# step  701, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:25.661612 #train# step  702, loss = 1.0051, cross_entropy loss = 1.0051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:27.194507 #train# step  703, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:28.734980 #train# step  704, loss = 1.0017, cross_entropy loss = 1.0017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:30.289590 #train# step  705, loss = 0.9898, cross_entropy loss = 0.9898, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:31.841653 #train# step  706, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:33.437416 #train# step  707, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:35.006752 #train# step  708, loss = 0.9874, cross_entropy loss = 0.9874, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:36.577643 #train# step  709, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:38.103175 #train# step  710, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:39.660512 #train# step  711, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:41.191525 #train# step  712, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:42.736045 #train# step  713, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:44.306486 #train# step  714, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:45.825381 #train# step  715, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:47.391277 #train# step  716, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:48.937658 #train# step  717, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:50.477491 #train# step  718, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:52.010754 #train# step  719, loss = 1.0065, cross_entropy loss = 1.0065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:53.561059 #train# step  720, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:55.127663 #train# step  721, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:56.678119 #train# step  722, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:58.220763 #train# step  723, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:11:59.756012 #train# step  724, loss = 0.9914, cross_entropy loss = 0.9914, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:01.296141 #train# step  725, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:02.838112 #train# step  726, loss = 1.0070, cross_entropy loss = 1.0070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:04.379962 #train# step  727, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:05.920649 #train# step  728, loss = 0.9888, cross_entropy loss = 0.9888, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:07.447298 #train# step  729, loss = 1.0026, cross_entropy loss = 1.0026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:09.027618 #train# step  730, loss = 1.0062, cross_entropy loss = 1.0062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:10.562119 #train# step  731, loss = 1.0072, cross_entropy loss = 1.0072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:12.125938 #train# step  732, loss = 0.9967, cross_entropy loss = 0.9967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:13.651049 #train# step  733, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:15.201829 #train# step  734, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:16.768996 #train# step  735, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:18.309247 #train# step  736, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:19.870247 #train# step  737, loss = 1.0000, cross_entropy loss = 1.0000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:21.425213 #train# step  738, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:22.969597 #train# step  739, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:24.512491 #train# step  740, loss = 1.0054, cross_entropy loss = 1.0054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:26.071040 #train# step  741, loss = 0.9967, cross_entropy loss = 0.9967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:27.661128 #train# step  742, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:29.209858 #train# step  743, loss = 0.9927, cross_entropy loss = 0.9927, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:30.763126 #train# step  744, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:32.326731 #train# step  745, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:33.864993 #train# step  746, loss = 1.0223, cross_entropy loss = 1.0223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:35.421108 #train# step  747, loss = 1.0211, cross_entropy loss = 1.0211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:36.973831 #train# step  748, loss = 0.9993, cross_entropy loss = 0.9993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:38.543736 #train# step  749, loss = 0.9888, cross_entropy loss = 0.9888, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:40.109489 #train# step  750, loss = 1.0034, cross_entropy loss = 1.0034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:41.673386 #train# step  751, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:43.211796 #train# step  752, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:44.795830 #train# step  753, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:46.335783 #train# step  754, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:47.913176 #train# step  755, loss = 0.9968, cross_entropy loss = 0.9968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:49.465449 #train# step  756, loss = 0.9937, cross_entropy loss = 0.9937, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:51.014658 #train# step  757, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:52.577855 #train# step  758, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:54.150590 #train# step  759, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:55.705552 #train# step  760, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:57.279994 #train# step  761, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:12:58.797784 #train# step  762, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:00.361121 #train# step  763, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:01.907749 #train# step  764, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:03.446595 #train# step  765, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:05.011860 #train# step  766, loss = 1.0113, cross_entropy loss = 1.0113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:06.576563 #train# step  767, loss = 0.9894, cross_entropy loss = 0.9894, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:08.120742 #train# step  768, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:09.665736 #train# step  769, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:11.211365 #train# step  770, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:12.748320 #train# step  771, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:14.303999 #train# step  772, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:15.844915 #train# step  773, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:17.428957 #train# step  774, loss = 0.9940, cross_entropy loss = 0.9940, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:18.981161 #train# step  775, loss = 1.0010, cross_entropy loss = 1.0010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:20.542466 #train# step  776, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:22.097003 #train# step  777, loss = 1.0120, cross_entropy loss = 1.0120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:23.596113 #train# step  778, loss = 0.9957, cross_entropy loss = 0.9957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:25.142289 #train# step  779, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:26.660905 #train# step  780, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:28.254152 #train# step  781, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:29.792109 #train# step  782, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:31.364929 #train# step  783, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:32.906021 #train# step  784, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:34.437279 #train# step  785, loss = 0.9813, cross_entropy loss = 0.9813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:36.005973 #train# step  786, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:37.525612 #train# step  787, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:39.087494 #train# step  788, loss = 0.9924, cross_entropy loss = 0.9924, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:40.655314 #train# step  789, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:42.256260 #train# step  790, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:43.781480 #train# step  791, loss = 1.0147, cross_entropy loss = 1.0147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:45.294671 #train# step  792, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:46.829665 #train# step  793, loss = 1.0031, cross_entropy loss = 1.0031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:48.372865 #train# step  794, loss = 1.0075, cross_entropy loss = 1.0075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:49.918254 #train# step  795, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:51.460744 #train# step  796, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:53.023869 #train# step  797, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:54.604446 #train# step  798, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:56.108079 #train# step  799, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:57.641513 #train# step  800, loss = 0.9945, cross_entropy loss = 0.9945, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:13:59.179515 #train# step  801, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:00.714284 #train# step  802, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:02.258396 #train# step  803, loss = 1.0080, cross_entropy loss = 1.0080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:03.829863 #train# step  804, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:05.376489 #train# step  805, loss = 0.9983, cross_entropy loss = 0.9983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:06.911442 #train# step  806, loss = 0.9942, cross_entropy loss = 0.9942, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:08.454115 #train# step  807, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:10.008604 #train# step  808, loss = 1.0003, cross_entropy loss = 1.0003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:11.593573 #train# step  809, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:13.149203 #train# step  810, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:14.664163 #train# step  811, loss = 0.9917, cross_entropy loss = 0.9917, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:16.243315 #train# step  812, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:17.814121 #train# step  813, loss = 0.9811, cross_entropy loss = 0.9811, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:19.356638 #train# step  814, loss = 1.0070, cross_entropy loss = 1.0070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:20.929842 #train# step  815, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:22.498525 #train# step  816, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:24.009560 #train# step  817, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:25.563721 #train# step  818, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:27.139833 #train# step  819, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:28.694591 #train# step  820, loss = 1.0003, cross_entropy loss = 1.0003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:30.240493 #train# step  821, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:31.831693 #train# step  822, loss = 0.9919, cross_entropy loss = 0.9919, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:33.393706 #train# step  823, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:34.929256 #train# step  824, loss = 1.0047, cross_entropy loss = 1.0047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:36.483434 #train# step  825, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:38.047418 #train# step  826, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:39.614062 #train# step  827, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:41.167928 #train# step  828, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:42.739367 #train# step  829, loss = 0.9895, cross_entropy loss = 0.9895, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:44.279001 #train# step  830, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:45.806295 #train# step  831, loss = 0.9920, cross_entropy loss = 0.9920, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:47.334881 #train# step  832, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:48.907809 #train# step  833, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:50.445230 #train# step  834, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:52.020738 #train# step  835, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:53.581385 #train# step  836, loss = 0.9898, cross_entropy loss = 0.9898, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:55.120874 #train# step  837, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:56.681801 #train# step  838, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:58.215315 #train# step  839, loss = 1.0024, cross_entropy loss = 1.0024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:14:59.738641 #train# step  840, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:01.283236 #train# step  841, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:02.834897 #train# step  842, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:04.400577 #train# step  843, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:05.943883 #train# step  844, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:07.502890 #train# step  845, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:09.036528 #train# step  846, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:10.574653 #train# step  847, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:12.104582 #train# step  848, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:13.661266 #train# step  849, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:15.183765 #train# step  850, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:16.751424 #train# step  851, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:18.280852 #train# step  852, loss = 0.9931, cross_entropy loss = 0.9931, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:19.824993 #train# step  853, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:21.435492 #train# step  854, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:22.974395 #train# step  855, loss = 1.0076, cross_entropy loss = 1.0076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:24.508938 #train# step  856, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:26.056211 #train# step  857, loss = 1.0092, cross_entropy loss = 1.0092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:27.591194 #train# step  858, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:29.132149 #train# step  859, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:30.676545 #train# step  860, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:32.250751 #train# step  861, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:33.793007 #train# step  862, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:35.382236 #train# step  863, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:37.002059 #train# step  864, loss = 0.9937, cross_entropy loss = 0.9937, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:38.771715 #train# step  865, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:40.324841 #train# step  866, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:41.880780 #train# step  867, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:43.443036 #train# step  868, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:45.007464 #train# step  869, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:46.574773 #train# step  870, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:48.255566 #train# step  871, loss = 0.9842, cross_entropy loss = 0.9842, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:49.879327 #train# step  872, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:51.427659 #train# step  873, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:53.131429 #train# step  874, loss = 1.0002, cross_entropy loss = 1.0002, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:54.734917 #train# step  875, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:56.473718 #train# step  876, loss = 1.0017, cross_entropy loss = 1.0017, 1.0 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:57.998687 #train# step  877, loss = 0.9979, cross_entropy loss = 0.9979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:15:59.567650 #train# step  878, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:01.118399 #train# step  879, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:02.697331 #train# step  880, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:04.241088 #train# step  881, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:05.792295 #train# step  882, loss = 0.9929, cross_entropy loss = 0.9929, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:07.367501 #train# step  883, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:08.961010 #train# step  884, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:10.533759 #train# step  885, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:12.054100 #train# step  886, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:13.632654 #train# step  887, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:15.195220 #train# step  888, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:16.731176 #train# step  889, loss = 0.9933, cross_entropy loss = 0.9933, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:18.301421 #train# step  890, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:19.846606 #train# step  891, loss = 0.9934, cross_entropy loss = 0.9934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:21.411828 #train# step  892, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:22.987353 #train# step  893, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:24.536992 #train# step  894, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:26.069588 #train# step  895, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:27.625851 #train# step  896, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:29.151512 #train# step  897, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:30.714733 #train# step  898, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:32.252283 #train# step  899, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:33.782356 #train# step  900, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:35.344265 #train# step  901, loss = 0.9995, cross_entropy loss = 0.9995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:36.898986 #train# step  902, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:38.435946 #train# step  903, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:40.022194 #train# step  904, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:41.571381 #train# step  905, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:43.112607 #train# step  906, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:44.666321 #train# step  907, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:46.247426 #train# step  908, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:47.783152 #train# step  909, loss = 0.9987, cross_entropy loss = 0.9987, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:49.291700 #train# step  910, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:50.819986 #train# step  911, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:52.365613 #train# step  912, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:53.895977 #train# step  913, loss = 0.9913, cross_entropy loss = 0.9913, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:55.470953 #train# step  914, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:57.019032 #train# step  915, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:16:58.582575 #train# step  916, loss = 0.9927, cross_entropy loss = 0.9927, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:00.148470 #train# step  917, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:01.716506 #train# step  918, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:03.281600 #train# step  919, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:04.809602 #train# step  920, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:06.350397 #train# step  921, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:07.918881 #train# step  922, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:09.479953 #train# step  923, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:11.032244 #train# step  924, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:12.595321 #train# step  925, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:14.172786 #train# step  926, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:15.707744 #train# step  927, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:17.281720 #train# step  928, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:18.852453 #train# step  929, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:20.437992 #train# step  930, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:21.951752 #train# step  931, loss = 0.9940, cross_entropy loss = 0.9940, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:23.544278 #train# step  932, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:25.094590 #train# step  933, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:26.647491 #train# step  934, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:28.188460 #train# step  935, loss = 1.0037, cross_entropy loss = 1.0037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:29.741156 #train# step  936, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:31.292193 #train# step  937, loss = 1.0065, cross_entropy loss = 1.0065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:32.836039 #train# step  938, loss = 1.0080, cross_entropy loss = 1.0080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:34.378006 #train# step  939, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:35.921152 #train# step  940, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:37.467964 #train# step  941, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:39.007617 #train# step  942, loss = 0.9935, cross_entropy loss = 0.9935, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:40.535965 #train# step  943, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:42.097451 #train# step  944, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:43.634802 #train# step  945, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:45.184420 #train# step  946, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:46.703942 #train# step  947, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:48.261716 #train# step  948, loss = 1.0032, cross_entropy loss = 1.0032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:49.797709 #train# step  949, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:51.346781 #train# step  950, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:52.872755 #train# step  951, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:54.436780 #train# step  952, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:55.975444 #train# step  953, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:57.511290 #train# step  954, loss = 0.9895, cross_entropy loss = 0.9895, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:17:59.078698 #train# step  955, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:00.605700 #train# step  956, loss = 0.9888, cross_entropy loss = 0.9888, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:02.166054 #train# step  957, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:03.718390 #train# step  958, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:05.267899 #train# step  959, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:06.829216 #train# step  960, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:08.390902 #train# step  961, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:09.968201 #train# step  962, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:11.505285 #train# step  963, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:13.034610 #train# step  964, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:14.585657 #train# step  965, loss = 0.9977, cross_entropy loss = 0.9977, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:16.156277 #train# step  966, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:17.742823 #train# step  967, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:19.295298 #train# step  968, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:20.862929 #train# step  969, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:22.423441 #train# step  970, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:23.968230 #train# step  971, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:25.553501 #train# step  972, loss = 0.9933, cross_entropy loss = 0.9933, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:27.080968 #train# step  973, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:28.887913 #train# step  974, loss = 0.9819, cross_entropy loss = 0.9819, 1.0 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:30.456607 #train# step  975, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:31.998128 #train# step  976, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:33.721273 #train# step  977, loss = 0.9857, cross_entropy loss = 0.9857, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:35.390440 #train# step  978, loss = 0.9962, cross_entropy loss = 0.9962, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:37.053540 #train# step  979, loss = 0.9854, cross_entropy loss = 0.9854, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:38.629641 #train# step  980, loss = 1.0111, cross_entropy loss = 1.0111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:40.188575 #train# step  981, loss = 1.0026, cross_entropy loss = 1.0026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:41.785889 #train# step  982, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:43.370842 #train# step  983, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:44.957987 #train# step  984, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:46.514968 #train# step  985, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:48.112312 #train# step  986, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:49.666271 #train# step  987, loss = 0.9863, cross_entropy loss = 0.9863, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:51.218552 #train# step  988, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:52.742069 #train# step  989, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:54.317302 #train# step  990, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:55.860352 #train# step  991, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:57.406309 #train# step  992, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:18:58.977595 #train# step  993, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:00.520971 #train# step  994, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:02.100434 #train# step  995, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:03.633958 #train# step  996, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:05.199651 #train# step  997, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:06.724654 #train# step  998, loss = 1.0126, cross_entropy loss = 1.0126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:08.254479 #train# step  999, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:09.790231 #train# step 1000, loss = 0.9795, cross_entropy loss = 0.9795, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:11.333910 #train# step 1001, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:12.854558 #train# step 1002, loss = 0.9928, cross_entropy loss = 0.9928, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:14.420491 #train# step 1003, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:15.942033 #train# step 1004, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:17.511874 #train# step 1005, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:19.040510 #train# step 1006, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:20.579474 #train# step 1007, loss = 1.0109, cross_entropy loss = 1.0109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:22.133092 #train# step 1008, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:23.693451 #train# step 1009, loss = 0.9824, cross_entropy loss = 0.9824, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:25.256901 #train# step 1010, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:26.840771 #train# step 1011, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:28.410838 #train# step 1012, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:29.943727 #train# step 1013, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:31.494441 #train# step 1014, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:33.050435 #train# step 1015, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:34.599744 #train# step 1016, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:36.144159 #train# step 1017, loss = 0.9961, cross_entropy loss = 0.9961, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:37.674670 #train# step 1018, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:39.243721 #train# step 1019, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:40.820270 #train# step 1020, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:42.367143 #train# step 1021, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:43.943914 #train# step 1022, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:45.486787 #train# step 1023, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:47.023696 #train# step 1024, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:48.618266 #train# step 1025, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:50.200529 #train# step 1026, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:51.771092 #train# step 1027, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:53.309009 #train# step 1028, loss = 0.9894, cross_entropy loss = 0.9894, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:54.851697 #train# step 1029, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:56.372994 #train# step 1030, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:57.897476 #train# step 1031, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:19:59.420408 #train# step 1032, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:01.014542 #train# step 1033, loss = 1.0001, cross_entropy loss = 1.0001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:02.538891 #train# step 1034, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:04.096842 #train# step 1035, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:05.656977 #train# step 1036, loss = 0.9820, cross_entropy loss = 0.9820, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:07.178254 #train# step 1037, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:08.702671 #train# step 1038, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:10.257496 #train# step 1039, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:11.820105 #train# step 1040, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:13.380176 #train# step 1041, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:14.947198 #train# step 1042, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:16.529998 #train# step 1043, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:18.069245 #train# step 1044, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:19.630305 #train# step 1045, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:21.180893 #train# step 1046, loss = 0.9820, cross_entropy loss = 0.9820, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:22.740781 #train# step 1047, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:24.320424 #train# step 1048, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:25.911653 #train# step 1049, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:27.438082 #train# step 1050, loss = 0.9897, cross_entropy loss = 0.9897, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:28.972014 #train# step 1051, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:30.543209 #train# step 1052, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:32.088585 #train# step 1053, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:33.614370 #train# step 1054, loss = 1.0006, cross_entropy loss = 1.0006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:35.178870 #train# step 1055, loss = 0.9890, cross_entropy loss = 0.9890, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:36.712446 #train# step 1056, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:38.256452 #train# step 1057, loss = 0.9881, cross_entropy loss = 0.9881, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:39.825683 #train# step 1058, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:41.371108 #train# step 1059, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:42.928698 #train# step 1060, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:44.478115 #train# step 1061, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:46.012641 #train# step 1062, loss = 0.9875, cross_entropy loss = 0.9875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:47.544028 #train# step 1063, loss = 0.9976, cross_entropy loss = 0.9976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:49.108731 #train# step 1064, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:50.657803 #train# step 1065, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:52.212911 #train# step 1066, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:53.749319 #train# step 1067, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:55.290934 #train# step 1068, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:56.871019 #train# step 1069, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:58.445834 #train# step 1070, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:20:59.995607 #train# step 1071, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:01.527623 #train# step 1072, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:03.072129 #train# step 1073, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:04.645792 #train# step 1074, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:06.198539 #train# step 1075, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:07.773999 #train# step 1076, loss = 0.9824, cross_entropy loss = 0.9824, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:09.342660 #train# step 1077, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:10.868753 #train# step 1078, loss = 0.9957, cross_entropy loss = 0.9957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:12.411244 #train# step 1079, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:13.942136 #train# step 1080, loss = 0.9877, cross_entropy loss = 0.9877, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:15.459670 #train# step 1081, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:16.990130 #train# step 1082, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:18.557705 #train# step 1083, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:20.083105 #train# step 1084, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:21.599353 #train# step 1085, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:23.159232 #train# step 1086, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:24.731481 #train# step 1087, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:26.276755 #train# step 1088, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:27.843739 #train# step 1089, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:29.394047 #train# step 1090, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:30.962184 #train# step 1091, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:32.520852 #train# step 1092, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:34.102230 #train# step 1093, loss = 0.9796, cross_entropy loss = 0.9796, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:35.659778 #train# step 1094, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:37.180430 #train# step 1095, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:38.732657 #train# step 1096, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:40.248273 #train# step 1097, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:41.789295 #train# step 1098, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:43.362675 #train# step 1099, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:44.909363 #train# step 1100, loss = 0.9660, cross_entropy loss = 0.9660, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:46.474990 #train# step 1101, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:48.014359 #train# step 1102, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:49.566332 #train# step 1103, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:51.087198 #train# step 1104, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:52.655051 #train# step 1105, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:54.198826 #train# step 1106, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:55.778346 #train# step 1107, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:57.309964 #train# step 1108, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:21:58.852813 #train# step 1109, loss = 0.9874, cross_entropy loss = 0.9874, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:00.414725 #train# step 1110, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:01.965773 #train# step 1111, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:03.506539 #train# step 1112, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:05.074097 #train# step 1113, loss = 0.9925, cross_entropy loss = 0.9925, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:06.641993 #train# step 1114, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:08.230395 #train# step 1115, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:09.763865 #train# step 1116, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:11.307963 #train# step 1117, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:12.965094 #train# step 1118, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:14.549532 #train# step 1119, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:16.119368 #train# step 1120, loss = 0.9974, cross_entropy loss = 0.9974, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:17.671276 #train# step 1121, loss = 0.9945, cross_entropy loss = 0.9945, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:19.227541 #train# step 1122, loss = 0.9885, cross_entropy loss = 0.9885, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:20.768110 #train# step 1123, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:22.312531 #train# step 1124, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:23.866705 #train# step 1125, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:25.433858 #train# step 1126, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:27.010984 #train# step 1127, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:28.552696 #train# step 1128, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:30.070067 #train# step 1129, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:31.647658 #train# step 1130, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:33.231805 #train# step 1131, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:34.762096 #train# step 1132, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:36.344287 #train# step 1133, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:37.885312 #train# step 1134, loss = 0.9934, cross_entropy loss = 0.9934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:39.416604 #train# step 1135, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:40.974024 #train# step 1136, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:42.512720 #train# step 1137, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:44.085190 #train# step 1138, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:45.609704 #train# step 1139, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:47.127227 #train# step 1140, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:48.689686 #train# step 1141, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:50.227048 #train# step 1142, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:51.818650 #train# step 1143, loss = 0.9865, cross_entropy loss = 0.9865, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:53.402049 #train# step 1144, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:54.969575 #train# step 1145, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:56.531515 #train# step 1146, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:58.109113 #train# step 1147, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:22:59.631984 #train# step 1148, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:01.166305 #train# step 1149, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:02.671828 #train# step 1150, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:04.209397 #train# step 1151, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:05.750175 #train# step 1152, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:07.311913 #train# step 1153, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:08.864333 #train# step 1154, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:10.424085 #train# step 1155, loss = 1.0074, cross_entropy loss = 1.0074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:12.007425 #train# step 1156, loss = 0.9875, cross_entropy loss = 0.9875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:13.585943 #train# step 1157, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:15.129207 #train# step 1158, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:16.665693 #train# step 1159, loss = 0.9957, cross_entropy loss = 0.9957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:18.229284 #train# step 1160, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:19.783070 #train# step 1161, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:21.378263 #train# step 1162, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:22.920488 #train# step 1163, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:24.453816 #train# step 1164, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:26.010772 #train# step 1165, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:27.544001 #train# step 1166, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:29.085372 #train# step 1167, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:30.624188 #train# step 1168, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:32.171540 #train# step 1169, loss = 1.0045, cross_entropy loss = 1.0045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:33.715441 #train# step 1170, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:35.269789 #train# step 1171, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:36.832682 #train# step 1172, loss = 0.9775, cross_entropy loss = 0.9775, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:38.333329 #train# step 1173, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:39.868135 #train# step 1174, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:41.424445 #train# step 1175, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:42.975487 #train# step 1176, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:44.528202 #train# step 1177, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:46.053655 #train# step 1178, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:47.587715 #train# step 1179, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:49.138715 #train# step 1180, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:50.711145 #train# step 1181, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:52.262398 #train# step 1182, loss = 0.9833, cross_entropy loss = 0.9833, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:53.831910 #train# step 1183, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:55.360446 #train# step 1184, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:56.903323 #train# step 1185, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:58.453254 #train# step 1186, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:23:59.998646 #train# step 1187, loss = 0.9990, cross_entropy loss = 0.9990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:01.548409 #train# step 1188, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:03.093564 #train# step 1189, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:04.638666 #train# step 1190, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:06.239516 #train# step 1191, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:07.831991 #train# step 1192, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:09.380174 #train# step 1193, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:10.909950 #train# step 1194, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:12.469824 #train# step 1195, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:14.011133 #train# step 1196, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:15.555574 #train# step 1197, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:17.129149 #train# step 1198, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:18.696901 #train# step 1199, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:20.251131 #train# step 1200, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:21.802081 #train# step 1201, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:23.342772 #train# step 1202, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:24.889146 #train# step 1203, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:26.435879 #train# step 1204, loss = 0.9765, cross_entropy loss = 0.9765, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:27.983512 #train# step 1205, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:29.542826 #train# step 1206, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:31.064422 #train# step 1207, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:32.612211 #train# step 1208, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:34.155843 #train# step 1209, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:35.688146 #train# step 1210, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:37.244200 #train# step 1211, loss = 0.9881, cross_entropy loss = 0.9881, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:38.785914 #train# step 1212, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:40.370345 #train# step 1213, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:41.887382 #train# step 1214, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:43.443412 #train# step 1215, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:44.969834 #train# step 1216, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:46.533096 #train# step 1217, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:48.103644 #train# step 1218, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:49.654107 #train# step 1219, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:51.204761 #train# step 1220, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:52.784297 #train# step 1221, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:54.355199 #train# step 1222, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:55.937270 #train# step 1223, loss = 0.9893, cross_entropy loss = 0.9893, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:57.487591 #train# step 1224, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:24:59.033059 #train# step 1225, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:00.587421 #train# step 1226, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:02.137693 #train# step 1227, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:03.675599 #train# step 1228, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:05.214761 #train# step 1229, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:06.745819 #train# step 1230, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:08.310373 #train# step 1231, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:09.823017 #train# step 1232, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:11.356285 #train# step 1233, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:12.884726 #train# step 1234, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:14.420367 #train# step 1235, loss = 0.9796, cross_entropy loss = 0.9796, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:15.974700 #train# step 1236, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:17.514231 #train# step 1237, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:19.066342 #train# step 1238, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:20.604616 #train# step 1239, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:22.165757 #train# step 1240, loss = 0.9875, cross_entropy loss = 0.9875, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:23.708229 #train# step 1241, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:25.270557 #train# step 1242, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:26.838394 #train# step 1243, loss = 0.9918, cross_entropy loss = 0.9918, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:28.382055 #train# step 1244, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:29.969880 #train# step 1245, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:31.573556 #train# step 1246, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:33.085063 #train# step 1247, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:34.667736 #train# step 1248, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:36.202927 #train# step 1249, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:37.811005 #train# step 1250, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:39.386020 #train# step 1251, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:40.941985 #train# step 1252, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:42.474734 #train# step 1253, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:44.040196 #train# step 1254, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:45.599715 #train# step 1255, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:47.165477 #train# step 1256, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:48.677713 #train# step 1257, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:50.201146 #train# step 1258, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:51.759777 #train# step 1259, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:53.308132 #train# step 1260, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:54.830636 #train# step 1261, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:56.435292 #train# step 1262, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:58.005088 #train# step 1263, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:25:59.581169 #train# step 1264, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:01.127135 #train# step 1265, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:02.671150 #train# step 1266, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:04.211619 #train# step 1267, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:05.748557 #train# step 1268, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:07.320587 #train# step 1269, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:08.872479 #train# step 1270, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:10.407306 #train# step 1271, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:11.948935 #train# step 1272, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:13.510413 #train# step 1273, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:15.050695 #train# step 1274, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:16.590198 #train# step 1275, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:18.156546 #train# step 1276, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:19.719984 #train# step 1277, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:21.240288 #train# step 1278, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:22.796452 #train# step 1279, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:24.380567 #train# step 1280, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:25.909221 #train# step 1281, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:27.484142 #train# step 1282, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:28.993599 #train# step 1283, loss = 0.9922, cross_entropy loss = 0.9922, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:30.534314 #train# step 1284, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:32.061147 #train# step 1285, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:33.612191 #train# step 1286, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:35.218940 #train# step 1287, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:36.766345 #train# step 1288, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:38.344557 #train# step 1289, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:39.891499 #train# step 1290, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:41.473877 #train# step 1291, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:43.023967 #train# step 1292, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:44.586302 #train# step 1293, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:46.141609 #train# step 1294, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:47.708277 #train# step 1295, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:49.274217 #train# step 1296, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:50.855003 #train# step 1297, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:52.387821 #train# step 1298, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:53.942130 #train# step 1299, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:55.491148 #train# step 1300, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:57.009987 #train# step 1301, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:26:58.573502 #train# step 1302, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:00.136178 #train# step 1303, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:01.708972 #train# step 1304, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:03.255011 #train# step 1305, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:04.791808 #train# step 1306, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:06.327723 #train# step 1307, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:07.868702 #train# step 1308, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:09.393534 #train# step 1309, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:10.912533 #train# step 1310, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:12.481720 #train# step 1311, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:14.022512 #train# step 1312, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:15.576156 #train# step 1313, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:17.122962 #train# step 1314, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:18.675661 #train# step 1315, loss = 1.0036, cross_entropy loss = 1.0036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:20.226258 #train# step 1316, loss = 0.9765, cross_entropy loss = 0.9765, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:21.792385 #train# step 1317, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:23.365330 #train# step 1318, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:24.940061 #train# step 1319, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:26.481916 #train# step 1320, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:28.031049 #train# step 1321, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:29.596628 #train# step 1322, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:31.159178 #train# step 1323, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:32.709754 #train# step 1324, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:34.255473 #train# step 1325, loss = 0.9903, cross_entropy loss = 0.9903, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:35.826119 #train# step 1326, loss = 0.9813, cross_entropy loss = 0.9813, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:37.441308 #train# step 1327, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:38.990540 #train# step 1328, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:40.556834 #train# step 1329, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:42.116806 #train# step 1330, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:43.664417 #train# step 1331, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:45.209584 #train# step 1332, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:46.762674 #train# step 1333, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:48.305430 #train# step 1334, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:49.843545 #train# step 1335, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:51.415799 #train# step 1336, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:52.946211 #train# step 1337, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:54.495898 #train# step 1338, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:56.023781 #train# step 1339, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:57.586844 #train# step 1340, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:27:59.125605 #train# step 1341, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:00.666015 #train# step 1342, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:02.211570 #train# step 1343, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:03.757399 #train# step 1344, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:05.292272 #train# step 1345, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:06.825501 #train# step 1346, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:08.369332 #train# step 1347, loss = 1.0103, cross_entropy loss = 1.0103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:09.925710 #train# step 1348, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:11.476164 #train# step 1349, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:13.025358 #train# step 1350, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:14.603447 #train# step 1351, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:16.147897 #train# step 1352, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:17.690267 #train# step 1353, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:19.269317 #train# step 1354, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:20.840839 #train# step 1355, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:22.431348 #train# step 1356, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:23.998038 #train# step 1357, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:25.520632 #train# step 1358, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:27.072384 #train# step 1359, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:28.597558 #train# step 1360, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:30.145545 #train# step 1361, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:31.706931 #train# step 1362, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:33.253361 #train# step 1363, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:34.808068 #train# step 1364, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:36.356976 #train# step 1365, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:37.887062 #train# step 1366, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:39.447088 #train# step 1367, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:40.970077 #train# step 1368, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:42.514440 #train# step 1369, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:44.101533 #train# step 1370, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:45.681642 #train# step 1371, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:47.193820 #train# step 1372, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:48.741300 #train# step 1373, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:50.272927 #train# step 1374, loss = 0.9946, cross_entropy loss = 0.9946, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:51.857505 #train# step 1375, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:53.395564 #train# step 1376, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:54.948011 #train# step 1377, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:56.488323 #train# step 1378, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:58.042651 #train# step 1379, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:28:59.605738 #train# step 1380, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:01.182041 #train# step 1381, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:02.783144 #train# step 1382, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:04.317072 #train# step 1383, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:05.879327 #train# step 1384, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:07.413432 #train# step 1385, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:08.973017 #train# step 1386, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:10.523938 #train# step 1387, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:12.078197 #train# step 1388, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:13.654831 #train# step 1389, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:15.192002 #train# step 1390, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:16.812689 #train# step 1391, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:18.376611 #train# step 1392, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:19.906600 #train# step 1393, loss = 0.9895, cross_entropy loss = 0.9895, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:21.471603 #train# step 1394, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:23.033102 #train# step 1395, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:24.580195 #train# step 1396, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:26.143875 #train# step 1397, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:27.710323 #train# step 1398, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:29.229177 #train# step 1399, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:30.768129 #train# step 1400, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:32.334429 #train# step 1401, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:33.877091 #train# step 1402, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:35.409292 #train# step 1403, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:36.940825 #train# step 1404, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:38.476092 #train# step 1405, loss = 0.9920, cross_entropy loss = 0.9920, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:40.049156 #train# step 1406, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:41.588937 #train# step 1407, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:43.150825 #train# step 1408, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:44.682351 #train# step 1409, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:46.228190 #train# step 1410, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:47.763632 #train# step 1411, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:49.310681 #train# step 1412, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:50.865789 #train# step 1413, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:52.418810 #train# step 1414, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:53.962736 #train# step 1415, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:55.529005 #train# step 1416, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:57.076144 #train# step 1417, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:29:58.613564 #train# step 1418, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:00.173433 #train# step 1419, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:01.731842 #train# step 1420, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:03.311158 #train# step 1421, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:04.862211 #train# step 1422, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:06.418809 #train# step 1423, loss = 0.9748, cross_entropy loss = 0.9748, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:07.983963 #train# step 1424, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:09.558320 #train# step 1425, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:11.134033 #train# step 1426, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:12.675774 #train# step 1427, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:14.219971 #train# step 1428, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:15.749133 #train# step 1429, loss = 0.9881, cross_entropy loss = 0.9881, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:17.316713 #train# step 1430, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:18.870612 #train# step 1431, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:20.451780 #train# step 1432, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:21.993644 #train# step 1433, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:23.543732 #train# step 1434, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:25.089661 #train# step 1435, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:26.640980 #train# step 1436, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:28.201455 #train# step 1437, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:29.770068 #train# step 1438, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:31.321330 #train# step 1439, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:32.861858 #train# step 1440, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:34.394260 #train# step 1441, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:35.954231 #train# step 1442, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:37.518050 #train# step 1443, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:39.097491 #train# step 1444, loss = 0.9660, cross_entropy loss = 0.9660, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:40.647574 #train# step 1445, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:42.187403 #train# step 1446, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:43.715688 #train# step 1447, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:45.245407 #train# step 1448, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:46.792606 #train# step 1449, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:48.383394 #train# step 1450, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:49.921063 #train# step 1451, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:51.460285 #train# step 1452, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:53.000854 #train# step 1453, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:54.583631 #train# step 1454, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:56.162264 #train# step 1455, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:57.704727 #train# step 1456, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:30:59.271144 #train# step 1457, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:00.835575 #train# step 1458, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:02.353848 #train# step 1459, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:03.879478 #train# step 1460, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:05.420895 #train# step 1461, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:06.986402 #train# step 1462, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:08.552944 #train# step 1463, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:10.100563 #train# step 1464, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:11.655227 #train# step 1465, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:13.211848 #train# step 1466, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:14.789816 #train# step 1467, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:16.332570 #train# step 1468, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:17.860368 #train# step 1469, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:19.480361 #train# step 1470, loss = 0.9697, cross_entropy loss = 0.9697, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:21.050409 #train# step 1471, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:22.592267 #train# step 1472, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:24.143822 #train# step 1473, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:25.672723 #train# step 1474, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:27.237348 #train# step 1475, loss = 0.9796, cross_entropy loss = 0.9796, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:28.782116 #train# step 1476, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:30.345471 #train# step 1477, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:31.895210 #train# step 1478, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:33.486807 #train# step 1479, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:35.031542 #train# step 1480, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:36.605970 #train# step 1481, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:38.151941 #train# step 1482, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:39.711681 #train# step 1483, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:41.221923 #train# step 1484, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:42.779273 #train# step 1485, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:44.327935 #train# step 1486, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:45.897519 #train# step 1487, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:47.464034 #train# step 1488, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:49.023817 #train# step 1489, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:50.562547 #train# step 1490, loss = 0.9845, cross_entropy loss = 0.9845, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:52.102516 #train# step 1491, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:53.645441 #train# step 1492, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:55.191106 #train# step 1493, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:56.773203 #train# step 1494, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:58.321372 #train# step 1495, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:31:59.855768 #train# step 1496, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:01.387950 #train# step 1497, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:02.932090 #train# step 1498, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:04.487402 #train# step 1499, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:06.032450 #train# step 1500, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:07.580592 #train# step 1501, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:09.128012 #train# step 1502, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:10.653035 #train# step 1503, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:12.238530 #train# step 1504, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:13.810549 #train# step 1505, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:15.355301 #train# step 1506, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:16.937862 #train# step 1507, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:18.478446 #train# step 1508, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:20.062038 #train# step 1509, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:21.627757 #train# step 1510, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:23.170889 #train# step 1511, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:24.719762 #train# step 1512, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:26.260506 #train# step 1513, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:27.809689 #train# step 1514, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:29.366618 #train# step 1515, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:30.924128 #train# step 1516, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:32.479906 #train# step 1517, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:34.038746 #train# step 1518, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:35.582096 #train# step 1519, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:37.134525 #train# step 1520, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:38.665694 #train# step 1521, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:40.205910 #train# step 1522, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:41.762842 #train# step 1523, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:43.312029 #train# step 1524, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:44.856397 #train# step 1525, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:46.397222 #train# step 1526, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:47.972374 #train# step 1527, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:49.510724 #train# step 1528, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:51.070573 #train# step 1529, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:52.611173 #train# step 1530, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:54.147795 #train# step 1531, loss = 0.9909, cross_entropy loss = 0.9909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:55.675536 #train# step 1532, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:57.216960 #train# step 1533, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:32:58.808392 #train# step 1534, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:00.351323 #train# step 1535, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:01.910474 #train# step 1536, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:03.477872 #train# step 1537, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:05.057462 #train# step 1538, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:06.605091 #train# step 1539, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:08.144451 #train# step 1540, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:09.707624 #train# step 1541, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:11.276727 #train# step 1542, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:12.853677 #train# step 1543, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:14.394689 #train# step 1544, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:15.940212 #train# step 1545, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:17.499289 #train# step 1546, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:19.076240 #train# step 1547, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:20.651688 #train# step 1548, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:22.213997 #train# step 1549, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:23.743598 #train# step 1550, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:25.300136 #train# step 1551, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:26.863362 #train# step 1552, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:28.422991 #train# step 1553, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:29.995304 #train# step 1554, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:31.557262 #train# step 1555, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:33.125123 #train# step 1556, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:34.665606 #train# step 1557, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:36.247207 #train# step 1558, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:37.826277 #train# step 1559, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:39.395098 #train# step 1560, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:40.935855 #train# step 1561, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:42.456351 #train# step 1562, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:44.039327 #train# step 1563, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:45.559855 #train# step 1564, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:47.091435 #train# step 1565, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:48.616269 #train# step 1566, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:50.151084 #train# step 1567, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:51.683975 #train# step 1568, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:53.265170 #train# step 1569, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:54.805307 #train# step 1570, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:56.336074 #train# step 1571, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:57.915660 #train# step 1572, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:33:59.459676 #train# step 1573, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:01.018019 #train# step 1574, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:02.571981 #train# step 1575, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:04.133811 #train# step 1576, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:05.696941 #train# step 1577, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:07.261741 #train# step 1578, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:08.853862 #train# step 1579, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:10.393158 #train# step 1580, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:11.943196 #train# step 1581, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:13.519318 #train# step 1582, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:15.064105 #train# step 1583, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:16.610787 #train# step 1584, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:18.144635 #train# step 1585, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:19.701403 #train# step 1586, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:21.259588 #train# step 1587, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:22.814904 #train# step 1588, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:24.336191 #train# step 1589, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:25.854726 #train# step 1590, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:27.451900 #train# step 1591, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:28.997610 #train# step 1592, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:30.551183 #train# step 1593, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:32.103341 #train# step 1594, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:33.650045 #train# step 1595, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:35.204142 #train# step 1596, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:36.797263 #train# step 1597, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:38.357486 #train# step 1598, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:39.917293 #train# step 1599, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:41.454709 #train# step 1600, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:43.004044 #train# step 1601, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:44.574999 #train# step 1602, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:46.122437 #train# step 1603, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:47.699187 #train# step 1604, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:49.275890 #train# step 1605, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:50.796741 #train# step 1606, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:52.323353 #train# step 1607, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:53.857651 #train# step 1608, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:55.421910 #train# step 1609, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:56.967708 #train# step 1610, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:34:58.536895 #train# step 1611, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:00.080858 #train# step 1612, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:01.642325 #train# step 1613, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:03.219610 #train# step 1614, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:04.780730 #train# step 1615, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:06.337190 #train# step 1616, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:07.870155 #train# step 1617, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:09.408348 #train# step 1618, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:10.951744 #train# step 1619, loss = 0.9885, cross_entropy loss = 0.9885, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:12.518729 #train# step 1620, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:14.056977 #train# step 1621, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:15.599867 #train# step 1622, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:17.188646 #train# step 1623, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:18.726525 #train# step 1624, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:20.291862 #train# step 1625, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:21.895042 #train# step 1626, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:23.459659 #train# step 1627, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:25.012461 #train# step 1628, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:26.574625 #train# step 1629, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:28.102931 #train# step 1630, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:29.654461 #train# step 1631, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:31.238859 #train# step 1632, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:32.785259 #train# step 1633, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:34.352674 #train# step 1634, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:35.927562 #train# step 1635, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:37.477612 #train# step 1636, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:39.035584 #train# step 1637, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:40.583053 #train# step 1638, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:42.118705 #train# step 1639, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:43.669091 #train# step 1640, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:45.229615 #train# step 1641, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:46.773066 #train# step 1642, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:48.363400 #train# step 1643, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:49.930111 #train# step 1644, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:51.478714 #train# step 1645, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:53.066640 #train# step 1646, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:54.641649 #train# step 1647, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:56.194860 #train# step 1648, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:57.752619 #train# step 1649, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:35:59.291358 #train# step 1650, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:00.842143 #train# step 1651, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:02.391365 #train# step 1652, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:03.932002 #train# step 1653, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:05.512783 #train# step 1654, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:07.032212 #train# step 1655, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:08.595111 #train# step 1656, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:10.187237 #train# step 1657, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:11.783660 #train# step 1658, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:13.318715 #train# step 1659, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:14.849781 #train# step 1660, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:16.400878 #train# step 1661, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:17.942657 #train# step 1662, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:19.468265 #train# step 1663, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:21.017519 #train# step 1664, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:22.583069 #train# step 1665, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:24.125217 #train# step 1666, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:25.667850 #train# step 1667, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:27.203042 #train# step 1668, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:28.760638 #train# step 1669, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:30.326576 #train# step 1670, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:31.861645 #train# step 1671, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:33.449995 #train# step 1672, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:34.998684 #train# step 1673, loss = 0.9777, cross_entropy loss = 0.9777, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:36.605517 #train# step 1674, loss = 0.9666, cross_entropy loss = 0.9666, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:38.333806 #train# step 1675, loss = 0.9660, cross_entropy loss = 0.9660, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:39.960371 #train# step 1676, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:41.561722 #train# step 1677, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:43.136481 #train# step 1678, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:44.644054 #train# step 1679, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:46.218936 #train# step 1680, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:47.781455 #train# step 1681, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:49.324096 #train# step 1682, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:50.906524 #train# step 1683, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:52.454179 #train# step 1684, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:53.983018 #train# step 1685, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:55.537193 #train# step 1686, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:57.080617 #train# step 1687, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:36:58.634902 #train# step 1688, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:00.197792 #train# step 1689, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:01.743136 #train# step 1690, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:03.362562 #train# step 1691, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:04.916899 #train# step 1692, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:06.492940 #train# step 1693, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:08.073059 #train# step 1694, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:09.645290 #train# step 1695, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:11.191374 #train# step 1696, loss = 0.9833, cross_entropy loss = 0.9833, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:12.793960 #train# step 1697, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:14.325918 #train# step 1698, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:15.905273 #train# step 1699, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:17.505061 #train# step 1700, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:19.097317 #train# step 1701, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:20.709253 #train# step 1702, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:22.268618 #train# step 1703, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:23.867640 #train# step 1704, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:25.466909 #train# step 1705, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:27.028217 #train# step 1706, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:28.567913 #train# step 1707, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:30.122332 #train# step 1708, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:31.715997 #train# step 1709, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:33.272213 #train# step 1710, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:34.815685 #train# step 1711, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:36.366491 #train# step 1712, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:37.898548 #train# step 1713, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:39.470506 #train# step 1714, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:41.041595 #train# step 1715, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:42.587109 #train# step 1716, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:44.153571 #train# step 1717, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:45.716201 #train# step 1718, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:47.235615 #train# step 1719, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:48.808827 #train# step 1720, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:50.343288 #train# step 1721, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:51.888613 #train# step 1722, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:53.453272 #train# step 1723, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:55.011793 #train# step 1724, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:56.548117 #train# step 1725, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:58.115980 #train# step 1726, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:37:59.662054 #train# step 1727, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:01.219795 #train# step 1728, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:02.755672 #train# step 1729, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:04.298407 #train# step 1730, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:05.808150 #train# step 1731, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:07.396212 #train# step 1732, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:08.939516 #train# step 1733, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:10.499648 #train# step 1734, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:12.039388 #train# step 1735, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:13.572284 #train# step 1736, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:15.076150 #train# step 1737, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:16.621489 #train# step 1738, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:18.188572 #train# step 1739, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:19.769068 #train# step 1740, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:21.330114 #train# step 1741, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:22.865004 #train# step 1742, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:24.410204 #train# step 1743, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:25.974886 #train# step 1744, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:27.497447 #train# step 1745, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:29.078228 #train# step 1746, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:30.610143 #train# step 1747, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:32.129262 #train# step 1748, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:33.695853 #train# step 1749, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:35.248854 #train# step 1750, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:36.778821 #train# step 1751, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:38.352118 #train# step 1752, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:39.909940 #train# step 1753, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:41.444828 #train# step 1754, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:43.027296 #train# step 1755, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:44.572046 #train# step 1756, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:46.161422 #train# step 1757, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:47.707453 #train# step 1758, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:49.282264 #train# step 1759, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:50.809909 #train# step 1760, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:52.389561 #train# step 1761, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:53.926239 #train# step 1762, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:55.466086 #train# step 1763, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:57.048850 #train# step 1764, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:38:58.602064 #train# step 1765, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:00.141346 #train# step 1766, loss = 0.9817, cross_entropy loss = 0.9817, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:01.732278 #train# step 1767, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:03.287998 #train# step 1768, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:04.828856 #train# step 1769, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:06.374996 #train# step 1770, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:07.918360 #train# step 1771, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:09.515090 #train# step 1772, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:11.065413 #train# step 1773, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:12.626855 #train# step 1774, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:14.151548 #train# step 1775, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:15.693338 #train# step 1776, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:17.223998 #train# step 1777, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:18.786445 #train# step 1778, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:20.338520 #train# step 1779, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:21.898112 #train# step 1780, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:23.463484 #train# step 1781, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:25.023478 #train# step 1782, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:26.563679 #train# step 1783, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:28.115804 #train# step 1784, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:29.683136 #train# step 1785, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:31.243703 #train# step 1786, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:32.797833 #train# step 1787, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:34.346762 #train# step 1788, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:35.910312 #train# step 1789, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:37.452040 #train# step 1790, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:39.015960 #train# step 1791, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:40.585732 #train# step 1792, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:42.154616 #train# step 1793, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:43.718565 #train# step 1794, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:45.296129 #train# step 1795, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:46.829371 #train# step 1796, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:48.377733 #train# step 1797, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:49.939650 #train# step 1798, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:51.486840 #train# step 1799, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:53.026795 #train# step 1800, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:54.623824 #train# step 1801, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:56.174629 #train# step 1802, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:57.728877 #train# step 1803, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:39:59.300717 #train# step 1804, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:00.867735 #train# step 1805, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:02.386023 #train# step 1806, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:03.958265 #train# step 1807, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:05.507369 #train# step 1808, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:07.045495 #train# step 1809, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:08.583041 #train# step 1810, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:10.142430 #train# step 1811, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:11.681302 #train# step 1812, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:13.237864 #train# step 1813, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:14.791100 #train# step 1814, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:16.340732 #train# step 1815, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:17.922033 #train# step 1816, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:19.473047 #train# step 1817, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:21.006485 #train# step 1818, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:22.550201 #train# step 1819, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:24.101691 #train# step 1820, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:25.692602 #train# step 1821, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:27.240749 #train# step 1822, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:28.770695 #train# step 1823, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:30.338526 #train# step 1824, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:31.909954 #train# step 1825, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:33.470044 #train# step 1826, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:35.024219 #train# step 1827, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:36.560582 #train# step 1828, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:38.127706 #train# step 1829, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:39.712374 #train# step 1830, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:41.254456 #train# step 1831, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:42.811319 #train# step 1832, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:44.344240 #train# step 1833, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:45.911145 #train# step 1834, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:47.483834 #train# step 1835, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:49.059468 #train# step 1836, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:50.624045 #train# step 1837, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:52.165266 #train# step 1838, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:53.736307 #train# step 1839, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:55.312206 #train# step 1840, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:56.860937 #train# step 1841, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:58.418358 #train# step 1842, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:40:59.944064 #train# step 1843, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:01.503602 #train# step 1844, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:03.046443 #train# step 1845, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:04.603902 #train# step 1846, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:06.155692 #train# step 1847, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:07.710999 #train# step 1848, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:09.264498 #train# step 1849, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:10.822969 #train# step 1850, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:12.366555 #train# step 1851, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:13.924395 #train# step 1852, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:15.473838 #train# step 1853, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:17.074884 #train# step 1854, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:18.621289 #train# step 1855, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:20.150750 #train# step 1856, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:21.723274 #train# step 1857, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:23.280036 #train# step 1858, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:24.850107 #train# step 1859, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:26.392461 #train# step 1860, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:27.947920 #train# step 1861, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:29.501467 #train# step 1862, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:31.058138 #train# step 1863, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:32.611096 #train# step 1864, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:34.161649 #train# step 1865, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:35.713784 #train# step 1866, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:37.259704 #train# step 1867, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:38.837550 #train# step 1868, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:40.379930 #train# step 1869, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:41.901980 #train# step 1870, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:43.468043 #train# step 1871, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:45.012718 #train# step 1872, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:46.591627 #train# step 1873, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:48.205687 #train# step 1874, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:49.746352 #train# step 1875, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:51.372123 #train# step 1876, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:52.932181 #train# step 1877, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:54.482680 #train# step 1878, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:56.026318 #train# step 1879, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:57.577615 #train# step 1880, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:41:59.202658 #train# step 1881, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:00.750305 #train# step 1882, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:02.310548 #train# step 1883, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:03.909450 #train# step 1884, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:05.476366 #train# step 1885, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:07.076477 #train# step 1886, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:08.686807 #train# step 1887, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:10.278220 #train# step 1888, loss = 0.9827, cross_entropy loss = 0.9827, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:11.876784 #train# step 1889, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:13.415120 #train# step 1890, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:14.965403 #train# step 1891, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:16.542827 #train# step 1892, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:18.079622 #train# step 1893, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:19.642826 #train# step 1894, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:21.228257 #train# step 1895, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:22.807351 #train# step 1896, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:24.390715 #train# step 1897, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:25.926225 #train# step 1898, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:27.502512 #train# step 1899, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:29.052590 #train# step 1900, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:30.640040 #train# step 1901, loss = 0.9697, cross_entropy loss = 0.9697, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:32.216809 #train# step 1902, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:33.847537 #train# step 1903, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:35.410065 #train# step 1904, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:36.961879 #train# step 1905, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:38.528528 #train# step 1906, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:40.095463 #train# step 1907, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:41.660067 #train# step 1908, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:43.204092 #train# step 1909, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:44.736733 #train# step 1910, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:46.328748 #train# step 1911, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:47.918069 #train# step 1912, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:49.482665 #train# step 1913, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:51.058372 #train# step 1914, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:52.629635 #train# step 1915, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:54.143245 #train# step 1916, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:55.694672 #train# step 1917, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:57.214107 #train# step 1918, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:42:58.774828 #train# step 1919, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:00.413279 #train# step 1920, loss = 0.9787, cross_entropy loss = 0.9787, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:02.024810 #train# step 1921, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:03.608151 #train# step 1922, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:05.187321 #train# step 1923, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:06.759568 #train# step 1924, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:08.513200 #train# step 1925, loss = 0.9622, cross_entropy loss = 0.9622, 1.0 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:10.276749 #train# step 1926, loss = 0.9719, cross_entropy loss = 0.9719, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:11.972863 #train# step 1927, loss = 0.9648, cross_entropy loss = 0.9648, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:13.562235 #train# step 1928, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:15.255428 #train# step 1929, loss = 0.9646, cross_entropy loss = 0.9646, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:16.890571 #train# step 1930, loss = 0.9553, cross_entropy loss = 0.9553, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:18.536877 #train# step 1931, loss = 0.9513, cross_entropy loss = 0.9513, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:20.229668 #train# step 1932, loss = 0.9768, cross_entropy loss = 0.9768, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:21.892693 #train# step 1933, loss = 0.9591, cross_entropy loss = 0.9591, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:23.635792 #train# step 1934, loss = 0.9538, cross_entropy loss = 0.9538, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:25.401631 #train# step 1935, loss = 0.9523, cross_entropy loss = 0.9523, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:27.076145 #train# step 1936, loss = 0.9513, cross_entropy loss = 0.9513, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:28.816432 #train# step 1937, loss = 0.9660, cross_entropy loss = 0.9660, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:30.448508 #train# step 1938, loss = 0.9821, cross_entropy loss = 0.9821, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:32.081227 #train# step 1939, loss = 0.9452, cross_entropy loss = 0.9452, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:33.683866 #train# step 1940, loss = 0.9705, cross_entropy loss = 0.9705, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:35.321183 #train# step 1941, loss = 0.9566, cross_entropy loss = 0.9566, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:36.921972 #train# step 1942, loss = 0.9765, cross_entropy loss = 0.9765, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:38.582844 #train# step 1943, loss = 0.9693, cross_entropy loss = 0.9693, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:40.245751 #train# step 1944, loss = 0.9623, cross_entropy loss = 0.9623, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:41.849809 #train# step 1945, loss = 0.9645, cross_entropy loss = 0.9645, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:43.480276 #train# step 1946, loss = 0.9833, cross_entropy loss = 0.9833, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:45.090181 #train# step 1947, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:46.757142 #train# step 1948, loss = 0.9593, cross_entropy loss = 0.9593, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:48.505870 #train# step 1949, loss = 0.9589, cross_entropy loss = 0.9589, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:50.136785 #train# step 1950, loss = 0.9600, cross_entropy loss = 0.9600, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:51.731562 #train# step 1951, loss = 0.9600, cross_entropy loss = 0.9600, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:53.358602 #train# step 1952, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:55.011672 #train# step 1953, loss = 0.9655, cross_entropy loss = 0.9655, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:56.604212 #train# step 1954, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:58.209594 #train# step 1955, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:43:59.796815 #train# step 1956, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:01.372262 #train# step 1957, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:03.010506 #train# step 1958, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:04.678487 #train# step 1959, loss = 0.9573, cross_entropy loss = 0.9573, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:06.315598 #train# step 1960, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:07.894593 #train# step 1961, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:09.521305 #train# step 1962, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:11.171272 #train# step 1963, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:12.734535 #train# step 1964, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:14.298104 #train# step 1965, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:15.913108 #train# step 1966, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:17.528667 #train# step 1967, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:19.103328 #train# step 1968, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:20.652852 #train# step 1969, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:22.243536 #train# step 1970, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:23.815407 #train# step 1971, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:25.428394 #train# step 1972, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:27.006864 #train# step 1973, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:28.655891 #train# step 1974, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:30.284463 #train# step 1975, loss = 0.9474, cross_entropy loss = 0.9474, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:31.916322 #train# step 1976, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:33.574341 #train# step 1977, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:35.147902 #train# step 1978, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:36.724975 #train# step 1979, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:38.316472 #train# step 1980, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:39.900124 #train# step 1981, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:41.486138 #train# step 1982, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:43.037985 #train# step 1983, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:44.643996 #train# step 1984, loss = 0.9635, cross_entropy loss = 0.9635, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:46.227006 #train# step 1985, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:47.839636 #train# step 1986, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:49.388812 #train# step 1987, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:51.055426 #train# step 1988, loss = 0.9640, cross_entropy loss = 0.9640, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:52.640027 #train# step 1989, loss = 0.9637, cross_entropy loss = 0.9637, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:54.204560 #train# step 1990, loss = 0.9664, cross_entropy loss = 0.9664, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:55.839631 #train# step 1991, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:57.449073 #train# step 1992, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:44:59.091757 #train# step 1993, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:00.755479 #train# step 1994, loss = 0.9682, cross_entropy loss = 0.9682, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:02.392734 #train# step 1995, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:04.036165 #train# step 1996, loss = 0.9430, cross_entropy loss = 0.9430, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:05.660295 #train# step 1997, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:07.298700 #train# step 1998, loss = 0.9715, cross_entropy loss = 0.9715, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:08.995724 #train# step 1999, loss = 0.9537, cross_entropy loss = 0.9537, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:10.688675 #train# step 2000, loss = 0.9617, cross_entropy loss = 0.9617, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:12.311425 #train# step 2001, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:14.082164 #train# step 2002, loss = 0.9502, cross_entropy loss = 0.9502, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:15.709828 #train# step 2003, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:17.299211 #train# step 2004, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:18.898068 #train# step 2005, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:20.447556 #train# step 2006, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:22.020426 #train# step 2007, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:23.702851 #train# step 2008, loss = 0.9459, cross_entropy loss = 0.9459, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:25.220324 #train# step 2009, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:26.852776 #train# step 2010, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:28.413395 #train# step 2011, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:30.005474 #train# step 2012, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:31.623344 #train# step 2013, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:33.209925 #train# step 2014, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:34.779209 #train# step 2015, loss = 0.9797, cross_entropy loss = 0.9797, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:36.383852 #train# step 2016, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:37.984246 #train# step 2017, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:39.561621 #train# step 2018, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:41.165240 #train# step 2019, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:42.682190 #train# step 2020, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:44.195979 #train# step 2021, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:45.848294 #train# step 2022, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:47.490383 #train# step 2023, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:49.086670 #train# step 2024, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:50.682775 #train# step 2025, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:52.237323 #train# step 2026, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:53.831409 #train# step 2027, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:55.409300 #train# step 2028, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:56.960153 #train# step 2029, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:45:58.548095 #train# step 2030, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:00.078281 #train# step 2031, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:01.658876 #train# step 2032, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:03.233763 #train# step 2033, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:04.780108 #train# step 2034, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:06.361657 #train# step 2035, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:07.922624 #train# step 2036, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:09.466808 #train# step 2037, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:10.988226 #train# step 2038, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:12.516959 #train# step 2039, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:14.034253 #train# step 2040, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:15.573904 #train# step 2041, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:17.116239 #train# step 2042, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:18.674601 #train# step 2043, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:20.250518 #train# step 2044, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:21.834852 #train# step 2045, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:23.369858 #train# step 2046, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:24.942528 #train# step 2047, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:26.495658 #train# step 2048, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:28.064491 #train# step 2049, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:29.614090 #train# step 2050, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:31.169075 #train# step 2051, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:32.720701 #train# step 2052, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:34.252459 #train# step 2053, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:35.797438 #train# step 2054, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:37.374641 #train# step 2055, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:38.913172 #train# step 2056, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:40.433473 #train# step 2057, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:41.974526 #train# step 2058, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:43.502181 #train# step 2059, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:45.031485 #train# step 2060, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:46.551160 #train# step 2061, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:48.076348 #train# step 2062, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:49.656831 #train# step 2063, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:51.238581 #train# step 2064, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:52.768612 #train# step 2065, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:54.312040 #train# step 2066, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:55.863525 #train# step 2067, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:57.428201 #train# step 2068, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:46:58.951388 #train# step 2069, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:00.486713 #train# step 2070, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:02.038539 #train# step 2071, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:03.536719 #train# step 2072, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:05.043745 #train# step 2073, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:06.571857 #train# step 2074, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:08.147177 #train# step 2075, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:09.668312 #train# step 2076, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:11.229936 #train# step 2077, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:12.789782 #train# step 2078, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:14.339721 #train# step 2079, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:15.889448 #train# step 2080, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:17.447737 #train# step 2081, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:19.011156 #train# step 2082, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:20.549794 #train# step 2083, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:22.089036 #train# step 2084, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:23.640927 #train# step 2085, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:25.189471 #train# step 2086, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:26.754614 #train# step 2087, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:28.289961 #train# step 2088, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:29.835228 #train# step 2089, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:31.374515 #train# step 2090, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:32.933720 #train# step 2091, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:34.508471 #train# step 2092, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:36.061937 #train# step 2093, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:37.607279 #train# step 2094, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:39.193620 #train# step 2095, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:40.746792 #train# step 2096, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:42.279749 #train# step 2097, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:43.815824 #train# step 2098, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:45.379645 #train# step 2099, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:46.899616 #train# step 2100, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:48.467651 #train# step 2101, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:50.038684 #train# step 2102, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:51.588740 #train# step 2103, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:53.173964 #train# step 2104, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:54.755225 #train# step 2105, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:56.308152 #train# step 2106, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:57.824617 #train# step 2107, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:47:59.357918 #train# step 2108, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:00.922129 #train# step 2109, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:02.468498 #train# step 2110, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:04.008212 #train# step 2111, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:05.574278 #train# step 2112, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:07.095949 #train# step 2113, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:08.640436 #train# step 2114, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:10.207094 #train# step 2115, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:11.759822 #train# step 2116, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:13.322016 #train# step 2117, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:14.880517 #train# step 2118, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:16.443808 #train# step 2119, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:17.990433 #train# step 2120, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:19.540267 #train# step 2121, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:21.106896 #train# step 2122, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:22.656079 #train# step 2123, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:24.228992 #train# step 2124, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:25.785445 #train# step 2125, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:27.330043 #train# step 2126, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:28.854164 #train# step 2127, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:30.380194 #train# step 2128, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:31.931324 #train# step 2129, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:33.477343 #train# step 2130, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:35.017911 #train# step 2131, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:36.593857 #train# step 2132, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:38.137384 #train# step 2133, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:39.686550 #train# step 2134, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:41.236467 #train# step 2135, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:42.769822 #train# step 2136, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:44.347325 #train# step 2137, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:45.879935 #train# step 2138, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:47.428437 #train# step 2139, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:48.961965 #train# step 2140, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:50.514678 #train# step 2141, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:52.112586 #train# step 2142, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:53.662231 #train# step 2143, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:55.217864 #train# step 2144, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:56.736223 #train# step 2145, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:58.288848 #train# step 2146, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:48:59.863366 #train# step 2147, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:01.437967 #train# step 2148, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:02.962750 #train# step 2149, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:04.515055 #train# step 2150, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:06.060934 #train# step 2151, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:07.594331 #train# step 2152, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:09.103431 #train# step 2153, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:10.678440 #train# step 2154, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:12.212531 #train# step 2155, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:13.750104 #train# step 2156, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:15.285750 #train# step 2157, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:16.844082 #train# step 2158, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:18.398959 #train# step 2159, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:20.041075 #train# step 2160, loss = 0.9550, cross_entropy loss = 0.9550, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:21.646695 #train# step 2161, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:23.216387 #train# step 2162, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:24.785242 #train# step 2163, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:26.327618 #train# step 2164, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:27.876713 #train# step 2165, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:29.413186 #train# step 2166, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:30.991329 #train# step 2167, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:32.523891 #train# step 2168, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:34.044157 #train# step 2169, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:35.611363 #train# step 2170, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:37.222994 #train# step 2171, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:38.749482 #train# step 2172, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:40.368539 #train# step 2173, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:41.933835 #train# step 2174, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:43.514147 #train# step 2175, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:45.078302 #train# step 2176, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:46.611474 #train# step 2177, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:48.179092 #train# step 2178, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:49.730958 #train# step 2179, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:51.313489 #train# step 2180, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:52.818571 #train# step 2181, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:54.353401 #train# step 2182, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:55.915371 #train# step 2183, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:57.449726 #train# step 2184, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:49:58.998962 #train# step 2185, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:00.595503 #train# step 2186, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:02.166580 #train# step 2187, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:03.733343 #train# step 2188, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:05.292114 #train# step 2189, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:06.850871 #train# step 2190, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:08.381550 #train# step 2191, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:09.921475 #train# step 2192, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:11.461916 #train# step 2193, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:13.035089 #train# step 2194, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:14.598219 #train# step 2195, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:16.191037 #train# step 2196, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:17.749581 #train# step 2197, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:19.351800 #train# step 2198, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:20.939497 #train# step 2199, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:22.489808 #train# step 2200, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:24.072516 #train# step 2201, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:25.620064 #train# step 2202, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:27.166482 #train# step 2203, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:28.763386 #train# step 2204, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:30.372031 #train# step 2205, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:31.989758 #train# step 2206, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:33.618522 #train# step 2207, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:35.168361 #train# step 2208, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:36.734636 #train# step 2209, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:38.335103 #train# step 2210, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:39.876630 #train# step 2211, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:41.431429 #train# step 2212, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:42.969290 #train# step 2213, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:44.511809 #train# step 2214, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:46.097648 #train# step 2215, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:47.663512 #train# step 2216, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:49.203193 #train# step 2217, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:50.771478 #train# step 2218, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:52.337952 #train# step 2219, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:53.880637 #train# step 2220, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:55.388803 #train# step 2221, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:56.945994 #train# step 2222, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:50:58.505386 #train# step 2223, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:00.077789 #train# step 2224, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:01.664095 #train# step 2225, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:03.206717 #train# step 2226, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:04.741021 #train# step 2227, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:06.286652 #train# step 2228, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:07.836555 #train# step 2229, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:09.403054 #train# step 2230, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:10.948637 #train# step 2231, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:12.494924 #train# step 2232, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:14.051751 #train# step 2233, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:15.611881 #train# step 2234, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:17.161962 #train# step 2235, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:18.703372 #train# step 2236, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:20.266042 #train# step 2237, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:21.822061 #train# step 2238, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:23.374106 #train# step 2239, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:24.929418 #train# step 2240, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:26.471807 #train# step 2241, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:27.995597 #train# step 2242, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:29.558807 #train# step 2243, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:31.111691 #train# step 2244, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:32.693618 #train# step 2245, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:34.241956 #train# step 2246, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:35.768444 #train# step 2247, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:37.356603 #train# step 2248, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:38.888501 #train# step 2249, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:40.434959 #train# step 2250, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:41.990969 #train# step 2251, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:43.566369 #train# step 2252, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:45.138278 #train# step 2253, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:46.671281 #train# step 2254, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:48.207241 #train# step 2255, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:49.769569 #train# step 2256, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:51.325902 #train# step 2257, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:52.908884 #train# step 2258, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:54.464551 #train# step 2259, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:56.007004 #train# step 2260, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:57.569209 #train# step 2261, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:51:59.093179 #train# step 2262, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:00.645754 #train# step 2263, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:02.197274 #train# step 2264, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:03.710834 #train# step 2265, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:05.224705 #train# step 2266, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:06.726653 #train# step 2267, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:08.307497 #train# step 2268, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:09.851819 #train# step 2269, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:11.400936 #train# step 2270, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:12.974329 #train# step 2271, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:14.528316 #train# step 2272, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:16.111678 #train# step 2273, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:17.689498 #train# step 2274, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:19.228358 #train# step 2275, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:20.765922 #train# step 2276, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:22.293035 #train# step 2277, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:23.814778 #train# step 2278, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:25.386617 #train# step 2279, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:26.927124 #train# step 2280, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:28.516306 #train# step 2281, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:30.050174 #train# step 2282, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:31.582880 #train# step 2283, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:33.149327 #train# step 2284, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:34.716032 #train# step 2285, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:36.261846 #train# step 2286, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:37.810639 #train# step 2287, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:39.350010 #train# step 2288, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:40.922540 #train# step 2289, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:42.478419 #train# step 2290, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:44.017993 #train# step 2291, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:45.569757 #train# step 2292, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:47.128800 #train# step 2293, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:48.696706 #train# step 2294, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:50.253610 #train# step 2295, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:51.792340 #train# step 2296, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:53.350761 #train# step 2297, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:54.891975 #train# step 2298, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:56.412485 #train# step 2299, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:57.983237 #train# step 2300, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:52:59.535011 #train# step 2301, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:01.110284 #train# step 2302, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:02.691161 #train# step 2303, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:04.248215 #train# step 2304, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:05.790359 #train# step 2305, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:07.306938 #train# step 2306, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:08.854333 #train# step 2307, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:10.412208 #train# step 2308, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:11.956979 #train# step 2309, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:13.511888 #train# step 2310, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:15.080643 #train# step 2311, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:16.644380 #train# step 2312, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:18.219084 #train# step 2313, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:19.775306 #train# step 2314, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:21.348291 #train# step 2315, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:22.901134 #train# step 2316, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:24.472859 #train# step 2317, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:25.995903 #train# step 2318, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:27.527037 #train# step 2319, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:29.093604 #train# step 2320, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:30.665110 #train# step 2321, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:32.231384 #train# step 2322, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:33.802334 #train# step 2323, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:35.405629 #train# step 2324, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:36.958019 #train# step 2325, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:38.478244 #train# step 2326, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:40.015433 #train# step 2327, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:41.544286 #train# step 2328, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:43.083450 #train# step 2329, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:44.651989 #train# step 2330, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:46.195707 #train# step 2331, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:47.774044 #train# step 2332, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:49.317850 #train# step 2333, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:50.848766 #train# step 2334, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:52.397785 #train# step 2335, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:53.959017 #train# step 2336, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:55.517538 #train# step 2337, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:57.048106 #train# step 2338, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:53:58.618826 #train# step 2339, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:00.172039 #train# step 2340, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:01.725406 #train# step 2341, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:03.289245 #train# step 2342, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:04.838978 #train# step 2343, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:06.377079 #train# step 2344, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:07.912315 #train# step 2345, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:09.447054 #train# step 2346, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:10.967194 #train# step 2347, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:12.534889 #train# step 2348, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:14.086074 #train# step 2349, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:15.627617 #train# step 2350, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:17.196264 #train# step 2351, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:18.762316 #train# step 2352, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:20.295058 #train# step 2353, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:21.839113 #train# step 2354, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:23.375502 #train# step 2355, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:24.936853 #train# step 2356, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:26.499807 #train# step 2357, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:28.053300 #train# step 2358, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:29.616888 #train# step 2359, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:31.149868 #train# step 2360, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:32.667310 #train# step 2361, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:34.212378 #train# step 2362, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:35.776355 #train# step 2363, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:37.321184 #train# step 2364, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:38.841177 #train# step 2365, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:40.350261 #train# step 2366, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:41.866259 #train# step 2367, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:43.428742 #train# step 2368, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:45.020904 #train# step 2369, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:46.578192 #train# step 2370, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:48.172374 #train# step 2371, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:49.728337 #train# step 2372, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:51.263069 #train# step 2373, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:52.802721 #train# step 2374, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:54.378193 #train# step 2375, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:55.918405 #train# step 2376, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:57.470903 #train# step 2377, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:54:59.034493 #train# step 2378, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:00.579502 #train# step 2379, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:02.135328 #train# step 2380, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:03.700792 #train# step 2381, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:05.247599 #train# step 2382, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:06.813927 #train# step 2383, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:08.371226 #train# step 2384, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:09.952948 #train# step 2385, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:11.495452 #train# step 2386, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:13.050395 #train# step 2387, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:14.569271 #train# step 2388, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:16.139186 #train# step 2389, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:17.706760 #train# step 2390, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:19.253266 #train# step 2391, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:20.799851 #train# step 2392, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:22.343686 #train# step 2393, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:23.869384 #train# step 2394, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:25.414859 #train# step 2395, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:26.994657 #train# step 2396, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:28.582819 #train# step 2397, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:30.126069 #train# step 2398, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:31.655367 #train# step 2399, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:33.160115 #train# step 2400, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:34.704354 #train# step 2401, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:36.272440 #train# step 2402, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:37.834144 #train# step 2403, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:39.399408 #train# step 2404, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:40.977362 #train# step 2405, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:42.561417 #train# step 2406, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:44.105137 #train# step 2407, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:45.632291 #train# step 2408, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:47.203591 #train# step 2409, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:48.737461 #train# step 2410, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:50.276555 #train# step 2411, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:51.836303 #train# step 2412, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:53.371785 #train# step 2413, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:54.896973 #train# step 2414, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:56.450961 #train# step 2415, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:58.002465 #train# step 2416, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:55:59.579894 #train# step 2417, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:01.115844 #train# step 2418, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:02.733795 #train# step 2419, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:04.361225 #train# step 2420, loss = 0.9525, cross_entropy loss = 0.9525, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:05.930746 #train# step 2421, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:07.473866 #train# step 2422, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:09.016934 #train# step 2423, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:10.578706 #train# step 2424, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:12.153042 #train# step 2425, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:13.738451 #train# step 2426, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:15.291250 #train# step 2427, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:16.867401 #train# step 2428, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:18.444190 #train# step 2429, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:20.018122 #train# step 2430, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:21.604101 #train# step 2431, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:23.170359 #train# step 2432, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:24.772443 #train# step 2433, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:26.319948 #train# step 2434, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:27.875820 #train# step 2435, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:29.454525 #train# step 2436, loss = 0.9466, cross_entropy loss = 0.9466, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:31.052419 #train# step 2437, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:32.623399 #train# step 2438, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:34.188802 #train# step 2439, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:35.763992 #train# step 2440, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:37.344975 #train# step 2441, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:38.969019 #train# step 2442, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:40.648103 #train# step 2443, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:42.231209 #train# step 2444, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:43.820665 #train# step 2445, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:45.384074 #train# step 2446, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:47.064615 #train# step 2447, loss = 0.9460, cross_entropy loss = 0.9460, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:48.647494 #train# step 2448, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:50.211396 #train# step 2449, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:51.743218 #train# step 2450, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:53.279889 #train# step 2451, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:54.845554 #train# step 2452, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:56.404396 #train# step 2453, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:57.971108 #train# step 2454, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:56:59.527446 #train# step 2455, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:01.123175 #train# step 2456, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:02.702628 #train# step 2457, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:04.279707 #train# step 2458, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:05.841901 #train# step 2459, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:07.430599 #train# step 2460, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:09.010766 #train# step 2461, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:10.563307 #train# step 2462, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:12.142829 #train# step 2463, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:13.759096 #train# step 2464, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:15.316256 #train# step 2465, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:16.929409 #train# step 2466, loss = 0.9663, cross_entropy loss = 0.9663, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:18.499539 #train# step 2467, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:20.079404 #train# step 2468, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:21.668497 #train# step 2469, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:23.248110 #train# step 2470, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:24.837496 #train# step 2471, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:26.385916 #train# step 2472, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:27.977507 #train# step 2473, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:29.562708 #train# step 2474, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:31.135974 #train# step 2475, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:32.680998 #train# step 2476, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:34.197587 #train# step 2477, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:35.796567 #train# step 2478, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:37.352072 #train# step 2479, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:38.935864 #train# step 2480, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:40.477363 #train# step 2481, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:42.012678 #train# step 2482, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:43.556789 #train# step 2483, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:45.077203 #train# step 2484, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:46.629583 #train# step 2485, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:48.185992 #train# step 2486, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:49.748119 #train# step 2487, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:51.323341 #train# step 2488, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:52.863645 #train# step 2489, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:54.446985 #train# step 2490, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:55.996852 #train# step 2491, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:57.530071 #train# step 2492, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:57:59.097613 #train# step 2493, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:00.654808 #train# step 2494, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:02.215745 #train# step 2495, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:03.784384 #train# step 2496, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:05.330385 #train# step 2497, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:06.865491 #train# step 2498, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:08.441393 #train# step 2499, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:09.989841 #train# step 2500, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:11.531367 #train# step 2501, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:13.089010 #train# step 2502, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:14.637011 #train# step 2503, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:16.216276 #train# step 2504, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:17.766938 #train# step 2505, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:19.330573 #train# step 2506, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:20.888960 #train# step 2507, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:22.425561 #train# step 2508, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:23.975352 #train# step 2509, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:25.515504 #train# step 2510, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:27.064614 #train# step 2511, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:28.635007 #train# step 2512, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:30.216670 #train# step 2513, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:31.779338 #train# step 2514, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:33.325543 #train# step 2515, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:34.863705 #train# step 2516, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:36.430966 #train# step 2517, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:37.997403 #train# step 2518, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:39.554821 #train# step 2519, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:41.130999 #train# step 2520, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:42.709020 #train# step 2521, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:44.273792 #train# step 2522, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:45.833817 #train# step 2523, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:47.399539 #train# step 2524, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:48.951174 #train# step 2525, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:50.507503 #train# step 2526, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:52.042783 #train# step 2527, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:53.583681 #train# step 2528, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:55.102930 #train# step 2529, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:56.625685 #train# step 2530, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:58.146566 #train# step 2531, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:58:59.698608 #train# step 2532, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:01.248455 #train# step 2533, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:02.812092 #train# step 2534, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:04.337964 #train# step 2535, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:05.845775 #train# step 2536, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:07.399822 #train# step 2537, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:08.987013 #train# step 2538, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:10.545340 #train# step 2539, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:12.083871 #train# step 2540, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:13.646679 #train# step 2541, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:15.167799 #train# step 2542, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:16.767448 #train# step 2543, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:18.336043 #train# step 2544, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:19.859513 #train# step 2545, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:21.379220 #train# step 2546, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:22.949050 #train# step 2547, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:24.499765 #train# step 2548, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:26.079593 #train# step 2549, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:27.636541 #train# step 2550, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:29.199598 #train# step 2551, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:30.761930 #train# step 2552, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:32.322829 #train# step 2553, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:33.867501 #train# step 2554, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:35.486514 #train# step 2555, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:37.026027 #train# step 2556, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:38.624052 #train# step 2557, loss = 0.9619, cross_entropy loss = 0.9619, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:40.190008 #train# step 2558, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:41.820396 #train# step 2559, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:43.355182 #train# step 2560, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:44.928679 #train# step 2561, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:46.503292 #train# step 2562, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:48.076206 #train# step 2563, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:49.652885 #train# step 2564, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:51.203835 #train# step 2565, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:52.801895 #train# step 2566, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:54.359665 #train# step 2567, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:55.893554 #train# step 2568, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:57.451322 #train# step 2569, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 21:59:59.024495 #train# step 2570, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:00.603561 #train# step 2571, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:02.192168 #train# step 2572, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:03.754112 #train# step 2573, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:05.319619 #train# step 2574, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:06.871916 #train# step 2575, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:08.438625 #train# step 2576, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:09.999546 #train# step 2577, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:11.584156 #train# step 2578, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:13.162479 #train# step 2579, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:14.704978 #train# step 2580, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:16.272419 #train# step 2581, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:17.799732 #train# step 2582, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:19.369429 #train# step 2583, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:20.920389 #train# step 2584, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:22.470891 #train# step 2585, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:24.041226 #train# step 2586, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:25.616929 #train# step 2587, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:27.207028 #train# step 2588, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:28.772947 #train# step 2589, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:30.353238 #train# step 2590, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:31.882779 #train# step 2591, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:33.436808 #train# step 2592, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:34.972470 #train# step 2593, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:36.518822 #train# step 2594, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:38.051435 #train# step 2595, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:39.607980 #train# step 2596, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:41.187741 #train# step 2597, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:42.737704 #train# step 2598, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:44.323775 #train# step 2599, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:45.880764 #train# step 2600, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:47.465684 #train# step 2601, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:49.065081 #train# step 2602, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:50.605682 #train# step 2603, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:52.176173 #train# step 2604, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:53.717806 #train# step 2605, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:55.253603 #train# step 2606, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:56.811737 #train# step 2607, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:58.313289 #train# step 2608, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:00:59.857552 #train# step 2609, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:01.421038 #train# step 2610, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:02.969903 #train# step 2611, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:04.512770 #train# step 2612, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:06.061511 #train# step 2613, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:07.622179 #train# step 2614, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:09.208244 #train# step 2615, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:10.764922 #train# step 2616, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:12.309990 #train# step 2617, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:13.877152 #train# step 2618, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:15.394458 #train# step 2619, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:16.915604 #train# step 2620, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:18.469035 #train# step 2621, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:20.035008 #train# step 2622, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:21.604772 #train# step 2623, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:23.155117 #train# step 2624, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:24.738869 #train# step 2625, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:26.281390 #train# step 2626, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:27.857820 #train# step 2627, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:29.406902 #train# step 2628, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:30.957194 #train# step 2629, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:32.504256 #train# step 2630, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:34.041701 #train# step 2631, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:35.604291 #train# step 2632, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:37.172230 #train# step 2633, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:38.724624 #train# step 2634, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:40.291967 #train# step 2635, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:41.886336 #train# step 2636, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:43.450931 #train# step 2637, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:45.023243 #train# step 2638, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:46.599053 #train# step 2639, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:48.173820 #train# step 2640, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:49.733186 #train# step 2641, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:51.270472 #train# step 2642, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:52.790371 #train# step 2643, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:54.360251 #train# step 2644, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:55.920211 #train# step 2645, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:57.468738 #train# step 2646, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:01:59.042775 #train# step 2647, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:00.620791 #train# step 2648, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:02.190409 #train# step 2649, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:03.745658 #train# step 2650, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:05.318364 #train# step 2651, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:06.863911 #train# step 2652, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:08.395510 #train# step 2653, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:09.951898 #train# step 2654, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:11.473903 #train# step 2655, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:13.012111 #train# step 2656, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:14.603728 #train# step 2657, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:16.123762 #train# step 2658, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:17.655946 #train# step 2659, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:19.210586 #train# step 2660, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:20.777538 #train# step 2661, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:22.348867 #train# step 2662, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:23.912840 #train# step 2663, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:25.472675 #train# step 2664, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:27.021815 #train# step 2665, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:28.549033 #train# step 2666, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:30.123046 #train# step 2667, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:31.673056 #train# step 2668, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:33.196997 #train# step 2669, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:34.741017 #train# step 2670, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:36.333034 #train# step 2671, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:37.870509 #train# step 2672, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:39.404911 #train# step 2673, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:40.963041 #train# step 2674, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:42.515843 #train# step 2675, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:44.043637 #train# step 2676, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:45.621814 #train# step 2677, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:47.164025 #train# step 2678, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:48.708349 #train# step 2679, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:50.278437 #train# step 2680, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:51.825119 #train# step 2681, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:53.415569 #train# step 2682, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:54.968614 #train# step 2683, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:56.496064 #train# step 2684, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:58.048548 #train# step 2685, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:02:59.594529 #train# step 2686, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:01.161499 #train# step 2687, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:02.736375 #train# step 2688, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:04.289635 #train# step 2689, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:05.843388 #train# step 2690, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:07.369926 #train# step 2691, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:08.926208 #train# step 2692, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:10.508166 #train# step 2693, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:12.071171 #train# step 2694, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:13.636903 #train# step 2695, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:15.172038 #train# step 2696, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:16.714531 #train# step 2697, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:18.291339 #train# step 2698, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:19.844537 #train# step 2699, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:21.366035 #train# step 2700, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:22.934892 #train# step 2701, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:24.483004 #train# step 2702, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:25.998359 #train# step 2703, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:27.566712 #train# step 2704, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:29.131855 #train# step 2705, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:30.700428 #train# step 2706, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:32.236792 #train# step 2707, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:33.781603 #train# step 2708, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:35.323664 #train# step 2709, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:36.897026 #train# step 2710, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:38.450728 #train# step 2711, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:40.014342 #train# step 2712, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:41.585582 #train# step 2713, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:43.147559 #train# step 2714, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:44.673507 #train# step 2715, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:46.253092 #train# step 2716, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:47.805117 #train# step 2717, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:49.375747 #train# step 2718, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:50.912565 #train# step 2719, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:52.486570 #train# step 2720, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:54.062776 #train# step 2721, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:55.659931 #train# step 2722, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:57.178403 #train# step 2723, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:03:58.732722 #train# step 2724, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:00.312410 #train# step 2725, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:01.879631 #train# step 2726, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:03.470791 #train# step 2727, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:05.023136 #train# step 2728, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:06.590531 #train# step 2729, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:08.135700 #train# step 2730, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:09.695999 #train# step 2731, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:11.259841 #train# step 2732, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:12.799527 #train# step 2733, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:14.368689 #train# step 2734, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:15.933202 #train# step 2735, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:17.467000 #train# step 2736, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:19.035273 #train# step 2737, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:20.603170 #train# step 2738, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:22.168436 #train# step 2739, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:23.719218 #train# step 2740, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:25.268792 #train# step 2741, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:26.846928 #train# step 2742, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:28.387024 #train# step 2743, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:29.931314 #train# step 2744, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:31.498992 #train# step 2745, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:33.062227 #train# step 2746, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:34.644123 #train# step 2747, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:36.208522 #train# step 2748, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:37.778166 #train# step 2749, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:39.332196 #train# step 2750, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:40.882553 #train# step 2751, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:42.468854 #train# step 2752, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:44.021965 #train# step 2753, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:45.582026 #train# step 2754, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:47.138753 #train# step 2755, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:48.682660 #train# step 2756, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:50.222192 #train# step 2757, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:51.788794 #train# step 2758, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:53.331392 #train# step 2759, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:54.881531 #train# step 2760, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:56.448752 #train# step 2761, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:57.988108 #train# step 2762, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:04:59.518990 #train# step 2763, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:01.071210 #train# step 2764, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:02.586612 #train# step 2765, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:04.184334 #train# step 2766, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:05.750240 #train# step 2767, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:07.284331 #train# step 2768, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:08.848746 #train# step 2769, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:10.386780 #train# step 2770, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:11.949781 #train# step 2771, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:13.487403 #train# step 2772, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:15.046455 #train# step 2773, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:16.605608 #train# step 2774, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:18.155659 #train# step 2775, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:19.701240 #train# step 2776, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:21.272325 #train# step 2777, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:22.789972 #train# step 2778, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:24.329417 #train# step 2779, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:25.900661 #train# step 2780, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:27.448229 #train# step 2781, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:28.991045 #train# step 2782, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:30.564702 #train# step 2783, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:32.114604 #train# step 2784, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:33.635495 #train# step 2785, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:35.192489 #train# step 2786, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:36.759384 #train# step 2787, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:38.295553 #train# step 2788, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:39.849785 #train# step 2789, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:41.418006 #train# step 2790, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:43.024594 #train# step 2791, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:44.544051 #train# step 2792, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:46.087449 #train# step 2793, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:47.632586 #train# step 2794, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:49.220147 #train# step 2795, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:50.767947 #train# step 2796, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:52.322251 #train# step 2797, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:53.868718 #train# step 2798, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:55.416322 #train# step 2799, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:56.956475 #train# step 2800, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:05:58.571685 #train# step 2801, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:00.126230 #train# step 2802, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:01.695683 #train# step 2803, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:03.248206 #train# step 2804, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:04.812746 #train# step 2805, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:06.372478 #train# step 2806, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:07.976098 #train# step 2807, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:09.560644 #train# step 2808, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:11.080338 #train# step 2809, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:12.630170 #train# step 2810, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:14.192052 #train# step 2811, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:15.766840 #train# step 2812, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:17.316312 #train# step 2813, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:18.889390 #train# step 2814, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:20.471385 #train# step 2815, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:22.032002 #train# step 2816, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:23.583453 #train# step 2817, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:25.143138 #train# step 2818, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:26.707356 #train# step 2819, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:28.269249 #train# step 2820, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:29.808055 #train# step 2821, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:31.341418 #train# step 2822, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:32.920103 #train# step 2823, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:34.495755 #train# step 2824, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:36.050749 #train# step 2825, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:37.639634 #train# step 2826, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:39.181232 #train# step 2827, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:40.743446 #train# step 2828, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:42.286925 #train# step 2829, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:43.846735 #train# step 2830, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:45.414716 #train# step 2831, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:46.992901 #train# step 2832, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:48.545110 #train# step 2833, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:50.129143 #train# step 2834, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:51.686887 #train# step 2835, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:53.224337 #train# step 2836, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:54.778083 #train# step 2837, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:56.302377 #train# step 2838, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:57.855725 #train# step 2839, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:06:59.412588 #train# step 2840, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:01.004891 #train# step 2841, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:02.537901 #train# step 2842, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:04.103744 #train# step 2843, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:05.672170 #train# step 2844, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:07.212459 #train# step 2845, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:08.803509 #train# step 2846, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:10.348297 #train# step 2847, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:11.860614 #train# step 2848, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:13.418900 #train# step 2849, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:14.987897 #train# step 2850, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:16.535563 #train# step 2851, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:18.109216 #train# step 2852, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:19.630296 #train# step 2853, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:21.218677 #train# step 2854, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:22.783086 #train# step 2855, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:24.333951 #train# step 2856, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:25.878180 #train# step 2857, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:27.471382 #train# step 2858, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:29.011947 #train# step 2859, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:30.553889 #train# step 2860, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:32.108486 #train# step 2861, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:33.625944 #train# step 2862, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:35.175103 #train# step 2863, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:36.713864 #train# step 2864, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:38.284113 #train# step 2865, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:39.862961 #train# step 2866, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:41.420996 #train# step 2867, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:42.953384 #train# step 2868, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:44.469120 #train# step 2869, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:46.034345 #train# step 2870, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:47.586569 #train# step 2871, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:49.143663 #train# step 2872, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:50.696694 #train# step 2873, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:52.286832 #train# step 2874, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:53.847958 #train# step 2875, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:55.432534 #train# step 2876, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:57.011204 #train# step 2877, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:07:58.587969 #train# step 2878, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:00.143413 #train# step 2879, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:01.695663 #train# step 2880, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:03.248518 #train# step 2881, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:04.840020 #train# step 2882, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:06.370038 #train# step 2883, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:07.914331 #train# step 2884, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:09.461314 #train# step 2885, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:11.007575 #train# step 2886, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:12.574384 #train# step 2887, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:14.134000 #train# step 2888, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:15.689168 #train# step 2889, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:17.253667 #train# step 2890, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:18.840946 #train# step 2891, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:20.382347 #train# step 2892, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:21.916248 #train# step 2893, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:23.446045 #train# step 2894, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:24.971960 #train# step 2895, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:26.536248 #train# step 2896, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:28.054782 #train# step 2897, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:29.610445 #train# step 2898, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:31.179181 #train# step 2899, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:32.740986 #train# step 2900, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:34.314304 #train# step 2901, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:35.876366 #train# step 2902, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:37.405969 #train# step 2903, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:38.949944 #train# step 2904, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:40.505466 #train# step 2905, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:42.075523 #train# step 2906, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:43.636839 #train# step 2907, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:45.187747 #train# step 2908, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:46.745683 #train# step 2909, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:48.276494 #train# step 2910, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:49.811316 #train# step 2911, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:51.368021 #train# step 2912, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:52.930950 #train# step 2913, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:54.494851 #train# step 2914, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:56.043411 #train# step 2915, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:57.632755 #train# step 2916, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:08:59.204572 #train# step 2917, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:00.765713 #train# step 2918, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:02.325024 #train# step 2919, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:03.875657 #train# step 2920, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:05.429733 #train# step 2921, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:07.004884 #train# step 2922, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:08.580296 #train# step 2923, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:10.172458 #train# step 2924, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:11.728809 #train# step 2925, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:13.281764 #train# step 2926, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:14.853179 #train# step 2927, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:16.427710 #train# step 2928, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:17.964527 #train# step 2929, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:19.512963 #train# step 2930, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:21.049336 #train# step 2931, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:22.592422 #train# step 2932, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:24.147765 #train# step 2933, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:25.690992 #train# step 2934, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:27.249565 #train# step 2935, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:28.828672 #train# step 2936, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:30.395803 #train# step 2937, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:31.979726 #train# step 2938, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:33.516555 #train# step 2939, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:35.087414 #train# step 2940, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:36.600226 #train# step 2941, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:38.141327 #train# step 2942, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:39.716403 #train# step 2943, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:41.252941 #train# step 2944, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:42.801378 #train# step 2945, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:44.351165 #train# step 2946, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:45.885951 #train# step 2947, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:47.440018 #train# step 2948, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:48.985447 #train# step 2949, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:50.543009 #train# step 2950, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:52.077681 #train# step 2951, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:53.610303 #train# step 2952, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:55.162955 #train# step 2953, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:56.715635 #train# step 2954, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:58.256257 #train# step 2955, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:09:59.798630 #train# step 2956, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:01.382938 #train# step 2957, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:02.930304 #train# step 2958, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:04.527125 #train# step 2959, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:06.067013 #train# step 2960, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:07.622281 #train# step 2961, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:09.210010 #train# step 2962, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:10.783231 #train# step 2963, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:12.379001 #train# step 2964, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:13.952902 #train# step 2965, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:15.499619 #train# step 2966, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:17.047134 #train# step 2967, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:18.596140 #train# step 2968, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:20.155085 #train# step 2969, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:21.730036 #train# step 2970, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:23.272928 #train# step 2971, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:24.800519 #train# step 2972, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:26.388981 #train# step 2973, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:27.956354 #train# step 2974, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:29.501538 #train# step 2975, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:31.073111 #train# step 2976, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:32.591918 #train# step 2977, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:34.119096 #train# step 2978, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:35.647550 #train# step 2979, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:37.194946 #train# step 2980, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:38.755506 #train# step 2981, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:40.332947 #train# step 2982, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:41.905027 #train# step 2983, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:43.452983 #train# step 2984, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:45.010426 #train# step 2985, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:46.561924 #train# step 2986, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:48.129304 #train# step 2987, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:49.685411 #train# step 2988, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:51.240272 #train# step 2989, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:52.767944 #train# step 2990, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:54.327165 #train# step 2991, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:55.906266 #train# step 2992, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:57.457724 #train# step 2993, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:10:58.987738 #train# step 2994, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:00.549271 #train# step 2995, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:02.095300 #train# step 2996, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:03.663319 #train# step 2997, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:05.253248 #train# step 2998, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:06.837744 #train# step 2999, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:08.371335 #train# step 3000, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:09.927498 #train# step 3001, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:11.463910 #train# step 3002, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:13.011616 #train# step 3003, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:14.585405 #train# step 3004, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:16.182514 #train# step 3005, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:17.751284 #train# step 3006, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:19.330811 #train# step 3007, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:20.912016 #train# step 3008, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:22.455323 #train# step 3009, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:24.040946 #train# step 3010, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:25.602664 #train# step 3011, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:27.157117 #train# step 3012, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:28.707139 #train# step 3013, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:30.299049 #train# step 3014, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:31.890283 #train# step 3015, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:33.428734 #train# step 3016, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:35.018974 #train# step 3017, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:36.618823 #train# step 3018, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:38.223210 #train# step 3019, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:39.880531 #train# step 3020, loss = 0.9378, cross_entropy loss = 0.9378, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:41.449450 #train# step 3021, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:43.037720 #train# step 3022, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:44.598585 #train# step 3023, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:46.156821 #train# step 3024, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:47.694136 #train# step 3025, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:49.245476 #train# step 3026, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:50.796062 #train# step 3027, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:52.375718 #train# step 3028, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:53.957462 #train# step 3029, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:55.511221 #train# step 3030, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:57.102905 #train# step 3031, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:11:58.721681 #train# step 3032, loss = 0.9440, cross_entropy loss = 0.9440, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:00.318132 #train# step 3033, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:01.883816 #train# step 3034, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:03.452026 #train# step 3035, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:05.017767 #train# step 3036, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:06.553890 #train# step 3037, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:08.091222 #train# step 3038, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:09.674105 #train# step 3039, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:11.222006 #train# step 3040, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:12.807681 #train# step 3041, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:14.374448 #train# step 3042, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:15.949336 #train# step 3043, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:17.532709 #train# step 3044, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:19.082546 #train# step 3045, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:20.636275 #train# step 3046, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:22.180662 #train# step 3047, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:23.756660 #train# step 3048, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:25.308065 #train# step 3049, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:26.865447 #train# step 3050, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:28.402307 #train# step 3051, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:29.931146 #train# step 3052, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:31.472465 #train# step 3053, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:33.014928 #train# step 3054, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:34.577065 #train# step 3055, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:36.149851 #train# step 3056, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:37.704794 #train# step 3057, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:39.279307 #train# step 3058, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:40.816967 #train# step 3059, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:42.394549 #train# step 3060, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:43.946742 #train# step 3061, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:45.466729 #train# step 3062, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:47.008780 #train# step 3063, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:48.566263 #train# step 3064, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:50.116498 #train# step 3065, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:51.687499 #train# step 3066, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:53.268436 #train# step 3067, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:54.829269 #train# step 3068, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:56.373586 #train# step 3069, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:57.918462 #train# step 3070, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:12:59.493015 #train# step 3071, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:01.049802 #train# step 3072, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:02.621188 #train# step 3073, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:04.211062 #train# step 3074, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:05.775940 #train# step 3075, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:07.350894 #train# step 3076, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:08.901710 #train# step 3077, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:10.449287 #train# step 3078, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:12.038130 #train# step 3079, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:13.599255 #train# step 3080, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:15.188975 #train# step 3081, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:16.790798 #train# step 3082, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:18.372887 #train# step 3083, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:19.935967 #train# step 3084, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:21.537783 #train# step 3085, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:23.119045 #train# step 3086, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:24.709746 #train# step 3087, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:26.271910 #train# step 3088, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:27.806687 #train# step 3089, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:29.359616 #train# step 3090, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:30.882910 #train# step 3091, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:32.434445 #train# step 3092, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:34.025122 #train# step 3093, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:35.579217 #train# step 3094, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:37.166332 #train# step 3095, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:38.685132 #train# step 3096, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:40.207515 #train# step 3097, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:41.750232 #train# step 3098, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:43.318394 #train# step 3099, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:44.892662 #train# step 3100, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:46.448979 #train# step 3101, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:47.978352 #train# step 3102, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:49.528131 #train# step 3103, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:51.082664 #train# step 3104, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:52.631628 #train# step 3105, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:54.223564 #train# step 3106, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:55.794913 #train# step 3107, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:57.329615 #train# step 3108, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:13:58.860707 #train# step 3109, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:00.431997 #train# step 3110, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:01.991675 #train# step 3111, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:03.539752 #train# step 3112, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:05.081961 #train# step 3113, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:06.630006 #train# step 3114, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:08.196827 #train# step 3115, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:09.734364 #train# step 3116, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:11.277778 #train# step 3117, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:12.863307 #train# step 3118, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:14.463637 #train# step 3119, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:16.036619 #train# step 3120, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:17.591560 #train# step 3121, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:19.165568 #train# step 3122, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:20.728674 #train# step 3123, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:22.268461 #train# step 3124, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:23.831306 #train# step 3125, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:25.388136 #train# step 3126, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:26.962675 #train# step 3127, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:28.534160 #train# step 3128, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:30.062167 #train# step 3129, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:31.629705 #train# step 3130, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:33.184973 #train# step 3131, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:34.735362 #train# step 3132, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:36.303431 #train# step 3133, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:37.905842 #train# step 3134, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:39.501034 #train# step 3135, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:41.068793 #train# step 3136, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:42.628186 #train# step 3137, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:44.214091 #train# step 3138, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:45.780426 #train# step 3139, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:47.378873 #train# step 3140, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:48.947855 #train# step 3141, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:50.518072 #train# step 3142, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:52.067114 #train# step 3143, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:53.632537 #train# step 3144, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:55.167912 #train# step 3145, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:56.711038 #train# step 3146, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:58.252076 #train# step 3147, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:14:59.804827 #train# step 3148, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:01.343305 #train# step 3149, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:02.944744 #train# step 3150, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:04.537127 #train# step 3151, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:06.124661 #train# step 3152, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:07.661304 #train# step 3153, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:09.224127 #train# step 3154, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:10.766077 #train# step 3155, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:12.341141 #train# step 3156, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:13.864476 #train# step 3157, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:15.395528 #train# step 3158, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:16.980391 #train# step 3159, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:18.510766 #train# step 3160, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:20.101660 #train# step 3161, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:21.668367 #train# step 3162, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:23.187840 #train# step 3163, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:24.713666 #train# step 3164, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:26.258683 #train# step 3165, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:27.814479 #train# step 3166, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:29.384116 #train# step 3167, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:30.981426 #train# step 3168, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:32.556733 #train# step 3169, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:34.101371 #train# step 3170, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:35.644112 #train# step 3171, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:37.175954 #train# step 3172, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:38.740050 #train# step 3173, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:40.333337 #train# step 3174, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:41.898819 #train# step 3175, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:43.473537 #train# step 3176, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:45.014005 #train# step 3177, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:46.609739 #train# step 3178, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:48.173822 #train# step 3179, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:49.711706 #train# step 3180, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:51.277211 #train# step 3181, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:52.816398 #train# step 3182, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:54.401924 #train# step 3183, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:55.986485 #train# step 3184, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:57.547985 #train# step 3185, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:15:59.113909 #train# step 3186, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:00.661206 #train# step 3187, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:02.259574 #train# step 3188, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:03.813087 #train# step 3189, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:05.389628 #train# step 3190, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:06.952311 #train# step 3191, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:08.529823 #train# step 3192, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:10.092612 #train# step 3193, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:11.672332 #train# step 3194, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:13.223100 #train# step 3195, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:14.764473 #train# step 3196, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:16.300251 #train# step 3197, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:17.862695 #train# step 3198, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:19.475639 #train# step 3199, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:21.042151 #train# step 3200, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:22.614174 #train# step 3201, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:24.172844 #train# step 3202, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:25.681337 #train# step 3203, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:27.264685 #train# step 3204, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:28.806566 #train# step 3205, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:30.426608 #train# step 3206, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:31.956078 #train# step 3207, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:33.510346 #train# step 3208, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:35.046331 #train# step 3209, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:36.622535 #train# step 3210, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:38.184726 #train# step 3211, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:39.714638 #train# step 3212, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:41.255393 #train# step 3213, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:42.792600 #train# step 3214, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:44.356421 #train# step 3215, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:45.875344 #train# step 3216, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:47.456264 #train# step 3217, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:49.007774 #train# step 3218, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:50.566400 #train# step 3219, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:52.173054 #train# step 3220, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:53.781137 #train# step 3221, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:55.391542 #train# step 3222, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:56.949527 #train# step 3223, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:16:58.511881 #train# step 3224, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:00.055758 #train# step 3225, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:01.633768 #train# step 3226, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:03.196282 #train# step 3227, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:04.748043 #train# step 3228, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:06.325465 #train# step 3229, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:07.889898 #train# step 3230, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:09.418831 #train# step 3231, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:10.959842 #train# step 3232, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:12.515735 #train# step 3233, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:14.048166 #train# step 3234, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:15.615011 #train# step 3235, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:17.168858 #train# step 3236, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:18.770666 #train# step 3237, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:20.357004 #train# step 3238, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:21.908608 #train# step 3239, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:23.483136 #train# step 3240, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:25.034911 #train# step 3241, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:26.588847 #train# step 3242, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:28.127767 #train# step 3243, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:29.669209 #train# step 3244, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:31.271250 #train# step 3245, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:32.828882 #train# step 3246, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:34.432357 #train# step 3247, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:35.984129 #train# step 3248, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:37.521512 #train# step 3249, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:39.063859 #train# step 3250, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:40.628428 #train# step 3251, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:42.219832 #train# step 3252, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:43.786864 #train# step 3253, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:45.348724 #train# step 3254, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:46.890475 #train# step 3255, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:48.473930 #train# step 3256, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:50.020127 #train# step 3257, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:51.582773 #train# step 3258, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:53.153860 #train# step 3259, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:54.743438 #train# step 3260, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:56.303270 #train# step 3261, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:57.834577 #train# step 3262, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:17:59.453475 #train# step 3263, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:01.074155 #train# step 3264, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:02.650127 #train# step 3265, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:04.214398 #train# step 3266, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:05.792780 #train# step 3267, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:07.340941 #train# step 3268, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:08.890206 #train# step 3269, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:10.444731 #train# step 3270, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:12.005194 #train# step 3271, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:13.534641 #train# step 3272, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:15.103278 #train# step 3273, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:16.657918 #train# step 3274, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:18.226858 #train# step 3275, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:19.792601 #train# step 3276, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:21.353696 #train# step 3277, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:22.901479 #train# step 3278, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:24.422456 #train# step 3279, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:25.970973 #train# step 3280, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:27.513866 #train# step 3281, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:29.065893 #train# step 3282, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:30.644765 #train# step 3283, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:32.194954 #train# step 3284, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:33.765830 #train# step 3285, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:35.285490 #train# step 3286, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:36.850397 #train# step 3287, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:38.368261 #train# step 3288, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:39.905536 #train# step 3289, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:41.468313 #train# step 3290, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:43.026754 #train# step 3291, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:44.581456 #train# step 3292, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:46.144703 #train# step 3293, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:47.688008 #train# step 3294, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:49.247669 #train# step 3295, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:50.802024 #train# step 3296, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:52.374572 #train# step 3297, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:53.974712 #train# step 3298, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:55.522899 #train# step 3299, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:57.074435 #train# step 3300, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:18:58.612683 #train# step 3301, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:00.143757 #train# step 3302, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:01.721721 #train# step 3303, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:03.262004 #train# step 3304, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:04.826298 #train# step 3305, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:06.335650 #train# step 3306, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:07.893632 #train# step 3307, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:09.465383 #train# step 3308, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:11.024697 #train# step 3309, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:12.594859 #train# step 3310, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:14.110495 #train# step 3311, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:15.692562 #train# step 3312, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:17.277597 #train# step 3313, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:18.836523 #train# step 3314, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:20.386038 #train# step 3315, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:22.012378 #train# step 3316, loss = 0.9411, cross_entropy loss = 0.9411, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:23.589610 #train# step 3317, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:25.177595 #train# step 3318, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:26.723530 #train# step 3319, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:28.315468 #train# step 3320, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:29.851306 #train# step 3321, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:31.431467 #train# step 3322, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:32.970741 #train# step 3323, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:34.541205 #train# step 3324, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:36.087940 #train# step 3325, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:37.641146 #train# step 3326, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:39.212317 #train# step 3327, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:40.791792 #train# step 3328, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:42.377216 #train# step 3329, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:43.989161 #train# step 3330, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:45.558069 #train# step 3331, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:47.143655 #train# step 3332, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:48.692592 #train# step 3333, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:50.246480 #train# step 3334, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:51.794618 #train# step 3335, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:53.368307 #train# step 3336, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:54.951516 #train# step 3337, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:56.526831 #train# step 3338, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:58.080993 #train# step 3339, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:19:59.652337 #train# step 3340, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:01.214247 #train# step 3341, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:02.787339 #train# step 3342, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:04.360436 #train# step 3343, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:05.912002 #train# step 3344, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:07.500344 #train# step 3345, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:09.027691 #train# step 3346, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:10.674152 #train# step 3347, loss = 0.9431, cross_entropy loss = 0.9431, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:12.420224 #train# step 3348, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:13.947114 #train# step 3349, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:15.508901 #train# step 3350, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:17.053346 #train# step 3351, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:18.592145 #train# step 3352, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:20.180424 #train# step 3353, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:21.751508 #train# step 3354, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:23.315046 #train# step 3355, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:24.888833 #train# step 3356, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:26.483167 #train# step 3357, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:28.081521 #train# step 3358, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:29.604340 #train# step 3359, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:31.226059 #train# step 3360, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:32.901729 #train# step 3361, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:34.427398 #train# step 3362, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:35.975879 #train# step 3363, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:37.583702 #train# step 3364, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:39.191059 #train# step 3365, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:40.781738 #train# step 3366, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:42.349727 #train# step 3367, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:43.878659 #train# step 3368, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:45.425497 #train# step 3369, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:46.981127 #train# step 3370, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:48.540195 #train# step 3371, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:50.101786 #train# step 3372, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:51.619273 #train# step 3373, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:53.365801 #train# step 3374, loss = 0.9294, cross_entropy loss = 0.9294, 1.0 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:54.941310 #train# step 3375, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:56.495414 #train# step 3376, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:58.121447 #train# step 3377, loss = 0.9355, cross_entropy loss = 0.9355, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:20:59.664106 #train# step 3378, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:01.232392 #train# step 3379, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:02.804023 #train# step 3380, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:04.359510 #train# step 3381, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:06.002611 #train# step 3382, loss = 0.9389, cross_entropy loss = 0.9389, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:07.594833 #train# step 3383, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:09.150186 #train# step 3384, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:10.739676 #train# step 3385, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:12.294472 #train# step 3386, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:13.866983 #train# step 3387, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:15.432994 #train# step 3388, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:16.968275 #train# step 3389, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:18.517185 #train# step 3390, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:20.070602 #train# step 3391, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:21.631779 #train# step 3392, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:23.196086 #train# step 3393, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:24.813646 #train# step 3394, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:26.538011 #train# step 3395, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:28.225945 #train# step 3396, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:29.806297 #train# step 3397, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:31.340201 #train# step 3398, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:32.915645 #train# step 3399, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:34.467659 #train# step 3400, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:36.056544 #train# step 3401, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:37.613624 #train# step 3402, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:39.168904 #train# step 3403, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:40.703822 #train# step 3404, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:42.279609 #train# step 3405, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:43.851144 #train# step 3406, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:45.408826 #train# step 3407, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:46.968034 #train# step 3408, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:48.506134 #train# step 3409, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:50.045419 #train# step 3410, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:51.602839 #train# step 3411, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:53.175623 #train# step 3412, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:54.750227 #train# step 3413, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:56.318973 #train# step 3414, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:57.861929 #train# step 3415, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:21:59.395467 #train# step 3416, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:00.913787 #train# step 3417, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:02.451989 #train# step 3418, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:03.996391 #train# step 3419, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:05.539053 #train# step 3420, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:07.110660 #train# step 3421, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:08.638896 #train# step 3422, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:10.238625 #train# step 3423, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:11.822534 #train# step 3424, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:13.373273 #train# step 3425, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:14.972321 #train# step 3426, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:16.538475 #train# step 3427, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:18.110317 #train# step 3428, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:19.637955 #train# step 3429, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:21.176389 #train# step 3430, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:22.787840 #train# step 3431, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:24.333008 #train# step 3432, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:25.893988 #train# step 3433, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:27.430671 #train# step 3434, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:28.994602 #train# step 3435, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:30.560520 #train# step 3436, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:32.124135 #train# step 3437, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:33.650812 #train# step 3438, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:35.214077 #train# step 3439, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:36.782688 #train# step 3440, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:38.321287 #train# step 3441, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:39.862632 #train# step 3442, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:41.396965 #train# step 3443, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:42.965151 #train# step 3444, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:44.509245 #train# step 3445, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:46.075290 #train# step 3446, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:47.640758 #train# step 3447, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:49.197431 #train# step 3448, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:50.745586 #train# step 3449, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:52.309717 #train# step 3450, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:53.878232 #train# step 3451, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:55.409129 #train# step 3452, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:56.957313 #train# step 3453, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:22:58.564982 #train# step 3454, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:00.131845 #train# step 3455, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:01.713158 #train# step 3456, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:03.269564 #train# step 3457, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:04.853597 #train# step 3458, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:06.425404 #train# step 3459, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:07.952506 #train# step 3460, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:09.497614 #train# step 3461, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:11.057490 #train# step 3462, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:12.657496 #train# step 3463, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:14.225610 #train# step 3464, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:15.785438 #train# step 3465, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:17.329939 #train# step 3466, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:18.875234 #train# step 3467, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:20.437340 #train# step 3468, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:21.983880 #train# step 3469, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:23.547878 #train# step 3470, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:25.123806 #train# step 3471, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:26.680888 #train# step 3472, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:28.203013 #train# step 3473, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:29.759470 #train# step 3474, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:31.292660 #train# step 3475, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:32.837822 #train# step 3476, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:34.393356 #train# step 3477, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:35.963611 #train# step 3478, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:37.514809 #train# step 3479, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:39.083498 #train# step 3480, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:40.664684 #train# step 3481, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:42.221718 #train# step 3482, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:43.785928 #train# step 3483, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:45.332151 #train# step 3484, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:46.918945 #train# step 3485, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:48.509549 #train# step 3486, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:50.050748 #train# step 3487, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:51.612226 #train# step 3488, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:53.181080 #train# step 3489, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:54.737639 #train# step 3490, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:56.292252 #train# step 3491, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:57.851276 #train# step 3492, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:23:59.423941 #train# step 3493, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:00.949440 #train# step 3494, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:02.466206 #train# step 3495, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:04.020333 #train# step 3496, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:05.566604 #train# step 3497, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:07.132425 #train# step 3498, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:08.701385 #train# step 3499, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:10.280598 #train# step 3500, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:11.842335 #train# step 3501, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:13.376186 #train# step 3502, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:14.945336 #train# step 3503, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:16.496090 #train# step 3504, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:18.060593 #train# step 3505, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:19.609788 #train# step 3506, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:21.181458 #train# step 3507, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:22.776011 #train# step 3508, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:24.378844 #train# step 3509, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:25.916854 #train# step 3510, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:27.470014 #train# step 3511, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:29.022376 #train# step 3512, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:30.581397 #train# step 3513, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:32.162038 #train# step 3514, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:33.693833 #train# step 3515, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:35.272929 #train# step 3516, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:36.792521 #train# step 3517, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:38.349084 #train# step 3518, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:39.898843 #train# step 3519, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:41.473432 #train# step 3520, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:43.048297 #train# step 3521, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:44.601484 #train# step 3522, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:46.144398 #train# step 3523, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:47.687393 #train# step 3524, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:49.281084 #train# step 3525, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:50.828356 #train# step 3526, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:52.349867 #train# step 3527, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:53.891556 #train# step 3528, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:55.436348 #train# step 3529, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:56.999920 #train# step 3530, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:24:58.570114 #train# step 3531, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:00.128127 #train# step 3532, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:01.671224 #train# step 3533, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:03.250155 #train# step 3534, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:04.787986 #train# step 3535, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:06.348495 #train# step 3536, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:07.912932 #train# step 3537, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:09.481895 #train# step 3538, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:11.046335 #train# step 3539, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:12.604264 #train# step 3540, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:14.145839 #train# step 3541, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:15.704029 #train# step 3542, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:17.258907 #train# step 3543, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:18.849277 #train# step 3544, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:20.390924 #train# step 3545, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:21.932356 #train# step 3546, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:23.487153 #train# step 3547, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:25.041994 #train# step 3548, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:26.572595 #train# step 3549, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:28.109586 #train# step 3550, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:29.642042 #train# step 3551, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:31.207959 #train# step 3552, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:32.758115 #train# step 3553, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:34.333202 #train# step 3554, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:35.910306 #train# step 3555, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:37.468143 #train# step 3556, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:39.045331 #train# step 3557, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:40.589787 #train# step 3558, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:42.139448 #train# step 3559, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:43.685159 #train# step 3560, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:45.257021 #train# step 3561, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:46.779067 #train# step 3562, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:48.371345 #train# step 3563, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:49.938032 #train# step 3564, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:51.476825 #train# step 3565, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:53.040448 #train# step 3566, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:54.583938 #train# step 3567, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:56.136243 #train# step 3568, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:57.708017 #train# step 3569, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:25:59.264868 #train# step 3570, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:00.837724 #train# step 3571, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:02.413739 #train# step 3572, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:03.971810 #train# step 3573, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:05.523241 #train# step 3574, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:07.077562 #train# step 3575, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:08.631270 #train# step 3576, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:10.199801 #train# step 3577, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:11.756236 #train# step 3578, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:13.308634 #train# step 3579, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:14.858313 #train# step 3580, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:16.421536 #train# step 3581, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:17.975434 #train# step 3582, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:19.553159 #train# step 3583, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:21.115562 #train# step 3584, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:22.701307 #train# step 3585, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:24.255028 #train# step 3586, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:25.836965 #train# step 3587, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:27.377170 #train# step 3588, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:28.941571 #train# step 3589, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:30.487482 #train# step 3590, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:32.045592 #train# step 3591, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:33.596677 #train# step 3592, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:35.129030 #train# step 3593, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:36.664687 #train# step 3594, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:38.208003 #train# step 3595, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:39.778532 #train# step 3596, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:41.372083 #train# step 3597, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:42.928923 #train# step 3598, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:44.451058 #train# step 3599, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:45.997372 #train# step 3600, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:47.551901 #train# step 3601, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:49.122216 #train# step 3602, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:50.667272 #train# step 3603, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:52.237277 #train# step 3604, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:53.783284 #train# step 3605, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:55.322310 #train# step 3606, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:56.859362 #train# step 3607, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:58.438170 #train# step 3608, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:26:59.980779 #train# step 3609, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:01.550407 #train# step 3610, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:03.115781 #train# step 3611, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:04.665293 #train# step 3612, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:06.239716 #train# step 3613, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:07.784336 #train# step 3614, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:09.342634 #train# step 3615, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:10.911969 #train# step 3616, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:12.456903 #train# step 3617, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:14.002337 #train# step 3618, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:15.629599 #train# step 3619, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:17.216780 #train# step 3620, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:18.768803 #train# step 3621, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:20.343568 #train# step 3622, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:21.883129 #train# step 3623, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:23.397432 #train# step 3624, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:24.935365 #train# step 3625, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:26.491105 #train# step 3626, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:28.035136 #train# step 3627, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:29.629360 #train# step 3628, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:31.193119 #train# step 3629, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:32.740937 #train# step 3630, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:34.286082 #train# step 3631, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:35.826024 #train# step 3632, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:37.364567 #train# step 3633, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:38.925862 #train# step 3634, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:40.444853 #train# step 3635, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:42.022148 #train# step 3636, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:43.612991 #train# step 3637, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:45.182721 #train# step 3638, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:46.746372 #train# step 3639, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:48.331286 #train# step 3640, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:49.891289 #train# step 3641, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:51.445961 #train# step 3642, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:53.030437 #train# step 3643, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:54.585983 #train# step 3644, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:56.137026 #train# step 3645, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:57.679798 #train# step 3646, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:27:59.252497 #train# step 3647, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:00.788001 #train# step 3648, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:02.337270 #train# step 3649, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:03.932201 #train# step 3650, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:05.537400 #train# step 3651, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:07.100811 #train# step 3652, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:08.673970 #train# step 3653, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:10.244156 #train# step 3654, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:11.787510 #train# step 3655, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:13.349343 #train# step 3656, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:14.911707 #train# step 3657, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:16.435281 #train# step 3658, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:17.977041 #train# step 3659, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:19.536301 #train# step 3660, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:21.063379 #train# step 3661, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:22.629388 #train# step 3662, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:24.170191 #train# step 3663, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:25.708165 #train# step 3664, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:27.277273 #train# step 3665, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:28.808055 #train# step 3666, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:30.354483 #train# step 3667, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:31.917672 #train# step 3668, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:33.540289 #train# step 3669, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:35.106822 #train# step 3670, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:36.667852 #train# step 3671, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:38.219563 #train# step 3672, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:39.770077 #train# step 3673, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:41.323385 #train# step 3674, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:42.868531 #train# step 3675, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:44.432685 #train# step 3676, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:46.003644 #train# step 3677, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:47.586146 #train# step 3678, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:49.139358 #train# step 3679, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:50.685619 #train# step 3680, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:52.270485 #train# step 3681, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:53.841827 #train# step 3682, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:55.410990 #train# step 3683, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:56.937876 #train# step 3684, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:28:58.531172 #train# step 3685, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:00.085575 #train# step 3686, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:01.639925 #train# step 3687, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:03.180154 #train# step 3688, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:04.743416 #train# step 3689, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:06.289923 #train# step 3690, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:07.850146 #train# step 3691, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:09.413103 #train# step 3692, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:10.990662 #train# step 3693, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:12.543178 #train# step 3694, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:14.103917 #train# step 3695, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:15.636600 #train# step 3696, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:17.211307 #train# step 3697, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:18.784658 #train# step 3698, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:20.340101 #train# step 3699, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:21.928389 #train# step 3700, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:23.488979 #train# step 3701, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:25.055228 #train# step 3702, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:26.607233 #train# step 3703, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:28.176914 #train# step 3704, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:29.739468 #train# step 3705, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:31.287711 #train# step 3706, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:32.854164 #train# step 3707, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:34.423381 #train# step 3708, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:35.992350 #train# step 3709, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:37.565732 #train# step 3710, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:39.164555 #train# step 3711, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:40.742745 #train# step 3712, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:42.271717 #train# step 3713, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:43.817685 #train# step 3714, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:45.391069 #train# step 3715, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:46.977023 #train# step 3716, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:48.532204 #train# step 3717, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:50.110253 #train# step 3718, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:51.668015 #train# step 3719, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:53.199715 #train# step 3720, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:54.770265 #train# step 3721, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:56.374442 #train# step 3722, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:57.944373 #train# step 3723, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:29:59.532766 #train# step 3724, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:01.048916 #train# step 3725, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:02.650335 #train# step 3726, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:04.195567 #train# step 3727, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:05.728704 #train# step 3728, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:07.269639 #train# step 3729, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:08.807059 #train# step 3730, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:10.363152 #train# step 3731, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:11.910338 #train# step 3732, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:13.461916 #train# step 3733, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:15.030491 #train# step 3734, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:16.580957 #train# step 3735, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:18.106069 #train# step 3736, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:19.660965 #train# step 3737, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:21.212172 #train# step 3738, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:22.762907 #train# step 3739, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:24.335254 #train# step 3740, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:25.886080 #train# step 3741, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:27.473702 #train# step 3742, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:29.007156 #train# step 3743, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:30.543911 #train# step 3744, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:32.107781 #train# step 3745, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:33.688874 #train# step 3746, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:35.230757 #train# step 3747, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:36.792039 #train# step 3748, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:38.328758 #train# step 3749, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:39.927267 #train# step 3750, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:41.522255 #train# step 3751, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:43.089536 #train# step 3752, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:44.642439 #train# step 3753, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:46.202544 #train# step 3754, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:47.771399 #train# step 3755, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:49.346878 #train# step 3756, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:50.911378 #train# step 3757, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:52.476872 #train# step 3758, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:54.032502 #train# step 3759, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:55.580389 #train# step 3760, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:57.122656 #train# step 3761, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:30:58.691861 #train# step 3762, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:00.257814 #train# step 3763, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:01.845524 #train# step 3764, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:03.374184 #train# step 3765, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:04.909614 #train# step 3766, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:06.457583 #train# step 3767, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:08.013280 #train# step 3768, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:09.594936 #train# step 3769, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:11.163836 #train# step 3770, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:12.715710 #train# step 3771, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:14.290159 #train# step 3772, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:15.864446 #train# step 3773, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:17.406850 #train# step 3774, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:18.951789 #train# step 3775, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:20.482184 #train# step 3776, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:22.045564 #train# step 3777, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:23.615692 #train# step 3778, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:25.184463 #train# step 3779, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:26.772267 #train# step 3780, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:28.300202 #train# step 3781, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:29.853567 #train# step 3782, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:31.401762 #train# step 3783, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:32.953405 #train# step 3784, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:34.523441 #train# step 3785, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:36.109093 #train# step 3786, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:37.628329 #train# step 3787, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:39.229241 #train# step 3788, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:40.807963 #train# step 3789, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:42.380682 #train# step 3790, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:43.928513 #train# step 3791, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:45.507730 #train# step 3792, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:47.085933 #train# step 3793, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:48.612221 #train# step 3794, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:50.167731 #train# step 3795, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:51.720281 #train# step 3796, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:53.303521 #train# step 3797, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:54.855214 #train# step 3798, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:56.417042 #train# step 3799, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:57.961687 #train# step 3800, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:31:59.521987 #train# step 3801, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:01.089343 #train# step 3802, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:02.648595 #train# step 3803, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:04.217541 #train# step 3804, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:05.785636 #train# step 3805, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:07.331929 #train# step 3806, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:08.882026 #train# step 3807, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:10.467807 #train# step 3808, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:12.004244 #train# step 3809, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:13.567985 #train# step 3810, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:15.125133 #train# step 3811, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:16.726339 #train# step 3812, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:18.282610 #train# step 3813, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:19.840181 #train# step 3814, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:21.420462 #train# step 3815, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:22.969959 #train# step 3816, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:24.511131 #train# step 3817, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:26.064665 #train# step 3818, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:27.631464 #train# step 3819, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:29.174346 #train# step 3820, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:30.728757 #train# step 3821, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:32.294923 #train# step 3822, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:33.800722 #train# step 3823, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:35.369606 #train# step 3824, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:36.905186 #train# step 3825, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:38.492014 #train# step 3826, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:40.034806 #train# step 3827, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:41.585415 #train# step 3828, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:43.172673 #train# step 3829, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:44.723638 #train# step 3830, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:46.302579 #train# step 3831, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:47.835499 #train# step 3832, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:49.376438 #train# step 3833, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:50.919721 #train# step 3834, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:52.472626 #train# step 3835, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:54.045676 #train# step 3836, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:55.612186 #train# step 3837, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:57.157091 #train# step 3838, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:32:58.722026 #train# step 3839, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:00.286670 #train# step 3840, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:01.829622 #train# step 3841, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:03.348968 #train# step 3842, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:04.904130 #train# step 3843, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:06.418004 #train# step 3844, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:07.999288 #train# step 3845, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:09.577049 #train# step 3846, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:11.133866 #train# step 3847, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:12.691202 #train# step 3848, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:14.257030 #train# step 3849, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:15.843339 #train# step 3850, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:17.408300 #train# step 3851, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:18.961563 #train# step 3852, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:20.508688 #train# step 3853, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:22.070845 #train# step 3854, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:23.621795 #train# step 3855, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:25.173242 #train# step 3856, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:26.719392 #train# step 3857, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:28.288092 #train# step 3858, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:29.878224 #train# step 3859, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:31.448334 #train# step 3860, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:33.038144 #train# step 3861, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:34.592626 #train# step 3862, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:36.140659 #train# step 3863, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:37.715967 #train# step 3864, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:39.277948 #train# step 3865, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:40.826032 #train# step 3866, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:42.394242 #train# step 3867, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:43.936586 #train# step 3868, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:45.494528 #train# step 3869, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:47.048824 #train# step 3870, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:48.589261 #train# step 3871, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:50.133050 #train# step 3872, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:51.698446 #train# step 3873, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:53.276581 #train# step 3874, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:54.849177 #train# step 3875, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:56.410368 #train# step 3876, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:57.959936 #train# step 3877, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:33:59.509834 #train# step 3878, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:01.051383 #train# step 3879, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:02.610746 #train# step 3880, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:04.146805 #train# step 3881, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:05.710048 #train# step 3882, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:07.273176 #train# step 3883, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:08.808335 #train# step 3884, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:10.365688 #train# step 3885, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:11.924155 #train# step 3886, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:13.458056 #train# step 3887, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:15.033236 #train# step 3888, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:16.628040 #train# step 3889, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:18.199261 #train# step 3890, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:19.780402 #train# step 3891, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:21.309454 #train# step 3892, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:22.868731 #train# step 3893, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:24.432078 #train# step 3894, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:25.968995 #train# step 3895, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:27.528558 #train# step 3896, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:29.056898 #train# step 3897, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:30.628001 #train# step 3898, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:32.192416 #train# step 3899, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:33.726620 #train# step 3900, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:35.305389 #train# step 3901, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:36.862420 #train# step 3902, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:38.415035 #train# step 3903, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:39.994187 #train# step 3904, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:41.546798 #train# step 3905, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:43.102959 #train# step 3906, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:44.668857 #train# step 3907, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:46.208357 #train# step 3908, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:47.775571 #train# step 3909, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:49.336302 #train# step 3910, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:50.920709 #train# step 3911, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:52.500325 #train# step 3912, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:54.058739 #train# step 3913, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:55.596186 #train# step 3914, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:57.144372 #train# step 3915, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:34:58.741336 #train# step 3916, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:00.275117 #train# step 3917, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:01.830055 #train# step 3918, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:03.511870 #train# step 3919, loss = 0.9326, cross_entropy loss = 0.9326, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:05.064413 #train# step 3920, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:06.646687 #train# step 3921, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:08.226523 #train# step 3922, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:09.834459 #train# step 3923, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:11.397715 #train# step 3924, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:12.970740 #train# step 3925, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:14.527668 #train# step 3926, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:16.096252 #train# step 3927, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:17.645813 #train# step 3928, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:19.197276 #train# step 3929, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:20.784140 #train# step 3930, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:22.345848 #train# step 3931, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:23.879267 #train# step 3932, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:25.433889 #train# step 3933, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:26.992323 #train# step 3934, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:28.587618 #train# step 3935, loss = 0.9425, cross_entropy loss = 0.9425, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:30.152936 #train# step 3936, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:31.715257 #train# step 3937, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:33.334235 #train# step 3938, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:34.897302 #train# step 3939, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:36.481080 #train# step 3940, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:38.057886 #train# step 3941, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:39.614793 #train# step 3942, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:41.171568 #train# step 3943, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:42.733599 #train# step 3944, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:44.301877 #train# step 3945, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:45.862065 #train# step 3946, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:47.413179 #train# step 3947, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:48.969264 #train# step 3948, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:50.558743 #train# step 3949, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:52.138937 #train# step 3950, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:53.739137 #train# step 3951, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:55.317848 #train# step 3952, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:56.889413 #train# step 3953, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:35:58.464365 #train# step 3954, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:00.018088 #train# step 3955, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:01.585191 #train# step 3956, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:03.166074 #train# step 3957, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:04.728483 #train# step 3958, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:06.289688 #train# step 3959, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:07.851006 #train# step 3960, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:09.483518 #train# step 3961, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:11.139522 #train# step 3962, loss = 0.9347, cross_entropy loss = 0.9347, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:12.732939 #train# step 3963, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:14.370963 #train# step 3964, loss = 0.9269, cross_entropy loss = 0.9269, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:15.992521 #train# step 3965, loss = 0.9487, cross_entropy loss = 0.9487, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:17.645834 #train# step 3966, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:19.245041 #train# step 3967, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:20.899920 #train# step 3968, loss = 0.9270, cross_entropy loss = 0.9270, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:22.541308 #train# step 3969, loss = 0.9392, cross_entropy loss = 0.9392, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:24.168365 #train# step 3970, loss = 0.9422, cross_entropy loss = 0.9422, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:25.749227 #train# step 3971, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:27.286514 #train# step 3972, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:28.865011 #train# step 3973, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:30.469215 #train# step 3974, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:32.039135 #train# step 3975, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:33.595840 #train# step 3976, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:35.129090 #train# step 3977, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:36.671276 #train# step 3978, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:38.273252 #train# step 3979, loss = 0.9318, cross_entropy loss = 0.9318, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:39.813492 #train# step 3980, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:41.367436 #train# step 3981, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:42.899708 #train# step 3982, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:44.433280 #train# step 3983, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:46.014930 #train# step 3984, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:47.601427 #train# step 3985, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:49.158700 #train# step 3986, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:50.704621 #train# step 3987, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:52.250964 #train# step 3988, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:53.829864 #train# step 3989, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:55.393090 #train# step 3990, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:56.965274 #train# step 3991, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:36:58.489299 #train# step 3992, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:00.108795 #train# step 3993, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:01.707000 #train# step 3994, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:03.309393 #train# step 3995, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:04.876241 #train# step 3996, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:06.441798 #train# step 3997, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:08.036117 #train# step 3998, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:09.623194 #train# step 3999, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:11.252506 #train# step 4000, loss = 0.9323, cross_entropy loss = 0.9323, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:12.884664 #train# step 4001, loss = 0.9301, cross_entropy loss = 0.9301, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:14.419889 #train# step 4002, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:15.974163 #train# step 4003, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:17.527345 #train# step 4004, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:19.090418 #train# step 4005, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:20.650643 #train# step 4006, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:22.203896 #train# step 4007, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:23.770007 #train# step 4008, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:25.319608 #train# step 4009, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:26.899717 #train# step 4010, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:28.421878 #train# step 4011, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:29.936749 #train# step 4012, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:31.545828 #train# step 4013, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:33.095313 #train# step 4014, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:34.676481 #train# step 4015, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:36.252572 #train# step 4016, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:37.820140 #train# step 4017, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:39.357872 #train# step 4018, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:40.907561 #train# step 4019, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:42.474096 #train# step 4020, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:44.042059 #train# step 4021, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:45.573305 #train# step 4022, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:47.141747 #train# step 4023, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:48.702593 #train# step 4024, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:50.270516 #train# step 4025, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:51.839624 #train# step 4026, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:53.420923 #train# step 4027, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:54.969122 #train# step 4028, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:56.487107 #train# step 4029, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:58.051301 #train# step 4030, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:37:59.641134 #train# step 4031, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:01.190911 #train# step 4032, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:02.769174 #train# step 4033, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:04.344964 #train# step 4034, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:05.961081 #train# step 4035, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:07.547963 #train# step 4036, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:09.195239 #train# step 4037, loss = 0.9245, cross_entropy loss = 0.9245, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:10.871810 #train# step 4038, loss = 0.9238, cross_entropy loss = 0.9238, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:12.522436 #train# step 4039, loss = 0.9238, cross_entropy loss = 0.9238, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:14.167029 #train# step 4040, loss = 0.9249, cross_entropy loss = 0.9249, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:15.816909 #train# step 4041, loss = 0.9257, cross_entropy loss = 0.9257, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:17.419690 #train# step 4042, loss = 0.9325, cross_entropy loss = 0.9325, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:19.070447 #train# step 4043, loss = 0.9474, cross_entropy loss = 0.9474, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:20.687055 #train# step 4044, loss = 0.9517, cross_entropy loss = 0.9517, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:22.320547 #train# step 4045, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:23.848184 #train# step 4046, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:25.387123 #train# step 4047, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:26.938578 #train# step 4048, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:28.504224 #train# step 4049, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:30.121168 #train# step 4050, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:31.761308 #train# step 4051, loss = 0.9273, cross_entropy loss = 0.9273, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:33.347137 #train# step 4052, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:34.939262 #train# step 4053, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:36.529221 #train# step 4054, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:38.124589 #train# step 4055, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:39.685252 #train# step 4056, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:41.230563 #train# step 4057, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:42.799909 #train# step 4058, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:44.347013 #train# step 4059, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:45.882460 #train# step 4060, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:47.462518 #train# step 4061, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:49.005419 #train# step 4062, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:50.585904 #train# step 4063, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:52.161145 #train# step 4064, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:53.736687 #train# step 4065, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:55.278893 #train# step 4066, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:56.851432 #train# step 4067, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:38:58.405561 #train# step 4068, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:00.008459 #train# step 4069, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:01.543985 #train# step 4070, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:03.182665 #train# step 4071, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:04.730952 #train# step 4072, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:06.304073 #train# step 4073, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:07.867938 #train# step 4074, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:09.424759 #train# step 4075, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:10.999744 #train# step 4076, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:12.557987 #train# step 4077, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:14.107773 #train# step 4078, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:15.714555 #train# step 4079, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:17.259218 #train# step 4080, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:18.814266 #train# step 4081, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:20.357412 #train# step 4082, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:21.923479 #train# step 4083, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:23.458653 #train# step 4084, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:25.037021 #train# step 4085, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:26.596767 #train# step 4086, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:28.155181 #train# step 4087, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:29.760942 #train# step 4088, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:31.341504 #train# step 4089, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:32.916624 #train# step 4090, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:34.497746 #train# step 4091, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:36.021016 #train# step 4092, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:37.582975 #train# step 4093, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:39.174415 #train# step 4094, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:40.743908 #train# step 4095, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:42.353009 #train# step 4096, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:43.934106 #train# step 4097, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:45.498902 #train# step 4098, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:47.071012 #train# step 4099, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:48.602960 #train# step 4100, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:50.180257 #train# step 4101, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:51.733447 #train# step 4102, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:53.281949 #train# step 4103, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:54.823395 #train# step 4104, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:56.392607 #train# step 4105, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:57.962417 #train# step 4106, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:39:59.545695 #train# step 4107, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:01.150072 #train# step 4108, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:02.683629 #train# step 4109, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:04.252724 #train# step 4110, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:05.836129 #train# step 4111, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:07.369219 #train# step 4112, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:08.934603 #train# step 4113, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:10.496077 #train# step 4114, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:12.046123 #train# step 4115, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:13.599125 #train# step 4116, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:15.179214 #train# step 4117, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:16.754538 #train# step 4118, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:18.319216 #train# step 4119, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:19.853194 #train# step 4120, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:21.420369 #train# step 4121, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:22.956779 #train# step 4122, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:24.522845 #train# step 4123, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:26.088662 #train# step 4124, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:27.657551 #train# step 4125, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:29.237860 #train# step 4126, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:30.771572 #train# step 4127, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:32.340642 #train# step 4128, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:33.919283 #train# step 4129, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:35.465563 #train# step 4130, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:37.036674 #train# step 4131, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:38.650304 #train# step 4132, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:40.235369 #train# step 4133, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:41.775825 #train# step 4134, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:43.368015 #train# step 4135, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:44.957355 #train# step 4136, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:46.507556 #train# step 4137, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:48.070375 #train# step 4138, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:49.633526 #train# step 4139, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:51.185488 #train# step 4140, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:52.740035 #train# step 4141, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:54.316039 #train# step 4142, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:55.897306 #train# step 4143, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:57.439478 #train# step 4144, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:40:59.023377 #train# step 4145, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:00.577408 #train# step 4146, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:02.137311 #train# step 4147, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:03.691343 #train# step 4148, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:05.256808 #train# step 4149, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:06.835468 #train# step 4150, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:08.412189 #train# step 4151, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:09.964779 #train# step 4152, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:11.499716 #train# step 4153, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:13.050107 #train# step 4154, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:14.614901 #train# step 4155, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:16.224590 #train# step 4156, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:17.801263 #train# step 4157, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:19.381267 #train# step 4158, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:20.902742 #train# step 4159, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:22.454464 #train# step 4160, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:24.023112 #train# step 4161, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:25.587522 #train# step 4162, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:27.160015 #train# step 4163, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:28.746933 #train# step 4164, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:30.293444 #train# step 4165, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:31.882632 #train# step 4166, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:33.409169 #train# step 4167, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:34.976425 #train# step 4168, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:36.547949 #train# step 4169, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:38.129418 #train# step 4170, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:39.669301 #train# step 4171, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:41.242407 #train# step 4172, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:42.804001 #train# step 4173, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:44.375055 #train# step 4174, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:45.954351 #train# step 4175, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:47.531578 #train# step 4176, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:49.076132 #train# step 4177, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:50.655478 #train# step 4178, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:52.202620 #train# step 4179, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:53.743592 #train# step 4180, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:55.299262 #train# step 4181, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:56.888535 #train# step 4182, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:58.424092 #train# step 4183, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:41:59.995185 #train# step 4184, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:01.558161 #train# step 4185, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:03.120435 #train# step 4186, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:04.688602 #train# step 4187, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:06.252192 #train# step 4188, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:07.804067 #train# step 4189, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:09.372530 #train# step 4190, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:10.955439 #train# step 4191, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:12.519911 #train# step 4192, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:14.072156 #train# step 4193, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:15.635764 #train# step 4194, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:17.222856 #train# step 4195, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:18.791243 #train# step 4196, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:20.355988 #train# step 4197, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:21.927165 #train# step 4198, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:23.495434 #train# step 4199, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:25.057962 #train# step 4200, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:26.624601 #train# step 4201, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:28.248340 #train# step 4202, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:29.797584 #train# step 4203, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:31.398376 #train# step 4204, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:32.924496 #train# step 4205, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:34.458862 #train# step 4206, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:36.003474 #train# step 4207, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:37.541899 #train# step 4208, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:39.125425 #train# step 4209, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:40.700242 #train# step 4210, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:42.249388 #train# step 4211, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:43.807908 #train# step 4212, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:45.384235 #train# step 4213, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:46.905373 #train# step 4214, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:48.453744 #train# step 4215, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:50.004831 #train# step 4216, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:51.549560 #train# step 4217, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:53.125622 #train# step 4218, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:54.724876 #train# step 4219, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:56.315792 #train# step 4220, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:57.872706 #train# step 4221, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:42:59.416909 #train# step 4222, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:00.972861 #train# step 4223, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:02.544921 #train# step 4224, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:04.097263 #train# step 4225, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:05.674081 #train# step 4226, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:07.232500 #train# step 4227, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:08.755958 #train# step 4228, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:10.294422 #train# step 4229, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:11.845155 #train# step 4230, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:13.414127 #train# step 4231, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:14.972266 #train# step 4232, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:16.555624 #train# step 4233, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:18.079163 #train# step 4234, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:19.685956 #train# step 4235, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:21.234861 #train# step 4236, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:22.786923 #train# step 4237, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:24.358399 #train# step 4238, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:25.945181 #train# step 4239, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:27.514726 #train# step 4240, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:29.058108 #train# step 4241, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:30.613983 #train# step 4242, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:32.168772 #train# step 4243, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:33.738119 #train# step 4244, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:35.318289 #train# step 4245, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:36.870683 #train# step 4246, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:38.433152 #train# step 4247, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:39.999761 #train# step 4248, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:41.590334 #train# step 4249, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:43.118316 #train# step 4250, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:44.672355 #train# step 4251, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:46.227086 #train# step 4252, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:47.809324 #train# step 4253, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:49.382451 #train# step 4254, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:50.911250 #train# step 4255, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:52.450855 #train# step 4256, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:54.046846 #train# step 4257, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:55.611969 #train# step 4258, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:57.152020 #train# step 4259, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:43:58.700099 #train# step 4260, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:00.281216 #train# step 4261, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:01.851379 #train# step 4262, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:03.424297 #train# step 4263, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:04.984587 #train# step 4264, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:06.542890 #train# step 4265, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:08.105176 #train# step 4266, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:09.652026 #train# step 4267, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:11.249636 #train# step 4268, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:12.810165 #train# step 4269, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:14.384934 #train# step 4270, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:15.922119 #train# step 4271, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:17.466571 #train# step 4272, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:19.014028 #train# step 4273, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:20.558324 #train# step 4274, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:22.131324 #train# step 4275, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:23.692771 #train# step 4276, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:25.287145 #train# step 4277, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:26.843442 #train# step 4278, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:28.374739 #train# step 4279, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:29.941131 #train# step 4280, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:31.509294 #train# step 4281, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:33.110258 #train# step 4282, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:34.650554 #train# step 4283, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:36.231466 #train# step 4284, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:37.823986 #train# step 4285, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:39.384017 #train# step 4286, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:40.929531 #train# step 4287, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:42.505981 #train# step 4288, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:44.041817 #train# step 4289, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:45.606841 #train# step 4290, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:47.161805 #train# step 4291, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:48.708046 #train# step 4292, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:50.293538 #train# step 4293, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:51.868095 #train# step 4294, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:53.449457 #train# step 4295, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:55.055116 #train# step 4296, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:56.609083 #train# step 4297, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:58.194056 #train# step 4298, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:44:59.747733 #train# step 4299, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:01.299406 #train# step 4300, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:02.863437 #train# step 4301, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:04.438814 #train# step 4302, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:06.020841 #train# step 4303, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:07.575486 #train# step 4304, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:09.125916 #train# step 4305, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:10.660446 #train# step 4306, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:12.176030 #train# step 4307, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:13.743762 #train# step 4308, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:15.281098 #train# step 4309, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:16.844713 #train# step 4310, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:18.411578 #train# step 4311, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:19.986489 #train# step 4312, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:21.557509 #train# step 4313, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:23.099249 #train# step 4314, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:24.631647 #train# step 4315, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:26.172756 #train# step 4316, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:27.723553 #train# step 4317, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:29.308659 #train# step 4318, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:30.909988 #train# step 4319, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:32.484146 #train# step 4320, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:34.016091 #train# step 4321, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:35.609040 #train# step 4322, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:37.173396 #train# step 4323, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:38.713596 #train# step 4324, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:40.277615 #train# step 4325, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:41.808631 #train# step 4326, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:43.360072 #train# step 4327, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:44.925320 #train# step 4328, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:46.458321 #train# step 4329, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:48.007759 #train# step 4330, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:49.574639 #train# step 4331, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:51.117106 #train# step 4332, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:52.672922 #train# step 4333, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:54.223727 #train# step 4334, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:55.771000 #train# step 4335, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:57.304703 #train# step 4336, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:45:58.881557 #train# step 4337, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:00.442528 #train# step 4338, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:02.029280 #train# step 4339, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:03.607554 #train# step 4340, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:05.171342 #train# step 4341, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:06.683185 #train# step 4342, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:08.224413 #train# step 4343, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:09.790002 #train# step 4344, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:11.358362 #train# step 4345, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:12.917243 #train# step 4346, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:14.468845 #train# step 4347, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:16.058511 #train# step 4348, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:17.635771 #train# step 4349, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:19.180426 #train# step 4350, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:20.736214 #train# step 4351, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:22.294847 #train# step 4352, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:23.860377 #train# step 4353, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:25.422286 #train# step 4354, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:26.998350 #train# step 4355, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:28.611584 #train# step 4356, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:30.194535 #train# step 4357, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:31.745087 #train# step 4358, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:33.274620 #train# step 4359, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:34.860447 #train# step 4360, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:36.428867 #train# step 4361, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:38.008061 #train# step 4362, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:39.571364 #train# step 4363, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:41.157675 #train# step 4364, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:42.750745 #train# step 4365, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:44.326173 #train# step 4366, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:45.894439 #train# step 4367, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:47.455587 #train# step 4368, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:48.997361 #train# step 4369, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:50.575619 #train# step 4370, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:52.161298 #train# step 4371, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:53.721775 #train# step 4372, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:55.275299 #train# step 4373, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:56.842027 #train# step 4374, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:58.383471 #train# step 4375, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:46:59.961448 #train# step 4376, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:01.526709 #train# step 4377, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:03.096559 #train# step 4378, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:04.668158 #train# step 4379, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:06.257634 #train# step 4380, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:07.830242 #train# step 4381, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:09.405617 #train# step 4382, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:10.979153 #train# step 4383, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:12.574214 #train# step 4384, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:14.158798 #train# step 4385, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:15.691508 #train# step 4386, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:17.245164 #train# step 4387, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:18.842881 #train# step 4388, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:20.401190 #train# step 4389, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:21.946364 #train# step 4390, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:23.491172 #train# step 4391, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:25.077847 #train# step 4392, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:26.648956 #train# step 4393, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:28.194814 #train# step 4394, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:29.752865 #train# step 4395, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:31.304971 #train# step 4396, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:32.873948 #train# step 4397, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:34.410721 #train# step 4398, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:35.943707 #train# step 4399, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:37.544513 #train# step 4400, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:39.098968 #train# step 4401, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:40.691673 #train# step 4402, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:42.281058 #train# step 4403, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:43.838692 #train# step 4404, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:45.394338 #train# step 4405, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:46.942195 #train# step 4406, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:48.503162 #train# step 4407, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:50.052551 #train# step 4408, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:51.636934 #train# step 4409, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:53.228688 #train# step 4410, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:54.754179 #train# step 4411, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:56.311568 #train# step 4412, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:57.864089 #train# step 4413, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:47:59.413527 #train# step 4414, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:00.968136 #train# step 4415, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:02.527048 #train# step 4416, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:04.089496 #train# step 4417, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:05.646164 #train# step 4418, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:07.216490 #train# step 4419, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:08.744646 #train# step 4420, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:10.310851 #train# step 4421, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:11.901010 #train# step 4422, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:13.448113 #train# step 4423, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:14.959755 #train# step 4424, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:16.493566 #train# step 4425, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:18.058375 #train# step 4426, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:19.646663 #train# step 4427, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:21.196252 #train# step 4428, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:22.777439 #train# step 4429, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:24.336892 #train# step 4430, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:25.888942 #train# step 4431, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:27.473443 #train# step 4432, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:29.041228 #train# step 4433, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:30.615401 #train# step 4434, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:32.162419 #train# step 4435, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:33.712474 #train# step 4436, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:35.285048 #train# step 4437, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:36.889243 #train# step 4438, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:38.430895 #train# step 4439, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:39.994172 #train# step 4440, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:41.575287 #train# step 4441, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:43.143790 #train# step 4442, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:44.692918 #train# step 4443, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:46.250348 #train# step 4444, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:47.808962 #train# step 4445, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:49.364071 #train# step 4446, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:50.938001 #train# step 4447, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:52.537265 #train# step 4448, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:54.120338 #train# step 4449, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:55.671224 #train# step 4450, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:57.250423 #train# step 4451, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:48:58.814120 #train# step 4452, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:00.368512 #train# step 4453, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:01.918570 #train# step 4454, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:03.464466 #train# step 4455, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:05.013764 #train# step 4456, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:06.594854 #train# step 4457, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:08.157205 #train# step 4458, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:09.703550 #train# step 4459, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:11.279322 #train# step 4460, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:12.843462 #train# step 4461, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:14.428859 #train# step 4462, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:15.992526 #train# step 4463, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:17.559697 #train# step 4464, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:19.115348 #train# step 4465, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:20.691240 #train# step 4466, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:22.278432 #train# step 4467, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:23.837561 #train# step 4468, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:25.391592 #train# step 4469, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:26.957312 #train# step 4470, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:28.530425 #train# step 4471, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:30.103488 #train# step 4472, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:31.674403 #train# step 4473, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:33.256040 #train# step 4474, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:34.822307 #train# step 4475, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:36.334763 #train# step 4476, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:37.911629 #train# step 4477, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:39.515742 #train# step 4478, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:41.080997 #train# step 4479, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:42.642297 #train# step 4480, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:44.201927 #train# step 4481, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:45.748203 #train# step 4482, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:47.261865 #train# step 4483, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:48.828425 #train# step 4484, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:50.393167 #train# step 4485, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:51.950002 #train# step 4486, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:53.528655 #train# step 4487, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:55.109316 #train# step 4488, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:56.677732 #train# step 4489, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:58.205832 #train# step 4490, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:49:59.780948 #train# step 4491, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:01.344283 #train# step 4492, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:02.890469 #train# step 4493, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:04.464838 #train# step 4494, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:06.011693 #train# step 4495, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:07.601187 #train# step 4496, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:09.157629 #train# step 4497, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:10.708649 #train# step 4498, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:12.288093 #train# step 4499, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:13.849544 #train# step 4500, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:15.417133 #train# step 4501, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:16.970618 #train# step 4502, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:18.540911 #train# step 4503, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:20.134822 #train# step 4504, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:21.687333 #train# step 4505, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:23.221415 #train# step 4506, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:24.785573 #train# step 4507, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:26.331123 #train# step 4508, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:27.880396 #train# step 4509, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:29.409084 #train# step 4510, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:30.968407 #train# step 4511, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:32.535969 #train# step 4512, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:34.129217 #train# step 4513, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:35.718653 #train# step 4514, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:37.279959 #train# step 4515, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:38.833737 #train# step 4516, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:40.382728 #train# step 4517, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:41.927634 #train# step 4518, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:43.494650 #train# step 4519, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:45.034618 #train# step 4520, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:46.587525 #train# step 4521, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:48.166292 #train# step 4522, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:49.734130 #train# step 4523, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:51.301810 #train# step 4524, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:52.888809 #train# step 4525, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:54.467445 #train# step 4526, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:56.034282 #train# step 4527, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:57.576950 #train# step 4528, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:50:59.133610 #train# step 4529, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:00.695716 #train# step 4530, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:02.276879 #train# step 4531, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:03.854340 #train# step 4532, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:05.383100 #train# step 4533, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:06.937320 #train# step 4534, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:08.497901 #train# step 4535, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:10.068131 #train# step 4536, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:11.610829 #train# step 4537, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:13.168145 #train# step 4538, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:14.732235 #train# step 4539, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:16.283909 #train# step 4540, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:17.811848 #train# step 4541, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:19.354394 #train# step 4542, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:20.934914 #train# step 4543, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:22.497961 #train# step 4544, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:24.093167 #train# step 4545, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:25.666050 #train# step 4546, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:27.211981 #train# step 4547, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:28.771169 #train# step 4548, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:30.330880 #train# step 4549, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:31.910436 #train# step 4550, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:33.462349 #train# step 4551, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:35.039880 #train# step 4552, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:36.609807 #train# step 4553, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:38.176053 #train# step 4554, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:39.745281 #train# step 4555, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:41.303589 #train# step 4556, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:42.883995 #train# step 4557, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:44.451089 #train# step 4558, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:46.020408 #train# step 4559, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:47.573011 #train# step 4560, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:49.118626 #train# step 4561, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:50.664963 #train# step 4562, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:52.205227 #train# step 4563, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:53.764982 #train# step 4564, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:55.344707 #train# step 4565, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:56.885149 #train# step 4566, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:58.422149 #train# step 4567, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:51:59.964484 #train# step 4568, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:01.533600 #train# step 4569, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:03.106425 #train# step 4570, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:04.665560 #train# step 4571, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:06.227912 #train# step 4572, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:07.798520 #train# step 4573, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:09.352230 #train# step 4574, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:10.971305 #train# step 4575, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:12.550619 #train# step 4576, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:14.101658 #train# step 4577, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:15.663653 #train# step 4578, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:17.209270 #train# step 4579, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:18.757136 #train# step 4580, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:20.357384 #train# step 4581, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:21.938925 #train# step 4582, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:23.488111 #train# step 4583, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:25.021317 #train# step 4584, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:26.582855 #train# step 4585, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:28.168539 #train# step 4586, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:29.721309 #train# step 4587, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:31.301563 #train# step 4588, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:32.864708 #train# step 4589, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:34.411948 #train# step 4590, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:36.002646 #train# step 4591, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:37.565930 #train# step 4592, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:39.135251 #train# step 4593, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:40.674507 #train# step 4594, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:42.233493 #train# step 4595, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:43.770930 #train# step 4596, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:45.327259 #train# step 4597, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:46.886472 #train# step 4598, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:48.434215 #train# step 4599, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:50.010001 #train# step 4600, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:51.560820 #train# step 4601, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:53.163235 #train# step 4602, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:54.749504 #train# step 4603, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:56.308654 #train# step 4604, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:57.838934 #train# step 4605, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:52:59.400714 #train# step 4606, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:00.942527 #train# step 4607, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:02.463817 #train# step 4608, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:03.981396 #train# step 4609, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:05.537362 #train# step 4610, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:07.132340 #train# step 4611, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:08.681729 #train# step 4612, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:10.275580 #train# step 4613, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:11.831333 #train# step 4614, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:13.347997 #train# step 4615, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:14.921498 #train# step 4616, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:16.479684 #train# step 4617, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:18.082832 #train# step 4618, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:19.677219 #train# step 4619, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:21.215955 #train# step 4620, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:22.783427 #train# step 4621, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:24.334188 #train# step 4622, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:25.884872 #train# step 4623, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:27.488067 #train# step 4624, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:29.024787 #train# step 4625, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:30.612413 #train# step 4626, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:32.193836 #train# step 4627, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:33.742339 #train# step 4628, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:35.303565 #train# step 4629, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:36.931977 #train# step 4630, loss = 0.9085, cross_entropy loss = 0.9085, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:38.606407 #train# step 4631, loss = 0.9317, cross_entropy loss = 0.9317, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:40.255677 #train# step 4632, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:41.853274 #train# step 4633, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:43.457085 #train# step 4634, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:45.090221 #train# step 4635, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:46.638302 #train# step 4636, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:48.234037 #train# step 4637, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:49.842357 #train# step 4638, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:51.427160 #train# step 4639, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:53.060197 #train# step 4640, loss = 0.9292, cross_entropy loss = 0.9292, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:54.687686 #train# step 4641, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:56.256659 #train# step 4642, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:57.874537 #train# step 4643, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:53:59.455016 #train# step 4644, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:01.019187 #train# step 4645, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:02.631687 #train# step 4646, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:04.259642 #train# step 4647, loss = 0.9268, cross_entropy loss = 0.9268, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:05.917395 #train# step 4648, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:07.529902 #train# step 4649, loss = 0.9225, cross_entropy loss = 0.9225, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:09.110548 #train# step 4650, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:10.693843 #train# step 4651, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:12.202242 #train# step 4652, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:13.730795 #train# step 4653, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:15.276309 #train# step 4654, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:16.854282 #train# step 4655, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:18.387093 #train# step 4656, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:19.935684 #train# step 4657, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:21.483902 #train# step 4658, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:23.059225 #train# step 4659, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:24.602544 #train# step 4660, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:26.172919 #train# step 4661, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:27.734507 #train# step 4662, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:29.275291 #train# step 4663, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:30.810665 #train# step 4664, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:32.359051 #train# step 4665, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:33.896124 #train# step 4666, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:35.492444 #train# step 4667, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:37.064114 #train# step 4668, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:38.641400 #train# step 4669, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:40.215096 #train# step 4670, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:41.789692 #train# step 4671, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:43.357425 #train# step 4672, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:44.906225 #train# step 4673, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:46.441811 #train# step 4674, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:47.981506 #train# step 4675, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:49.558576 #train# step 4676, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:51.169530 #train# step 4677, loss = 0.9220, cross_entropy loss = 0.9220, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:52.762819 #train# step 4678, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:54.328763 #train# step 4679, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:56.009129 #train# step 4680, loss = 0.9185, cross_entropy loss = 0.9185, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:57.653348 #train# step 4681, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:54:59.277698 #train# step 4682, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:00.876113 #train# step 4683, loss = 0.9356, cross_entropy loss = 0.9356, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:02.461956 #train# step 4684, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:04.032194 #train# step 4685, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:05.661672 #train# step 4686, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:07.230008 #train# step 4687, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:08.794848 #train# step 4688, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:10.373693 #train# step 4689, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:11.926853 #train# step 4690, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:13.521354 #train# step 4691, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:15.091949 #train# step 4692, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:16.655797 #train# step 4693, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:18.216858 #train# step 4694, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:19.793755 #train# step 4695, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:21.349694 #train# step 4696, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:22.965869 #train# step 4697, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:24.552065 #train# step 4698, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:26.151972 #train# step 4699, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:27.712918 #train# step 4700, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:29.281448 #train# step 4701, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:30.873200 #train# step 4702, loss = 0.9272, cross_entropy loss = 0.9272, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:32.415917 #train# step 4703, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:33.989185 #train# step 4704, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:35.546969 #train# step 4705, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:37.087540 #train# step 4706, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:38.644483 #train# step 4707, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:40.230045 #train# step 4708, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:41.770961 #train# step 4709, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:43.326875 #train# step 4710, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:44.893285 #train# step 4711, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:46.457789 #train# step 4712, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:48.033078 #train# step 4713, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:49.629208 #train# step 4714, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:51.183706 #train# step 4715, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:52.738671 #train# step 4716, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:54.279082 #train# step 4717, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:55.843014 #train# step 4718, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:57.390547 #train# step 4719, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:55:58.930765 #train# step 4720, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:00.477860 #train# step 4721, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:02.026380 #train# step 4722, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:03.597373 #train# step 4723, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:05.139888 #train# step 4724, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:06.712338 #train# step 4725, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:08.266586 #train# step 4726, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:09.829364 #train# step 4727, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:11.419472 #train# step 4728, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:12.969063 #train# step 4729, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:14.518935 #train# step 4730, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:16.074910 #train# step 4731, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:17.599022 #train# step 4732, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:19.160247 #train# step 4733, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:20.725153 #train# step 4734, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:22.300761 #train# step 4735, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:23.890525 #train# step 4736, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:25.458694 #train# step 4737, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:27.000437 #train# step 4738, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:28.574592 #train# step 4739, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:30.147701 #train# step 4740, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:31.679884 #train# step 4741, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:33.245517 #train# step 4742, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:34.797187 #train# step 4743, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:36.344965 #train# step 4744, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:37.931335 #train# step 4745, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:39.497678 #train# step 4746, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:41.046722 #train# step 4747, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:42.606503 #train# step 4748, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:44.131291 #train# step 4749, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:45.674981 #train# step 4750, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:47.238196 #train# step 4751, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:48.850233 #train# step 4752, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:50.418075 #train# step 4753, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:51.967358 #train# step 4754, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:53.540478 #train# step 4755, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:55.084400 #train# step 4756, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:56.655423 #train# step 4757, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:58.194772 #train# step 4758, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:56:59.753238 #train# step 4759, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:01.316007 #train# step 4760, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:02.873455 #train# step 4761, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:04.428514 #train# step 4762, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:05.997982 #train# step 4763, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:07.541968 #train# step 4764, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:09.117676 #train# step 4765, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:10.669082 #train# step 4766, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:12.217482 #train# step 4767, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:13.784471 #train# step 4768, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:15.346044 #train# step 4769, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:16.910046 #train# step 4770, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:18.479428 #train# step 4771, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:20.027549 #train# step 4772, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:21.585100 #train# step 4773, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:23.157190 #train# step 4774, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:24.731251 #train# step 4775, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:26.254895 #train# step 4776, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:27.817684 #train# step 4777, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:29.339655 #train# step 4778, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:30.930845 #train# step 4779, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:32.483447 #train# step 4780, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:34.063480 #train# step 4781, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:35.601583 #train# step 4782, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:37.156138 #train# step 4783, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:38.686999 #train# step 4784, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:40.252129 #train# step 4785, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:41.801096 #train# step 4786, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:43.351653 #train# step 4787, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:44.899044 #train# step 4788, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:46.479843 #train# step 4789, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:48.049741 #train# step 4790, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:49.620832 #train# step 4791, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:51.167132 #train# step 4792, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:52.725138 #train# step 4793, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:54.279131 #train# step 4794, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:55.865460 #train# step 4795, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:57.414613 #train# step 4796, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:57:58.983605 #train# step 4797, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:00.552098 #train# step 4798, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:02.127888 #train# step 4799, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:03.664174 #train# step 4800, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:05.212895 #train# step 4801, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:06.784775 #train# step 4802, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:08.350762 #train# step 4803, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:09.908244 #train# step 4804, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:11.428412 #train# step 4805, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:12.982596 #train# step 4806, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:14.551739 #train# step 4807, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:16.125426 #train# step 4808, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:17.672582 #train# step 4809, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:19.245829 #train# step 4810, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:20.792885 #train# step 4811, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:22.372032 #train# step 4812, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:23.906960 #train# step 4813, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:25.507607 #train# step 4814, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:27.131193 #train# step 4815, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:28.723723 #train# step 4816, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:30.332719 #train# step 4817, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:31.906610 #train# step 4818, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:33.547426 #train# step 4819, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:35.147026 #train# step 4820, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:36.717708 #train# step 4821, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:38.292614 #train# step 4822, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:39.871866 #train# step 4823, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:41.451994 #train# step 4824, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:43.042218 #train# step 4825, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:44.658205 #train# step 4826, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:46.248743 #train# step 4827, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:47.786277 #train# step 4828, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:49.363262 #train# step 4829, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:50.900389 #train# step 4830, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:52.518915 #train# step 4831, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:54.112832 #train# step 4832, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:55.724009 #train# step 4833, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:57.282306 #train# step 4834, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:58:58.863428 #train# step 4835, loss = 0.9269, cross_entropy loss = 0.9269, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:00.428292 #train# step 4836, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:01.983349 #train# step 4837, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:03.560437 #train# step 4838, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:05.146340 #train# step 4839, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:06.692416 #train# step 4840, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:08.364786 #train# step 4841, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:09.984998 #train# step 4842, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:11.582431 #train# step 4843, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:13.145547 #train# step 4844, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:14.703536 #train# step 4845, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:16.279571 #train# step 4846, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:17.924286 #train# step 4847, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:19.525811 #train# step 4848, loss = 0.9259, cross_entropy loss = 0.9259, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:21.100545 #train# step 4849, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:22.646164 #train# step 4850, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:24.207958 #train# step 4851, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:25.770315 #train# step 4852, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:27.359959 #train# step 4853, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:28.954442 #train# step 4854, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:30.541826 #train# step 4855, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:32.079837 #train# step 4856, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:33.640180 #train# step 4857, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:35.241305 #train# step 4858, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:36.917303 #train# step 4859, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:38.473406 #train# step 4860, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:40.042061 #train# step 4861, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:41.598416 #train# step 4862, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:43.159708 #train# step 4863, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:44.730368 #train# step 4864, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:46.300755 #train# step 4865, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:47.864659 #train# step 4866, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:49.412751 #train# step 4867, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:50.987582 #train# step 4868, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:52.574217 #train# step 4869, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:54.205517 #train# step 4870, loss = 0.9185, cross_entropy loss = 0.9185, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:55.759034 #train# step 4871, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:57.463209 #train# step 4872, loss = 0.9318, cross_entropy loss = 0.9318, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 22:59:59.098887 #train# step 4873, loss = 0.9289, cross_entropy loss = 0.9289, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:00.752804 #train# step 4874, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:02.345958 #train# step 4875, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:03.989565 #train# step 4876, loss = 0.9319, cross_entropy loss = 0.9319, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:05.550201 #train# step 4877, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:07.083295 #train# step 4878, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:08.639749 #train# step 4879, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:10.190517 #train# step 4880, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:11.777538 #train# step 4881, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:13.302668 #train# step 4882, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:14.885989 #train# step 4883, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:16.436163 #train# step 4884, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:17.986743 #train# step 4885, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:19.541832 #train# step 4886, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:21.127755 #train# step 4887, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:22.728678 #train# step 4888, loss = 0.9107, cross_entropy loss = 0.9107, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:24.326143 #train# step 4889, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:25.930884 #train# step 4890, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:27.492051 #train# step 4891, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:29.106597 #train# step 4892, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:30.656259 #train# step 4893, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:32.210472 #train# step 4894, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:33.794411 #train# step 4895, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:35.361930 #train# step 4896, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:36.902717 #train# step 4897, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:38.459190 #train# step 4898, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:40.038598 #train# step 4899, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:41.631046 #train# step 4900, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:43.218411 #train# step 4901, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:44.823266 #train# step 4902, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:46.363639 #train# step 4903, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:47.935045 #train# step 4904, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:49.497961 #train# step 4905, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:51.109618 #train# step 4906, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:52.659606 #train# step 4907, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:54.253030 #train# step 4908, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:55.852264 #train# step 4909, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:57.407403 #train# step 4910, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:00:58.958957 #train# step 4911, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:00.506116 #train# step 4912, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:02.079817 #train# step 4913, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:03.658478 #train# step 4914, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:05.227245 #train# step 4915, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:06.760020 #train# step 4916, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:08.302731 #train# step 4917, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:09.827248 #train# step 4918, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:11.425069 #train# step 4919, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:13.023807 #train# step 4920, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:14.603883 #train# step 4921, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:16.144447 #train# step 4922, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:17.711405 #train# step 4923, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:19.257695 #train# step 4924, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:20.788900 #train# step 4925, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:22.343934 #train# step 4926, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:23.882672 #train# step 4927, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:25.445529 #train# step 4928, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:27.008556 #train# step 4929, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:28.583851 #train# step 4930, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:30.181407 #train# step 4931, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:31.756291 #train# step 4932, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:33.343782 #train# step 4933, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:34.927779 #train# step 4934, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:36.484528 #train# step 4935, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:38.026768 #train# step 4936, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:39.607754 #train# step 4937, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:41.188717 #train# step 4938, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:42.745591 #train# step 4939, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:44.292575 #train# step 4940, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:45.848704 #train# step 4941, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:47.429684 #train# step 4942, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:49.005606 #train# step 4943, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:50.608633 #train# step 4944, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:52.163691 #train# step 4945, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:53.774452 #train# step 4946, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:55.387296 #train# step 4947, loss = 0.9082, cross_entropy loss = 0.9082, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:56.928791 #train# step 4948, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:01:58.493372 #train# step 4949, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:00.046604 #train# step 4950, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:01.578395 #train# step 4951, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:03.109286 #train# step 4952, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:04.706146 #train# step 4953, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:06.240058 #train# step 4954, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:07.778161 #train# step 4955, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:09.336751 #train# step 4956, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:10.884029 #train# step 4957, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:12.467439 #train# step 4958, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:14.069510 #train# step 4959, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:15.668409 #train# step 4960, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:17.322338 #train# step 4961, loss = 0.9186, cross_entropy loss = 0.9186, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:18.855669 #train# step 4962, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:20.392435 #train# step 4963, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:21.973093 #train# step 4964, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:23.555503 #train# step 4965, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:25.132681 #train# step 4966, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:26.687107 #train# step 4967, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:28.288252 #train# step 4968, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:29.883971 #train# step 4969, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:31.449349 #train# step 4970, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:33.059985 #train# step 4971, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:34.615027 #train# step 4972, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:36.214695 #train# step 4973, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:37.786926 #train# step 4974, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:39.355031 #train# step 4975, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:40.904599 #train# step 4976, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:42.495482 #train# step 4977, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:44.074433 #train# step 4978, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:45.651640 #train# step 4979, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:47.211641 #train# step 4980, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:48.780081 #train# step 4981, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:50.367988 #train# step 4982, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:51.948056 #train# step 4983, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:53.584642 #train# step 4984, loss = 0.9336, cross_entropy loss = 0.9336, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:55.148153 #train# step 4985, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:56.802122 #train# step 4986, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:02:58.448823 #train# step 4987, loss = 0.9218, cross_entropy loss = 0.9218, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:00.061130 #train# step 4988, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:01.699573 #train# step 4989, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:03.273399 #train# step 4990, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:04.869918 #train# step 4991, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:06.509588 #train# step 4992, loss = 0.9230, cross_entropy loss = 0.9230, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:08.110070 #train# step 4993, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:09.652573 #train# step 4994, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:11.235529 #train# step 4995, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:12.833616 #train# step 4996, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:14.378448 #train# step 4997, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:15.959219 #train# step 4998, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:17.566785 #train# step 4999, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:19.135022 #train# step 5000, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:20.766649 #train# step 5001, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:22.339598 #train# step 5002, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:23.947825 #train# step 5003, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:25.501941 #train# step 5004, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:27.055912 #train# step 5005, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:28.629629 #train# step 5006, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:30.198998 #train# step 5007, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:31.785566 #train# step 5008, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:33.378326 #train# step 5009, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:34.959446 #train# step 5010, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:36.569542 #train# step 5011, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:38.167828 #train# step 5012, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:39.747667 #train# step 5013, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:41.286534 #train# step 5014, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:42.876016 #train# step 5015, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:44.519442 #train# step 5016, loss = 0.9284, cross_entropy loss = 0.9284, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:46.117526 #train# step 5017, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:47.714279 #train# step 5018, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:49.279365 #train# step 5019, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:50.839589 #train# step 5020, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:52.450503 #train# step 5021, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:54.002597 #train# step 5022, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:55.528702 #train# step 5023, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:57.082590 #train# step 5024, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:03:58.667214 #train# step 5025, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:00.266103 #train# step 5026, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:01.819718 #train# step 5027, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:03.390005 #train# step 5028, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:04.978647 #train# step 5029, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:06.557869 #train# step 5030, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:08.170006 #train# step 5031, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:09.708848 #train# step 5032, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:11.302563 #train# step 5033, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:12.845862 #train# step 5034, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:14.418154 #train# step 5035, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:15.985499 #train# step 5036, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:17.500794 #train# step 5037, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:19.053872 #train# step 5038, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:20.606447 #train# step 5039, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:22.179135 #train# step 5040, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:23.767711 #train# step 5041, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:25.340907 #train# step 5042, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:26.865306 #train# step 5043, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:28.429434 #train# step 5044, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:29.968284 #train# step 5045, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:31.548848 #train# step 5046, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:33.113604 #train# step 5047, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:34.714119 #train# step 5048, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:36.327624 #train# step 5049, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:37.867176 #train# step 5050, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:39.407246 #train# step 5051, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:40.931489 #train# step 5052, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:42.506973 #train# step 5053, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:44.051159 #train# step 5054, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:45.586509 #train# step 5055, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:47.131270 #train# step 5056, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:48.657249 #train# step 5057, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:50.203523 #train# step 5058, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:51.743918 #train# step 5059, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:53.302853 #train# step 5060, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:54.870241 #train# step 5061, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:56.410436 #train# step 5062, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:57.972384 #train# step 5063, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:04:59.495498 #train# step 5064, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:01.065537 #train# step 5065, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:02.618888 #train# step 5066, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:04.198380 #train# step 5067, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:05.770346 #train# step 5068, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:07.356668 #train# step 5069, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:08.937964 #train# step 5070, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:10.505494 #train# step 5071, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:12.049464 #train# step 5072, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:13.586017 #train# step 5073, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:15.154728 #train# step 5074, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:16.688623 #train# step 5075, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:18.255580 #train# step 5076, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:19.829843 #train# step 5077, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:21.372191 #train# step 5078, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:22.916227 #train# step 5079, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:24.440180 #train# step 5080, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:26.028793 #train# step 5081, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:27.633963 #train# step 5082, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:29.237633 #train# step 5083, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:30.771989 #train# step 5084, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:32.334695 #train# step 5085, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:33.914624 #train# step 5086, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:35.452199 #train# step 5087, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:37.032877 #train# step 5088, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:38.589058 #train# step 5089, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:40.141599 #train# step 5090, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:41.675479 #train# step 5091, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:43.256527 #train# step 5092, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:44.848321 #train# step 5093, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:46.463596 #train# step 5094, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:48.058452 #train# step 5095, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:49.609068 #train# step 5096, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:51.171810 #train# step 5097, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:52.750950 #train# step 5098, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:54.315555 #train# step 5099, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:55.891437 #train# step 5100, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:57.442141 #train# step 5101, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:05:59.015128 #train# step 5102, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:00.619990 #train# step 5103, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:02.244180 #train# step 5104, loss = 0.9226, cross_entropy loss = 0.9226, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:03.804286 #train# step 5105, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:05.386565 #train# step 5106, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:06.960895 #train# step 5107, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:08.498729 #train# step 5108, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:10.054057 #train# step 5109, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:11.609423 #train# step 5110, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:13.141457 #train# step 5111, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:14.695200 #train# step 5112, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:16.229919 #train# step 5113, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:17.801329 #train# step 5114, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:19.389712 #train# step 5115, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:20.930839 #train# step 5116, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:22.504078 #train# step 5117, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:24.021430 #train# step 5118, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:25.577961 #train# step 5119, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:27.142003 #train# step 5120, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:28.670815 #train# step 5121, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:30.236272 #train# step 5122, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:31.821297 #train# step 5123, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:33.407035 #train# step 5124, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:34.991696 #train# step 5125, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:36.560090 #train# step 5126, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:38.156217 #train# step 5127, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:39.737827 #train# step 5128, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:41.299971 #train# step 5129, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:42.849488 #train# step 5130, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:44.408258 #train# step 5131, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:45.937702 #train# step 5132, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:47.490373 #train# step 5133, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:49.010991 #train# step 5134, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:50.539111 #train# step 5135, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:52.059593 #train# step 5136, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:53.662052 #train# step 5137, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:55.232575 #train# step 5138, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:56.810846 #train# step 5139, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:58.344758 #train# step 5140, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:06:59.921534 #train# step 5141, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:01.482288 #train# step 5142, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:03.013176 #train# step 5143, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:04.542440 #train# step 5144, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:06.077536 #train# step 5145, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:07.628503 #train# step 5146, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:09.212825 #train# step 5147, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:10.769356 #train# step 5148, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:12.319000 #train# step 5149, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:13.855883 #train# step 5150, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:15.455405 #train# step 5151, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:17.012783 #train# step 5152, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:18.585311 #train# step 5153, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:20.161723 #train# step 5154, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:21.740077 #train# step 5155, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:23.304552 #train# step 5156, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:24.866287 #train# step 5157, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:26.428524 #train# step 5158, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:27.983223 #train# step 5159, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:29.568629 #train# step 5160, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:31.104620 #train# step 5161, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:32.637659 #train# step 5162, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:34.201385 #train# step 5163, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:35.759104 #train# step 5164, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:37.294727 #train# step 5165, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:38.893634 #train# step 5166, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:40.449128 #train# step 5167, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:41.962056 #train# step 5168, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:43.546129 #train# step 5169, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:45.128534 #train# step 5170, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:46.679366 #train# step 5171, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:48.247813 #train# step 5172, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:49.807474 #train# step 5173, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:51.346229 #train# step 5174, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:52.922970 #train# step 5175, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:54.467999 #train# step 5176, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:56.020545 #train# step 5177, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:57.574915 #train# step 5178, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:07:59.147725 #train# step 5179, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:00.765825 #train# step 5180, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:02.297146 #train# step 5181, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:03.855980 #train# step 5182, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:05.414143 #train# step 5183, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:07.004508 #train# step 5184, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:08.566725 #train# step 5185, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:10.109953 #train# step 5186, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:11.646099 #train# step 5187, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:13.205098 #train# step 5188, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:14.771323 #train# step 5189, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:16.314794 #train# step 5190, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:17.867204 #train# step 5191, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:19.409534 #train# step 5192, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:20.981447 #train# step 5193, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:22.525274 #train# step 5194, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:24.112329 #train# step 5195, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:25.666793 #train# step 5196, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:27.208693 #train# step 5197, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:28.788861 #train# step 5198, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:30.321076 #train# step 5199, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:31.906981 #train# step 5200, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:33.467838 #train# step 5201, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:35.038589 #train# step 5202, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:36.578701 #train# step 5203, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:38.127828 #train# step 5204, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:39.695992 #train# step 5205, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:41.290784 #train# step 5206, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:42.848826 #train# step 5207, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:44.393077 #train# step 5208, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:45.946025 #train# step 5209, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:47.517525 #train# step 5210, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:49.069903 #train# step 5211, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:50.641473 #train# step 5212, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:52.212839 #train# step 5213, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:53.776400 #train# step 5214, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:55.350105 #train# step 5215, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:56.903975 #train# step 5216, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:08:58.435706 #train# step 5217, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:00.040354 #train# step 5218, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:01.603125 #train# step 5219, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:03.149275 #train# step 5220, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:04.672586 #train# step 5221, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:06.240034 #train# step 5222, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:07.842292 #train# step 5223, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:09.497378 #train# step 5224, loss = 0.9169, cross_entropy loss = 0.9169, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:11.123426 #train# step 5225, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:12.708034 #train# step 5226, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:14.283884 #train# step 5227, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:15.918131 #train# step 5228, loss = 0.9244, cross_entropy loss = 0.9244, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:17.694763 #train# step 5229, loss = 0.9178, cross_entropy loss = 0.9178, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:19.307479 #train# step 5230, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:20.858500 #train# step 5231, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:22.411751 #train# step 5232, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:24.017397 #train# step 5233, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:25.777051 #train# step 5234, loss = 0.9233, cross_entropy loss = 0.9233, 1.0 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:27.401577 #train# step 5235, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:28.997396 #train# step 5236, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:30.597844 #train# step 5237, loss = 0.9306, cross_entropy loss = 0.9306, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:32.131091 #train# step 5238, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:33.671489 #train# step 5239, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:35.212027 #train# step 5240, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:36.822693 #train# step 5241, loss = 0.9169, cross_entropy loss = 0.9169, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:38.517021 #train# step 5242, loss = 0.9257, cross_entropy loss = 0.9257, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:40.112190 #train# step 5243, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:41.667664 #train# step 5244, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:43.218275 #train# step 5245, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:44.762290 #train# step 5246, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:46.304039 #train# step 5247, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:47.839867 #train# step 5248, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:49.366002 #train# step 5249, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:50.953065 #train# step 5250, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:52.527298 #train# step 5251, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:54.087056 #train# step 5252, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:55.668200 #train# step 5253, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:57.237999 #train# step 5254, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:09:58.800847 #train# step 5255, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:00.343701 #train# step 5256, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:01.912018 #train# step 5257, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:03.470297 #train# step 5258, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:05.040007 #train# step 5259, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:06.658183 #train# step 5260, loss = 0.9280, cross_entropy loss = 0.9280, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:08.231249 #train# step 5261, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:09.827457 #train# step 5262, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:11.418230 #train# step 5263, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:12.966303 #train# step 5264, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:14.516066 #train# step 5265, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:16.071562 #train# step 5266, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:17.647834 #train# step 5267, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:19.201065 #train# step 5268, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:20.783210 #train# step 5269, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:22.365275 #train# step 5270, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:23.953000 #train# step 5271, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:25.516901 #train# step 5272, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:27.077519 #train# step 5273, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:28.688627 #train# step 5274, loss = 0.9294, cross_entropy loss = 0.9294, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:30.326409 #train# step 5275, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:31.876535 #train# step 5276, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:33.411490 #train# step 5277, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:34.927039 #train# step 5278, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:36.504426 #train# step 5279, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:38.117658 #train# step 5280, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:39.656574 #train# step 5281, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:41.242443 #train# step 5282, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:42.804097 #train# step 5283, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:44.375417 #train# step 5284, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:45.946912 #train# step 5285, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:47.507690 #train# step 5286, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:49.073844 #train# step 5287, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:50.631067 #train# step 5288, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:52.174044 #train# step 5289, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:53.752000 #train# step 5290, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:55.273373 #train# step 5291, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:56.785279 #train# step 5292, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:58.335760 #train# step 5293, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:10:59.858607 #train# step 5294, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:01.413490 #train# step 5295, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:02.937757 #train# step 5296, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:04.521332 #train# step 5297, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:06.114790 #train# step 5298, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:07.655312 #train# step 5299, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:09.217361 #train# step 5300, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:10.804397 #train# step 5301, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:12.356165 #train# step 5302, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:13.913039 #train# step 5303, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:15.480483 #train# step 5304, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:17.050170 #train# step 5305, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:18.621294 #train# step 5306, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:20.171480 #train# step 5307, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:21.721096 #train# step 5308, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:23.302938 #train# step 5309, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:24.856476 #train# step 5310, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:26.418730 #train# step 5311, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:27.981098 #train# step 5312, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:29.532883 #train# step 5313, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:31.062113 #train# step 5314, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:32.641741 #train# step 5315, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:34.197136 #train# step 5316, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:35.770304 #train# step 5317, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:37.342816 #train# step 5318, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:38.902343 #train# step 5319, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:40.442206 #train# step 5320, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:42.037127 #train# step 5321, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:43.567834 #train# step 5322, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:45.097268 #train# step 5323, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:46.651517 #train# step 5324, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:48.186839 #train# step 5325, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:49.743661 #train# step 5326, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:51.321255 #train# step 5327, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:52.898849 #train# step 5328, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:54.425602 #train# step 5329, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:55.977939 #train# step 5330, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:57.507342 #train# step 5331, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:11:59.072457 #train# step 5332, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:00.634649 #train# step 5333, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:02.185924 #train# step 5334, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:03.804618 #train# step 5335, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:05.371976 #train# step 5336, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:06.944404 #train# step 5337, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:08.544135 #train# step 5338, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:10.129671 #train# step 5339, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:11.703546 #train# step 5340, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:13.283255 #train# step 5341, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:14.853741 #train# step 5342, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:16.363481 #train# step 5343, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:17.904759 #train# step 5344, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:19.453222 #train# step 5345, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:20.994941 #train# step 5346, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:22.573765 #train# step 5347, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:24.104191 #train# step 5348, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:25.666328 #train# step 5349, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:27.202458 #train# step 5350, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:28.780563 #train# step 5351, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:30.360318 #train# step 5352, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:31.922387 #train# step 5353, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:33.486076 #train# step 5354, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:35.071120 #train# step 5355, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:36.663001 #train# step 5356, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:38.209419 #train# step 5357, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:39.774179 #train# step 5358, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:41.311567 #train# step 5359, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:42.851955 #train# step 5360, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:44.421501 #train# step 5361, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:45.964222 #train# step 5362, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:47.540527 #train# step 5363, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:49.104446 #train# step 5364, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:50.690086 #train# step 5365, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:52.249267 #train# step 5366, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:53.782862 #train# step 5367, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:55.372631 #train# step 5368, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:56.930379 #train# step 5369, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:12:58.510002 #train# step 5370, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:00.097210 #train# step 5371, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:01.629496 #train# step 5372, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:03.222726 #train# step 5373, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:04.770020 #train# step 5374, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:06.307552 #train# step 5375, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:07.838238 #train# step 5376, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:09.408408 #train# step 5377, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:10.980068 #train# step 5378, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:12.559681 #train# step 5379, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:14.151079 #train# step 5380, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:15.710207 #train# step 5381, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:17.294982 #train# step 5382, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:18.817195 #train# step 5383, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:20.375815 #train# step 5384, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:21.939822 #train# step 5385, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:23.488863 #train# step 5386, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:25.076802 #train# step 5387, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:26.608909 #train# step 5388, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:28.141004 #train# step 5389, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:29.729309 #train# step 5390, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:31.250765 #train# step 5391, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:32.786646 #train# step 5392, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:34.343530 #train# step 5393, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:35.898148 #train# step 5394, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:37.510013 #train# step 5395, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:39.065423 #train# step 5396, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:40.603291 #train# step 5397, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:42.178843 #train# step 5398, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:43.712478 #train# step 5399, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:45.231873 #train# step 5400, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:46.816349 #train# step 5401, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:48.348358 #train# step 5402, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:49.894438 #train# step 5403, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:51.459724 #train# step 5404, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:52.992573 #train# step 5405, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:54.545356 #train# step 5406, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:56.124417 #train# step 5407, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:57.685346 #train# step 5408, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:13:59.241826 #train# step 5409, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:00.778814 #train# step 5410, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:02.342472 #train# step 5411, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:03.882733 #train# step 5412, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:05.423710 #train# step 5413, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:06.973000 #train# step 5414, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:08.510181 #train# step 5415, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:10.068438 #train# step 5416, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:11.645825 #train# step 5417, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:13.245462 #train# step 5418, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:14.795495 #train# step 5419, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:16.361783 #train# step 5420, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:17.934524 #train# step 5421, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:19.493479 #train# step 5422, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:21.054715 #train# step 5423, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:22.591739 #train# step 5424, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:24.135083 #train# step 5425, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:25.684879 #train# step 5426, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:27.246042 #train# step 5427, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:28.800749 #train# step 5428, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:30.370058 #train# step 5429, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:31.936844 #train# step 5430, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:33.486813 #train# step 5431, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:35.070353 #train# step 5432, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:36.642604 #train# step 5433, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:38.201520 #train# step 5434, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:39.746092 #train# step 5435, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:41.315164 #train# step 5436, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:42.848685 #train# step 5437, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:44.448827 #train# step 5438, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:46.021716 #train# step 5439, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:47.586772 #train# step 5440, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:49.150722 #train# step 5441, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:50.701785 #train# step 5442, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:52.268535 #train# step 5443, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:53.789784 #train# step 5444, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:55.329445 #train# step 5445, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:56.917135 #train# step 5446, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:14:58.480650 #train# step 5447, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:00.046761 #train# step 5448, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:01.603101 #train# step 5449, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:03.153205 #train# step 5450, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:04.705390 #train# step 5451, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:06.278913 #train# step 5452, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:07.828454 #train# step 5453, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:09.379249 #train# step 5454, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:10.960315 #train# step 5455, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:12.546000 #train# step 5456, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:14.132841 #train# step 5457, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:15.679973 #train# step 5458, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:17.234845 #train# step 5459, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:18.784694 #train# step 5460, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:20.332269 #train# step 5461, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:21.912634 #train# step 5462, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:23.478939 #train# step 5463, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:25.030557 #train# step 5464, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:26.622198 #train# step 5465, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:28.192306 #train# step 5466, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:29.756997 #train# step 5467, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:31.319251 #train# step 5468, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:32.868747 #train# step 5469, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:34.437523 #train# step 5470, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:35.966748 #train# step 5471, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:37.537767 #train# step 5472, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:39.084338 #train# step 5473, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:40.629624 #train# step 5474, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:42.207453 #train# step 5475, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:43.783472 #train# step 5476, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:45.329410 #train# step 5477, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:46.854323 #train# step 5478, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:48.397096 #train# step 5479, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:49.972625 #train# step 5480, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:51.504777 #train# step 5481, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:53.072563 #train# step 5482, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:54.663849 #train# step 5483, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:56.251807 #train# step 5484, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:57.823051 #train# step 5485, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:15:59.394278 #train# step 5486, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:00.950495 #train# step 5487, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:02.478095 #train# step 5488, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:04.032408 #train# step 5489, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:05.600491 #train# step 5490, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:07.173845 #train# step 5491, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:08.737247 #train# step 5492, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:10.271482 #train# step 5493, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:11.823449 #train# step 5494, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:13.351093 #train# step 5495, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:14.918328 #train# step 5496, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:16.468174 #train# step 5497, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:18.000673 #train# step 5498, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:19.554488 #train# step 5499, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:21.075984 #train# step 5500, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:22.603673 #train# step 5501, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:24.195647 #train# step 5502, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:25.752114 #train# step 5503, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:27.291572 #train# step 5504, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:28.861322 #train# step 5505, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:30.438605 #train# step 5506, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:31.998315 #train# step 5507, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:33.554071 #train# step 5508, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:35.115030 #train# step 5509, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:36.684018 #train# step 5510, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:38.210470 #train# step 5511, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:39.783884 #train# step 5512, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:41.325981 #train# step 5513, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:42.868330 #train# step 5514, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:44.412525 #train# step 5515, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:45.980751 #train# step 5516, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:47.518550 #train# step 5517, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:49.062831 #train# step 5518, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:50.635915 #train# step 5519, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:52.171154 #train# step 5520, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:53.732964 #train# step 5521, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:55.294397 #train# step 5522, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:56.850939 #train# step 5523, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:16:58.422485 #train# step 5524, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:00.001433 #train# step 5525, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:01.571911 #train# step 5526, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:03.142841 #train# step 5527, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:04.635113 #train# step 5528, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:06.201141 #train# step 5529, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:07.745519 #train# step 5530, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:09.344065 #train# step 5531, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:10.926666 #train# step 5532, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:12.511841 #train# step 5533, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:14.123295 #train# step 5534, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:15.666522 #train# step 5535, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:17.254790 #train# step 5536, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:18.795749 #train# step 5537, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:20.359462 #train# step 5538, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:21.928406 #train# step 5539, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:23.455665 #train# step 5540, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:25.002750 #train# step 5541, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:26.562934 #train# step 5542, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:28.103458 #train# step 5543, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:29.686815 #train# step 5544, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:31.232350 #train# step 5545, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:32.780918 #train# step 5546, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:34.329819 #train# step 5547, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:35.903803 #train# step 5548, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:37.445313 #train# step 5549, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:39.011907 #train# step 5550, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:40.586940 #train# step 5551, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:42.160244 #train# step 5552, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:43.707862 #train# step 5553, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:45.257810 #train# step 5554, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:46.795995 #train# step 5555, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:48.394731 #train# step 5556, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:49.943840 #train# step 5557, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:51.508431 #train# step 5558, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:53.075902 #train# step 5559, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:54.642261 #train# step 5560, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:56.161840 #train# step 5561, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:57.753090 #train# step 5562, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:17:59.304616 #train# step 5563, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:00.867713 #train# step 5564, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:02.424547 #train# step 5565, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:03.972835 #train# step 5566, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:05.519254 #train# step 5567, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:07.077353 #train# step 5568, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:08.604442 #train# step 5569, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:10.186697 #train# step 5570, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:11.778200 #train# step 5571, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:13.388168 #train# step 5572, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:14.931740 #train# step 5573, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:16.498737 #train# step 5574, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:18.095060 #train# step 5575, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:19.644272 #train# step 5576, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:21.175297 #train# step 5577, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:22.727463 #train# step 5578, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:24.277529 #train# step 5579, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:25.826061 #train# step 5580, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:27.396271 #train# step 5581, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:28.975315 #train# step 5582, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:30.532866 #train# step 5583, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:32.129104 #train# step 5584, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:33.702214 #train# step 5585, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:35.267893 #train# step 5586, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:36.828410 #train# step 5587, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:38.362129 #train# step 5588, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:39.912218 #train# step 5589, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:41.493476 #train# step 5590, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:43.038206 #train# step 5591, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:44.570093 #train# step 5592, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:46.144383 #train# step 5593, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:47.707478 #train# step 5594, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:49.286348 #train# step 5595, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:50.861685 #train# step 5596, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:52.378073 #train# step 5597, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:53.928908 #train# step 5598, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:55.517294 #train# step 5599, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:57.063447 #train# step 5600, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:18:58.606478 #train# step 5601, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:00.198578 #train# step 5602, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:01.757789 #train# step 5603, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:03.324968 #train# step 5604, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:04.899996 #train# step 5605, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:06.440470 #train# step 5606, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:08.001828 #train# step 5607, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:09.580630 #train# step 5608, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:11.132470 #train# step 5609, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:12.684218 #train# step 5610, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:14.245068 #train# step 5611, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:15.783178 #train# step 5612, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:17.344476 #train# step 5613, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:18.924306 #train# step 5614, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:20.476886 #train# step 5615, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:22.026218 #train# step 5616, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:23.554005 #train# step 5617, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:25.120671 #train# step 5618, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:26.678476 #train# step 5619, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:28.262842 #train# step 5620, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:29.824403 #train# step 5621, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:31.370074 #train# step 5622, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:32.940294 #train# step 5623, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:34.496568 #train# step 5624, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:36.078366 #train# step 5625, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:37.623262 #train# step 5626, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:39.183895 #train# step 5627, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:40.723085 #train# step 5628, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:42.313438 #train# step 5629, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:43.856537 #train# step 5630, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:45.388329 #train# step 5631, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:46.913511 #train# step 5632, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:48.463826 #train# step 5633, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:49.980987 #train# step 5634, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:51.544198 #train# step 5635, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:53.125106 #train# step 5636, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:54.721065 #train# step 5637, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:56.280995 #train# step 5638, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:57.857248 #train# step 5639, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:19:59.423371 #train# step 5640, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:01.018777 #train# step 5641, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:02.570807 #train# step 5642, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:04.108787 #train# step 5643, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:05.668787 #train# step 5644, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:07.231591 #train# step 5645, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:08.793178 #train# step 5646, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:10.349583 #train# step 5647, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:11.925554 #train# step 5648, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:13.487460 #train# step 5649, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:15.022030 #train# step 5650, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:16.568738 #train# step 5651, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:18.130963 #train# step 5652, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:19.657685 #train# step 5653, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:21.217673 #train# step 5654, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:22.796838 #train# step 5655, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:24.369354 #train# step 5656, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:25.917522 #train# step 5657, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:27.474098 #train# step 5658, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:29.044610 #train# step 5659, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:30.592416 #train# step 5660, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:32.187064 #train# step 5661, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:33.748927 #train# step 5662, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:35.294779 #train# step 5663, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:36.866189 #train# step 5664, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:38.432929 #train# step 5665, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:39.983897 #train# step 5666, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:41.509111 #train# step 5667, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:43.066240 #train# step 5668, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:44.657655 #train# step 5669, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:46.238858 #train# step 5670, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:47.770222 #train# step 5671, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:49.304231 #train# step 5672, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:50.860116 #train# step 5673, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:52.410071 #train# step 5674, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:53.967928 #train# step 5675, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:55.553266 #train# step 5676, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:57.124306 #train# step 5677, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:20:58.686942 #train# step 5678, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:00.241948 #train# step 5679, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:01.803958 #train# step 5680, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:03.335945 #train# step 5681, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:04.931217 #train# step 5682, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:06.476352 #train# step 5683, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:08.018523 #train# step 5684, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:09.583745 #train# step 5685, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:11.172401 #train# step 5686, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:12.743022 #train# step 5687, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:14.284603 #train# step 5688, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:15.904835 #train# step 5689, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:17.449680 #train# step 5690, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:19.019813 #train# step 5691, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:20.580657 #train# step 5692, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:22.134990 #train# step 5693, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:23.675812 #train# step 5694, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:25.228122 #train# step 5695, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:26.775607 #train# step 5696, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:28.342293 #train# step 5697, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:29.891197 #train# step 5698, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:31.436765 #train# step 5699, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:33.014473 #train# step 5700, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:34.581153 #train# step 5701, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:36.153744 #train# step 5702, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:37.722252 #train# step 5703, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:39.287114 #train# step 5704, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:40.881705 #train# step 5705, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:42.415745 #train# step 5706, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:43.976538 #train# step 5707, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:45.500815 #train# step 5708, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:47.073511 #train# step 5709, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:48.661906 #train# step 5710, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:50.231070 #train# step 5711, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:51.779530 #train# step 5712, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:53.312982 #train# step 5713, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:54.845394 #train# step 5714, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:56.426326 #train# step 5715, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:57.989427 #train# step 5716, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:21:59.536917 #train# step 5717, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:01.104725 #train# step 5718, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:02.645371 #train# step 5719, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:04.193426 #train# step 5720, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:05.765163 #train# step 5721, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:07.376091 #train# step 5722, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:08.896039 #train# step 5723, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:10.443126 #train# step 5724, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:12.015336 #train# step 5725, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:13.577922 #train# step 5726, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:15.134014 #train# step 5727, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:16.730502 #train# step 5728, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:18.314156 #train# step 5729, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:19.859932 #train# step 5730, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:21.402291 #train# step 5731, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:22.953487 #train# step 5732, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:24.491351 #train# step 5733, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:26.045727 #train# step 5734, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:27.586533 #train# step 5735, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:29.148581 #train# step 5736, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:30.720502 #train# step 5737, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:32.248120 #train# step 5738, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:33.791972 #train# step 5739, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:35.311291 #train# step 5740, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:36.868991 #train# step 5741, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:38.421297 #train# step 5742, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:39.968289 #train# step 5743, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:41.510229 #train# step 5744, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:43.064003 #train# step 5745, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:44.597352 #train# step 5746, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:46.191027 #train# step 5747, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:47.755806 #train# step 5748, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:49.304673 #train# step 5749, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:50.868902 #train# step 5750, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:52.440553 #train# step 5751, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:53.989977 #train# step 5752, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:55.544689 #train# step 5753, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:57.103824 #train# step 5754, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:22:58.682403 #train# step 5755, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:00.254267 #train# step 5756, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:01.823197 #train# step 5757, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:03.397811 #train# step 5758, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:04.974833 #train# step 5759, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:06.528451 #train# step 5760, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:08.131983 #train# step 5761, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:09.688082 #train# step 5762, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:11.254613 #train# step 5763, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:12.813088 #train# step 5764, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:14.374306 #train# step 5765, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:15.957048 #train# step 5766, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:17.497597 #train# step 5767, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:19.059043 #train# step 5768, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:20.637419 #train# step 5769, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:22.199163 #train# step 5770, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:23.748002 #train# step 5771, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:25.328225 #train# step 5772, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:26.906564 #train# step 5773, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:28.482689 #train# step 5774, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:30.025422 #train# step 5775, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:31.587170 #train# step 5776, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:33.145416 #train# step 5777, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:34.662754 #train# step 5778, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:36.198679 #train# step 5779, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:37.761359 #train# step 5780, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:39.315929 #train# step 5781, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:40.885262 #train# step 5782, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:42.443530 #train# step 5783, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:43.980821 #train# step 5784, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:45.574331 #train# step 5785, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:47.108992 #train# step 5786, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:48.650788 #train# step 5787, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:50.207633 #train# step 5788, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:51.760837 #train# step 5789, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:53.294751 #train# step 5790, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:54.895154 #train# step 5791, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:56.440886 #train# step 5792, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:58.036796 #train# step 5793, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:23:59.584572 #train# step 5794, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:01.113399 #train# step 5795, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:02.681827 #train# step 5796, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:04.218033 #train# step 5797, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:05.793852 #train# step 5798, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:07.351213 #train# step 5799, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:08.928148 #train# step 5800, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:10.484858 #train# step 5801, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:12.048877 #train# step 5802, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:13.641101 #train# step 5803, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:15.199019 #train# step 5804, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:16.737288 #train# step 5805, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:18.271888 #train# step 5806, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:19.787360 #train# step 5807, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:21.334044 #train# step 5808, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:22.911383 #train# step 5809, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:24.470477 #train# step 5810, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:26.028917 #train# step 5811, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:27.581999 #train# step 5812, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:29.137203 #train# step 5813, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:30.671948 #train# step 5814, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:32.238477 #train# step 5815, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:33.811888 #train# step 5816, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:35.383334 #train# step 5817, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:36.930312 #train# step 5818, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:38.488184 #train# step 5819, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:40.051721 #train# step 5820, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:41.611545 #train# step 5821, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:43.180846 #train# step 5822, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:44.736222 #train# step 5823, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:46.292004 #train# step 5824, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:47.867990 #train# step 5825, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:49.403228 #train# step 5826, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:50.968303 #train# step 5827, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:52.520237 #train# step 5828, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:54.105409 #train# step 5829, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:55.674484 #train# step 5830, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:57.226872 #train# step 5831, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:24:58.766457 #train# step 5832, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:00.322223 #train# step 5833, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:01.909652 #train# step 5834, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:03.485375 #train# step 5835, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:05.031530 #train# step 5836, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:06.571618 #train# step 5837, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:08.155780 #train# step 5838, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:09.719832 #train# step 5839, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:11.254235 #train# step 5840, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:12.790315 #train# step 5841, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:14.411792 #train# step 5842, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:15.969909 #train# step 5843, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:17.543632 #train# step 5844, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:19.133875 #train# step 5845, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:20.694363 #train# step 5846, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:22.244063 #train# step 5847, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:23.816415 #train# step 5848, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:25.369608 #train# step 5849, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:26.945207 #train# step 5850, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:28.494902 #train# step 5851, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:30.070166 #train# step 5852, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:31.629880 #train# step 5853, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:33.158758 #train# step 5854, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:34.706202 #train# step 5855, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:36.239936 #train# step 5856, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:37.790188 #train# step 5857, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:39.375874 #train# step 5858, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:40.923067 #train# step 5859, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:42.490348 #train# step 5860, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:44.057593 #train# step 5861, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:45.620005 #train# step 5862, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:47.131945 #train# step 5863, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:48.664500 #train# step 5864, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:50.221665 #train# step 5865, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:51.785702 #train# step 5866, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:53.323192 #train# step 5867, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:54.874471 #train# step 5868, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:56.451577 #train# step 5869, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:58.012179 #train# step 5870, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:25:59.586128 #train# step 5871, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:01.178413 #train# step 5872, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:02.735280 #train# step 5873, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:04.290515 #train# step 5874, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:05.824809 #train# step 5875, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:07.398283 #train# step 5876, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:08.954008 #train# step 5877, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:10.516759 #train# step 5878, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:12.102968 #train# step 5879, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:13.657531 #train# step 5880, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:15.222894 #train# step 5881, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:16.762434 #train# step 5882, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:18.314893 #train# step 5883, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:19.841824 #train# step 5884, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:21.398620 #train# step 5885, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:22.928260 #train# step 5886, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:24.492623 #train# step 5887, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:26.075730 #train# step 5888, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:27.634249 #train# step 5889, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:29.187179 #train# step 5890, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:30.744977 #train# step 5891, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:32.283832 #train# step 5892, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:33.853039 #train# step 5893, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:35.424040 #train# step 5894, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:36.985112 #train# step 5895, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:38.542393 #train# step 5896, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:40.108922 #train# step 5897, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:41.671183 #train# step 5898, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:43.251199 #train# step 5899, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:44.823179 #train# step 5900, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:46.421468 #train# step 5901, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:47.966443 #train# step 5902, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:49.531527 #train# step 5903, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:51.068374 #train# step 5904, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:52.646352 #train# step 5905, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:54.226954 #train# step 5906, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:55.791390 #train# step 5907, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:57.349374 #train# step 5908, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:26:58.916626 #train# step 5909, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:00.463680 #train# step 5910, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:01.992594 #train# step 5911, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:03.541271 #train# step 5912, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:05.073974 #train# step 5913, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:06.626524 #train# step 5914, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:08.161892 #train# step 5915, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:09.710195 #train# step 5916, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:11.269073 #train# step 5917, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:12.802190 #train# step 5918, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:14.351439 #train# step 5919, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:15.957244 #train# step 5920, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:17.512922 #train# step 5921, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:19.080920 #train# step 5922, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:20.659152 #train# step 5923, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:22.243197 #train# step 5924, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:23.816394 #train# step 5925, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:25.327904 #train# step 5926, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:26.886196 #train# step 5927, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:28.439000 #train# step 5928, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:30.003485 #train# step 5929, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:31.544385 #train# step 5930, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:33.106046 #train# step 5931, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:34.671432 #train# step 5932, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:36.261587 #train# step 5933, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:37.824660 #train# step 5934, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:39.389648 #train# step 5935, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:40.952608 #train# step 5936, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:42.521770 #train# step 5937, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:44.094039 #train# step 5938, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:45.677354 #train# step 5939, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:47.229895 #train# step 5940, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:48.792949 #train# step 5941, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:50.357816 #train# step 5942, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:51.943825 #train# step 5943, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:53.511256 #train# step 5944, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:55.053744 #train# step 5945, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:56.619318 #train# step 5946, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:58.193576 #train# step 5947, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:27:59.743377 #train# step 5948, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:01.305543 #train# step 5949, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:02.844426 #train# step 5950, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:04.429466 #train# step 5951, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:06.003942 #train# step 5952, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:07.546009 #train# step 5953, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:09.074979 #train# step 5954, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:10.628844 #train# step 5955, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:12.166045 #train# step 5956, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:13.720067 #train# step 5957, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:15.274623 #train# step 5958, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:16.830513 #train# step 5959, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:18.409799 #train# step 5960, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:19.971718 #train# step 5961, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:21.516347 #train# step 5962, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:23.062949 #train# step 5963, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:24.618584 #train# step 5964, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:26.149020 #train# step 5965, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:27.695827 #train# step 5966, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:29.308819 #train# step 5967, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:30.859427 #train# step 5968, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:32.422022 #train# step 5969, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:33.963348 #train# step 5970, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:35.512055 #train# step 5971, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:37.046438 #train# step 5972, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:38.626834 #train# step 5973, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:40.207438 #train# step 5974, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:41.771599 #train# step 5975, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:43.331859 #train# step 5976, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:44.917218 #train# step 5977, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:46.527098 #train# step 5978, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:48.133860 #train# step 5979, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:49.716235 #train# step 5980, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:51.262113 #train# step 5981, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:52.791995 #train# step 5982, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:54.351915 #train# step 5983, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:55.902796 #train# step 5984, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:57.452153 #train# step 5985, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:28:58.967057 #train# step 5986, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:00.511060 #train# step 5987, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:02.027639 #train# step 5988, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:03.559745 #train# step 5989, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:05.135980 #train# step 5990, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:06.714439 #train# step 5991, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:08.262021 #train# step 5992, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:09.813878 #train# step 5993, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:11.384638 #train# step 5994, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:12.963980 #train# step 5995, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:14.499476 #train# step 5996, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:16.036172 #train# step 5997, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:17.591318 #train# step 5998, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:19.153240 #train# step 5999, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:20.733957 #train# step 6000, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:22.285037 #train# step 6001, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:23.836037 #train# step 6002, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:25.396692 #train# step 6003, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:26.970425 #train# step 6004, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:28.544075 #train# step 6005, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:30.132823 #train# step 6006, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:31.715151 #train# step 6007, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:33.280857 #train# step 6008, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:34.826867 #train# step 6009, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:36.371242 #train# step 6010, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:37.931084 #train# step 6011, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:39.516583 #train# step 6012, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:41.096451 #train# step 6013, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:42.661953 #train# step 6014, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:44.217008 #train# step 6015, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:45.767006 #train# step 6016, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:47.319025 #train# step 6017, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:48.888434 #train# step 6018, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:50.427717 #train# step 6019, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:51.969919 #train# step 6020, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:53.510534 #train# step 6021, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:55.068480 #train# step 6022, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:56.627452 #train# step 6023, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:58.171479 #train# step 6024, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:29:59.742277 #train# step 6025, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:01.312671 #train# step 6026, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:02.880017 #train# step 6027, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:04.426839 #train# step 6028, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:05.977245 #train# step 6029, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:07.536444 #train# step 6030, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:09.100984 #train# step 6031, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:10.695349 #train# step 6032, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:12.224525 #train# step 6033, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:13.778417 #train# step 6034, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:15.345685 #train# step 6035, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:16.880502 #train# step 6036, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:18.415442 #train# step 6037, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:19.981935 #train# step 6038, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:21.581361 #train# step 6039, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:23.139123 #train# step 6040, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:24.701020 #train# step 6041, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:26.233786 #train# step 6042, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:27.781131 #train# step 6043, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:29.346849 #train# step 6044, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:30.870325 #train# step 6045, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:32.413194 #train# step 6046, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:33.975947 #train# step 6047, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:35.537526 #train# step 6048, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:37.094395 #train# step 6049, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:38.647853 #train# step 6050, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:40.210090 #train# step 6051, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:41.809426 #train# step 6052, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:43.371538 #train# step 6053, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:44.924082 #train# step 6054, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:46.484097 #train# step 6055, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:48.041023 #train# step 6056, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:49.625489 #train# step 6057, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:51.150779 #train# step 6058, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:52.697790 #train# step 6059, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:54.269135 #train# step 6060, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:55.861591 #train# step 6061, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:57.433893 #train# step 6062, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:30:59.005830 #train# step 6063, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:00.551045 #train# step 6064, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:02.131393 #train# step 6065, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:03.689353 #train# step 6066, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:05.212629 #train# step 6067, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:06.773524 #train# step 6068, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:08.339661 #train# step 6069, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:09.889591 #train# step 6070, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:11.453438 #train# step 6071, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:13.000430 #train# step 6072, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:14.556576 #train# step 6073, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:16.112883 #train# step 6074, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:17.666561 #train# step 6075, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:19.240626 #train# step 6076, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:20.785989 #train# step 6077, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:22.347794 #train# step 6078, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:23.923728 #train# step 6079, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:25.484091 #train# step 6080, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:27.036296 #train# step 6081, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:28.618191 #train# step 6082, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:30.156060 #train# step 6083, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:31.690874 #train# step 6084, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:33.242874 #train# step 6085, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:34.816612 #train# step 6086, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:36.374105 #train# step 6087, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:37.942064 #train# step 6088, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:39.522871 #train# step 6089, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:41.072331 #train# step 6090, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:42.643269 #train# step 6091, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:44.238970 #train# step 6092, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:45.761009 #train# step 6093, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:47.340927 #train# step 6094, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:48.866489 #train# step 6095, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:50.421710 #train# step 6096, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:51.999153 #train# step 6097, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:53.591724 #train# step 6098, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:55.161717 #train# step 6099, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:56.690178 #train# step 6100, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:58.244889 #train# step 6101, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:31:59.808348 #train# step 6102, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:01.339060 #train# step 6103, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:02.926269 #train# step 6104, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:04.498410 #train# step 6105, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:06.038668 #train# step 6106, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:07.610518 #train# step 6107, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:09.176554 #train# step 6108, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:10.696731 #train# step 6109, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:12.260640 #train# step 6110, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:13.827611 #train# step 6111, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:15.407493 #train# step 6112, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:16.998580 #train# step 6113, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:18.560076 #train# step 6114, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:20.115625 #train# step 6115, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:21.660798 #train# step 6116, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:23.207253 #train# step 6117, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:24.780267 #train# step 6118, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:26.347989 #train# step 6119, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:27.919883 #train# step 6120, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:29.462622 #train# step 6121, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:31.012273 #train# step 6122, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:32.597736 #train# step 6123, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:34.143626 #train# step 6124, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:35.731112 #train# step 6125, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:37.322966 #train# step 6126, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:38.861531 #train# step 6127, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:40.363593 #train# step 6128, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:41.896356 #train# step 6129, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:43.446595 #train# step 6130, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:44.989827 #train# step 6131, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:46.548652 #train# step 6132, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:48.120588 #train# step 6133, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:49.672061 #train# step 6134, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:51.225775 #train# step 6135, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:52.769841 #train# step 6136, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:54.324457 #train# step 6137, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:55.905716 #train# step 6138, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:57.466114 #train# step 6139, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:32:59.029512 #train# step 6140, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:00.567370 #train# step 6141, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:02.094660 #train# step 6142, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:03.646859 #train# step 6143, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:05.175204 #train# step 6144, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:06.762033 #train# step 6145, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:08.316587 #train# step 6146, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:09.847205 #train# step 6147, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:11.422811 #train# step 6148, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:12.973943 #train# step 6149, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:14.529074 #train# step 6150, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:16.069762 #train# step 6151, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:17.630269 #train# step 6152, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:19.210970 #train# step 6153, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:20.761026 #train# step 6154, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:22.330332 #train# step 6155, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:23.890281 #train# step 6156, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:25.501858 #train# step 6157, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:27.095097 #train# step 6158, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:28.622600 #train# step 6159, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:30.194195 #train# step 6160, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:31.757121 #train# step 6161, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:33.323583 #train# step 6162, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:34.898858 #train# step 6163, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:36.480987 #train# step 6164, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:38.048879 #train# step 6165, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:39.600506 #train# step 6166, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:41.124400 #train# step 6167, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:42.677763 #train# step 6168, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:44.207984 #train# step 6169, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:45.768360 #train# step 6170, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:47.301399 #train# step 6171, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:48.857863 #train# step 6172, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:50.430615 #train# step 6173, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:51.982634 #train# step 6174, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:53.538334 #train# step 6175, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:55.094712 #train# step 6176, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:56.658947 #train# step 6177, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:58.227545 #train# step 6178, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:33:59.796992 #train# step 6179, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:01.343709 #train# step 6180, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:02.902728 #train# step 6181, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:04.469520 #train# step 6182, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:06.047444 #train# step 6183, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:07.629358 #train# step 6184, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:09.181612 #train# step 6185, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:10.740324 #train# step 6186, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:12.311461 #train# step 6187, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:13.848603 #train# step 6188, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:15.406340 #train# step 6189, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:16.932158 #train# step 6190, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:18.511783 #train# step 6191, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:20.059671 #train# step 6192, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:21.614523 #train# step 6193, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:23.180240 #train# step 6194, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:24.754262 #train# step 6195, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:26.283412 #train# step 6196, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:27.823152 #train# step 6197, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:29.419784 #train# step 6198, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:30.974535 #train# step 6199, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:32.540746 #train# step 6200, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:34.111217 #train# step 6201, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:35.667150 #train# step 6202, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:37.217932 #train# step 6203, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:38.818836 #train# step 6204, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:40.399911 #train# step 6205, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:41.980258 #train# step 6206, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:43.522962 #train# step 6207, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:45.083057 #train# step 6208, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:46.649720 #train# step 6209, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:48.202203 #train# step 6210, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:49.748140 #train# step 6211, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:51.308742 #train# step 6212, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:52.868631 #train# step 6213, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:54.419883 #train# step 6214, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:55.953102 #train# step 6215, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:57.502749 #train# step 6216, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:34:59.085239 #train# step 6217, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:00.644973 #train# step 6218, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:02.214200 #train# step 6219, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:03.799174 #train# step 6220, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:05.364434 #train# step 6221, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:06.927085 #train# step 6222, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:08.499565 #train# step 6223, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:10.047283 #train# step 6224, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:11.623137 #train# step 6225, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:13.189103 #train# step 6226, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:14.757906 #train# step 6227, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:16.300605 #train# step 6228, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:17.871168 #train# step 6229, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:19.421203 #train# step 6230, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:21.005086 #train# step 6231, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:22.560506 #train# step 6232, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:24.122615 #train# step 6233, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:25.648293 #train# step 6234, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:27.186499 #train# step 6235, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:28.702684 #train# step 6236, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:30.279737 #train# step 6237, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:31.847049 #train# step 6238, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:33.420010 #train# step 6239, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:34.988151 #train# step 6240, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:36.566489 #train# step 6241, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:38.089697 #train# step 6242, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:39.639752 #train# step 6243, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:41.202894 #train# step 6244, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:42.780587 #train# step 6245, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:44.333499 #train# step 6246, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:45.914509 #train# step 6247, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:47.466115 #train# step 6248, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:49.020878 #train# step 6249, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:50.572918 #train# step 6250, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:52.120833 #train# step 6251, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:53.653937 #train# step 6252, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:55.223298 #train# step 6253, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:56.797370 #train# step 6254, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:58.319377 #train# step 6255, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:35:59.875932 #train# step 6256, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:01.469289 #train# step 6257, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:02.996803 #train# step 6258, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:04.512486 #train# step 6259, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:06.070723 #train# step 6260, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:07.608391 #train# step 6261, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:09.176434 #train# step 6262, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:10.716493 #train# step 6263, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:12.306429 #train# step 6264, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:13.841292 #train# step 6265, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:15.414950 #train# step 6266, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:16.969867 #train# step 6267, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:18.538456 #train# step 6268, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:20.079341 #train# step 6269, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:21.606320 #train# step 6270, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:23.200724 #train# step 6271, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:24.760033 #train# step 6272, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:26.299284 #train# step 6273, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:27.856474 #train# step 6274, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:29.416786 #train# step 6275, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:30.969775 #train# step 6276, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:32.587264 #train# step 6277, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:34.151005 #train# step 6278, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:35.728508 #train# step 6279, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:37.304372 #train# step 6280, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:38.906957 #train# step 6281, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:40.480485 #train# step 6282, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:42.019872 #train# step 6283, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:43.570768 #train# step 6284, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:45.148146 #train# step 6285, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:46.685437 #train# step 6286, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:48.234409 #train# step 6287, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:49.750985 #train# step 6288, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:51.330917 #train# step 6289, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:52.869272 #train# step 6290, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:54.425114 #train# step 6291, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:55.987744 #train# step 6292, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:57.565082 #train# step 6293, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:36:59.135889 #train# step 6294, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:00.728708 #train# step 6295, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:02.305813 #train# step 6296, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:03.872213 #train# step 6297, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:05.421316 #train# step 6298, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:06.973142 #train# step 6299, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:08.551121 #train# step 6300, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:10.106016 #train# step 6301, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:11.641997 #train# step 6302, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:13.185583 #train# step 6303, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:14.741200 #train# step 6304, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:16.318975 #train# step 6305, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:17.840984 #train# step 6306, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:19.405185 #train# step 6307, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:20.959934 #train# step 6308, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:22.489499 #train# step 6309, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:24.038932 #train# step 6310, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:25.586778 #train# step 6311, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:27.166049 #train# step 6312, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:28.740122 #train# step 6313, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:30.308032 #train# step 6314, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:31.855349 #train# step 6315, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:33.405876 #train# step 6316, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:34.984672 #train# step 6317, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:36.546040 #train# step 6318, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:38.077774 #train# step 6319, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:39.641202 #train# step 6320, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:41.195197 #train# step 6321, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:42.768079 #train# step 6322, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:44.343716 #train# step 6323, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:45.880213 #train# step 6324, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:47.432754 #train# step 6325, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:49.000168 #train# step 6326, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:50.568453 #train# step 6327, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:52.121458 #train# step 6328, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:53.685326 #train# step 6329, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:55.232254 #train# step 6330, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:56.779136 #train# step 6331, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:58.332610 #train# step 6332, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:37:59.908619 #train# step 6333, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:01.474918 #train# step 6334, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:03.033208 #train# step 6335, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:04.598764 #train# step 6336, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:06.179150 #train# step 6337, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:07.777475 #train# step 6338, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:09.343550 #train# step 6339, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:10.915805 #train# step 6340, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:12.464603 #train# step 6341, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:14.031969 #train# step 6342, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:15.608794 #train# step 6343, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:17.148462 #train# step 6344, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:18.730139 #train# step 6345, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:20.289655 #train# step 6346, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:21.844808 #train# step 6347, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:23.423256 #train# step 6348, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:24.962662 #train# step 6349, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:26.508207 #train# step 6350, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:28.080120 #train# step 6351, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:29.605905 #train# step 6352, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:31.173214 #train# step 6353, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:32.710509 #train# step 6354, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:34.296576 #train# step 6355, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:35.862617 #train# step 6356, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:37.402338 #train# step 6357, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:38.934674 #train# step 6358, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:40.509635 #train# step 6359, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:42.036123 #train# step 6360, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:43.627598 #train# step 6361, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:45.202801 #train# step 6362, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:46.782076 #train# step 6363, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:48.325921 #train# step 6364, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:49.895847 #train# step 6365, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:51.429142 #train# step 6366, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:52.987174 #train# step 6367, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:54.516592 #train# step 6368, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:56.103225 #train# step 6369, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:57.667900 #train# step 6370, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:38:59.235250 #train# step 6371, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:00.799956 #train# step 6372, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:02.366985 #train# step 6373, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:03.926637 #train# step 6374, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:05.482178 #train# step 6375, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:07.053103 #train# step 6376, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:08.604240 #train# step 6377, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:10.186470 #train# step 6378, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:11.773448 #train# step 6379, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:13.350230 #train# step 6380, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:14.915145 #train# step 6381, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:16.470629 #train# step 6382, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:18.021381 #train# step 6383, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:19.579633 #train# step 6384, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:21.152943 #train# step 6385, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:22.700301 #train# step 6386, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:24.253796 #train# step 6387, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:25.792732 #train# step 6388, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:27.359720 #train# step 6389, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:28.917843 #train# step 6390, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:30.515471 #train# step 6391, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:32.094223 #train# step 6392, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:33.658528 #train# step 6393, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:35.187849 #train# step 6394, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:36.757230 #train# step 6395, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:38.326668 #train# step 6396, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:39.911560 #train# step 6397, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:41.490439 #train# step 6398, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:43.050389 #train# step 6399, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:44.610511 #train# step 6400, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:46.155969 #train# step 6401, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:47.705689 #train# step 6402, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:49.262245 #train# step 6403, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:50.821123 #train# step 6404, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:52.385384 #train# step 6405, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:53.960438 #train# step 6406, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:55.519375 #train# step 6407, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:57.102092 #train# step 6408, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:39:58.618409 #train# step 6409, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:00.166704 #train# step 6410, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:01.730663 #train# step 6411, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:03.300358 #train# step 6412, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:04.838214 #train# step 6413, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:06.379643 #train# step 6414, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:07.954164 #train# step 6415, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:09.499064 #train# step 6416, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:11.062103 #train# step 6417, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:12.582182 #train# step 6418, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:14.155461 #train# step 6419, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:15.717948 #train# step 6420, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:17.303091 #train# step 6421, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:18.869456 #train# step 6422, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:20.452282 #train# step 6423, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:22.012595 #train# step 6424, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:23.568293 #train# step 6425, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:25.138773 #train# step 6426, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:26.748597 #train# step 6427, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:28.359414 #train# step 6428, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:29.899503 #train# step 6429, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:31.441173 #train# step 6430, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:33.015385 #train# step 6431, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:34.528124 #train# step 6432, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:36.108795 #train# step 6433, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:37.669095 #train# step 6434, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:39.251261 #train# step 6435, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:40.786727 #train# step 6436, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:42.335942 #train# step 6437, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:43.863294 #train# step 6438, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:45.420563 #train# step 6439, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:46.954005 #train# step 6440, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:48.505929 #train# step 6441, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:50.060864 #train# step 6442, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:51.654536 #train# step 6443, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:53.220750 #train# step 6444, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:54.804596 #train# step 6445, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:56.351835 #train# step 6446, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:57.946401 #train# step 6447, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:40:59.530271 #train# step 6448, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:01.116045 #train# step 6449, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:02.684794 #train# step 6450, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:04.223380 #train# step 6451, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:05.797620 #train# step 6452, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:07.357743 #train# step 6453, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:08.921345 #train# step 6454, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:10.448384 #train# step 6455, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:12.027376 #train# step 6456, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:13.551207 #train# step 6457, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:15.082070 #train# step 6458, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:16.641031 #train# step 6459, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:18.207246 #train# step 6460, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:19.759173 #train# step 6461, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:21.329612 #train# step 6462, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:22.905188 #train# step 6463, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:24.461968 #train# step 6464, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:26.026015 #train# step 6465, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:27.613404 #train# step 6466, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:29.155497 #train# step 6467, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:30.718617 #train# step 6468, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:32.241454 #train# step 6469, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:33.810638 #train# step 6470, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:35.355140 #train# step 6471, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:36.902382 #train# step 6472, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:38.457669 #train# step 6473, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:40.021570 #train# step 6474, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:41.589848 #train# step 6475, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:43.121270 #train# step 6476, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:44.658630 #train# step 6477, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:46.246696 #train# step 6478, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:47.797531 #train# step 6479, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:49.365718 #train# step 6480, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:50.889900 #train# step 6481, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:52.440729 #train# step 6482, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:54.002215 #train# step 6483, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:55.571923 #train# step 6484, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:57.139832 #train# step 6485, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:41:58.706582 #train# step 6486, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:00.267846 #train# step 6487, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:01.860732 #train# step 6488, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:03.418349 #train# step 6489, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:04.963927 #train# step 6490, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:06.549115 #train# step 6491, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:08.112202 #train# step 6492, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:09.670477 #train# step 6493, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:11.239744 #train# step 6494, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:12.811241 #train# step 6495, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:14.357188 #train# step 6496, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:15.929002 #train# step 6497, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:17.497905 #train# step 6498, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:19.038719 #train# step 6499, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:20.620022 #train# step 6500, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:22.158661 #train# step 6501, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:23.736072 #train# step 6502, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:25.272670 #train# step 6503, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:26.816891 #train# step 6504, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:28.380252 #train# step 6505, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:29.946229 #train# step 6506, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:31.510773 #train# step 6507, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:33.062193 #train# step 6508, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:34.634797 #train# step 6509, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:36.192730 #train# step 6510, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:37.736530 #train# step 6511, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:39.318249 #train# step 6512, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:40.896945 #train# step 6513, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:42.471764 #train# step 6514, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:44.026327 #train# step 6515, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:45.581037 #train# step 6516, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:47.139899 #train# step 6517, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:48.678361 #train# step 6518, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:50.219857 #train# step 6519, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:51.807229 #train# step 6520, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:53.320978 #train# step 6521, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:54.910776 #train# step 6522, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:56.479875 #train# step 6523, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:58.054833 #train# step 6524, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:42:59.639633 #train# step 6525, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:01.229965 #train# step 6526, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:02.778072 #train# step 6527, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:04.312873 #train# step 6528, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:05.870428 #train# step 6529, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:07.423683 #train# step 6530, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:08.969337 #train# step 6531, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:10.498520 #train# step 6532, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:12.050500 #train# step 6533, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:13.587705 #train# step 6534, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:15.163148 #train# step 6535, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:16.717354 #train# step 6536, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:18.281081 #train# step 6537, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:19.821267 #train# step 6538, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:21.361767 #train# step 6539, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:22.932834 #train# step 6540, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:24.509713 #train# step 6541, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:26.046138 #train# step 6542, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:27.607177 #train# step 6543, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:29.169385 #train# step 6544, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:30.739527 #train# step 6545, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:32.307923 #train# step 6546, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:33.875879 #train# step 6547, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:35.447115 #train# step 6548, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:37.016851 #train# step 6549, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:38.617123 #train# step 6550, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:40.239036 #train# step 6551, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:41.798284 #train# step 6552, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:43.332526 #train# step 6553, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:44.900236 #train# step 6554, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:46.465077 #train# step 6555, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:48.039883 #train# step 6556, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:49.563990 #train# step 6557, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:51.132667 #train# step 6558, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:52.700524 #train# step 6559, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:54.286363 #train# step 6560, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:55.831653 #train# step 6561, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:57.346830 #train# step 6562, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:43:58.931022 #train# step 6563, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:00.476128 #train# step 6564, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:02.043086 #train# step 6565, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:03.618379 #train# step 6566, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:05.157903 #train# step 6567, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:06.723593 #train# step 6568, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:08.248045 #train# step 6569, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:09.794789 #train# step 6570, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:11.366164 #train# step 6571, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:12.956735 #train# step 6572, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:14.533198 #train# step 6573, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:16.066389 #train# step 6574, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:17.621395 #train# step 6575, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:19.197542 #train# step 6576, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:20.742355 #train# step 6577, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:22.343686 #train# step 6578, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:23.901913 #train# step 6579, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:25.462877 #train# step 6580, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:26.987310 #train# step 6581, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:28.591159 #train# step 6582, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:30.183379 #train# step 6583, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:31.761489 #train# step 6584, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:33.373573 #train# step 6585, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:34.940264 #train# step 6586, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:36.501432 #train# step 6587, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:38.085920 #train# step 6588, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:39.632075 #train# step 6589, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:41.193984 #train# step 6590, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:42.734471 #train# step 6591, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:44.328688 #train# step 6592, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:45.892273 #train# step 6593, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:47.452015 #train# step 6594, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:49.005683 #train# step 6595, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:50.565879 #train# step 6596, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:52.136090 #train# step 6597, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:53.701380 #train# step 6598, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:55.230172 #train# step 6599, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:56.811703 #train# step 6600, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:58.386422 #train# step 6601, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:44:59.941138 #train# step 6602, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:01.530179 #train# step 6603, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:03.084800 #train# step 6604, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:04.601475 #train# step 6605, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:06.125382 #train# step 6606, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:07.669099 #train# step 6607, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:09.230639 #train# step 6608, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:10.764764 #train# step 6609, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:12.306700 #train# step 6610, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:13.898070 #train# step 6611, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:15.481590 #train# step 6612, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:17.044398 #train# step 6613, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:18.613434 #train# step 6614, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:20.289778 #train# step 6615, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:21.845442 #train# step 6616, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:23.397743 #train# step 6617, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:24.964301 #train# step 6618, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:26.514624 #train# step 6619, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:28.063128 #train# step 6620, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:29.611023 #train# step 6621, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:31.168232 #train# step 6622, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:32.711779 #train# step 6623, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:34.278837 #train# step 6624, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:35.845732 #train# step 6625, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:37.412835 #train# step 6626, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:38.980641 #train# step 6627, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:40.557976 #train# step 6628, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:42.117305 #train# step 6629, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:43.689860 #train# step 6630, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:45.262068 #train# step 6631, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:46.824378 #train# step 6632, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:48.396493 #train# step 6633, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:49.957330 #train# step 6634, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:51.522914 #train# step 6635, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:53.087664 #train# step 6636, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:54.627430 #train# step 6637, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:56.156603 #train# step 6638, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:57.693113 #train# step 6639, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:45:59.248742 #train# step 6640, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:00.781611 #train# step 6641, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:02.324295 #train# step 6642, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:03.877769 #train# step 6643, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:05.429677 #train# step 6644, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:06.996976 #train# step 6645, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:08.584528 #train# step 6646, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:10.172370 #train# step 6647, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:11.754106 #train# step 6648, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:13.324414 #train# step 6649, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:14.875412 #train# step 6650, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:16.440567 #train# step 6651, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:18.009974 #train# step 6652, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:19.589333 #train# step 6653, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:21.176976 #train# step 6654, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:22.717156 #train# step 6655, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:24.296161 #train# step 6656, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:25.840298 #train# step 6657, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:27.376999 #train# step 6658, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:28.941651 #train# step 6659, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:30.508434 #train# step 6660, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:32.056608 #train# step 6661, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:33.627178 #train# step 6662, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:35.207168 #train# step 6663, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:36.822102 #train# step 6664, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:38.397506 #train# step 6665, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:39.972605 #train# step 6666, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:41.510129 #train# step 6667, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:43.072977 #train# step 6668, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:44.645292 #train# step 6669, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:46.177892 #train# step 6670, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:47.716229 #train# step 6671, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:49.287366 #train# step 6672, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:50.833531 #train# step 6673, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:52.437163 #train# step 6674, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:53.969798 #train# step 6675, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:55.572526 #train# step 6676, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:57.126978 #train# step 6677, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:46:58.656759 #train# step 6678, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:00.179375 #train# step 6679, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:01.744702 #train# step 6680, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:03.261151 #train# step 6681, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:04.809812 #train# step 6682, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:06.371018 #train# step 6683, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:07.946409 #train# step 6684, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:09.542976 #train# step 6685, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:11.119971 #train# step 6686, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:12.686075 #train# step 6687, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:14.238130 #train# step 6688, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:15.807072 #train# step 6689, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:17.362919 #train# step 6690, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:18.910930 #train# step 6691, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:20.457394 #train# step 6692, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:21.993486 #train# step 6693, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:23.556266 #train# step 6694, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:25.125566 #train# step 6695, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:26.689669 #train# step 6696, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:28.236405 #train# step 6697, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:29.785020 #train# step 6698, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:31.344108 #train# step 6699, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:32.910967 #train# step 6700, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:34.453583 #train# step 6701, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:35.990776 #train# step 6702, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:37.552328 #train# step 6703, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:39.155935 #train# step 6704, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:40.694811 #train# step 6705, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:42.265386 #train# step 6706, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:43.856984 #train# step 6707, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:45.427196 #train# step 6708, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:46.973680 #train# step 6709, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:48.551658 #train# step 6710, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:50.095852 #train# step 6711, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:51.677152 #train# step 6712, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:53.237911 #train# step 6713, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:54.817570 #train# step 6714, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:56.380944 #train# step 6715, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:57.923970 #train# step 6716, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:47:59.505412 #train# step 6717, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:01.071575 #train# step 6718, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:02.621334 #train# step 6719, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:04.206190 #train# step 6720, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:05.730290 #train# step 6721, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:07.279634 #train# step 6722, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:08.866022 #train# step 6723, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:10.432480 #train# step 6724, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:11.992899 #train# step 6725, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:13.559308 #train# step 6726, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:15.097185 #train# step 6727, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:16.639224 #train# step 6728, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:18.200805 #train# step 6729, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:19.792091 #train# step 6730, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:21.330203 #train# step 6731, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:22.865104 #train# step 6732, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:24.398087 #train# step 6733, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:25.962856 #train# step 6734, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:27.546481 #train# step 6735, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:29.108723 #train# step 6736, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:30.648202 #train# step 6737, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:32.208877 #train# step 6738, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:33.786796 #train# step 6739, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:35.355417 #train# step 6740, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:36.905589 #train# step 6741, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:38.503979 #train# step 6742, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:40.076064 #train# step 6743, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:41.628113 #train# step 6744, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:43.150072 #train# step 6745, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:44.733448 #train# step 6746, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:46.268700 #train# step 6747, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:47.824784 #train# step 6748, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:49.404129 #train# step 6749, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:50.969213 #train# step 6750, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:52.508736 #train# step 6751, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:54.081557 #train# step 6752, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:55.657009 #train# step 6753, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:57.212914 #train# step 6754, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:48:58.763508 #train# step 6755, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:00.341928 #train# step 6756, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:01.897528 #train# step 6757, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:03.465566 #train# step 6758, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:05.023980 #train# step 6759, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:06.591463 #train# step 6760, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:08.123478 #train# step 6761, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:09.706913 #train# step 6762, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:11.262185 #train# step 6763, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:12.850116 #train# step 6764, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:14.430904 #train# step 6765, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:15.982121 #train# step 6766, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:17.520685 #train# step 6767, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:19.092516 #train# step 6768, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:20.679791 #train# step 6769, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:22.230907 #train# step 6770, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:23.768980 #train# step 6771, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:25.318429 #train# step 6772, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:26.881153 #train# step 6773, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:28.450021 #train# step 6774, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:29.980454 #train# step 6775, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:31.566761 #train# step 6776, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:33.130587 #train# step 6777, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:34.693994 #train# step 6778, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:36.255749 #train# step 6779, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:37.818581 #train# step 6780, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:39.384154 #train# step 6781, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:40.934099 #train# step 6782, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:42.471651 #train# step 6783, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:44.017257 #train# step 6784, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:45.559883 #train# step 6785, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:47.149477 #train# step 6786, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:48.701919 #train# step 6787, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:50.279507 #train# step 6788, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:51.824257 #train# step 6789, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:53.404503 #train# step 6790, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:54.954472 #train# step 6791, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:56.521992 #train# step 6792, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:58.082228 #train# step 6793, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:49:59.685876 #train# step 6794, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:01.239217 #train# step 6795, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:02.791067 #train# step 6796, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:04.353915 #train# step 6797, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:05.912038 #train# step 6798, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:07.486778 #train# step 6799, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:09.053511 #train# step 6800, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:10.598539 #train# step 6801, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:12.161186 #train# step 6802, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:13.711110 #train# step 6803, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:15.264086 #train# step 6804, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:16.796763 #train# step 6805, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:18.332618 #train# step 6806, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:19.888287 #train# step 6807, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:21.422956 #train# step 6808, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:22.988350 #train# step 6809, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:24.559364 #train# step 6810, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:26.140431 #train# step 6811, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:27.703195 #train# step 6812, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:29.256403 #train# step 6813, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:30.823268 #train# step 6814, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:32.356050 #train# step 6815, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:33.905829 #train# step 6816, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:35.495180 #train# step 6817, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:37.070210 #train# step 6818, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:38.668663 #train# step 6819, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:40.219322 #train# step 6820, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:41.768750 #train# step 6821, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:43.328434 #train# step 6822, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:44.916517 #train# step 6823, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:46.480378 #train# step 6824, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:48.068634 #train# step 6825, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:49.607465 #train# step 6826, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:51.167900 #train# step 6827, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:52.744384 #train# step 6828, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:54.306834 #train# step 6829, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:55.847131 #train# step 6830, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:57.422875 #train# step 6831, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:50:58.970814 #train# step 6832, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:00.529478 #train# step 6833, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:02.092824 #train# step 6834, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:03.636247 #train# step 6835, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:05.200469 #train# step 6836, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:06.753735 #train# step 6837, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:08.314648 #train# step 6838, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:09.900169 #train# step 6839, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:11.435136 #train# step 6840, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:12.984472 #train# step 6841, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:14.545591 #train# step 6842, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:16.119496 #train# step 6843, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:17.706989 #train# step 6844, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:19.295117 #train# step 6845, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:20.881006 #train# step 6846, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:22.427392 #train# step 6847, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:23.989963 #train# step 6848, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:25.533219 #train# step 6849, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:27.092643 #train# step 6850, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:28.644306 #train# step 6851, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:30.205410 #train# step 6852, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:31.792552 #train# step 6853, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:33.345683 #train# step 6854, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:34.875164 #train# step 6855, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:36.456483 #train# step 6856, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:38.027055 #train# step 6857, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:39.582007 #train# step 6858, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:41.172531 #train# step 6859, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:42.722178 #train# step 6860, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:44.264022 #train# step 6861, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:45.799925 #train# step 6862, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:47.340703 #train# step 6863, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:48.916121 #train# step 6864, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:50.469450 #train# step 6865, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:52.015280 #train# step 6866, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:53.578445 #train# step 6867, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:55.128218 #train# step 6868, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:56.693052 #train# step 6869, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:58.272655 #train# step 6870, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:51:59.827606 #train# step 6871, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:01.398394 #train# step 6872, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:02.949173 #train# step 6873, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:04.504922 #train# step 6874, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:06.080830 #train# step 6875, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:07.649859 #train# step 6876, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:09.178360 #train# step 6877, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:10.751464 #train# step 6878, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:12.307504 #train# step 6879, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:13.835629 #train# step 6880, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:15.401211 #train# step 6881, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:16.981971 #train# step 6882, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:18.543697 #train# step 6883, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:20.079647 #train# step 6884, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:21.622083 #train# step 6885, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:23.178560 #train# step 6886, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:24.747233 #train# step 6887, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:26.318377 #train# step 6888, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:27.858410 #train# step 6889, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:29.397661 #train# step 6890, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:30.940145 #train# step 6891, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:32.521161 #train# step 6892, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:34.085161 #train# step 6893, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:35.642835 #train# step 6894, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:37.215547 #train# step 6895, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:38.752572 #train# step 6896, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:40.319474 #train# step 6897, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:41.904891 #train# step 6898, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:43.478127 #train# step 6899, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:45.032313 #train# step 6900, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:46.605797 #train# step 6901, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:48.148637 #train# step 6902, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:49.743013 #train# step 6903, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:51.323834 #train# step 6904, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:52.909529 #train# step 6905, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:54.465729 #train# step 6906, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:56.027366 #train# step 6907, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:57.585690 #train# step 6908, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:52:59.171935 #train# step 6909, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:00.708816 #train# step 6910, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:02.286974 #train# step 6911, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:03.871271 #train# step 6912, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:05.449237 #train# step 6913, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:07.033925 #train# step 6914, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:08.587145 #train# step 6915, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:10.148587 #train# step 6916, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:11.722661 #train# step 6917, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:13.284395 #train# step 6918, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:14.824599 #train# step 6919, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:16.446642 #train# step 6920, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:17.978679 #train# step 6921, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:19.566038 #train# step 6922, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:21.120513 #train# step 6923, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:22.656968 #train# step 6924, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:24.221749 #train# step 6925, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:25.803677 #train# step 6926, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:27.348830 #train# step 6927, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:28.923550 #train# step 6928, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:30.459976 #train# step 6929, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:32.043472 #train# step 6930, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:33.592986 #train# step 6931, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:35.142249 #train# step 6932, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:36.702760 #train# step 6933, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:38.250121 #train# step 6934, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:39.805893 #train# step 6935, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:41.365967 #train# step 6936, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:42.959489 #train# step 6937, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:44.502844 #train# step 6938, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:46.060357 #train# step 6939, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:47.660293 #train# step 6940, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:49.218942 #train# step 6941, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:50.749725 #train# step 6942, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:52.278749 #train# step 6943, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:53.861993 #train# step 6944, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:55.407876 #train# step 6945, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:56.957859 #train# step 6946, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:53:58.510837 #train# step 6947, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:00.057686 #train# step 6948, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:01.665294 #train# step 6949, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:03.205499 #train# step 6950, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:04.763184 #train# step 6951, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:06.346228 #train# step 6952, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:07.891088 #train# step 6953, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:09.473026 #train# step 6954, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:11.040748 #train# step 6955, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:12.581860 #train# step 6956, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:14.157374 #train# step 6957, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:15.735281 #train# step 6958, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:17.283198 #train# step 6959, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:18.837980 #train# step 6960, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:20.403009 #train# step 6961, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:21.937967 #train# step 6962, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:23.495693 #train# step 6963, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:25.079525 #train# step 6964, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:26.642374 #train# step 6965, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:28.178319 #train# step 6966, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:29.750421 #train# step 6967, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:31.309370 #train# step 6968, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:32.836799 #train# step 6969, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:34.415389 #train# step 6970, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:35.997549 #train# step 6971, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:37.590026 #train# step 6972, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:39.172064 #train# step 6973, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:40.730769 #train# step 6974, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:42.287198 #train# step 6975, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:43.850166 #train# step 6976, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:45.415599 #train# step 6977, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:46.968792 #train# step 6978, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:48.568420 #train# step 6979, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:50.161709 #train# step 6980, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:51.712275 #train# step 6981, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:53.232784 #train# step 6982, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:54.784086 #train# step 6983, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:56.332287 #train# step 6984, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:57.911730 #train# step 6985, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:54:59.468678 #train# step 6986, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:01.024707 #train# step 6987, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:02.586638 #train# step 6988, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:04.166274 #train# step 6989, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:05.717722 #train# step 6990, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:07.279785 #train# step 6991, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:08.886268 #train# step 6992, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:10.460603 #train# step 6993, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:11.997546 #train# step 6994, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:13.575016 #train# step 6995, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:15.122222 #train# step 6996, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:16.645513 #train# step 6997, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:18.228112 #train# step 6998, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:19.782707 #train# step 6999, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:21.334846 #train# step 7000, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:22.896315 #train# step 7001, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:24.435436 #train# step 7002, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:26.014766 #train# step 7003, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:27.548739 #train# step 7004, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:29.129882 #train# step 7005, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:30.671396 #train# step 7006, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:32.219987 #train# step 7007, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:33.777953 #train# step 7008, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:35.335893 #train# step 7009, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:36.882725 #train# step 7010, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:38.471720 #train# step 7011, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:40.025487 #train# step 7012, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:41.589201 #train# step 7013, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:43.162920 #train# step 7014, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:44.749066 #train# step 7015, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:46.288925 #train# step 7016, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:47.862997 #train# step 7017, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:49.394911 #train# step 7018, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:50.963424 #train# step 7019, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:52.508283 #train# step 7020, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:54.069637 #train# step 7021, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:55.617807 #train# step 7022, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:57.155212 #train# step 7023, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:55:58.727682 #train# step 7024, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:00.282046 #train# step 7025, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:01.831588 #train# step 7026, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:03.421079 #train# step 7027, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:04.985761 #train# step 7028, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:06.569986 #train# step 7029, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:08.154664 #train# step 7030, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:09.718577 #train# step 7031, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:11.306462 #train# step 7032, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:12.853418 #train# step 7033, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:14.375132 #train# step 7034, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:15.933353 #train# step 7035, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:17.485626 #train# step 7036, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:19.056704 #train# step 7037, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:20.604166 #train# step 7038, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:22.158604 #train# step 7039, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:23.689407 #train# step 7040, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:25.240716 #train# step 7041, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:26.781330 #train# step 7042, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:28.360703 #train# step 7043, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:29.897437 #train# step 7044, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:31.465814 #train# step 7045, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:33.052340 #train# step 7046, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:34.635296 #train# step 7047, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:36.183313 #train# step 7048, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:37.751263 #train# step 7049, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:39.356031 #train# step 7050, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:40.914843 #train# step 7051, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:42.447987 #train# step 7052, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:44.026967 #train# step 7053, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:45.641687 #train# step 7054, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:47.201801 #train# step 7055, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:48.744966 #train# step 7056, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:50.303104 #train# step 7057, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:51.854469 #train# step 7058, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:53.377545 #train# step 7059, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:54.922850 #train# step 7060, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:56.486892 #train# step 7061, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:58.055020 #train# step 7062, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:56:59.629896 #train# step 7063, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:01.195800 #train# step 7064, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:02.760980 #train# step 7065, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:04.347960 #train# step 7066, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:05.907251 #train# step 7067, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:07.498637 #train# step 7068, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:09.065950 #train# step 7069, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:10.583902 #train# step 7070, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:12.175641 #train# step 7071, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:13.742152 #train# step 7072, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:15.285609 #train# step 7073, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:16.881037 #train# step 7074, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:18.480079 #train# step 7075, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:20.062016 #train# step 7076, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:21.625950 #train# step 7077, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:23.177311 #train# step 7078, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:24.749524 #train# step 7079, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:26.298587 #train# step 7080, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:27.832763 #train# step 7081, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:29.373112 #train# step 7082, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:30.960230 #train# step 7083, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:32.517944 #train# step 7084, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:34.078391 #train# step 7085, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:35.626271 #train# step 7086, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:37.171061 #train# step 7087, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:38.745952 #train# step 7088, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:40.276592 #train# step 7089, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:41.845507 #train# step 7090, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:43.429404 #train# step 7091, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:44.968850 #train# step 7092, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:46.513709 #train# step 7093, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:48.088564 #train# step 7094, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:49.607672 #train# step 7095, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:51.141070 #train# step 7096, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:52.687387 #train# step 7097, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:54.257465 #train# step 7098, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:55.832458 #train# step 7099, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:57.398540 #train# step 7100, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:57:58.963536 #train# step 7101, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:00.529310 #train# step 7102, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:02.098186 #train# step 7103, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:03.652964 #train# step 7104, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:05.198062 #train# step 7105, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:06.771923 #train# step 7106, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:08.327506 #train# step 7107, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:09.897994 #train# step 7108, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:11.438043 #train# step 7109, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:12.995094 #train# step 7110, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:14.557904 #train# step 7111, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:16.143427 #train# step 7112, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:17.693904 #train# step 7113, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:19.259947 #train# step 7114, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:20.788576 #train# step 7115, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:22.360154 #train# step 7116, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:23.886973 #train# step 7117, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:25.469093 #train# step 7118, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:27.032718 #train# step 7119, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:28.603287 #train# step 7120, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:30.157010 #train# step 7121, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:31.719492 #train# step 7122, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:33.292879 #train# step 7123, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:34.851890 #train# step 7124, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:36.402565 #train# step 7125, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:37.960384 #train# step 7126, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:39.520525 #train# step 7127, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:41.089973 #train# step 7128, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:42.651745 #train# step 7129, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:44.185996 #train# step 7130, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:45.717544 #train# step 7131, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:47.266715 #train# step 7132, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:48.839741 #train# step 7133, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:50.407262 #train# step 7134, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:51.965116 #train# step 7135, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:53.553499 #train# step 7136, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:55.108884 #train# step 7137, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:56.659684 #train# step 7138, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:58.204550 #train# step 7139, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:58:59.769079 #train# step 7140, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:01.336787 #train# step 7141, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:02.870069 #train# step 7142, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:04.419245 #train# step 7143, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:06.014687 #train# step 7144, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:07.586674 #train# step 7145, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:09.151469 #train# step 7146, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:10.705364 #train# step 7147, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:12.234120 #train# step 7148, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:13.769165 #train# step 7149, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:15.350536 #train# step 7150, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:16.916390 #train# step 7151, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:18.476600 #train# step 7152, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:20.021467 #train# step 7153, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:21.584236 #train# step 7154, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:23.152004 #train# step 7155, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:24.698398 #train# step 7156, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:26.272866 #train# step 7157, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:27.821260 #train# step 7158, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:29.381123 #train# step 7159, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:30.932324 #train# step 7160, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:32.485695 #train# step 7161, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:34.023865 #train# step 7162, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:35.583817 #train# step 7163, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:37.149262 #train# step 7164, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:38.715446 #train# step 7165, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:40.278615 #train# step 7166, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:41.851348 #train# step 7167, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:43.412075 #train# step 7168, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:44.954062 #train# step 7169, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:46.543352 #train# step 7170, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:48.119453 #train# step 7171, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:49.678510 #train# step 7172, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:51.217335 #train# step 7173, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:52.785313 #train# step 7174, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:54.338373 #train# step 7175, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:55.903364 #train# step 7176, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:57.470846 #train# step 7177, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-20 23:59:59.079913 #train# step 7178, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:00.630540 #train# step 7179, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:02.234041 #train# step 7180, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:03.798088 #train# step 7181, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:05.362311 #train# step 7182, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:06.909077 #train# step 7183, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:08.468252 #train# step 7184, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:09.982784 #train# step 7185, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:11.529226 #train# step 7186, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:13.100876 #train# step 7187, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:14.627704 #train# step 7188, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:16.181823 #train# step 7189, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:17.748211 #train# step 7190, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:19.330939 #train# step 7191, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:20.888847 #train# step 7192, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:22.458783 #train# step 7193, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:24.019408 #train# step 7194, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:25.574463 #train# step 7195, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:27.141412 #train# step 7196, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:28.724409 #train# step 7197, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:30.291351 #train# step 7198, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:31.827233 #train# step 7199, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:33.369656 #train# step 7200, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:34.937781 #train# step 7201, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:36.529615 #train# step 7202, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:38.075397 #train# step 7203, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:39.622121 #train# step 7204, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:41.187124 #train# step 7205, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:42.728599 #train# step 7206, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:44.276038 #train# step 7207, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:45.864759 #train# step 7208, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:47.413073 #train# step 7209, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:48.984823 #train# step 7210, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:50.545361 #train# step 7211, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:52.105916 #train# step 7212, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:53.639342 #train# step 7213, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:55.195992 #train# step 7214, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:56.725042 #train# step 7215, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:58.334091 #train# step 7216, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:00:59.864802 #train# step 7217, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:01.415137 #train# step 7218, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:02.959084 #train# step 7219, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:04.544744 #train# step 7220, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:06.083647 #train# step 7221, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:07.663696 #train# step 7222, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:09.235240 #train# step 7223, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:10.816816 #train# step 7224, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:12.397149 #train# step 7225, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:13.943706 #train# step 7226, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:15.507595 #train# step 7227, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:17.065382 #train# step 7228, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:18.675540 #train# step 7229, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:20.248110 #train# step 7230, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:21.820695 #train# step 7231, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:23.420116 #train# step 7232, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:24.988041 #train# step 7233, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:26.559274 #train# step 7234, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:28.142911 #train# step 7235, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:29.713427 #train# step 7236, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:31.299240 #train# step 7237, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:32.827431 #train# step 7238, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:34.361853 #train# step 7239, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:35.946851 #train# step 7240, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:37.533711 #train# step 7241, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:39.091332 #train# step 7242, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:40.647423 #train# step 7243, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:42.220096 #train# step 7244, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:43.781368 #train# step 7245, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:45.371266 #train# step 7246, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:46.932325 #train# step 7247, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:48.469623 #train# step 7248, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:50.028601 #train# step 7249, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:51.547548 #train# step 7250, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:53.098750 #train# step 7251, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:54.653108 #train# step 7252, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:56.221789 #train# step 7253, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:57.759654 #train# step 7254, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:01:59.351326 #train# step 7255, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:00.933242 #train# step 7256, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:02.467725 #train# step 7257, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:04.070433 #train# step 7258, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:05.615759 #train# step 7259, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:07.156061 #train# step 7260, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:08.700211 #train# step 7261, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:10.253315 #train# step 7262, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:11.804691 #train# step 7263, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:13.367570 #train# step 7264, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:14.928947 #train# step 7265, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:16.467462 #train# step 7266, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:18.031744 #train# step 7267, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:19.588032 #train# step 7268, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:21.170938 #train# step 7269, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:22.736905 #train# step 7270, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:24.322208 #train# step 7271, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:25.906158 #train# step 7272, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:27.486217 #train# step 7273, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:29.054453 #train# step 7274, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:30.600587 #train# step 7275, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:32.148712 #train# step 7276, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:33.722949 #train# step 7277, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:35.275284 #train# step 7278, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:36.834287 #train# step 7279, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:38.400519 #train# step 7280, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:39.997835 #train# step 7281, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:41.585765 #train# step 7282, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:43.140647 #train# step 7283, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:44.684594 #train# step 7284, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:46.258265 #train# step 7285, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:47.836581 #train# step 7286, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:49.383603 #train# step 7287, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:50.963629 #train# step 7288, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:52.535933 #train# step 7289, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:54.081470 #train# step 7290, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:55.632824 #train# step 7291, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:57.175639 #train# step 7292, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:02:58.741351 #train# step 7293, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:00.298980 #train# step 7294, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:01.840801 #train# step 7295, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:03.378504 #train# step 7296, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:04.918820 #train# step 7297, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:06.460038 #train# step 7298, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:08.035338 #train# step 7299, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:09.607147 #train# step 7300, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:11.173293 #train# step 7301, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:12.736399 #train# step 7302, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:14.281806 #train# step 7303, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:15.838087 #train# step 7304, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:17.397783 #train# step 7305, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:18.967605 #train# step 7306, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:20.539710 #train# step 7307, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:22.103946 #train# step 7308, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:23.666264 #train# step 7309, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:25.222005 #train# step 7310, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:26.825520 #train# step 7311, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:28.376093 #train# step 7312, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:29.937853 #train# step 7313, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:31.523149 #train# step 7314, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:33.038877 #train# step 7315, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:34.623257 #train# step 7316, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:36.192101 #train# step 7317, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:37.771020 #train# step 7318, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:39.346596 #train# step 7319, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:40.889215 #train# step 7320, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:42.443636 #train# step 7321, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:44.012429 #train# step 7322, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:45.590411 #train# step 7323, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:47.141437 #train# step 7324, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:48.651464 #train# step 7325, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:50.196691 #train# step 7326, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:51.759762 #train# step 7327, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:53.303857 #train# step 7328, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:54.896150 #train# step 7329, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:56.467537 #train# step 7330, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:58.022592 #train# step 7331, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:03:59.609709 #train# step 7332, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:01.180832 #train# step 7333, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:02.736634 #train# step 7334, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:04.282208 #train# step 7335, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:05.843431 #train# step 7336, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:07.384707 #train# step 7337, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:08.953679 #train# step 7338, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:10.516854 #train# step 7339, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:12.099333 #train# step 7340, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:13.670350 #train# step 7341, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:15.256741 #train# step 7342, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:16.880604 #train# step 7343, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:18.440929 #train# step 7344, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:19.980148 #train# step 7345, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:21.526711 #train# step 7346, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:23.069512 #train# step 7347, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:24.615477 #train# step 7348, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:26.193740 #train# step 7349, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:27.759722 #train# step 7350, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:29.299400 #train# step 7351, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:30.865710 #train# step 7352, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:32.437933 #train# step 7353, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:34.007148 #train# step 7354, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:35.583199 #train# step 7355, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:37.131645 #train# step 7356, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:38.715391 #train# step 7357, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:40.276411 #train# step 7358, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:41.841325 #train# step 7359, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:43.381441 #train# step 7360, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:44.930514 #train# step 7361, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:46.502567 #train# step 7362, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:48.045901 #train# step 7363, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:49.611879 #train# step 7364, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:51.193076 #train# step 7365, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:52.749905 #train# step 7366, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:54.309597 #train# step 7367, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:55.862283 #train# step 7368, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:57.432021 #train# step 7369, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:04:58.978643 #train# step 7370, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:00.511056 #train# step 7371, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:02.109569 #train# step 7372, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:03.702165 #train# step 7373, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:05.249803 #train# step 7374, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:06.789268 #train# step 7375, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:08.353583 #train# step 7376, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:09.898622 #train# step 7377, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:11.454996 #train# step 7378, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:13.013363 #train# step 7379, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:14.566187 #train# step 7380, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:16.109712 #train# step 7381, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:17.670718 #train# step 7382, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:19.267980 #train# step 7383, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:20.847561 #train# step 7384, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:22.423010 #train# step 7385, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:24.007542 #train# step 7386, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:25.550927 #train# step 7387, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:27.118052 #train# step 7388, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:28.661260 #train# step 7389, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:30.218709 #train# step 7390, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:31.758043 #train# step 7391, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:33.288438 #train# step 7392, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:34.828765 #train# step 7393, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:36.398197 #train# step 7394, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:37.960652 #train# step 7395, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:39.520726 #train# step 7396, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:41.067767 #train# step 7397, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:42.657712 #train# step 7398, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:44.216113 #train# step 7399, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:45.745383 #train# step 7400, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:47.313080 #train# step 7401, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:48.896788 #train# step 7402, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:50.467809 #train# step 7403, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:52.021048 #train# step 7404, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:53.602841 #train# step 7405, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:55.190181 #train# step 7406, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:56.788824 #train# step 7407, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:58.354233 #train# step 7408, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:05:59.926575 #train# step 7409, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:01.495036 #train# step 7410, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:03.070745 #train# step 7411, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:04.635028 #train# step 7412, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:06.184852 #train# step 7413, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:07.742416 #train# step 7414, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:09.320439 #train# step 7415, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:10.877365 #train# step 7416, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:12.442266 #train# step 7417, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:13.982595 #train# step 7418, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:15.545032 #train# step 7419, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:17.112703 #train# step 7420, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:18.676048 #train# step 7421, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:20.251197 #train# step 7422, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:21.807969 #train# step 7423, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:23.363216 #train# step 7424, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:24.918588 #train# step 7425, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:26.495710 #train# step 7426, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:28.058006 #train# step 7427, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:29.617457 #train# step 7428, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:31.201750 #train# step 7429, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:32.759388 #train# step 7430, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:34.320560 #train# step 7431, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:35.882157 #train# step 7432, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:37.423940 #train# step 7433, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:38.979219 #train# step 7434, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:40.566938 #train# step 7435, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:42.128243 #train# step 7436, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:43.673929 #train# step 7437, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:45.236470 #train# step 7438, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:46.788331 #train# step 7439, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:48.332473 #train# step 7440, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:49.883874 #train# step 7441, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:51.465333 #train# step 7442, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:53.039069 #train# step 7443, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:54.584889 #train# step 7444, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:56.165653 #train# step 7445, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:57.702815 #train# step 7446, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:06:59.275909 #train# step 7447, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:00.853089 #train# step 7448, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:02.436330 #train# step 7449, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:03.980189 #train# step 7450, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:05.557587 #train# step 7451, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:07.132894 #train# step 7452, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:08.670348 #train# step 7453, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:10.274119 #train# step 7454, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:11.823176 #train# step 7455, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:13.408355 #train# step 7456, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:14.984146 #train# step 7457, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:16.541773 #train# step 7458, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:18.094483 #train# step 7459, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:19.642800 #train# step 7460, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:21.221466 #train# step 7461, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:22.775731 #train# step 7462, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:24.326853 #train# step 7463, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:25.888319 #train# step 7464, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:27.455765 #train# step 7465, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:29.014465 #train# step 7466, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:30.589390 #train# step 7467, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:32.140171 #train# step 7468, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:33.725864 #train# step 7469, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:35.286959 #train# step 7470, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:36.859929 #train# step 7471, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:38.411210 #train# step 7472, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:39.927103 #train# step 7473, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:41.450192 #train# step 7474, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:43.038865 #train# step 7475, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:44.602446 #train# step 7476, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:46.144639 #train# step 7477, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:47.709005 #train# step 7478, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:49.272474 #train# step 7479, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:50.818139 #train# step 7480, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:52.390524 #train# step 7481, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:53.938600 #train# step 7482, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:55.503974 #train# step 7483, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:57.103636 #train# step 7484, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:07:58.662188 #train# step 7485, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:00.249032 #train# step 7486, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:01.828176 #train# step 7487, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:03.409749 #train# step 7488, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:04.986411 #train# step 7489, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:06.512829 #train# step 7490, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:08.059982 #train# step 7491, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:09.619614 #train# step 7492, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:11.190336 #train# step 7493, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:12.747777 #train# step 7494, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:14.304493 #train# step 7495, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:15.915170 #train# step 7496, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:17.490328 #train# step 7497, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:19.060294 #train# step 7498, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:20.642294 #train# step 7499, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:22.213634 #train# step 7500, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:23.753977 #train# step 7501, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:25.306679 #train# step 7502, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:26.870895 #train# step 7503, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:28.415236 #train# step 7504, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:29.995983 #train# step 7505, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:31.564650 #train# step 7506, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:33.109587 #train# step 7507, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:34.697162 #train# step 7508, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:36.229337 #train# step 7509, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:37.778245 #train# step 7510, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:39.368755 #train# step 7511, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:40.957171 #train# step 7512, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:42.531697 #train# step 7513, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:44.066690 #train# step 7514, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:45.638387 #train# step 7515, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:47.209245 #train# step 7516, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:48.809235 #train# step 7517, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:50.374789 #train# step 7518, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:51.892814 #train# step 7519, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:53.456405 #train# step 7520, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:55.016440 #train# step 7521, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:56.565023 #train# step 7522, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:58.180437 #train# step 7523, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:08:59.722541 #train# step 7524, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:01.267298 #train# step 7525, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:02.841507 #train# step 7526, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:04.400947 #train# step 7527, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:05.933680 #train# step 7528, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:07.497695 #train# step 7529, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:09.091700 #train# step 7530, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:10.650680 #train# step 7531, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:12.216964 #train# step 7532, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:13.805454 #train# step 7533, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:15.359521 #train# step 7534, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:16.922143 #train# step 7535, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:18.481257 #train# step 7536, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:20.065541 #train# step 7537, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:21.647166 #train# step 7538, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:23.214026 #train# step 7539, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:24.772338 #train# step 7540, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:26.335822 #train# step 7541, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:27.890166 #train# step 7542, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:29.465630 #train# step 7543, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:31.026682 #train# step 7544, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:32.543847 #train# step 7545, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:34.117235 #train# step 7546, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:35.654932 #train# step 7547, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:37.203579 #train# step 7548, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:38.765736 #train# step 7549, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:40.301777 #train# step 7550, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:41.903606 #train# step 7551, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:43.491689 #train# step 7552, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:45.060114 #train# step 7553, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:46.597576 #train# step 7554, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:48.181939 #train# step 7555, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:49.734643 #train# step 7556, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:51.282307 #train# step 7557, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:52.799639 #train# step 7558, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:54.390369 #train# step 7559, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:55.960504 #train# step 7560, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:57.512882 #train# step 7561, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:09:59.071436 #train# step 7562, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:00.600244 #train# step 7563, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:02.137347 #train# step 7564, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:03.733586 #train# step 7565, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:05.302008 #train# step 7566, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:06.852947 #train# step 7567, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:08.388510 #train# step 7568, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:09.969431 #train# step 7569, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:11.515375 #train# step 7570, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:13.064601 #train# step 7571, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:14.611037 #train# step 7572, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:16.157918 #train# step 7573, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:17.747553 #train# step 7574, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:19.285162 #train# step 7575, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:20.839979 #train# step 7576, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:22.406247 #train# step 7577, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:23.976964 #train# step 7578, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:25.522686 #train# step 7579, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:27.072382 #train# step 7580, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:28.636783 #train# step 7581, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:30.215839 #train# step 7582, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:31.757709 #train# step 7583, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:33.293976 #train# step 7584, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:34.858259 #train# step 7585, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:36.420525 #train# step 7586, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:37.955323 #train# step 7587, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:39.565484 #train# step 7588, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:41.142781 #train# step 7589, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:42.708150 #train# step 7590, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:44.299889 #train# step 7591, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:45.853052 #train# step 7592, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:47.436297 #train# step 7593, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:49.019982 #train# step 7594, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:50.581509 #train# step 7595, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:52.159228 #train# step 7596, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:53.726435 #train# step 7597, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:55.304143 #train# step 7598, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:56.859857 #train# step 7599, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:58.424473 #train# step 7600, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:10:59.964875 #train# step 7601, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:01.542527 #train# step 7602, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:03.110708 #train# step 7603, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:04.641604 #train# step 7604, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:06.248755 #train# step 7605, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:07.824726 #train# step 7606, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:09.390641 #train# step 7607, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:10.925003 #train# step 7608, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:12.503005 #train# step 7609, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:14.057199 #train# step 7610, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:15.613669 #train# step 7611, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:17.172834 #train# step 7612, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:18.733757 #train# step 7613, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:20.293022 #train# step 7614, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:21.841315 #train# step 7615, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:23.424819 #train# step 7616, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:24.958566 #train# step 7617, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:26.542619 #train# step 7618, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:28.081003 #train# step 7619, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:29.623375 #train# step 7620, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:31.176984 #train# step 7621, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:32.757530 #train# step 7622, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:34.324960 #train# step 7623, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:35.892278 #train# step 7624, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:37.489320 #train# step 7625, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:39.055392 #train# step 7626, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:40.612918 #train# step 7627, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:42.167042 #train# step 7628, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:43.738217 #train# step 7629, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:45.270442 #train# step 7630, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:46.844972 #train# step 7631, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:48.386555 #train# step 7632, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:49.958369 #train# step 7633, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:51.512485 #train# step 7634, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:53.091067 #train# step 7635, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:54.641163 #train# step 7636, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:56.165601 #train# step 7637, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:57.725012 #train# step 7638, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:11:59.311119 #train# step 7639, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:00.916659 #train# step 7640, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:02.460362 #train# step 7641, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:04.021812 #train# step 7642, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:05.577647 #train# step 7643, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:07.142751 #train# step 7644, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:08.677505 #train# step 7645, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:10.226371 #train# step 7646, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:11.786181 #train# step 7647, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:13.429269 #train# step 7648, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:15.001534 #train# step 7649, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:16.548056 #train# step 7650, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:18.078197 #train# step 7651, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:19.646382 #train# step 7652, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:21.221216 #train# step 7653, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:22.813046 #train# step 7654, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:24.412010 #train# step 7655, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:25.986596 #train# step 7656, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:27.575349 #train# step 7657, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:29.150105 #train# step 7658, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:30.705259 #train# step 7659, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:32.293903 #train# step 7660, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:33.844180 #train# step 7661, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:35.384289 #train# step 7662, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:36.896119 #train# step 7663, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:38.423837 #train# step 7664, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:39.976519 #train# step 7665, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:41.523505 #train# step 7666, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:43.081227 #train# step 7667, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:44.706861 #train# step 7668, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:46.263675 #train# step 7669, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:47.823905 #train# step 7670, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:49.362602 #train# step 7671, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:50.946849 #train# step 7672, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:52.487466 #train# step 7673, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:54.059505 #train# step 7674, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:55.583302 #train# step 7675, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:57.127112 #train# step 7676, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:12:58.672657 #train# step 7677, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:00.246252 #train# step 7678, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:01.785263 #train# step 7679, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:03.325926 #train# step 7680, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:04.878274 #train# step 7681, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:06.405232 #train# step 7682, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:07.942851 #train# step 7683, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:09.481005 #train# step 7684, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:11.061028 #train# step 7685, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:12.640135 #train# step 7686, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:14.186512 #train# step 7687, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:15.711590 #train# step 7688, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:17.248995 #train# step 7689, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:18.802570 #train# step 7690, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:20.355172 #train# step 7691, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:21.907202 #train# step 7692, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:23.484973 #train# step 7693, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:25.029970 #train# step 7694, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:26.579518 #train# step 7695, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:28.119049 #train# step 7696, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:29.645648 #train# step 7697, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:31.182167 #train# step 7698, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:32.743880 #train# step 7699, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:34.310885 #train# step 7700, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:35.897643 #train# step 7701, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:37.420308 #train# step 7702, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:38.970178 #train# step 7703, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:40.522516 #train# step 7704, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:42.112386 #train# step 7705, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:43.641626 #train# step 7706, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:45.171061 #train# step 7707, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:46.731883 #train# step 7708, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:48.275470 #train# step 7709, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:49.786734 #train# step 7710, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:51.337224 #train# step 7711, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:52.898597 #train# step 7712, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:54.449023 #train# step 7713, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:56.004749 #train# step 7714, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:57.519284 #train# step 7715, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:13:59.063538 #train# step 7716, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:00.641085 #train# step 7717, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:02.177021 #train# step 7718, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:03.727035 #train# step 7719, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:05.269387 #train# step 7720, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:06.822696 #train# step 7721, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:08.384320 #train# step 7722, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:09.924134 #train# step 7723, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:11.503594 #train# step 7724, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:13.055110 #train# step 7725, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:14.629822 #train# step 7726, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:16.195609 #train# step 7727, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:17.744194 #train# step 7728, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:19.327142 #train# step 7729, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:20.880281 #train# step 7730, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:22.474641 #train# step 7731, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:24.027413 #train# step 7732, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:25.576676 #train# step 7733, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:27.096341 #train# step 7734, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:28.674364 #train# step 7735, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:30.223175 #train# step 7736, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:31.757682 #train# step 7737, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:33.281066 #train# step 7738, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:34.841124 #train# step 7739, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:36.384489 #train# step 7740, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:37.916568 #train# step 7741, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:39.477178 #train# step 7742, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:40.999483 #train# step 7743, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:42.569695 #train# step 7744, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:44.103741 #train# step 7745, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:45.653251 #train# step 7746, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:47.207687 #train# step 7747, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:48.760309 #train# step 7748, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:50.276399 #train# step 7749, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:51.802000 #train# step 7750, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:53.367876 #train# step 7751, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:54.897550 #train# step 7752, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:56.449556 #train# step 7753, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:58.009482 #train# step 7754, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:14:59.543426 #train# step 7755, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:01.115920 #train# step 7756, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:02.661475 #train# step 7757, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:04.216366 #train# step 7758, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:05.763229 #train# step 7759, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:07.279112 #train# step 7760, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:08.822837 #train# step 7761, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:10.355852 #train# step 7762, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:11.909748 #train# step 7763, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:13.465180 #train# step 7764, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:15.020832 #train# step 7765, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:16.593197 #train# step 7766, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:18.136689 #train# step 7767, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:19.669893 #train# step 7768, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:21.218401 #train# step 7769, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:22.737273 #train# step 7770, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:24.270736 #train# step 7771, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:25.810938 #train# step 7772, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:27.385950 #train# step 7773, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:28.929253 #train# step 7774, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:30.484200 #train# step 7775, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:32.065106 #train# step 7776, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:33.605569 #train# step 7777, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:35.170201 #train# step 7778, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:36.742118 #train# step 7779, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:38.288201 #train# step 7780, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:39.838642 #train# step 7781, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:41.411639 #train# step 7782, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:42.970973 #train# step 7783, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:44.515878 #train# step 7784, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:46.067900 #train# step 7785, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:47.653925 #train# step 7786, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:49.208439 #train# step 7787, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:50.760147 #train# step 7788, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:52.302512 #train# step 7789, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:53.844034 #train# step 7790, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:55.374232 #train# step 7791, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:56.911118 #train# step 7792, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:58.461353 #train# step 7793, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:15:59.972273 #train# step 7794, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:01.528602 #train# step 7795, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:03.082916 #train# step 7796, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:04.639996 #train# step 7797, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:06.180999 #train# step 7798, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:07.696284 #train# step 7799, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:09.272015 #train# step 7800, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:10.822339 #train# step 7801, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:12.402646 #train# step 7802, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:14.012932 #train# step 7803, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:15.551590 #train# step 7804, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:17.130847 #train# step 7805, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:18.658631 #train# step 7806, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:20.217408 #train# step 7807, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:21.761197 #train# step 7808, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:23.278814 #train# step 7809, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:24.826599 #train# step 7810, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:26.374737 #train# step 7811, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:27.920387 #train# step 7812, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:29.507374 #train# step 7813, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:31.071366 #train# step 7814, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:32.629846 #train# step 7815, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:34.134868 #train# step 7816, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:35.704408 #train# step 7817, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:37.245704 #train# step 7818, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:38.779952 #train# step 7819, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:40.302937 #train# step 7820, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:41.837414 #train# step 7821, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:43.399581 #train# step 7822, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:44.943225 #train# step 7823, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:46.478563 #train# step 7824, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:48.030638 #train# step 7825, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:49.581275 #train# step 7826, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:51.134597 #train# step 7827, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:52.700254 #train# step 7828, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:54.235618 #train# step 7829, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:55.787088 #train# step 7830, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:57.322689 #train# step 7831, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:16:58.890584 #train# step 7832, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:00.438162 #train# step 7833, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:02.013131 #train# step 7834, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:03.534990 #train# step 7835, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:05.059214 #train# step 7836, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:06.634317 #train# step 7837, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:08.186290 #train# step 7838, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:09.739111 #train# step 7839, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:11.308166 #train# step 7840, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:12.859116 #train# step 7841, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:14.423551 #train# step 7842, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:15.967453 #train# step 7843, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:17.503390 #train# step 7844, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:19.058539 #train# step 7845, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:20.616510 #train# step 7846, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:22.175183 #train# step 7847, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:23.703815 #train# step 7848, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:25.255922 #train# step 7849, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:26.790178 #train# step 7850, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:28.320771 #train# step 7851, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:29.875387 #train# step 7852, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:31.408966 #train# step 7853, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:32.931430 #train# step 7854, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:34.488818 #train# step 7855, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:36.032739 #train# step 7856, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:37.587238 #train# step 7857, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:39.137967 #train# step 7858, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:40.681586 #train# step 7859, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:42.250924 #train# step 7860, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:43.787550 #train# step 7861, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:45.358787 #train# step 7862, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:46.896392 #train# step 7863, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:48.431453 #train# step 7864, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:49.961806 #train# step 7865, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:51.514340 #train# step 7866, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:53.035924 #train# step 7867, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:54.575198 #train# step 7868, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:56.131976 #train# step 7869, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:57.706082 #train# step 7870, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:17:59.246316 #train# step 7871, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:00.785475 #train# step 7872, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:02.324070 #train# step 7873, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:03.885401 #train# step 7874, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:05.449654 #train# step 7875, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:07.017589 #train# step 7876, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:08.586885 #train# step 7877, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:10.110041 #train# step 7878, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:11.653659 #train# step 7879, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:13.232707 #train# step 7880, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:14.759095 #train# step 7881, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:16.317964 #train# step 7882, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:17.870725 #train# step 7883, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:19.415205 #train# step 7884, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:20.971645 #train# step 7885, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:22.524372 #train# step 7886, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:24.069669 #train# step 7887, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:25.625890 #train# step 7888, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:27.155443 #train# step 7889, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:28.699527 #train# step 7890, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:30.239930 #train# step 7891, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:31.810173 #train# step 7892, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:33.347550 #train# step 7893, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:34.916548 #train# step 7894, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:36.468478 #train# step 7895, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:38.021152 #train# step 7896, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:39.596232 #train# step 7897, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:41.156882 #train# step 7898, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:42.708187 #train# step 7899, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:44.236560 #train# step 7900, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:45.793177 #train# step 7901, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:47.351828 #train# step 7902, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:48.908304 #train# step 7903, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:50.509856 #train# step 7904, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:52.071636 #train# step 7905, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:53.663374 #train# step 7906, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:55.205166 #train# step 7907, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:56.922792 #train# step 7908, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:18:58.579698 #train# step 7909, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:00.123923 #train# step 7910, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:01.754446 #train# step 7911, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:03.376863 #train# step 7912, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:04.919419 #train# step 7913, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:06.493701 #train# step 7914, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:08.044487 #train# step 7915, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:09.613197 #train# step 7916, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:11.137539 #train# step 7917, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:12.751548 #train# step 7918, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:14.305511 #train# step 7919, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:15.819719 #train# step 7920, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:17.359072 #train# step 7921, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:18.883886 #train# step 7922, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:20.441711 #train# step 7923, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:21.999561 #train# step 7924, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:23.532215 #train# step 7925, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:25.076160 #train# step 7926, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:26.605076 #train# step 7927, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:28.150911 #train# step 7928, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:29.687019 #train# step 7929, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:31.241919 #train# step 7930, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:32.765287 #train# step 7931, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:34.317024 #train# step 7932, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:35.895614 #train# step 7933, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:37.479378 #train# step 7934, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:39.011633 #train# step 7935, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:40.593586 #train# step 7936, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:42.151981 #train# step 7937, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:43.678138 #train# step 7938, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:45.253320 #train# step 7939, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:46.787534 #train# step 7940, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:48.344014 #train# step 7941, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:49.898588 #train# step 7942, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:51.480966 #train# step 7943, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:53.014945 #train# step 7944, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:54.576751 #train# step 7945, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:56.124851 #train# step 7946, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:57.683865 #train# step 7947, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:19:59.243364 #train# step 7948, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:00.848147 #train# step 7949, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:02.377241 #train# step 7950, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:03.904450 #train# step 7951, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:05.424165 #train# step 7952, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:06.994994 #train# step 7953, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:08.530395 #train# step 7954, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:10.070626 #train# step 7955, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:11.609874 #train# step 7956, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:13.125384 #train# step 7957, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:14.716112 #train# step 7958, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:16.242334 #train# step 7959, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:17.794161 #train# step 7960, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:19.326243 #train# step 7961, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:20.877551 #train# step 7962, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:22.414329 #train# step 7963, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:23.963260 #train# step 7964, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:25.512630 #train# step 7965, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:27.046123 #train# step 7966, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:28.601000 #train# step 7967, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:30.155376 #train# step 7968, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:31.677926 #train# step 7969, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:33.278396 #train# step 7970, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:34.784141 #train# step 7971, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:36.341789 #train# step 7972, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:37.870117 #train# step 7973, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:39.427024 #train# step 7974, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:40.973538 #train# step 7975, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:42.513011 #train# step 7976, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:44.055433 #train# step 7977, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:45.642541 #train# step 7978, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:47.188247 #train# step 7979, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:48.723360 #train# step 7980, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:50.274986 #train# step 7981, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:51.794451 #train# step 7982, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:53.352342 #train# step 7983, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:54.948634 #train# step 7984, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:56.524952 #train# step 7985, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:58.121047 #train# step 7986, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:20:59.738893 #train# step 7987, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:01.353188 #train# step 7988, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:03.024655 #train# step 7989, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:04.624715 #train# step 7990, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:06.209121 #train# step 7991, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:07.758846 #train# step 7992, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:09.312907 #train# step 7993, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:10.883776 #train# step 7994, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:12.405206 #train# step 7995, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:14.010920 #train# step 7996, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:15.561159 #train# step 7997, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:17.096291 #train# step 7998, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:18.642727 #train# step 7999, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:20.200192 #train# step 8000, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:21.804029 #train# step 8001, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:23.356706 #train# step 8002, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:24.881811 #train# step 8003, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:26.434210 #train# step 8004, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:27.952153 #train# step 8005, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:29.500515 #train# step 8006, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:31.097495 #train# step 8007, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:32.701480 #train# step 8008, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:34.312551 #train# step 8009, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:35.954705 #train# step 8010, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:37.566590 #train# step 8011, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:39.245670 #train# step 8012, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:40.917976 #train# step 8013, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:42.506026 #train# step 8014, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:44.126759 #train# step 8015, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:45.741684 #train# step 8016, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:47.292790 #train# step 8017, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:48.874522 #train# step 8018, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:50.484849 #train# step 8019, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:52.060886 #train# step 8020, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:53.618757 #train# step 8021, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:55.116185 #train# step 8022, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:56.658119 #train# step 8023, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:58.205741 #train# step 8024, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:21:59.736789 #train# step 8025, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:01.302305 #train# step 8026, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:02.816872 #train# step 8027, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:04.344694 #train# step 8028, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:05.891223 #train# step 8029, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:07.426148 #train# step 8030, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:08.958607 #train# step 8031, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:10.486163 #train# step 8032, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:12.000891 #train# step 8033, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:13.535712 #train# step 8034, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:15.106668 #train# step 8035, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:16.623103 #train# step 8036, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:18.145176 #train# step 8037, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:19.665340 #train# step 8038, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:21.228122 #train# step 8039, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:22.753119 #train# step 8040, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:24.290882 #train# step 8041, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:25.829880 #train# step 8042, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:27.402508 #train# step 8043, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:28.944340 #train# step 8044, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:30.501701 #train# step 8045, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:32.080474 #train# step 8046, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:33.616606 #train# step 8047, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:35.162190 #train# step 8048, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:36.671485 #train# step 8049, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:38.212983 #train# step 8050, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:39.729057 #train# step 8051, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:41.310212 #train# step 8052, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:42.860803 #train# step 8053, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:44.421525 #train# step 8054, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:45.971749 #train# step 8055, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:47.513647 #train# step 8056, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:49.053313 #train# step 8057, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:50.604329 #train# step 8058, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:52.116242 #train# step 8059, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:53.650731 #train# step 8060, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:55.190748 #train# step 8061, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:56.748254 #train# step 8062, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:58.281057 #train# step 8063, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:22:59.791236 #train# step 8064, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:01.325137 #train# step 8065, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:02.850828 #train# step 8066, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:04.379821 #train# step 8067, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:05.925379 #train# step 8068, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:07.488438 #train# step 8069, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:09.036383 #train# step 8070, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:10.589410 #train# step 8071, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:12.141065 #train# step 8072, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:13.661553 #train# step 8073, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:15.217956 #train# step 8074, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:16.765131 #train# step 8075, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:18.276799 #train# step 8076, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:19.837781 #train# step 8077, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:21.363040 #train# step 8078, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:22.900269 #train# step 8079, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:24.462617 #train# step 8080, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:26.006339 #train# step 8081, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:27.532205 #train# step 8082, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:29.066931 #train# step 8083, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:30.636040 #train# step 8084, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:32.188478 #train# step 8085, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:33.709463 #train# step 8086, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:35.268925 #train# step 8087, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:36.811341 #train# step 8088, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:38.350576 #train# step 8089, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:39.882218 #train# step 8090, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:41.475330 #train# step 8091, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:43.015396 #train# step 8092, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:44.538936 #train# step 8093, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:46.061331 #train# step 8094, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:47.634934 #train# step 8095, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:49.204539 #train# step 8096, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:50.733792 #train# step 8097, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:52.283418 #train# step 8098, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:53.825168 #train# step 8099, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:55.375632 #train# step 8100, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:56.907267 #train# step 8101, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:23:58.477333 #train# step 8102, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:00.007696 #train# step 8103, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:01.519604 #train# step 8104, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:03.062938 #train# step 8105, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:04.603657 #train# step 8106, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:06.172219 #train# step 8107, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:07.688300 #train# step 8108, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:09.240617 #train# step 8109, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:10.752210 #train# step 8110, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:12.315744 #train# step 8111, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:13.873487 #train# step 8112, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:15.410979 #train# step 8113, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:16.944021 #train# step 8114, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:18.503993 #train# step 8115, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:20.055158 #train# step 8116, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:21.646071 #train# step 8117, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:23.191254 #train# step 8118, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:24.731173 #train# step 8119, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:26.277092 #train# step 8120, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:27.818630 #train# step 8121, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:29.363501 #train# step 8122, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:30.908102 #train# step 8123, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:32.436583 #train# step 8124, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:33.955758 #train# step 8125, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:35.483651 #train# step 8126, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:36.990886 #train# step 8127, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:38.526721 #train# step 8128, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:40.044661 #train# step 8129, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:41.595146 #train# step 8130, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:43.152389 #train# step 8131, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:44.693920 #train# step 8132, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:46.216264 #train# step 8133, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:47.812285 #train# step 8134, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:49.338655 #train# step 8135, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:50.889641 #train# step 8136, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:52.417867 #train# step 8137, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:53.972102 #train# step 8138, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:55.532654 #train# step 8139, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:57.059720 #train# step 8140, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:24:58.609911 #train# step 8141, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:00.137560 #train# step 8142, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:01.657801 #train# step 8143, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:03.191151 #train# step 8144, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:04.716891 #train# step 8145, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:06.226542 #train# step 8146, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:07.774808 #train# step 8147, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:09.294266 #train# step 8148, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:10.857468 #train# step 8149, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:12.385049 #train# step 8150, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:13.932138 #train# step 8151, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:15.486916 #train# step 8152, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:17.019444 #train# step 8153, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:18.550830 #train# step 8154, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:20.085285 #train# step 8155, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:21.624843 #train# step 8156, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:23.156256 #train# step 8157, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:24.707959 #train# step 8158, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:26.245846 #train# step 8159, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:27.798160 #train# step 8160, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:29.362237 #train# step 8161, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:30.921856 #train# step 8162, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:32.468765 #train# step 8163, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:34.001874 #train# step 8164, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:35.535550 #train# step 8165, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:37.025859 #train# step 8166, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:38.545258 #train# step 8167, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:40.117269 #train# step 8168, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:41.662786 #train# step 8169, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:43.166229 #train# step 8170, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:44.706721 #train# step 8171, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:46.255226 #train# step 8172, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:47.819459 #train# step 8173, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:49.345131 #train# step 8174, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:50.875164 #train# step 8175, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:52.435581 #train# step 8176, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:53.986134 #train# step 8177, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:55.554189 #train# step 8178, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:57.102219 #train# step 8179, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:25:58.645687 #train# step 8180, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:00.199500 #train# step 8181, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:01.771304 #train# step 8182, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:03.279713 #train# step 8183, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:04.806742 #train# step 8184, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:06.329695 #train# step 8185, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:07.880666 #train# step 8186, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:09.416779 #train# step 8187, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:10.978012 #train# step 8188, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:12.520975 #train# step 8189, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:14.089433 #train# step 8190, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:15.626691 #train# step 8191, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:17.164022 #train# step 8192, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:18.697283 #train# step 8193, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:20.204211 #train# step 8194, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:21.743904 #train# step 8195, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:23.288316 #train# step 8196, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:24.814810 #train# step 8197, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:26.346182 #train# step 8198, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:27.871798 #train# step 8199, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:29.406218 #train# step 8200, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:30.944817 #train# step 8201, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:32.492006 #train# step 8202, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:34.046551 #train# step 8203, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:35.622582 #train# step 8204, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:37.177566 #train# step 8205, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:38.742004 #train# step 8206, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:40.263303 #train# step 8207, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:41.786478 #train# step 8208, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:43.299341 #train# step 8209, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:44.844338 #train# step 8210, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:46.376181 #train# step 8211, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:47.920214 #train# step 8212, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:49.441016 #train# step 8213, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:51.006497 #train# step 8214, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:52.570880 #train# step 8215, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:54.113683 #train# step 8216, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:55.652798 #train# step 8217, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:57.233879 #train# step 8218, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:26:58.771059 #train# step 8219, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:00.303675 #train# step 8220, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:01.840878 #train# step 8221, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:03.387922 #train# step 8222, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:04.914071 #train# step 8223, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:06.443090 #train# step 8224, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:07.988698 #train# step 8225, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:09.536296 #train# step 8226, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:11.137318 #train# step 8227, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:12.664344 #train# step 8228, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:14.203198 #train# step 8229, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:15.738930 #train# step 8230, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:17.268405 #train# step 8231, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:18.841727 #train# step 8232, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:20.369756 #train# step 8233, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:21.906839 #train# step 8234, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:23.443917 #train# step 8235, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:24.983619 #train# step 8236, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:26.512991 #train# step 8237, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:28.025604 #train# step 8238, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:29.561740 #train# step 8239, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:31.090627 #train# step 8240, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:32.605452 #train# step 8241, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:34.141237 #train# step 8242, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:35.664938 #train# step 8243, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:37.202202 #train# step 8244, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:38.755231 #train# step 8245, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:40.268272 #train# step 8246, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:41.843597 #train# step 8247, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:43.393014 #train# step 8248, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:44.916294 #train# step 8249, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:46.459468 #train# step 8250, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:47.997175 #train# step 8251, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:49.560265 #train# step 8252, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:51.138735 #train# step 8253, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:52.701941 #train# step 8254, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:54.252997 #train# step 8255, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:55.791635 #train# step 8256, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:57.333387 #train# step 8257, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:27:58.864941 #train# step 8258, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:00.415461 #train# step 8259, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:01.973093 #train# step 8260, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:03.496155 #train# step 8261, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:05.013529 #train# step 8262, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:06.536986 #train# step 8263, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:08.080686 #train# step 8264, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:09.618374 #train# step 8265, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:11.156257 #train# step 8266, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:12.684832 #train# step 8267, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:14.212573 #train# step 8268, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:15.788602 #train# step 8269, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:17.296942 #train# step 8270, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:18.851987 #train# step 8271, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:20.397491 #train# step 8272, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:21.907316 #train# step 8273, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:23.442717 #train# step 8274, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:24.980284 #train# step 8275, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:26.532875 #train# step 8276, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:28.088880 #train# step 8277, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:29.640865 #train# step 8278, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:31.197930 #train# step 8279, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:32.736239 #train# step 8280, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:34.246296 #train# step 8281, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:35.762137 #train# step 8282, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:37.295193 #train# step 8283, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:38.837237 #train# step 8284, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:40.370546 #train# step 8285, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:41.871857 #train# step 8286, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:43.438460 #train# step 8287, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:44.958028 #train# step 8288, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:46.518174 #train# step 8289, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:48.063294 #train# step 8290, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:49.569209 #train# step 8291, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:51.135857 #train# step 8292, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:52.738982 #train# step 8293, loss = 0.8874, cross_entropy loss = 0.8874, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:54.276973 #train# step 8294, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:55.851213 #train# step 8295, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:57.366561 #train# step 8296, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:28:58.893776 #train# step 8297, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:00.426020 #train# step 8298, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:01.992589 #train# step 8299, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:03.519457 #train# step 8300, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:05.062504 #train# step 8301, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:06.601572 #train# step 8302, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:08.143455 #train# step 8303, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:09.691231 #train# step 8304, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:11.233699 #train# step 8305, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:12.786416 #train# step 8306, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:14.303402 #train# step 8307, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:15.833022 #train# step 8308, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:17.418204 #train# step 8309, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:18.972666 #train# step 8310, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:20.501810 #train# step 8311, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:22.050744 #train# step 8312, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:23.600899 #train# step 8313, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:25.133540 #train# step 8314, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:26.667444 #train# step 8315, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:28.223624 #train# step 8316, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:29.783666 #train# step 8317, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:31.347190 #train# step 8318, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:32.945170 #train# step 8319, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:34.527387 #train# step 8320, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:36.081604 #train# step 8321, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:37.621473 #train# step 8322, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:39.187375 #train# step 8323, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:40.720351 #train# step 8324, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:42.275146 #train# step 8325, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:43.865516 #train# step 8326, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:45.398890 #train# step 8327, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:46.946238 #train# step 8328, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:48.454846 #train# step 8329, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:49.940326 #train# step 8330, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:51.462778 #train# step 8331, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:52.979052 #train# step 8332, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:54.526888 #train# step 8333, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:56.082650 #train# step 8334, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:57.618518 #train# step 8335, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:29:59.184370 #train# step 8336, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:00.723887 #train# step 8337, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:02.262448 #train# step 8338, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:03.785882 #train# step 8339, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:05.330773 #train# step 8340, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:06.892566 #train# step 8341, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:08.427707 #train# step 8342, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:09.968223 #train# step 8343, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:11.523616 #train# step 8344, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:13.106353 #train# step 8345, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:14.630509 #train# step 8346, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:16.155599 #train# step 8347, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:17.691762 #train# step 8348, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:19.216457 #train# step 8349, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:20.730292 #train# step 8350, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:22.276074 #train# step 8351, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:23.823156 #train# step 8352, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:25.354784 #train# step 8353, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:26.903214 #train# step 8354, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:28.463020 #train# step 8355, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:29.995133 #train# step 8356, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:31.548163 #train# step 8357, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:33.095034 #train# step 8358, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:34.651836 #train# step 8359, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:36.196703 #train# step 8360, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:37.709111 #train# step 8361, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:39.258119 #train# step 8362, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:40.802677 #train# step 8363, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:42.305469 #train# step 8364, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:43.856369 #train# step 8365, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:45.388026 #train# step 8366, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:46.900668 #train# step 8367, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:48.451388 #train# step 8368, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:49.996339 #train# step 8369, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:51.539294 #train# step 8370, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:53.098283 #train# step 8371, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:54.621240 #train# step 8372, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:56.160671 #train# step 8373, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:57.719824 #train# step 8374, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:30:59.273226 #train# step 8375, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:00.783779 #train# step 8376, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:02.312349 #train# step 8377, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:03.844665 #train# step 8378, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:05.365266 #train# step 8379, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:06.885891 #train# step 8380, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:08.438868 #train# step 8381, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:09.958180 #train# step 8382, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:11.488152 #train# step 8383, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:13.011846 #train# step 8384, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:14.560114 #train# step 8385, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:16.120142 #train# step 8386, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:17.643646 #train# step 8387, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:19.194340 #train# step 8388, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:20.711989 #train# step 8389, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:22.266243 #train# step 8390, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:23.822819 #train# step 8391, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:25.387965 #train# step 8392, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:26.951587 #train# step 8393, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:28.503485 #train# step 8394, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:30.022291 #train# step 8395, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:31.592893 #train# step 8396, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:33.128203 #train# step 8397, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:34.718973 #train# step 8398, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:36.274485 #train# step 8399, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:37.826806 #train# step 8400, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:39.357082 #train# step 8401, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:40.944326 #train# step 8402, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:42.469801 #train# step 8403, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:43.998505 #train# step 8404, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:45.560799 #train# step 8405, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:47.109320 #train# step 8406, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:48.652996 #train# step 8407, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:50.183175 #train# step 8408, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:51.684450 #train# step 8409, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:53.219695 #train# step 8410, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:54.759745 #train# step 8411, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:56.318579 #train# step 8412, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:57.830394 #train# step 8413, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:31:59.399345 #train# step 8414, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:00.951559 #train# step 8415, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:02.493070 #train# step 8416, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:04.044339 #train# step 8417, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:05.617946 #train# step 8418, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:07.188621 #train# step 8419, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:08.750714 #train# step 8420, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:10.267469 #train# step 8421, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:11.801350 #train# step 8422, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:13.330366 #train# step 8423, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:14.897890 #train# step 8424, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:16.430721 #train# step 8425, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:17.950745 #train# step 8426, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:19.473873 #train# step 8427, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:20.987966 #train# step 8428, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:22.505204 #train# step 8429, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:24.044295 #train# step 8430, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:25.586821 #train# step 8431, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:27.143021 #train# step 8432, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:28.690154 #train# step 8433, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:30.263477 #train# step 8434, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:31.805774 #train# step 8435, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:33.315273 #train# step 8436, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:34.823775 #train# step 8437, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:36.361998 #train# step 8438, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:37.909903 #train# step 8439, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:39.473277 #train# step 8440, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:40.993607 #train# step 8441, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:42.564706 #train# step 8442, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:44.102312 #train# step 8443, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:45.670337 #train# step 8444, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:47.239496 #train# step 8445, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:48.796326 #train# step 8446, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:50.310808 #train# step 8447, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:51.825596 #train# step 8448, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:53.372914 #train# step 8449, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:54.905294 #train# step 8450, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:56.468059 #train# step 8451, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:57.980667 #train# step 8452, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:32:59.548295 #train# step 8453, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:01.078763 #train# step 8454, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:02.651406 #train# step 8455, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:04.200160 #train# step 8456, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:05.751692 #train# step 8457, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:07.304787 #train# step 8458, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:08.842651 #train# step 8459, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:10.360944 #train# step 8460, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:11.864193 #train# step 8461, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:13.405019 #train# step 8462, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:14.970400 #train# step 8463, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:16.499935 #train# step 8464, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:18.055112 #train# step 8465, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:19.595145 #train# step 8466, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:21.131968 #train# step 8467, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:22.693290 #train# step 8468, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:24.222706 #train# step 8469, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:25.770723 #train# step 8470, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:27.294341 #train# step 8471, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:28.859857 #train# step 8472, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:30.408831 #train# step 8473, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:31.932296 #train# step 8474, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:33.467984 #train# step 8475, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:34.993988 #train# step 8476, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:36.522637 #train# step 8477, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:38.030474 #train# step 8478, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:39.595048 #train# step 8479, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:41.084073 #train# step 8480, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:42.623835 #train# step 8481, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:44.180130 #train# step 8482, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:45.695015 #train# step 8483, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:47.255681 #train# step 8484, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:48.790893 #train# step 8485, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:50.332989 #train# step 8486, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:51.877124 #train# step 8487, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:53.427791 #train# step 8488, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:54.981057 #train# step 8489, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:56.509159 #train# step 8490, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:58.039859 #train# step 8491, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:33:59.583593 #train# step 8492, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:01.101950 #train# step 8493, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:02.626412 #train# step 8494, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:04.171680 #train# step 8495, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:05.732628 #train# step 8496, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:07.287760 #train# step 8497, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:08.824659 #train# step 8498, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:10.356639 #train# step 8499, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:11.920596 #train# step 8500, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:13.484664 #train# step 8501, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:15.012503 #train# step 8502, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:16.556808 #train# step 8503, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:18.109655 #train# step 8504, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:19.681782 #train# step 8505, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:21.234923 #train# step 8506, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:22.771985 #train# step 8507, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:24.305161 #train# step 8508, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:25.792690 #train# step 8509, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:27.309571 #train# step 8510, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:28.856990 #train# step 8511, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:30.399783 #train# step 8512, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:31.938859 #train# step 8513, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:33.476272 #train# step 8514, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:35.001337 #train# step 8515, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:36.533689 #train# step 8516, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:38.080046 #train# step 8517, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:39.621695 #train# step 8518, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:41.176941 #train# step 8519, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:42.724096 #train# step 8520, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:44.261199 #train# step 8521, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:45.821814 #train# step 8522, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:47.333398 #train# step 8523, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:48.860578 #train# step 8524, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:50.373669 #train# step 8525, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:51.929476 #train# step 8526, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:53.466562 #train# step 8527, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:55.025034 #train# step 8528, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:56.551677 #train# step 8529, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:58.112059 #train# step 8530, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:34:59.662976 #train# step 8531, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:01.218531 #train# step 8532, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:02.761122 #train# step 8533, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:04.317124 #train# step 8534, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:05.834916 #train# step 8535, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:07.378298 #train# step 8536, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:08.911274 #train# step 8537, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:10.464227 #train# step 8538, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:11.984707 #train# step 8539, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:13.527807 #train# step 8540, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:15.075428 #train# step 8541, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:16.628991 #train# step 8542, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:18.181112 #train# step 8543, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:19.722734 #train# step 8544, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:21.264037 #train# step 8545, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:22.791459 #train# step 8546, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:24.348547 #train# step 8547, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:25.888460 #train# step 8548, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:27.458339 #train# step 8549, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:29.004393 #train# step 8550, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:30.577618 #train# step 8551, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:32.092421 #train# step 8552, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:33.651361 #train# step 8553, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:35.200197 #train# step 8554, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:36.742997 #train# step 8555, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:38.268021 #train# step 8556, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:39.823595 #train# step 8557, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:41.365163 #train# step 8558, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:42.903261 #train# step 8559, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:44.409674 #train# step 8560, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:45.915267 #train# step 8561, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:47.462736 #train# step 8562, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:49.018868 #train# step 8563, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:50.579925 #train# step 8564, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:52.126922 #train# step 8565, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:53.645568 #train# step 8566, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:55.187547 #train# step 8567, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:56.721497 #train# step 8568, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:58.245201 #train# step 8569, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:35:59.781629 #train# step 8570, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:01.324121 #train# step 8571, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:02.852303 #train# step 8572, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:04.424572 #train# step 8573, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:05.949713 #train# step 8574, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:07.484402 #train# step 8575, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:08.988709 #train# step 8576, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:10.541767 #train# step 8577, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:12.063330 #train# step 8578, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:13.641031 #train# step 8579, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:15.162764 #train# step 8580, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:16.670436 #train# step 8581, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:18.225709 #train# step 8582, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:19.764578 #train# step 8583, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:21.315129 #train# step 8584, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:22.870597 #train# step 8585, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:24.412953 #train# step 8586, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:25.950564 #train# step 8587, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:27.490343 #train# step 8588, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:29.093584 #train# step 8589, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:30.657002 #train# step 8590, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:32.224962 #train# step 8591, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:33.755082 #train# step 8592, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:35.291559 #train# step 8593, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:36.822517 #train# step 8594, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:38.353033 #train# step 8595, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:39.921968 #train# step 8596, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:41.467377 #train# step 8597, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:42.971297 #train# step 8598, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:44.524202 #train# step 8599, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:46.063886 #train# step 8600, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:47.609378 #train# step 8601, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:49.164187 #train# step 8602, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:50.689988 #train# step 8603, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:52.258362 #train# step 8604, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:53.842881 #train# step 8605, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:55.354555 #train# step 8606, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:56.926642 #train# step 8607, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:36:58.488191 #train# step 8608, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:00.021576 #train# step 8609, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:01.559345 #train# step 8610, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:03.112356 #train# step 8611, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:04.615412 #train# step 8612, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:06.132452 #train# step 8613, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:07.684155 #train# step 8614, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:09.234491 #train# step 8615, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:10.807179 #train# step 8616, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:12.322558 #train# step 8617, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:13.877924 #train# step 8618, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:15.450775 #train# step 8619, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:17.000850 #train# step 8620, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:18.544285 #train# step 8621, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:20.062038 #train# step 8622, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:21.568115 #train# step 8623, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:23.064810 #train# step 8624, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:24.618983 #train# step 8625, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:26.163163 #train# step 8626, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:27.698931 #train# step 8627, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:29.201103 #train# step 8628, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:30.718107 #train# step 8629, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:32.235175 #train# step 8630, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:33.783821 #train# step 8631, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:35.360933 #train# step 8632, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:36.927950 #train# step 8633, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:38.454031 #train# step 8634, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:39.980358 #train# step 8635, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:41.525005 #train# step 8636, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:43.074569 #train# step 8637, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:44.636270 #train# step 8638, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:46.223626 #train# step 8639, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:47.759458 #train# step 8640, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:49.282632 #train# step 8641, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:50.817208 #train# step 8642, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:52.364698 #train# step 8643, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:53.894040 #train# step 8644, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:55.424727 #train# step 8645, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:56.984997 #train# step 8646, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:37:58.541301 #train# step 8647, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:00.087105 #train# step 8648, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:01.649059 #train# step 8649, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:03.187989 #train# step 8650, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:04.714110 #train# step 8651, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:06.263823 #train# step 8652, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:07.814460 #train# step 8653, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:09.391010 #train# step 8654, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:10.933624 #train# step 8655, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:12.474940 #train# step 8656, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:14.012680 #train# step 8657, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:15.568843 #train# step 8658, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:17.086381 #train# step 8659, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:18.641103 #train# step 8660, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:20.186586 #train# step 8661, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:21.737254 #train# step 8662, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:23.286654 #train# step 8663, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:24.801772 #train# step 8664, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:26.330972 #train# step 8665, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:27.872389 #train# step 8666, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:29.436677 #train# step 8667, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:30.933273 #train# step 8668, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:32.472905 #train# step 8669, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:34.007269 #train# step 8670, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:35.548601 #train# step 8671, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:37.072142 #train# step 8672, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:38.624176 #train# step 8673, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:40.157252 #train# step 8674, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:41.688314 #train# step 8675, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:43.213159 #train# step 8676, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:44.733776 #train# step 8677, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:46.322034 #train# step 8678, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:47.886853 #train# step 8679, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:49.395443 #train# step 8680, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:50.949240 #train# step 8681, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:52.512133 #train# step 8682, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:54.073818 #train# step 8683, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:55.621806 #train# step 8684, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:57.170000 #train# step 8685, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:38:58.688400 #train# step 8686, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:00.268872 #train# step 8687, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:01.827571 #train# step 8688, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:03.367120 #train# step 8689, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:04.902601 #train# step 8690, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:06.440505 #train# step 8691, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:07.984911 #train# step 8692, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:09.548319 #train# step 8693, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:11.118132 #train# step 8694, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:12.622979 #train# step 8695, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:14.172272 #train# step 8696, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:15.718037 #train# step 8697, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:17.282074 #train# step 8698, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:18.822809 #train# step 8699, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:20.386197 #train# step 8700, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:21.946789 #train# step 8701, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:23.496117 #train# step 8702, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:25.043701 #train# step 8703, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:26.571806 #train# step 8704, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:28.132892 #train# step 8705, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:29.690432 #train# step 8706, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:31.235107 #train# step 8707, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:32.766903 #train# step 8708, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:34.335707 #train# step 8709, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:35.908180 #train# step 8710, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:37.449023 #train# step 8711, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:39.023339 #train# step 8712, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:40.565812 #train# step 8713, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:42.105779 #train# step 8714, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:43.660830 #train# step 8715, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:45.211995 #train# step 8716, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:46.799753 #train# step 8717, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:48.344402 #train# step 8718, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:49.911261 #train# step 8719, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:51.453478 #train# step 8720, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:52.977532 #train# step 8721, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:54.504505 #train# step 8722, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:56.051817 #train# step 8723, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:57.606261 #train# step 8724, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:39:59.131499 #train# step 8725, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:00.659960 #train# step 8726, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:02.166909 #train# step 8727, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:03.686531 #train# step 8728, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:05.208974 #train# step 8729, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:06.732979 #train# step 8730, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:08.289390 #train# step 8731, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:09.807599 #train# step 8732, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:11.335037 #train# step 8733, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:12.859890 #train# step 8734, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:14.397705 #train# step 8735, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:15.942550 #train# step 8736, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:17.444871 #train# step 8737, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:18.989195 #train# step 8738, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:20.537865 #train# step 8739, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:22.070761 #train# step 8740, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:23.584215 #train# step 8741, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:25.110310 #train# step 8742, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:26.671425 #train# step 8743, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:28.219129 #train# step 8744, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:29.745891 #train# step 8745, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:31.284443 #train# step 8746, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:32.840315 #train# step 8747, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:34.376548 #train# step 8748, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:35.945843 #train# step 8749, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:37.432273 #train# step 8750, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:38.955148 #train# step 8751, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:40.476815 #train# step 8752, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:42.023836 #train# step 8753, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:43.581411 #train# step 8754, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:45.121375 #train# step 8755, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:46.662436 #train# step 8756, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:48.201861 #train# step 8757, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:49.779061 #train# step 8758, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:51.354304 #train# step 8759, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:52.925035 #train# step 8760, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:54.476030 #train# step 8761, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:56.029657 #train# step 8762, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:57.537283 #train# step 8763, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:40:59.117414 #train# step 8764, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:00.663399 #train# step 8765, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:02.207626 #train# step 8766, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:03.706438 #train# step 8767, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:05.255011 #train# step 8768, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:06.816742 #train# step 8769, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:08.354629 #train# step 8770, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:09.922609 #train# step 8771, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:11.433490 #train# step 8772, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:12.972256 #train# step 8773, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:14.552387 #train# step 8774, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:16.094557 #train# step 8775, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:17.629657 #train# step 8776, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:19.155247 #train# step 8777, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:20.684500 #train# step 8778, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:22.235447 #train# step 8779, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:23.767772 #train# step 8780, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:25.307531 #train# step 8781, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:26.822148 #train# step 8782, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:28.362772 #train# step 8783, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:29.898524 #train# step 8784, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:31.430740 #train# step 8785, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:32.982988 #train# step 8786, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:34.524717 #train# step 8787, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:36.068405 #train# step 8788, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:37.625592 #train# step 8789, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:39.172438 #train# step 8790, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:40.742030 #train# step 8791, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:42.260274 #train# step 8792, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:43.797215 #train# step 8793, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:45.345516 #train# step 8794, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:46.919211 #train# step 8795, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:48.487364 #train# step 8796, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:50.050605 #train# step 8797, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:51.597747 #train# step 8798, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:53.115046 #train# step 8799, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:54.663099 #train# step 8800, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:56.184668 #train# step 8801, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:57.713399 #train# step 8802, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:41:59.266188 #train# step 8803, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:00.814205 #train# step 8804, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:02.363701 #train# step 8805, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:03.955192 #train# step 8806, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:05.480829 #train# step 8807, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:07.041638 #train# step 8808, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:08.592790 #train# step 8809, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:10.130695 #train# step 8810, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:11.682000 #train# step 8811, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:13.221211 #train# step 8812, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:14.759826 #train# step 8813, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:16.301250 #train# step 8814, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:17.825255 #train# step 8815, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:19.363974 #train# step 8816, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:20.905641 #train# step 8817, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:22.437265 #train# step 8818, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:23.995964 #train# step 8819, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:25.521800 #train# step 8820, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:27.071286 #train# step 8821, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:28.631413 #train# step 8822, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:30.166306 #train# step 8823, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:31.720979 #train# step 8824, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:33.248769 #train# step 8825, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:34.800644 #train# step 8826, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:36.345888 #train# step 8827, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:37.863361 #train# step 8828, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:39.416349 #train# step 8829, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:40.939551 #train# step 8830, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:42.503307 #train# step 8831, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:44.030448 #train# step 8832, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:45.565356 #train# step 8833, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:47.105914 #train# step 8834, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:48.644737 #train# step 8835, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:50.190671 #train# step 8836, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:51.741269 #train# step 8837, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:53.295710 #train# step 8838, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:54.847988 #train# step 8839, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:56.381149 #train# step 8840, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:57.933067 #train# step 8841, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:42:59.466266 #train# step 8842, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:01.021211 #train# step 8843, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:02.572007 #train# step 8844, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:04.116823 #train# step 8845, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:05.667745 #train# step 8846, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:07.233732 #train# step 8847, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:08.770674 #train# step 8848, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:10.315181 #train# step 8849, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:11.873240 #train# step 8850, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:13.406403 #train# step 8851, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:14.921691 #train# step 8852, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:16.453056 #train# step 8853, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:17.967088 #train# step 8854, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:19.468367 #train# step 8855, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:21.021776 #train# step 8856, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:22.549367 #train# step 8857, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:24.074485 #train# step 8858, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:25.601126 #train# step 8859, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:27.150585 #train# step 8860, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:28.710768 #train# step 8861, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:30.265343 #train# step 8862, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:31.809091 #train# step 8863, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:33.323909 #train# step 8864, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:34.853430 #train# step 8865, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:36.389282 #train# step 8866, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:37.939932 #train# step 8867, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:39.507739 #train# step 8868, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:41.062373 #train# step 8869, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:42.587286 #train# step 8870, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:44.089657 #train# step 8871, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:45.633226 #train# step 8872, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:47.234850 #train# step 8873, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:48.767699 #train# step 8874, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:50.318136 #train# step 8875, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:51.882216 #train# step 8876, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:53.402799 #train# step 8877, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:54.952361 #train# step 8878, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:56.500066 #train# step 8879, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:58.039454 #train# step 8880, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:43:59.581186 #train# step 8881, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:01.131614 #train# step 8882, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:02.699145 #train# step 8883, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:04.241293 #train# step 8884, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:05.809775 #train# step 8885, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:07.337840 #train# step 8886, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:08.892417 #train# step 8887, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:10.467869 #train# step 8888, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:12.034552 #train# step 8889, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:13.561354 #train# step 8890, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:15.135563 #train# step 8891, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:16.690258 #train# step 8892, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:18.230167 #train# step 8893, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:19.760914 #train# step 8894, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:21.274570 #train# step 8895, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:22.808675 #train# step 8896, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:24.328512 #train# step 8897, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:25.849267 #train# step 8898, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:27.388865 #train# step 8899, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:28.963627 #train# step 8900, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:30.492447 #train# step 8901, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:32.023545 #train# step 8902, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:33.590948 #train# step 8903, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:35.102973 #train# step 8904, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:36.631574 #train# step 8905, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:38.205873 #train# step 8906, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:39.724195 #train# step 8907, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:41.284418 #train# step 8908, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:42.814656 #train# step 8909, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:44.393832 #train# step 8910, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:45.948588 #train# step 8911, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:47.498803 #train# step 8912, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:49.004941 #train# step 8913, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:50.554512 #train# step 8914, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:52.138414 #train# step 8915, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:53.674751 #train# step 8916, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:55.196976 #train# step 8917, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:56.748253 #train# step 8918, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:58.270638 #train# step 8919, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:44:59.839135 #train# step 8920, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:01.420923 #train# step 8921, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:02.969552 #train# step 8922, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:04.542118 #train# step 8923, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:06.094014 #train# step 8924, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:07.618497 #train# step 8925, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:09.199000 #train# step 8926, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:10.720796 #train# step 8927, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:12.251271 #train# step 8928, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:13.796905 #train# step 8929, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:15.295329 #train# step 8930, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:16.833909 #train# step 8931, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:18.374267 #train# step 8932, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:19.928897 #train# step 8933, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:21.445611 #train# step 8934, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:22.969290 #train# step 8935, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:24.521534 #train# step 8936, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:26.057414 #train# step 8937, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:27.611121 #train# step 8938, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:29.116108 #train# step 8939, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:30.668695 #train# step 8940, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:32.181731 #train# step 8941, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:33.734972 #train# step 8942, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:35.278956 #train# step 8943, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:36.819722 #train# step 8944, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:38.381234 #train# step 8945, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:39.913167 #train# step 8946, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:41.439907 #train# step 8947, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:42.971233 #train# step 8948, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:44.532727 #train# step 8949, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:46.090328 #train# step 8950, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:47.686445 #train# step 8951, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:49.229527 #train# step 8952, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:50.760675 #train# step 8953, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:52.290777 #train# step 8954, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:53.832481 #train# step 8955, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:55.382508 #train# step 8956, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:56.928786 #train# step 8957, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:58.426216 #train# step 8958, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:45:59.994489 #train# step 8959, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:01.540774 #train# step 8960, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:03.118386 #train# step 8961, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:04.642881 #train# step 8962, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:06.196950 #train# step 8963, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:07.791106 #train# step 8964, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:09.320593 #train# step 8965, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:10.873638 #train# step 8966, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:12.456803 #train# step 8967, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:14.000847 #train# step 8968, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:15.559935 #train# step 8969, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:17.032069 #train# step 8970, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:18.572478 #train# step 8971, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:20.105850 #train# step 8972, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:21.650899 #train# step 8973, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:23.215102 #train# step 8974, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:24.747367 #train# step 8975, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:26.268723 #train# step 8976, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:27.811634 #train# step 8977, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:29.359500 #train# step 8978, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:30.874434 #train# step 8979, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:32.456724 #train# step 8980, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:33.992661 #train# step 8981, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:35.550897 #train# step 8982, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:37.117901 #train# step 8983, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:38.671422 #train# step 8984, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:40.225103 #train# step 8985, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:41.736562 #train# step 8986, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:43.287424 #train# step 8987, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:44.818996 #train# step 8988, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:46.393926 #train# step 8989, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:47.886207 #train# step 8990, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:49.417409 #train# step 8991, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:50.956219 #train# step 8992, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:52.538246 #train# step 8993, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:54.077955 #train# step 8994, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:55.602597 #train# step 8995, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:57.117026 #train# step 8996, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:46:58.700340 #train# step 8997, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:00.258139 #train# step 8998, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:01.806634 #train# step 8999, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:03.343633 #train# step 9000, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:04.886914 #train# step 9001, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:06.420958 #train# step 9002, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:07.963423 #train# step 9003, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:09.512861 #train# step 9004, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:11.054208 #train# step 9005, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:12.580077 #train# step 9006, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:14.078242 #train# step 9007, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:15.639353 #train# step 9008, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:17.190328 #train# step 9009, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:18.738015 #train# step 9010, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:20.270188 #train# step 9011, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:21.825815 #train# step 9012, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:23.393593 #train# step 9013, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:24.910698 #train# step 9014, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:26.433120 #train# step 9015, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:28.020721 #train# step 9016, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:29.559101 #train# step 9017, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:31.093668 #train# step 9018, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:32.659391 #train# step 9019, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:34.195993 #train# step 9020, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:35.745647 #train# step 9021, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:37.299449 #train# step 9022, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:38.829411 #train# step 9023, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:40.362071 #train# step 9024, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:41.946999 #train# step 9025, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:43.494030 #train# step 9026, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:45.061233 #train# step 9027, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:46.596330 #train# step 9028, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:48.106096 #train# step 9029, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:49.648140 #train# step 9030, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:51.187271 #train# step 9031, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:52.732317 #train# step 9032, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:54.281750 #train# step 9033, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:55.828876 #train# step 9034, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:57.383457 #train# step 9035, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:47:58.905502 #train# step 9036, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:00.430246 #train# step 9037, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:01.985129 #train# step 9038, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:03.526049 #train# step 9039, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:05.108942 #train# step 9040, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:06.645701 #train# step 9041, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:08.192442 #train# step 9042, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:09.739282 #train# step 9043, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:11.301838 #train# step 9044, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:12.815437 #train# step 9045, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:14.353573 #train# step 9046, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:15.883507 #train# step 9047, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:17.413322 #train# step 9048, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:18.957857 #train# step 9049, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:20.508543 #train# step 9050, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:22.072587 #train# step 9051, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:23.622611 #train# step 9052, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:25.177054 #train# step 9053, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:26.690065 #train# step 9054, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:28.203787 #train# step 9055, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:29.740257 #train# step 9056, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:31.320139 #train# step 9057, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:32.867656 #train# step 9058, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:34.407840 #train# step 9059, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:35.968746 #train# step 9060, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:37.476799 #train# step 9061, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:38.998100 #train# step 9062, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:40.527069 #train# step 9063, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:42.065064 #train# step 9064, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:43.604761 #train# step 9065, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:45.161754 #train# step 9066, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:46.712346 #train# step 9067, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:48.263992 #train# step 9068, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:49.798629 #train# step 9069, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:51.330872 #train# step 9070, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:52.885840 #train# step 9071, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:54.442276 #train# step 9072, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:55.986598 #train# step 9073, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:57.546491 #train# step 9074, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:48:59.085224 #train# step 9075, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:00.635794 #train# step 9076, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:02.186244 #train# step 9077, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:03.722412 #train# step 9078, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:05.259436 #train# step 9079, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:06.802465 #train# step 9080, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:08.315630 #train# step 9081, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:09.838785 #train# step 9082, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:11.354427 #train# step 9083, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:12.870462 #train# step 9084, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:14.435605 #train# step 9085, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:15.975115 #train# step 9086, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:17.532830 #train# step 9087, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:19.092600 #train# step 9088, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:20.623110 #train# step 9089, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:22.179115 #train# step 9090, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:23.706788 #train# step 9091, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:25.239322 #train# step 9092, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:26.812449 #train# step 9093, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:28.356573 #train# step 9094, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:29.917354 #train# step 9095, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:31.466589 #train# step 9096, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:33.035410 #train# step 9097, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:34.560789 #train# step 9098, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:36.135646 #train# step 9099, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:37.694284 #train# step 9100, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:39.251951 #train# step 9101, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:40.751240 #train# step 9102, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:42.306091 #train# step 9103, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:43.872028 #train# step 9104, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:45.415976 #train# step 9105, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:46.992729 #train# step 9106, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:48.525496 #train# step 9107, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:50.051770 #train# step 9108, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:51.610021 #train# step 9109, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:53.166742 #train# step 9110, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:54.698744 #train# step 9111, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:56.233542 #train# step 9112, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:57.769650 #train# step 9113, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:49:59.329671 #train# step 9114, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:00.840152 #train# step 9115, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:02.400988 #train# step 9116, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:03.946706 #train# step 9117, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:05.466696 #train# step 9118, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:07.030405 #train# step 9119, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:08.570470 #train# step 9120, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:10.117165 #train# step 9121, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:11.692308 #train# step 9122, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:13.257962 #train# step 9123, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:14.783353 #train# step 9124, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:16.343294 #train# step 9125, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:17.873124 #train# step 9126, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:19.395480 #train# step 9127, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:20.956388 #train# step 9128, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:22.493504 #train# step 9129, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:24.042046 #train# step 9130, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:25.594375 #train# step 9131, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:27.145910 #train# step 9132, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:28.665074 #train# step 9133, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:30.207433 #train# step 9134, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:31.730854 #train# step 9135, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:33.274409 #train# step 9136, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:34.841441 #train# step 9137, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:36.382976 #train# step 9138, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:37.891270 #train# step 9139, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:39.466121 #train# step 9140, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:41.025598 #train# step 9141, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:42.535933 #train# step 9142, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:44.061904 #train# step 9143, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:45.630646 #train# step 9144, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:47.174461 #train# step 9145, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:48.697294 #train# step 9146, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:50.256446 #train# step 9147, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:51.767151 #train# step 9148, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:53.314479 #train# step 9149, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:54.865270 #train# step 9150, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:56.409014 #train# step 9151, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:57.969838 #train# step 9152, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:50:59.521420 #train# step 9153, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:01.097791 #train# step 9154, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:02.633372 #train# step 9155, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:04.187285 #train# step 9156, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:05.716883 #train# step 9157, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:07.235229 #train# step 9158, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:08.742238 #train# step 9159, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:10.339102 #train# step 9160, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:11.849404 #train# step 9161, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:13.376009 #train# step 9162, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:14.920571 #train# step 9163, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:16.486051 #train# step 9164, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:18.060124 #train# step 9165, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:19.612648 #train# step 9166, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:21.147916 #train# step 9167, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:22.701520 #train# step 9168, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:24.220926 #train# step 9169, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:25.730654 #train# step 9170, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:27.256383 #train# step 9171, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:28.795484 #train# step 9172, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:30.326216 #train# step 9173, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:31.846227 #train# step 9174, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:33.401959 #train# step 9175, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:34.967597 #train# step 9176, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:36.537108 #train# step 9177, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:38.097407 #train# step 9178, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:39.641020 #train# step 9179, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:41.185095 #train# step 9180, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:42.756698 #train# step 9181, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:44.289884 #train# step 9182, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:45.814136 #train# step 9183, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:47.345862 #train# step 9184, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:48.910725 #train# step 9185, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:50.471744 #train# step 9186, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:52.038138 #train# step 9187, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:53.594557 #train# step 9188, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:55.149721 #train# step 9189, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:56.678088 #train# step 9190, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:58.205489 #train# step 9191, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:51:59.764473 #train# step 9192, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:01.333628 #train# step 9193, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:02.873965 #train# step 9194, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:04.420249 #train# step 9195, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:05.968452 #train# step 9196, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:07.502905 #train# step 9197, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:09.054704 #train# step 9198, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:10.583145 #train# step 9199, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:12.131090 #train# step 9200, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:13.675529 #train# step 9201, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:15.265106 #train# step 9202, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:16.832215 #train# step 9203, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:18.394659 #train# step 9204, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:19.927666 #train# step 9205, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:21.478626 #train# step 9206, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:23.004507 #train# step 9207, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:24.557507 #train# step 9208, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:26.090532 #train# step 9209, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:27.622127 #train# step 9210, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:29.170861 #train# step 9211, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:30.698541 #train# step 9212, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:32.247699 #train# step 9213, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:33.762444 #train# step 9214, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:35.317209 #train# step 9215, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:36.864322 #train# step 9216, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:38.380994 #train# step 9217, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:39.918295 #train# step 9218, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:41.447522 #train# step 9219, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:42.997124 #train# step 9220, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:44.549756 #train# step 9221, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:46.085461 #train# step 9222, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:47.622039 #train# step 9223, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:49.127090 #train# step 9224, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:50.662258 #train# step 9225, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:52.209872 #train# step 9226, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:53.738352 #train# step 9227, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:55.259414 #train# step 9228, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:56.799529 #train# step 9229, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:58.350063 #train# step 9230, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:52:59.883187 #train# step 9231, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:01.425652 #train# step 9232, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:02.976488 #train# step 9233, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:04.520549 #train# step 9234, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:06.081314 #train# step 9235, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:07.616601 #train# step 9236, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:09.188551 #train# step 9237, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:10.742457 #train# step 9238, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:12.301667 #train# step 9239, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:13.844975 #train# step 9240, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:15.408640 #train# step 9241, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:16.953422 #train# step 9242, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:18.474493 #train# step 9243, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:20.023579 #train# step 9244, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:21.584844 #train# step 9245, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:23.161173 #train# step 9246, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:24.709838 #train# step 9247, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:26.277451 #train# step 9248, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:27.823888 #train# step 9249, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:29.402898 #train# step 9250, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:30.973818 #train# step 9251, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:32.495475 #train# step 9252, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:34.072365 #train# step 9253, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:35.607876 #train# step 9254, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:37.165646 #train# step 9255, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:38.697288 #train# step 9256, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:40.208249 #train# step 9257, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:41.733611 #train# step 9258, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:43.279349 #train# step 9259, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:44.785214 #train# step 9260, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:46.332476 #train# step 9261, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:47.882223 #train# step 9262, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:49.461424 #train# step 9263, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:50.993770 #train# step 9264, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:52.538065 #train# step 9265, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:54.090583 #train# step 9266, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:55.623187 #train# step 9267, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:57.198815 #train# step 9268, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:53:58.707703 #train# step 9269, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:00.220557 #train# step 9270, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:01.782893 #train# step 9271, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:03.380684 #train# step 9272, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:04.904761 #train# step 9273, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:06.439102 #train# step 9274, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:07.994841 #train# step 9275, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:09.518537 #train# step 9276, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:11.057263 #train# step 9277, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:12.603004 #train# step 9278, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:14.160794 #train# step 9279, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:15.698887 #train# step 9280, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:17.231382 #train# step 9281, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:18.777399 #train# step 9282, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:20.350059 #train# step 9283, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:21.898319 #train# step 9284, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:23.457162 #train# step 9285, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:24.980615 #train# step 9286, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:26.545594 #train# step 9287, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:28.121123 #train# step 9288, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:29.653785 #train# step 9289, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:31.212699 #train# step 9290, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:32.741177 #train# step 9291, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:34.283876 #train# step 9292, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:35.840144 #train# step 9293, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:37.356620 #train# step 9294, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:38.901313 #train# step 9295, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:40.453692 #train# step 9296, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:41.995110 #train# step 9297, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:43.535876 #train# step 9298, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:45.056017 #train# step 9299, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:46.592910 #train# step 9300, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:48.128990 #train# step 9301, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:49.651477 #train# step 9302, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:51.226417 #train# step 9303, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:52.756975 #train# step 9304, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:54.302776 #train# step 9305, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:55.867683 #train# step 9306, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:57.378376 #train# step 9307, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:54:58.931090 #train# step 9308, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:00.490731 #train# step 9309, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:02.006128 #train# step 9310, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:03.532127 #train# step 9311, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:05.062236 #train# step 9312, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:06.648572 #train# step 9313, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:08.200012 #train# step 9314, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:09.754492 #train# step 9315, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:11.280262 #train# step 9316, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:12.836100 #train# step 9317, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:14.364284 #train# step 9318, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:15.884765 #train# step 9319, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:17.437718 #train# step 9320, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:18.981094 #train# step 9321, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:20.525271 #train# step 9322, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:22.071923 #train# step 9323, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:23.585254 #train# step 9324, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:25.132440 #train# step 9325, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:26.670428 #train# step 9326, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:28.208597 #train# step 9327, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:29.750349 #train# step 9328, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:31.284861 #train# step 9329, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:32.834713 #train# step 9330, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:34.375901 #train# step 9331, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:35.952002 #train# step 9332, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:37.537041 #train# step 9333, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:39.048863 #train# step 9334, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:40.591390 #train# step 9335, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:42.146764 #train# step 9336, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:43.723445 #train# step 9337, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:45.264485 #train# step 9338, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:46.798584 #train# step 9339, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:48.341526 #train# step 9340, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:49.864032 #train# step 9341, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:51.440906 #train# step 9342, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:53.003029 #train# step 9343, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:54.564131 #train# step 9344, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:56.113530 #train# step 9345, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:57.666272 #train# step 9346, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:55:59.193582 #train# step 9347, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:00.753480 #train# step 9348, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:02.308676 #train# step 9349, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:03.860662 #train# step 9350, loss = 0.8899, cross_entropy loss = 0.8899, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:05.395939 #train# step 9351, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:06.945803 #train# step 9352, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:08.496153 #train# step 9353, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:10.066948 #train# step 9354, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:11.615838 #train# step 9355, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:13.178393 #train# step 9356, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:14.761072 #train# step 9357, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:16.308195 #train# step 9358, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:17.850968 #train# step 9359, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:19.388024 #train# step 9360, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:20.942774 #train# step 9361, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:22.455221 #train# step 9362, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:23.991676 #train# step 9363, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:25.561154 #train# step 9364, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:27.098108 #train# step 9365, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:28.654047 #train# step 9366, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:30.189770 #train# step 9367, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:31.713228 #train# step 9368, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:33.269398 #train# step 9369, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:34.817242 #train# step 9370, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:36.395799 #train# step 9371, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:38.018588 #train# step 9372, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:39.616245 #train# step 9373, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:41.205345 #train# step 9374, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:42.820398 #train# step 9375, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:44.452998 #train# step 9376, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:46.060706 #train# step 9377, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:47.683185 #train# step 9378, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:49.281862 #train# step 9379, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:50.910358 #train# step 9380, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:52.552978 #train# step 9381, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:54.194107 #train# step 9382, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:56.018973 #train# step 9383, loss = 0.9109, cross_entropy loss = 0.9109, 0.9 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:57.678407 #train# step 9384, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:56:59.442632 #train# step 9385, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:01.182084 #train# step 9386, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:02.871611 #train# step 9387, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:04.611195 #train# step 9388, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:06.338640 #train# step 9389, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:08.030109 #train# step 9390, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:09.572189 #train# step 9391, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:11.118629 #train# step 9392, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:12.673610 #train# step 9393, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:14.230728 #train# step 9394, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:15.819927 #train# step 9395, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:17.486225 #train# step 9396, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:19.125193 #train# step 9397, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:20.687948 #train# step 9398, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:22.239407 #train# step 9399, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:23.822972 #train# step 9400, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:25.407710 #train# step 9401, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:26.977212 #train# step 9402, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:28.570944 #train# step 9403, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:30.136692 #train# step 9404, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:31.692407 #train# step 9405, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:33.275569 #train# step 9406, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:34.832434 #train# step 9407, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:36.385266 #train# step 9408, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:37.951349 #train# step 9409, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:39.492341 #train# step 9410, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:41.027554 #train# step 9411, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:42.584921 #train# step 9412, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:44.120584 #train# step 9413, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:45.698297 #train# step 9414, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:47.256890 #train# step 9415, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:48.814240 #train# step 9416, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:50.377757 #train# step 9417, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:51.882433 #train# step 9418, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:53.453559 #train# step 9419, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:55.037345 #train# step 9420, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:56.585798 #train# step 9421, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:58.127796 #train# step 9422, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:57:59.679980 #train# step 9423, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:01.229262 #train# step 9424, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:02.784081 #train# step 9425, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:04.327488 #train# step 9426, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:05.860170 #train# step 9427, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:07.412952 #train# step 9428, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:08.943681 #train# step 9429, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:10.497123 #train# step 9430, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:12.008503 #train# step 9431, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:13.521015 #train# step 9432, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:15.067782 #train# step 9433, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:16.611875 #train# step 9434, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:18.152694 #train# step 9435, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:19.697973 #train# step 9436, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:21.266072 #train# step 9437, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:22.841586 #train# step 9438, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:24.427864 #train# step 9439, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:25.976640 #train# step 9440, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:27.529433 #train# step 9441, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:29.083292 #train# step 9442, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:30.619281 #train# step 9443, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:32.198555 #train# step 9444, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:33.737683 #train# step 9445, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:35.313858 #train# step 9446, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:36.853407 #train# step 9447, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:38.412884 #train# step 9448, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:39.967639 #train# step 9449, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:41.504033 #train# step 9450, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:43.055345 #train# step 9451, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:44.603584 #train# step 9452, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:46.159339 #train# step 9453, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:47.718916 #train# step 9454, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:49.234228 #train# step 9455, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:50.796015 #train# step 9456, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:52.343282 #train# step 9457, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:53.920815 #train# step 9458, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:55.476040 #train# step 9459, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:57.035322 #train# step 9460, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:58:58.588819 #train# step 9461, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:00.110730 #train# step 9462, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:01.669047 #train# step 9463, loss = 0.8904, cross_entropy loss = 0.8904, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:03.236978 #train# step 9464, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:04.780677 #train# step 9465, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:06.322317 #train# step 9466, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:07.855093 #train# step 9467, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:09.395995 #train# step 9468, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:10.921673 #train# step 9469, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:12.484193 #train# step 9470, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:14.064851 #train# step 9471, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:15.629509 #train# step 9472, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:17.176308 #train# step 9473, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:18.705477 #train# step 9474, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:20.252244 #train# step 9475, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:21.803841 #train# step 9476, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:23.332002 #train# step 9477, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:24.901318 #train# step 9478, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:26.428708 #train# step 9479, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:27.964726 #train# step 9480, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:29.507722 #train# step 9481, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:31.062652 #train# step 9482, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:32.614737 #train# step 9483, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:34.222939 #train# step 9484, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:35.762346 #train# step 9485, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:37.305290 #train# step 9486, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:38.841025 #train# step 9487, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:40.443801 #train# step 9488, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:41.992038 #train# step 9489, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:43.528191 #train# step 9490, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:45.097081 #train# step 9491, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:46.660931 #train# step 9492, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:48.217470 #train# step 9493, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:49.762556 #train# step 9494, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:51.285636 #train# step 9495, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:52.833726 #train# step 9496, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:54.405040 #train# step 9497, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:55.927107 #train# step 9498, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:57.469078 #train# step 9499, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 00:59:59.029262 #train# step 9500, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:00.586868 #train# step 9501, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:02.121450 #train# step 9502, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:03.627858 #train# step 9503, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:05.169497 #train# step 9504, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:06.753412 #train# step 9505, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:08.298073 #train# step 9506, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:09.845199 #train# step 9507, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:11.386765 #train# step 9508, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:12.963560 #train# step 9509, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:14.496743 #train# step 9510, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:16.022733 #train# step 9511, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:17.555066 #train# step 9512, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:19.121864 #train# step 9513, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:20.658174 #train# step 9514, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:22.220820 #train# step 9515, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:23.747795 #train# step 9516, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:25.308807 #train# step 9517, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:26.862507 #train# step 9518, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:28.405189 #train# step 9519, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:29.998291 #train# step 9520, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:31.539952 #train# step 9521, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:33.071313 #train# step 9522, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:34.648694 #train# step 9523, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:36.209365 #train# step 9524, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:37.752364 #train# step 9525, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:39.292212 #train# step 9526, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:40.849941 #train# step 9527, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:42.363123 #train# step 9528, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:43.937041 #train# step 9529, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:45.507895 #train# step 9530, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:47.072815 #train# step 9531, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:48.636355 #train# step 9532, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:50.170310 #train# step 9533, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:51.716033 #train# step 9534, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:53.272184 #train# step 9535, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:54.836126 #train# step 9536, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:56.378819 #train# step 9537, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:57.926279 #train# step 9538, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:00:59.465172 #train# step 9539, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:01.031829 #train# step 9540, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:02.583184 #train# step 9541, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:04.184164 #train# step 9542, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:05.742143 #train# step 9543, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:07.287739 #train# step 9544, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:08.841884 #train# step 9545, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:10.394104 #train# step 9546, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:11.938483 #train# step 9547, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:13.473972 #train# step 9548, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:14.990914 #train# step 9549, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:16.561045 #train# step 9550, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:18.088398 #train# step 9551, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:19.663618 #train# step 9552, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:21.182450 #train# step 9553, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:22.722686 #train# step 9554, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:24.249420 #train# step 9555, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:25.772947 #train# step 9556, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:27.371412 #train# step 9557, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:28.914857 #train# step 9558, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:30.437150 #train# step 9559, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:31.975256 #train# step 9560, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:33.560709 #train# step 9561, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:35.116385 #train# step 9562, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:36.676872 #train# step 9563, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:38.236362 #train# step 9564, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:39.782293 #train# step 9565, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:41.343042 #train# step 9566, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:42.885263 #train# step 9567, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:44.431171 #train# step 9568, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:45.973710 #train# step 9569, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:47.520143 #train# step 9570, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:49.103634 #train# step 9571, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:50.668321 #train# step 9572, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:52.232014 #train# step 9573, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:53.779637 #train# step 9574, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:55.329384 #train# step 9575, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:56.868327 #train# step 9576, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:58.431058 #train# step 9577, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:01:59.984389 #train# step 9578, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:01.550094 #train# step 9579, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:03.109381 #train# step 9580, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:04.657081 #train# step 9581, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:06.184538 #train# step 9582, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:07.738022 #train# step 9583, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:09.281385 #train# step 9584, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:10.851657 #train# step 9585, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:12.365232 #train# step 9586, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:13.901776 #train# step 9587, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:15.466234 #train# step 9588, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:17.015746 #train# step 9589, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:18.539449 #train# step 9590, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:20.062149 #train# step 9591, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:21.615918 #train# step 9592, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:23.143557 #train# step 9593, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:24.697353 #train# step 9594, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:26.206604 #train# step 9595, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:27.741827 #train# step 9596, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:29.277814 #train# step 9597, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:30.850405 #train# step 9598, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:32.398203 #train# step 9599, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:33.949162 #train# step 9600, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:35.510769 #train# step 9601, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:37.072284 #train# step 9602, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:38.655169 #train# step 9603, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:40.228701 #train# step 9604, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:41.755709 #train# step 9605, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:43.321206 #train# step 9606, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:44.854860 #train# step 9607, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:46.430588 #train# step 9608, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:48.009645 #train# step 9609, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:49.573398 #train# step 9610, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:51.110589 #train# step 9611, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:52.674576 #train# step 9612, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:54.241634 #train# step 9613, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:55.786699 #train# step 9614, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:57.339572 #train# step 9615, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:02:58.879988 #train# step 9616, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:00.413276 #train# step 9617, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:02.003674 #train# step 9618, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:03.595961 #train# step 9619, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:05.118573 #train# step 9620, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:06.652576 #train# step 9621, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:08.194817 #train# step 9622, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:09.746263 #train# step 9623, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:11.323906 #train# step 9624, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:12.874813 #train# step 9625, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:14.423454 #train# step 9626, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:16.013896 #train# step 9627, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:17.578604 #train# step 9628, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:19.109226 #train# step 9629, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:20.669172 #train# step 9630, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:22.209902 #train# step 9631, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:23.754034 #train# step 9632, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:25.312133 #train# step 9633, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:26.833992 #train# step 9634, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:28.357473 #train# step 9635, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:29.917638 #train# step 9636, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:31.465619 #train# step 9637, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:32.988333 #train# step 9638, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:34.515566 #train# step 9639, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:36.081518 #train# step 9640, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:37.642090 #train# step 9641, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:39.179271 #train# step 9642, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:40.726153 #train# step 9643, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:42.283984 #train# step 9644, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:43.839816 #train# step 9645, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:45.383820 #train# step 9646, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:46.949598 #train# step 9647, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:48.525069 #train# step 9648, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:50.086783 #train# step 9649, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:51.637027 #train# step 9650, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:53.238215 #train# step 9651, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:54.763202 #train# step 9652, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:56.321913 #train# step 9653, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:57.896704 #train# step 9654, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:03:59.452627 #train# step 9655, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:01.014637 #train# step 9656, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:02.567781 #train# step 9657, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:04.096831 #train# step 9658, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:05.675664 #train# step 9659, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:07.221945 #train# step 9660, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:08.767636 #train# step 9661, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:10.313097 #train# step 9662, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:11.876671 #train# step 9663, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:13.421489 #train# step 9664, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:14.997827 #train# step 9665, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:16.540134 #train# step 9666, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:18.102178 #train# step 9667, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:19.621850 #train# step 9668, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:21.153944 #train# step 9669, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:22.730151 #train# step 9670, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:24.272099 #train# step 9671, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:25.843527 #train# step 9672, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:27.406791 #train# step 9673, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:28.934592 #train# step 9674, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:30.476461 #train# step 9675, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:32.024088 #train# step 9676, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:33.536108 #train# step 9677, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:35.071845 #train# step 9678, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:36.654714 #train# step 9679, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:38.228212 #train# step 9680, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:39.772171 #train# step 9681, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:41.311294 #train# step 9682, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:42.815030 #train# step 9683, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:44.369146 #train# step 9684, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:45.941568 #train# step 9685, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:47.477470 #train# step 9686, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:49.028951 #train# step 9687, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:50.591879 #train# step 9688, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:52.119877 #train# step 9689, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:53.643839 #train# step 9690, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:55.189938 #train# step 9691, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:56.742946 #train# step 9692, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:58.323042 #train# step 9693, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:04:59.893855 #train# step 9694, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:01.447158 #train# step 9695, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:03.025746 #train# step 9696, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:04.600941 #train# step 9697, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:06.199274 #train# step 9698, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:07.763065 #train# step 9699, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:09.358605 #train# step 9700, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:10.928187 #train# step 9701, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:12.484121 #train# step 9702, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:14.055460 #train# step 9703, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:15.609595 #train# step 9704, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:17.197533 #train# step 9705, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:18.755396 #train# step 9706, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:20.263502 #train# step 9707, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:21.798572 #train# step 9708, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:23.344031 #train# step 9709, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:24.875924 #train# step 9710, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:26.442723 #train# step 9711, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:28.001581 #train# step 9712, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:29.544581 #train# step 9713, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:31.076204 #train# step 9714, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:32.607303 #train# step 9715, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:34.135752 #train# step 9716, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:35.678291 #train# step 9717, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:37.227997 #train# step 9718, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:38.788640 #train# step 9719, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:40.339991 #train# step 9720, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:41.834873 #train# step 9721, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:43.392010 #train# step 9722, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:44.948181 #train# step 9723, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:46.480562 #train# step 9724, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:48.007377 #train# step 9725, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:49.540543 #train# step 9726, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:51.086579 #train# step 9727, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:52.603504 #train# step 9728, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:54.129711 #train# step 9729, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:55.672408 #train# step 9730, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:57.223178 #train# step 9731, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:05:58.746293 #train# step 9732, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:00.328296 #train# step 9733, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:01.865152 #train# step 9734, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:03.429360 #train# step 9735, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:04.971265 #train# step 9736, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:06.561429 #train# step 9737, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:08.103839 #train# step 9738, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:09.690142 #train# step 9739, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:11.212110 #train# step 9740, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:12.742739 #train# step 9741, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:14.262968 #train# step 9742, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:15.825594 #train# step 9743, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:17.377353 #train# step 9744, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:18.912379 #train# step 9745, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:20.464136 #train# step 9746, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:22.022084 #train# step 9747, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:23.585323 #train# step 9748, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:25.144345 #train# step 9749, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:26.669884 #train# step 9750, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:28.194349 #train# step 9751, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:29.744419 #train# step 9752, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:31.272964 #train# step 9753, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:32.820889 #train# step 9754, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:34.382432 #train# step 9755, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:35.921828 #train# step 9756, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:37.488448 #train# step 9757, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:39.017509 #train# step 9758, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:40.587423 #train# step 9759, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:42.135730 #train# step 9760, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:43.726055 #train# step 9761, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:45.261308 #train# step 9762, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:46.862164 #train# step 9763, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:48.417985 #train# step 9764, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:49.977125 #train# step 9765, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:51.530962 #train# step 9766, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:53.063276 #train# step 9767, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:54.626070 #train# step 9768, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:56.150756 #train# step 9769, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:57.709104 #train# step 9770, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:06:59.272019 #train# step 9771, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:00.822167 #train# step 9772, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:02.364801 #train# step 9773, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:03.918798 #train# step 9774, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:05.486439 #train# step 9775, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:07.014068 #train# step 9776, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:08.574905 #train# step 9777, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:10.139052 #train# step 9778, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:11.715762 #train# step 9779, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:13.224574 #train# step 9780, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:14.789258 #train# step 9781, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:16.341635 #train# step 9782, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:17.834452 #train# step 9783, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:19.389804 #train# step 9784, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:20.938363 #train# step 9785, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:22.493324 #train# step 9786, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:24.032278 #train# step 9787, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:25.566615 #train# step 9788, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:27.155740 #train# step 9789, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:28.696661 #train# step 9790, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:30.260588 #train# step 9791, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:31.791030 #train# step 9792, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:33.348824 #train# step 9793, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:34.885440 #train# step 9794, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:36.438991 #train# step 9795, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:37.994763 #train# step 9796, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:39.526080 #train# step 9797, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:41.082693 #train# step 9798, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:42.655300 #train# step 9799, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:44.199302 #train# step 9800, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:45.741673 #train# step 9801, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:47.259876 #train# step 9802, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:48.825006 #train# step 9803, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:50.389951 #train# step 9804, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:51.952145 #train# step 9805, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:53.483455 #train# step 9806, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:55.036281 #train# step 9807, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:56.578977 #train# step 9808, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:58.109983 #train# step 9809, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:07:59.670150 #train# step 9810, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:01.197051 #train# step 9811, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:02.788722 #train# step 9812, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:04.330648 #train# step 9813, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:05.886797 #train# step 9814, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:07.444879 #train# step 9815, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:08.983992 #train# step 9816, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:10.548665 #train# step 9817, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:12.110497 #train# step 9818, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:13.677654 #train# step 9819, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:15.217207 #train# step 9820, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:16.749338 #train# step 9821, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:18.294609 #train# step 9822, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:19.873752 #train# step 9823, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:21.434770 #train# step 9824, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:23.036203 #train# step 9825, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:24.606585 #train# step 9826, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:26.178758 #train# step 9827, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:27.714295 #train# step 9828, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:29.252446 #train# step 9829, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:30.808105 #train# step 9830, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:32.337066 #train# step 9831, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:33.873844 #train# step 9832, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:35.415166 #train# step 9833, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:36.922653 #train# step 9834, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:38.478392 #train# step 9835, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:40.064525 #train# step 9836, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:41.638667 #train# step 9837, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:43.152064 #train# step 9838, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:44.737411 #train# step 9839, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:46.294833 #train# step 9840, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:47.851632 #train# step 9841, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:49.390760 #train# step 9842, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:50.924494 #train# step 9843, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:52.438927 #train# step 9844, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:54.006651 #train# step 9845, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:55.571315 #train# step 9846, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:57.135275 #train# step 9847, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:08:58.703775 #train# step 9848, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:00.306092 #train# step 9849, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:01.835431 #train# step 9850, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:03.400643 #train# step 9851, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:04.969235 #train# step 9852, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:06.501782 #train# step 9853, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:08.071003 #train# step 9854, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:09.601734 #train# step 9855, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:11.111025 #train# step 9856, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:12.636121 #train# step 9857, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:14.165082 #train# step 9858, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:15.707789 #train# step 9859, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:17.248788 #train# step 9860, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:18.804052 #train# step 9861, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:20.331913 #train# step 9862, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:21.887638 #train# step 9863, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:23.438900 #train# step 9864, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:24.997822 #train# step 9865, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:26.537363 #train# step 9866, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:28.098217 #train# step 9867, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:29.644813 #train# step 9868, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:31.202440 #train# step 9869, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:32.734125 #train# step 9870, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:34.304735 #train# step 9871, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:35.836374 #train# step 9872, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:37.392848 #train# step 9873, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:38.950035 #train# step 9874, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:40.500746 #train# step 9875, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:42.040594 #train# step 9876, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:43.574043 #train# step 9877, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:45.104521 #train# step 9878, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:46.648176 #train# step 9879, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:48.213473 #train# step 9880, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:49.780306 #train# step 9881, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:51.356142 #train# step 9882, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:52.905864 #train# step 9883, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:54.449776 #train# step 9884, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:55.995933 #train# step 9885, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:57.548818 #train# step 9886, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:09:59.127648 #train# step 9887, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:00.657239 #train# step 9888, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:02.231496 #train# step 9889, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:03.771307 #train# step 9890, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:05.313953 #train# step 9891, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:06.860451 #train# step 9892, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:08.408588 #train# step 9893, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:09.948604 #train# step 9894, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:11.485196 #train# step 9895, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:13.022315 #train# step 9896, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:14.564176 #train# step 9897, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:16.104370 #train# step 9898, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:17.660522 #train# step 9899, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:19.189490 #train# step 9900, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:20.724929 #train# step 9901, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:22.288352 #train# step 9902, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:23.855617 #train# step 9903, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:25.414145 #train# step 9904, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:26.965537 #train# step 9905, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:28.500714 #train# step 9906, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:30.054997 #train# step 9907, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:31.623002 #train# step 9908, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:33.189712 #train# step 9909, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:34.689932 #train# step 9910, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:36.252374 #train# step 9911, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:37.806801 #train# step 9912, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:39.374714 #train# step 9913, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:40.946149 #train# step 9914, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:42.513146 #train# step 9915, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:44.058308 #train# step 9916, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:45.619565 #train# step 9917, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:47.175069 #train# step 9918, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:48.717809 #train# step 9919, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:50.264746 #train# step 9920, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:51.796235 #train# step 9921, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:53.339207 #train# step 9922, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:54.884699 #train# step 9923, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:56.421938 #train# step 9924, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:57.991802 #train# step 9925, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:10:59.557072 #train# step 9926, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:01.063507 #train# step 9927, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:02.596210 #train# step 9928, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:04.139907 #train# step 9929, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:05.685419 #train# step 9930, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:07.244718 #train# step 9931, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:08.822324 #train# step 9932, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:10.391848 #train# step 9933, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:11.966173 #train# step 9934, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:13.507435 #train# step 9935, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:15.062678 #train# step 9936, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:16.645303 #train# step 9937, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:18.184595 #train# step 9938, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:19.781092 #train# step 9939, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:21.355132 #train# step 9940, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:22.869208 #train# step 9941, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:24.422240 #train# step 9942, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:25.980696 #train# step 9943, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:27.566824 #train# step 9944, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:29.108843 #train# step 9945, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:30.646678 #train# step 9946, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:32.196731 #train# step 9947, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:33.704449 #train# step 9948, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:35.268423 #train# step 9949, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:36.821092 #train# step 9950, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:38.345529 #train# step 9951, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:39.862514 #train# step 9952, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:41.417067 #train# step 9953, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:42.988053 #train# step 9954, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:44.540791 #train# step 9955, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:46.060120 #train# step 9956, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:47.611883 #train# step 9957, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:49.173557 #train# step 9958, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:50.718185 #train# step 9959, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:52.257018 #train# step 9960, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:53.801954 #train# step 9961, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:55.351794 #train# step 9962, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:56.914206 #train# step 9963, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:11:58.455330 #train# step 9964, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:00.007729 #train# step 9965, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:01.560151 #train# step 9966, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:03.111833 #train# step 9967, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:04.686703 #train# step 9968, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:06.246074 #train# step 9969, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:07.816945 #train# step 9970, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:09.390264 #train# step 9971, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:10.912114 #train# step 9972, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:12.461022 #train# step 9973, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:14.010932 #train# step 9974, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:15.569443 #train# step 9975, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:17.125098 #train# step 9976, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:18.650328 #train# step 9977, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:20.165958 #train# step 9978, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:21.706237 #train# step 9979, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:23.267292 #train# step 9980, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:24.822371 #train# step 9981, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:26.365433 #train# step 9982, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:27.921213 #train# step 9983, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:29.487519 #train# step 9984, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:31.035982 #train# step 9985, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:32.591952 #train# step 9986, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:34.141637 #train# step 9987, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:35.688839 #train# step 9988, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:37.224633 #train# step 9989, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:38.779692 #train# step 9990, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:40.352068 #train# step 9991, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:41.918726 #train# step 9992, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:43.473353 #train# step 9993, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:45.009882 #train# step 9994, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:46.546606 #train# step 9995, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:48.055493 #train# step 9996, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:49.611714 #train# step 9997, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:51.185946 #train# step 9998, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:52.740355 #train# step 9999, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 01:12:54.295405 #train# step 10000, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
2021-01-21 01:12:54.295692 #traing# finish training
saving model to ./models/lr_5e-05_cqlambda_0.0_alpha_10.0_dataset_VeRi_hashbit_256.npy
model saved
{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 256,
 'save_dir': './models/',
 'val_batch_size': 100}
