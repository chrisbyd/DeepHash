{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 256,
 'save_dir': './models/',
 'val_batch_size': 100}
initializing
launching session
loading img model from ../../architecture/pretrained_model/reference_pretrain.npy
['hash_layer', 'fc6', 'fc7', 'conv3', 'conv2', 'conv1', 'conv5', 'conv4']
img model loading finished
Initializing Dataset
Dataset already
2021-01-21 23:03:26.932438 #train# start training
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:44.457107 #train# step    1, loss = 2.1024, cross_entropy loss = 2.1024, 12.7 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:46.019217 #train# step    2, loss = 2.0303, cross_entropy loss = 2.0303, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:47.578125 #train# step    3, loss = 1.8494, cross_entropy loss = 1.8494, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:49.104729 #train# step    4, loss = 1.6464, cross_entropy loss = 1.6464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:50.647511 #train# step    5, loss = 1.4612, cross_entropy loss = 1.4612, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:52.218054 #train# step    6, loss = 1.2998, cross_entropy loss = 1.2998, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:53.781703 #train# step    7, loss = 1.2317, cross_entropy loss = 1.2317, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:55.318336 #train# step    8, loss = 1.1703, cross_entropy loss = 1.1703, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:56.898668 #train# step    9, loss = 1.1674, cross_entropy loss = 1.1674, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:58.426432 #train# step   10, loss = 1.1618, cross_entropy loss = 1.1618, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:03:59.990162 #train# step   11, loss = 1.1637, cross_entropy loss = 1.1637, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:01.558865 #train# step   12, loss = 1.2141, cross_entropy loss = 1.2141, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:03.089156 #train# step   13, loss = 1.2420, cross_entropy loss = 1.2420, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:04.628155 #train# step   14, loss = 1.2464, cross_entropy loss = 1.2464, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:06.191451 #train# step   15, loss = 1.2634, cross_entropy loss = 1.2634, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:07.737038 #train# step   16, loss = 1.2985, cross_entropy loss = 1.2985, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:09.290475 #train# step   17, loss = 1.2867, cross_entropy loss = 1.2867, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:10.878956 #train# step   18, loss = 1.2722, cross_entropy loss = 1.2722, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:12.409816 #train# step   19, loss = 1.2631, cross_entropy loss = 1.2631, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:13.969250 #train# step   20, loss = 1.2255, cross_entropy loss = 1.2255, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:15.524676 #train# step   21, loss = 1.2184, cross_entropy loss = 1.2184, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:17.072279 #train# step   22, loss = 1.1958, cross_entropy loss = 1.1958, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:18.629621 #train# step   23, loss = 1.1906, cross_entropy loss = 1.1906, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:20.135475 #train# step   24, loss = 1.1636, cross_entropy loss = 1.1636, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:21.700967 #train# step   25, loss = 1.1460, cross_entropy loss = 1.1460, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:23.223291 #train# step   26, loss = 1.1541, cross_entropy loss = 1.1541, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:24.744071 #train# step   27, loss = 1.1210, cross_entropy loss = 1.1210, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:26.294649 #train# step   28, loss = 1.1202, cross_entropy loss = 1.1202, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:27.834305 #train# step   29, loss = 1.1392, cross_entropy loss = 1.1392, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:29.353558 #train# step   30, loss = 1.1319, cross_entropy loss = 1.1319, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:30.920017 #train# step   31, loss = 1.1237, cross_entropy loss = 1.1237, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:32.471201 #train# step   32, loss = 1.1511, cross_entropy loss = 1.1511, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:34.018695 #train# step   33, loss = 1.1327, cross_entropy loss = 1.1327, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:35.580284 #train# step   34, loss = 1.1400, cross_entropy loss = 1.1400, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:37.087891 #train# step   35, loss = 1.1453, cross_entropy loss = 1.1453, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:38.615470 #train# step   36, loss = 1.1621, cross_entropy loss = 1.1621, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:40.169612 #train# step   37, loss = 1.1418, cross_entropy loss = 1.1418, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:41.710036 #train# step   38, loss = 1.1610, cross_entropy loss = 1.1610, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:43.293120 #train# step   39, loss = 1.1462, cross_entropy loss = 1.1462, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:44.850310 #train# step   40, loss = 1.1239, cross_entropy loss = 1.1239, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:46.406148 #train# step   41, loss = 1.1399, cross_entropy loss = 1.1399, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:47.965789 #train# step   42, loss = 1.1318, cross_entropy loss = 1.1318, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:49.561710 #train# step   43, loss = 1.1307, cross_entropy loss = 1.1307, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:51.119830 #train# step   44, loss = 1.1260, cross_entropy loss = 1.1260, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:52.664845 #train# step   45, loss = 1.1331, cross_entropy loss = 1.1331, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:54.223216 #train# step   46, loss = 1.1216, cross_entropy loss = 1.1216, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:55.807459 #train# step   47, loss = 1.0954, cross_entropy loss = 1.0954, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:57.359351 #train# step   48, loss = 1.1447, cross_entropy loss = 1.1447, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:04:58.917190 #train# step   49, loss = 1.1149, cross_entropy loss = 1.1149, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:00.482036 #train# step   50, loss = 1.0980, cross_entropy loss = 1.0980, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:02.014713 #train# step   51, loss = 1.1002, cross_entropy loss = 1.1002, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:03.566199 #train# step   52, loss = 1.1269, cross_entropy loss = 1.1269, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:05.098520 #train# step   53, loss = 1.1344, cross_entropy loss = 1.1344, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:06.628194 #train# step   54, loss = 1.1031, cross_entropy loss = 1.1031, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:08.167112 #train# step   55, loss = 1.1381, cross_entropy loss = 1.1381, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:09.737900 #train# step   56, loss = 1.1044, cross_entropy loss = 1.1044, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:11.301457 #train# step   57, loss = 1.1127, cross_entropy loss = 1.1127, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:12.871790 #train# step   58, loss = 1.0967, cross_entropy loss = 1.0967, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:14.438409 #train# step   59, loss = 1.1110, cross_entropy loss = 1.1110, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:15.972499 #train# step   60, loss = 1.1156, cross_entropy loss = 1.1156, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:17.517384 #train# step   61, loss = 1.1293, cross_entropy loss = 1.1293, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:19.058595 #train# step   62, loss = 1.1391, cross_entropy loss = 1.1391, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:20.620298 #train# step   63, loss = 1.1011, cross_entropy loss = 1.1011, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:22.213117 #train# step   64, loss = 1.0930, cross_entropy loss = 1.0930, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:23.778015 #train# step   65, loss = 1.0934, cross_entropy loss = 1.0934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:25.337395 #train# step   66, loss = 1.1198, cross_entropy loss = 1.1198, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:26.902488 #train# step   67, loss = 1.1228, cross_entropy loss = 1.1228, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:28.490588 #train# step   68, loss = 1.0909, cross_entropy loss = 1.0909, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:30.056194 #train# step   69, loss = 1.1096, cross_entropy loss = 1.1096, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:31.571052 #train# step   70, loss = 1.0951, cross_entropy loss = 1.0951, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:33.092514 #train# step   71, loss = 1.0933, cross_entropy loss = 1.0933, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:34.651288 #train# step   72, loss = 1.1093, cross_entropy loss = 1.1093, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:36.208789 #train# step   73, loss = 1.0935, cross_entropy loss = 1.0935, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:37.765087 #train# step   74, loss = 1.1057, cross_entropy loss = 1.1057, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:39.357395 #train# step   75, loss = 1.1046, cross_entropy loss = 1.1046, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:40.939563 #train# step   76, loss = 1.1017, cross_entropy loss = 1.1017, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:42.518925 #train# step   77, loss = 1.0962, cross_entropy loss = 1.0962, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:44.095459 #train# step   78, loss = 1.0947, cross_entropy loss = 1.0947, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:45.635664 #train# step   79, loss = 1.1098, cross_entropy loss = 1.1098, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:47.157870 #train# step   80, loss = 1.0934, cross_entropy loss = 1.0934, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:48.683764 #train# step   81, loss = 1.1028, cross_entropy loss = 1.1028, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:50.280071 #train# step   82, loss = 1.0914, cross_entropy loss = 1.0914, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:51.824868 #train# step   83, loss = 1.0914, cross_entropy loss = 1.0914, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:53.389724 #train# step   84, loss = 1.0752, cross_entropy loss = 1.0752, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:54.940589 #train# step   85, loss = 1.0948, cross_entropy loss = 1.0948, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:56.494764 #train# step   86, loss = 1.0926, cross_entropy loss = 1.0926, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:58.074175 #train# step   87, loss = 1.0901, cross_entropy loss = 1.0901, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:05:59.630311 #train# step   88, loss = 1.0779, cross_entropy loss = 1.0779, 0.8 sec/batch
the output has dimension (800, 256)

the output occupies 819200 bytes
2021-01-21 23:06:01.171252 #train# step   89, loss = 1.1048, cross_entropy loss = 1.1048, 0.8 sec/batch
the output has dimension (800, 256)
