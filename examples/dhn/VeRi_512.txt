{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 512,
 'save_dir': './models/',
 'val_batch_size': 100}
initializing
launching session
loading img model from ../../architecture/pretrained_model/reference_pretrain.npy
['hash_layer', 'fc6', 'fc7', 'conv3', 'conv2', 'conv1', 'conv5', 'conv4']
img model loading finished
Initializing Dataset
Dataset already
2021-01-21 01:13:23.278123 #train# start training
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:40.609217 #train# step    1, loss = 2.1827, cross_entropy loss = 2.1827, 12.5 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:42.139464 #train# step    2, loss = 2.1382, cross_entropy loss = 2.1382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:43.639754 #train# step    3, loss = 2.0272, cross_entropy loss = 2.0272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:45.175927 #train# step    4, loss = 1.8782, cross_entropy loss = 1.8782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:46.705618 #train# step    5, loss = 1.7293, cross_entropy loss = 1.7293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:48.234286 #train# step    6, loss = 1.5600, cross_entropy loss = 1.5600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:49.796192 #train# step    7, loss = 1.4058, cross_entropy loss = 1.4058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:51.341446 #train# step    8, loss = 1.3292, cross_entropy loss = 1.3292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:52.895105 #train# step    9, loss = 1.2448, cross_entropy loss = 1.2448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:54.466097 #train# step   10, loss = 1.1858, cross_entropy loss = 1.1858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:56.033067 #train# step   11, loss = 1.1624, cross_entropy loss = 1.1624, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:57.585204 #train# step   12, loss = 1.1444, cross_entropy loss = 1.1444, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:13:59.158463 #train# step   13, loss = 1.1253, cross_entropy loss = 1.1253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:00.706838 #train# step   14, loss = 1.1175, cross_entropy loss = 1.1175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:02.271127 #train# step   15, loss = 1.1074, cross_entropy loss = 1.1074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:03.830661 #train# step   16, loss = 1.1284, cross_entropy loss = 1.1284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:05.400534 #train# step   17, loss = 1.1104, cross_entropy loss = 1.1104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:06.961753 #train# step   18, loss = 1.1384, cross_entropy loss = 1.1384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:08.484383 #train# step   19, loss = 1.1334, cross_entropy loss = 1.1334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:10.021813 #train# step   20, loss = 1.1513, cross_entropy loss = 1.1513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:11.575516 #train# step   21, loss = 1.1614, cross_entropy loss = 1.1614, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:13.128785 #train# step   22, loss = 1.1520, cross_entropy loss = 1.1520, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:14.696687 #train# step   23, loss = 1.1681, cross_entropy loss = 1.1681, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:16.232803 #train# step   24, loss = 1.1626, cross_entropy loss = 1.1626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:17.770913 #train# step   25, loss = 1.1489, cross_entropy loss = 1.1489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:19.290019 #train# step   26, loss = 1.1669, cross_entropy loss = 1.1669, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:20.818200 #train# step   27, loss = 1.1652, cross_entropy loss = 1.1652, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:22.346821 #train# step   28, loss = 1.1477, cross_entropy loss = 1.1477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:23.899538 #train# step   29, loss = 1.1499, cross_entropy loss = 1.1499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:25.415906 #train# step   30, loss = 1.1355, cross_entropy loss = 1.1355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:26.946211 #train# step   31, loss = 1.1469, cross_entropy loss = 1.1469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:28.464424 #train# step   32, loss = 1.1261, cross_entropy loss = 1.1261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:29.978662 #train# step   33, loss = 1.1219, cross_entropy loss = 1.1219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:31.519594 #train# step   34, loss = 1.1326, cross_entropy loss = 1.1326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:33.078891 #train# step   35, loss = 1.1250, cross_entropy loss = 1.1250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:34.607734 #train# step   36, loss = 1.0933, cross_entropy loss = 1.0933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:36.141880 #train# step   37, loss = 1.1141, cross_entropy loss = 1.1141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:37.684031 #train# step   38, loss = 1.0981, cross_entropy loss = 1.0981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:39.231304 #train# step   39, loss = 1.0940, cross_entropy loss = 1.0940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:40.763624 #train# step   40, loss = 1.1273, cross_entropy loss = 1.1273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:42.304480 #train# step   41, loss = 1.0953, cross_entropy loss = 1.0953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:43.871388 #train# step   42, loss = 1.1037, cross_entropy loss = 1.1037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:45.421135 #train# step   43, loss = 1.1276, cross_entropy loss = 1.1276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:46.968102 #train# step   44, loss = 1.1003, cross_entropy loss = 1.1003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:48.528982 #train# step   45, loss = 1.0895, cross_entropy loss = 1.0895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:50.043213 #train# step   46, loss = 1.1167, cross_entropy loss = 1.1167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:51.580285 #train# step   47, loss = 1.1109, cross_entropy loss = 1.1109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:53.139284 #train# step   48, loss = 1.0894, cross_entropy loss = 1.0894, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:54.688779 #train# step   49, loss = 1.0837, cross_entropy loss = 1.0837, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:56.221253 #train# step   50, loss = 1.1019, cross_entropy loss = 1.1019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:57.782429 #train# step   51, loss = 1.0818, cross_entropy loss = 1.0818, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:14:59.334270 #train# step   52, loss = 1.0858, cross_entropy loss = 1.0858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:00.881010 #train# step   53, loss = 1.0803, cross_entropy loss = 1.0803, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:02.414488 #train# step   54, loss = 1.1270, cross_entropy loss = 1.1270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:03.994279 #train# step   55, loss = 1.0860, cross_entropy loss = 1.0860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:05.561457 #train# step   56, loss = 1.0858, cross_entropy loss = 1.0858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:07.118108 #train# step   57, loss = 1.0871, cross_entropy loss = 1.0871, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:08.664704 #train# step   58, loss = 1.0982, cross_entropy loss = 1.0982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:10.226679 #train# step   59, loss = 1.0855, cross_entropy loss = 1.0855, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:11.779294 #train# step   60, loss = 1.0912, cross_entropy loss = 1.0912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:13.323752 #train# step   61, loss = 1.0770, cross_entropy loss = 1.0770, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:14.834370 #train# step   62, loss = 1.0778, cross_entropy loss = 1.0778, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:16.357507 #train# step   63, loss = 1.0824, cross_entropy loss = 1.0824, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:17.881132 #train# step   64, loss = 1.0909, cross_entropy loss = 1.0909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:19.414668 #train# step   65, loss = 1.0916, cross_entropy loss = 1.0916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:20.970982 #train# step   66, loss = 1.0839, cross_entropy loss = 1.0839, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:22.512028 #train# step   67, loss = 1.0750, cross_entropy loss = 1.0750, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:24.034084 #train# step   68, loss = 1.1001, cross_entropy loss = 1.1001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:25.561685 #train# step   69, loss = 1.0903, cross_entropy loss = 1.0903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:27.092910 #train# step   70, loss = 1.0842, cross_entropy loss = 1.0842, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:28.609799 #train# step   71, loss = 1.0629, cross_entropy loss = 1.0629, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:30.135937 #train# step   72, loss = 1.0991, cross_entropy loss = 1.0991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:31.675936 #train# step   73, loss = 1.0775, cross_entropy loss = 1.0775, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:33.202879 #train# step   74, loss = 1.0720, cross_entropy loss = 1.0720, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:34.771807 #train# step   75, loss = 1.1073, cross_entropy loss = 1.1073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:36.360420 #train# step   76, loss = 1.1002, cross_entropy loss = 1.1002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:37.882079 #train# step   77, loss = 1.0939, cross_entropy loss = 1.0939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:39.394925 #train# step   78, loss = 1.0930, cross_entropy loss = 1.0930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:40.922110 #train# step   79, loss = 1.1028, cross_entropy loss = 1.1028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:42.461845 #train# step   80, loss = 1.0937, cross_entropy loss = 1.0937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:44.032780 #train# step   81, loss = 1.0761, cross_entropy loss = 1.0761, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:45.609651 #train# step   82, loss = 1.0789, cross_entropy loss = 1.0789, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:47.172354 #train# step   83, loss = 1.0976, cross_entropy loss = 1.0976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:48.700211 #train# step   84, loss = 1.0763, cross_entropy loss = 1.0763, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:50.228289 #train# step   85, loss = 1.0749, cross_entropy loss = 1.0749, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:51.795456 #train# step   86, loss = 1.0711, cross_entropy loss = 1.0711, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:53.349470 #train# step   87, loss = 1.0567, cross_entropy loss = 1.0567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:54.886364 #train# step   88, loss = 1.0887, cross_entropy loss = 1.0887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:56.439863 #train# step   89, loss = 1.0981, cross_entropy loss = 1.0981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:57.972977 #train# step   90, loss = 1.0627, cross_entropy loss = 1.0627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:15:59.504756 #train# step   91, loss = 1.0814, cross_entropy loss = 1.0814, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:01.032367 #train# step   92, loss = 1.0772, cross_entropy loss = 1.0772, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:02.577497 #train# step   93, loss = 1.0622, cross_entropy loss = 1.0622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:04.104172 #train# step   94, loss = 1.0852, cross_entropy loss = 1.0852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:05.654460 #train# step   95, loss = 1.0859, cross_entropy loss = 1.0859, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:07.180344 #train# step   96, loss = 1.0675, cross_entropy loss = 1.0675, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:08.739875 #train# step   97, loss = 1.0564, cross_entropy loss = 1.0564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:10.300531 #train# step   98, loss = 1.0808, cross_entropy loss = 1.0808, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:11.847266 #train# step   99, loss = 1.0800, cross_entropy loss = 1.0800, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:13.370468 #train# step  100, loss = 1.1009, cross_entropy loss = 1.1009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:14.900280 #train# step  101, loss = 1.0915, cross_entropy loss = 1.0915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:16.446899 #train# step  102, loss = 1.0592, cross_entropy loss = 1.0592, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:17.982852 #train# step  103, loss = 1.0669, cross_entropy loss = 1.0669, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:19.512322 #train# step  104, loss = 1.0814, cross_entropy loss = 1.0814, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:21.089175 #train# step  105, loss = 1.0574, cross_entropy loss = 1.0574, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:22.598683 #train# step  106, loss = 1.0896, cross_entropy loss = 1.0896, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:24.153155 #train# step  107, loss = 1.0844, cross_entropy loss = 1.0844, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:25.702037 #train# step  108, loss = 1.0563, cross_entropy loss = 1.0563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:27.252405 #train# step  109, loss = 1.0713, cross_entropy loss = 1.0713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:28.784107 #train# step  110, loss = 1.0682, cross_entropy loss = 1.0682, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:30.310871 #train# step  111, loss = 1.0533, cross_entropy loss = 1.0533, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:31.863935 #train# step  112, loss = 1.0746, cross_entropy loss = 1.0746, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:33.399641 #train# step  113, loss = 1.0603, cross_entropy loss = 1.0603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:34.941996 #train# step  114, loss = 1.0552, cross_entropy loss = 1.0552, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:36.500867 #train# step  115, loss = 1.0513, cross_entropy loss = 1.0513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:38.082776 #train# step  116, loss = 1.0735, cross_entropy loss = 1.0735, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:39.629107 #train# step  117, loss = 1.0601, cross_entropy loss = 1.0601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:41.165544 #train# step  118, loss = 1.0481, cross_entropy loss = 1.0481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:42.681564 #train# step  119, loss = 1.0831, cross_entropy loss = 1.0831, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:44.253698 #train# step  120, loss = 1.0485, cross_entropy loss = 1.0485, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:45.806387 #train# step  121, loss = 1.0570, cross_entropy loss = 1.0570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:47.356298 #train# step  122, loss = 1.0703, cross_entropy loss = 1.0703, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:48.899310 #train# step  123, loss = 1.0545, cross_entropy loss = 1.0545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:50.442729 #train# step  124, loss = 1.0631, cross_entropy loss = 1.0631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:51.965327 #train# step  125, loss = 1.0557, cross_entropy loss = 1.0557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:53.495242 #train# step  126, loss = 1.0746, cross_entropy loss = 1.0746, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:55.041459 #train# step  127, loss = 1.0589, cross_entropy loss = 1.0589, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:56.594089 #train# step  128, loss = 1.0451, cross_entropy loss = 1.0451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:58.143682 #train# step  129, loss = 1.0708, cross_entropy loss = 1.0708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:16:59.666012 #train# step  130, loss = 1.0690, cross_entropy loss = 1.0690, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:01.199264 #train# step  131, loss = 1.0612, cross_entropy loss = 1.0612, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:02.749368 #train# step  132, loss = 1.0650, cross_entropy loss = 1.0650, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:04.280759 #train# step  133, loss = 1.0390, cross_entropy loss = 1.0390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:05.831523 #train# step  134, loss = 1.0515, cross_entropy loss = 1.0515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:07.374846 #train# step  135, loss = 1.0560, cross_entropy loss = 1.0560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:08.941225 #train# step  136, loss = 1.0546, cross_entropy loss = 1.0546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:10.518300 #train# step  137, loss = 1.0445, cross_entropy loss = 1.0445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:12.054054 #train# step  138, loss = 1.0461, cross_entropy loss = 1.0461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:13.571928 #train# step  139, loss = 1.0703, cross_entropy loss = 1.0703, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:15.117621 #train# step  140, loss = 1.0720, cross_entropy loss = 1.0720, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:16.676400 #train# step  141, loss = 1.0417, cross_entropy loss = 1.0417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:18.220833 #train# step  142, loss = 1.0517, cross_entropy loss = 1.0517, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:19.758020 #train# step  143, loss = 1.0493, cross_entropy loss = 1.0493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:21.285318 #train# step  144, loss = 1.0666, cross_entropy loss = 1.0666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:22.843519 #train# step  145, loss = 1.0385, cross_entropy loss = 1.0385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:24.395848 #train# step  146, loss = 1.0415, cross_entropy loss = 1.0415, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:25.947873 #train# step  147, loss = 1.0452, cross_entropy loss = 1.0452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:27.499768 #train# step  148, loss = 1.0410, cross_entropy loss = 1.0410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:29.061851 #train# step  149, loss = 1.0595, cross_entropy loss = 1.0595, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:30.598270 #train# step  150, loss = 1.0323, cross_entropy loss = 1.0323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:32.112455 #train# step  151, loss = 1.0737, cross_entropy loss = 1.0737, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:33.632567 #train# step  152, loss = 1.0557, cross_entropy loss = 1.0557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:35.164867 #train# step  153, loss = 1.0436, cross_entropy loss = 1.0436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:36.710532 #train# step  154, loss = 1.0465, cross_entropy loss = 1.0465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:38.244022 #train# step  155, loss = 1.0302, cross_entropy loss = 1.0302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:39.811035 #train# step  156, loss = 1.0604, cross_entropy loss = 1.0604, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:41.359982 #train# step  157, loss = 1.0539, cross_entropy loss = 1.0539, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:42.895688 #train# step  158, loss = 1.0367, cross_entropy loss = 1.0367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:44.442564 #train# step  159, loss = 1.0366, cross_entropy loss = 1.0366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:45.981633 #train# step  160, loss = 1.0375, cross_entropy loss = 1.0375, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:47.516505 #train# step  161, loss = 1.0248, cross_entropy loss = 1.0248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:49.047492 #train# step  162, loss = 1.0302, cross_entropy loss = 1.0302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:50.592688 #train# step  163, loss = 1.0340, cross_entropy loss = 1.0340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:52.115506 #train# step  164, loss = 1.0516, cross_entropy loss = 1.0516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:53.655229 #train# step  165, loss = 1.0496, cross_entropy loss = 1.0496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:55.213651 #train# step  166, loss = 1.0402, cross_entropy loss = 1.0402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:56.740803 #train# step  167, loss = 1.0454, cross_entropy loss = 1.0454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:58.304275 #train# step  168, loss = 1.0302, cross_entropy loss = 1.0302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:17:59.855318 #train# step  169, loss = 1.0460, cross_entropy loss = 1.0460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:01.402320 #train# step  170, loss = 1.0435, cross_entropy loss = 1.0435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:02.967305 #train# step  171, loss = 1.0469, cross_entropy loss = 1.0469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:04.515169 #train# step  172, loss = 1.0271, cross_entropy loss = 1.0271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:06.097195 #train# step  173, loss = 1.0254, cross_entropy loss = 1.0254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:07.650133 #train# step  174, loss = 1.0245, cross_entropy loss = 1.0245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:09.200470 #train# step  175, loss = 1.0476, cross_entropy loss = 1.0476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:10.749769 #train# step  176, loss = 1.0342, cross_entropy loss = 1.0342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:12.303600 #train# step  177, loss = 1.0182, cross_entropy loss = 1.0182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:13.824187 #train# step  178, loss = 1.0509, cross_entropy loss = 1.0509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:15.374555 #train# step  179, loss = 1.0530, cross_entropy loss = 1.0530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:16.928168 #train# step  180, loss = 1.0379, cross_entropy loss = 1.0379, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:18.462693 #train# step  181, loss = 1.0378, cross_entropy loss = 1.0378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:19.990879 #train# step  182, loss = 1.0263, cross_entropy loss = 1.0263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:21.568797 #train# step  183, loss = 1.0388, cross_entropy loss = 1.0388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:23.135928 #train# step  184, loss = 1.0456, cross_entropy loss = 1.0456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:24.654811 #train# step  185, loss = 1.0267, cross_entropy loss = 1.0267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:26.199066 #train# step  186, loss = 1.0548, cross_entropy loss = 1.0548, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:27.741793 #train# step  187, loss = 1.0163, cross_entropy loss = 1.0163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:29.273283 #train# step  188, loss = 1.0503, cross_entropy loss = 1.0503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:30.807786 #train# step  189, loss = 1.0349, cross_entropy loss = 1.0349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:32.367400 #train# step  190, loss = 1.0344, cross_entropy loss = 1.0344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:33.943679 #train# step  191, loss = 1.0364, cross_entropy loss = 1.0364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:35.493576 #train# step  192, loss = 1.0481, cross_entropy loss = 1.0481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:37.022154 #train# step  193, loss = 1.0407, cross_entropy loss = 1.0407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:38.589101 #train# step  194, loss = 1.0279, cross_entropy loss = 1.0279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:40.135276 #train# step  195, loss = 1.0314, cross_entropy loss = 1.0314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:41.691779 #train# step  196, loss = 1.0402, cross_entropy loss = 1.0402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:43.239758 #train# step  197, loss = 1.0305, cross_entropy loss = 1.0305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:44.777531 #train# step  198, loss = 1.0249, cross_entropy loss = 1.0249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:46.346072 #train# step  199, loss = 1.0126, cross_entropy loss = 1.0126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:47.928576 #train# step  200, loss = 1.0275, cross_entropy loss = 1.0275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:49.486285 #train# step  201, loss = 1.0358, cross_entropy loss = 1.0358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:51.039634 #train# step  202, loss = 1.0271, cross_entropy loss = 1.0271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:52.585410 #train# step  203, loss = 1.0183, cross_entropy loss = 1.0183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:54.129974 #train# step  204, loss = 1.0473, cross_entropy loss = 1.0473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:55.674605 #train# step  205, loss = 1.0276, cross_entropy loss = 1.0276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:57.214336 #train# step  206, loss = 1.0343, cross_entropy loss = 1.0343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:18:58.752933 #train# step  207, loss = 1.0226, cross_entropy loss = 1.0226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:00.301609 #train# step  208, loss = 1.0272, cross_entropy loss = 1.0272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:01.869639 #train# step  209, loss = 1.0300, cross_entropy loss = 1.0300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:03.384958 #train# step  210, loss = 1.0271, cross_entropy loss = 1.0271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:04.909416 #train# step  211, loss = 1.0276, cross_entropy loss = 1.0276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:06.449899 #train# step  212, loss = 1.0283, cross_entropy loss = 1.0283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:07.966113 #train# step  213, loss = 1.0261, cross_entropy loss = 1.0261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:09.495840 #train# step  214, loss = 1.0352, cross_entropy loss = 1.0352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:11.061997 #train# step  215, loss = 1.0249, cross_entropy loss = 1.0249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:12.625187 #train# step  216, loss = 1.0274, cross_entropy loss = 1.0274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:14.138401 #train# step  217, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:15.656629 #train# step  218, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:17.206732 #train# step  219, loss = 1.0448, cross_entropy loss = 1.0448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:18.724362 #train# step  220, loss = 1.0147, cross_entropy loss = 1.0147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:20.252818 #train# step  221, loss = 1.0284, cross_entropy loss = 1.0284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:21.792078 #train# step  222, loss = 1.0115, cross_entropy loss = 1.0115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:23.324796 #train# step  223, loss = 1.0264, cross_entropy loss = 1.0264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:24.844065 #train# step  224, loss = 1.0418, cross_entropy loss = 1.0418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:26.383222 #train# step  225, loss = 1.0347, cross_entropy loss = 1.0347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:27.959468 #train# step  226, loss = 1.0143, cross_entropy loss = 1.0143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:29.529324 #train# step  227, loss = 1.0260, cross_entropy loss = 1.0260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:31.091073 #train# step  228, loss = 1.0322, cross_entropy loss = 1.0322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:32.649000 #train# step  229, loss = 1.0295, cross_entropy loss = 1.0295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:34.217724 #train# step  230, loss = 1.0271, cross_entropy loss = 1.0271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:35.753922 #train# step  231, loss = 1.0404, cross_entropy loss = 1.0404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:37.283107 #train# step  232, loss = 1.0259, cross_entropy loss = 1.0259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:38.814791 #train# step  233, loss = 1.0215, cross_entropy loss = 1.0215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:40.367639 #train# step  234, loss = 1.0296, cross_entropy loss = 1.0296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:41.926199 #train# step  235, loss = 1.0278, cross_entropy loss = 1.0278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:43.462272 #train# step  236, loss = 1.0241, cross_entropy loss = 1.0241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:45.013322 #train# step  237, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:46.574855 #train# step  238, loss = 1.0341, cross_entropy loss = 1.0341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:48.135101 #train# step  239, loss = 1.0120, cross_entropy loss = 1.0120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:49.686003 #train# step  240, loss = 1.0290, cross_entropy loss = 1.0290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:51.257088 #train# step  241, loss = 1.0042, cross_entropy loss = 1.0042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:52.802640 #train# step  242, loss = 1.0254, cross_entropy loss = 1.0254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:54.332839 #train# step  243, loss = 1.0195, cross_entropy loss = 1.0195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:55.885081 #train# step  244, loss = 0.9967, cross_entropy loss = 0.9967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:57.435027 #train# step  245, loss = 1.0204, cross_entropy loss = 1.0204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:19:59.008203 #train# step  246, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:00.543680 #train# step  247, loss = 1.0166, cross_entropy loss = 1.0166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:02.117751 #train# step  248, loss = 1.0297, cross_entropy loss = 1.0297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:03.665708 #train# step  249, loss = 1.0301, cross_entropy loss = 1.0301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:05.222095 #train# step  250, loss = 1.0213, cross_entropy loss = 1.0213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:06.755284 #train# step  251, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:08.290828 #train# step  252, loss = 1.0194, cross_entropy loss = 1.0194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:09.826466 #train# step  253, loss = 1.0270, cross_entropy loss = 1.0270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:11.399159 #train# step  254, loss = 1.0282, cross_entropy loss = 1.0282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:12.995295 #train# step  255, loss = 1.0212, cross_entropy loss = 1.0212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:14.533191 #train# step  256, loss = 1.0183, cross_entropy loss = 1.0183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:16.035624 #train# step  257, loss = 1.0400, cross_entropy loss = 1.0400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:17.555319 #train# step  258, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:19.113589 #train# step  259, loss = 1.0124, cross_entropy loss = 1.0124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:20.654229 #train# step  260, loss = 1.0253, cross_entropy loss = 1.0253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:22.227729 #train# step  261, loss = 1.0149, cross_entropy loss = 1.0149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:23.751495 #train# step  262, loss = 1.0317, cross_entropy loss = 1.0317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:25.297415 #train# step  263, loss = 1.0127, cross_entropy loss = 1.0127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:26.849994 #train# step  264, loss = 1.0221, cross_entropy loss = 1.0221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:28.385989 #train# step  265, loss = 1.0222, cross_entropy loss = 1.0222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:29.940270 #train# step  266, loss = 1.0171, cross_entropy loss = 1.0171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:31.484647 #train# step  267, loss = 1.0474, cross_entropy loss = 1.0474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:33.034094 #train# step  268, loss = 1.0171, cross_entropy loss = 1.0171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:34.562207 #train# step  269, loss = 1.0173, cross_entropy loss = 1.0173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:36.110893 #train# step  270, loss = 1.0262, cross_entropy loss = 1.0262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:37.658299 #train# step  271, loss = 1.0020, cross_entropy loss = 1.0020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:39.211806 #train# step  272, loss = 1.0256, cross_entropy loss = 1.0256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:40.771845 #train# step  273, loss = 1.0271, cross_entropy loss = 1.0271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:42.297903 #train# step  274, loss = 1.0354, cross_entropy loss = 1.0354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:43.837697 #train# step  275, loss = 1.0086, cross_entropy loss = 1.0086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:45.387813 #train# step  276, loss = 1.0046, cross_entropy loss = 1.0046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:46.907728 #train# step  277, loss = 1.0249, cross_entropy loss = 1.0249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:48.450090 #train# step  278, loss = 1.0236, cross_entropy loss = 1.0236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:49.999965 #train# step  279, loss = 1.0100, cross_entropy loss = 1.0100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:51.530143 #train# step  280, loss = 1.0140, cross_entropy loss = 1.0140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:53.064518 #train# step  281, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:54.609179 #train# step  282, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:56.155303 #train# step  283, loss = 1.0206, cross_entropy loss = 1.0206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:57.702096 #train# step  284, loss = 1.0269, cross_entropy loss = 1.0269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:20:59.224965 #train# step  285, loss = 1.0290, cross_entropy loss = 1.0290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:00.792032 #train# step  286, loss = 1.0260, cross_entropy loss = 1.0260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:02.308680 #train# step  287, loss = 1.0166, cross_entropy loss = 1.0166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:03.864691 #train# step  288, loss = 1.0130, cross_entropy loss = 1.0130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:05.420443 #train# step  289, loss = 1.0260, cross_entropy loss = 1.0260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:06.969747 #train# step  290, loss = 1.0130, cross_entropy loss = 1.0130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:08.495392 #train# step  291, loss = 0.9979, cross_entropy loss = 0.9979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:10.024540 #train# step  292, loss = 0.9996, cross_entropy loss = 0.9996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:11.570293 #train# step  293, loss = 1.0086, cross_entropy loss = 1.0086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:13.104896 #train# step  294, loss = 1.0325, cross_entropy loss = 1.0325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:14.663310 #train# step  295, loss = 1.0092, cross_entropy loss = 1.0092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:16.212610 #train# step  296, loss = 0.9903, cross_entropy loss = 0.9903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:17.759267 #train# step  297, loss = 1.0246, cross_entropy loss = 1.0246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:19.320327 #train# step  298, loss = 1.0242, cross_entropy loss = 1.0242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:20.879753 #train# step  299, loss = 0.9961, cross_entropy loss = 0.9961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:22.431808 #train# step  300, loss = 1.0113, cross_entropy loss = 1.0113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:23.970323 #train# step  301, loss = 1.0110, cross_entropy loss = 1.0110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:25.525061 #train# step  302, loss = 1.0118, cross_entropy loss = 1.0118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:27.067468 #train# step  303, loss = 1.0118, cross_entropy loss = 1.0118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:28.628492 #train# step  304, loss = 1.0171, cross_entropy loss = 1.0171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:30.174132 #train# step  305, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:31.754884 #train# step  306, loss = 1.0116, cross_entropy loss = 1.0116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:33.294133 #train# step  307, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:34.859452 #train# step  308, loss = 1.0116, cross_entropy loss = 1.0116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:36.411976 #train# step  309, loss = 1.0085, cross_entropy loss = 1.0085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:37.954675 #train# step  310, loss = 1.0048, cross_entropy loss = 1.0048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:39.513798 #train# step  311, loss = 1.0253, cross_entropy loss = 1.0253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:41.027999 #train# step  312, loss = 0.9913, cross_entropy loss = 0.9913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:42.567066 #train# step  313, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:44.078099 #train# step  314, loss = 1.0134, cross_entropy loss = 1.0134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:45.618345 #train# step  315, loss = 1.0160, cross_entropy loss = 1.0160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:47.175587 #train# step  316, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:48.726920 #train# step  317, loss = 1.0136, cross_entropy loss = 1.0136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:50.292358 #train# step  318, loss = 1.0037, cross_entropy loss = 1.0037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:51.828669 #train# step  319, loss = 1.0069, cross_entropy loss = 1.0069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:53.363153 #train# step  320, loss = 1.0142, cross_entropy loss = 1.0142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:54.900609 #train# step  321, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:56.441925 #train# step  322, loss = 1.0162, cross_entropy loss = 1.0162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:57.981601 #train# step  323, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:21:59.531849 #train# step  324, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:01.090959 #train# step  325, loss = 1.0212, cross_entropy loss = 1.0212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:02.682440 #train# step  326, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:04.244853 #train# step  327, loss = 1.0159, cross_entropy loss = 1.0159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:05.771196 #train# step  328, loss = 0.9993, cross_entropy loss = 0.9993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:07.316384 #train# step  329, loss = 1.0193, cross_entropy loss = 1.0193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:08.835618 #train# step  330, loss = 1.0215, cross_entropy loss = 1.0215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:10.365656 #train# step  331, loss = 1.0149, cross_entropy loss = 1.0149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:11.887682 #train# step  332, loss = 1.0042, cross_entropy loss = 1.0042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:13.402395 #train# step  333, loss = 1.0075, cross_entropy loss = 1.0075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:14.927948 #train# step  334, loss = 1.0050, cross_entropy loss = 1.0050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:16.481482 #train# step  335, loss = 1.0117, cross_entropy loss = 1.0117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:18.040250 #train# step  336, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:19.567345 #train# step  337, loss = 1.0137, cross_entropy loss = 1.0137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:21.109602 #train# step  338, loss = 1.0158, cross_entropy loss = 1.0158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:22.653728 #train# step  339, loss = 1.0129, cross_entropy loss = 1.0129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:24.190205 #train# step  340, loss = 1.0030, cross_entropy loss = 1.0030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:25.777229 #train# step  341, loss = 0.9916, cross_entropy loss = 0.9916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:27.335222 #train# step  342, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:28.885656 #train# step  343, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:30.395346 #train# step  344, loss = 1.0052, cross_entropy loss = 1.0052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:31.950598 #train# step  345, loss = 1.0102, cross_entropy loss = 1.0102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:33.528527 #train# step  346, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:35.074167 #train# step  347, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:36.604307 #train# step  348, loss = 1.0103, cross_entropy loss = 1.0103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:38.163037 #train# step  349, loss = 1.0160, cross_entropy loss = 1.0160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:39.666890 #train# step  350, loss = 1.0148, cross_entropy loss = 1.0148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:41.194397 #train# step  351, loss = 1.0020, cross_entropy loss = 1.0020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:42.753683 #train# step  352, loss = 0.9987, cross_entropy loss = 0.9987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:44.287215 #train# step  353, loss = 1.0052, cross_entropy loss = 1.0052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:45.832633 #train# step  354, loss = 1.0100, cross_entropy loss = 1.0100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:47.394252 #train# step  355, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:48.941004 #train# step  356, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:50.511865 #train# step  357, loss = 1.0350, cross_entropy loss = 1.0350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:52.089081 #train# step  358, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:53.607013 #train# step  359, loss = 1.0082, cross_entropy loss = 1.0082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:55.185411 #train# step  360, loss = 1.0073, cross_entropy loss = 1.0073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:56.750432 #train# step  361, loss = 1.0115, cross_entropy loss = 1.0115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:58.303639 #train# step  362, loss = 1.0104, cross_entropy loss = 1.0104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:22:59.842047 #train# step  363, loss = 1.0127, cross_entropy loss = 1.0127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:01.373534 #train# step  364, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:02.929416 #train# step  365, loss = 1.0105, cross_entropy loss = 1.0105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:04.472501 #train# step  366, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:05.990602 #train# step  367, loss = 1.0112, cross_entropy loss = 1.0112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:07.576122 #train# step  368, loss = 1.0057, cross_entropy loss = 1.0057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:09.140356 #train# step  369, loss = 1.0013, cross_entropy loss = 1.0013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:10.658327 #train# step  370, loss = 1.0106, cross_entropy loss = 1.0106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:12.211727 #train# step  371, loss = 0.9962, cross_entropy loss = 0.9962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:13.749279 #train# step  372, loss = 1.0002, cross_entropy loss = 1.0002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:15.293629 #train# step  373, loss = 0.9777, cross_entropy loss = 0.9777, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:16.845468 #train# step  374, loss = 1.0171, cross_entropy loss = 1.0171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:18.421285 #train# step  375, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:19.955885 #train# step  376, loss = 0.9927, cross_entropy loss = 0.9927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:21.527157 #train# step  377, loss = 1.0006, cross_entropy loss = 1.0006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:23.084538 #train# step  378, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:24.581409 #train# step  379, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:26.160640 #train# step  380, loss = 1.0032, cross_entropy loss = 1.0032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:27.711770 #train# step  381, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:29.250870 #train# step  382, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:30.813912 #train# step  383, loss = 1.0070, cross_entropy loss = 1.0070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:32.392276 #train# step  384, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:33.935141 #train# step  385, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:35.500001 #train# step  386, loss = 1.0104, cross_entropy loss = 1.0104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:37.025955 #train# step  387, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:38.559992 #train# step  388, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:40.069976 #train# step  389, loss = 1.0139, cross_entropy loss = 1.0139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:41.629862 #train# step  390, loss = 1.0105, cross_entropy loss = 1.0105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:43.191495 #train# step  391, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:44.713640 #train# step  392, loss = 1.0064, cross_entropy loss = 1.0064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:46.267645 #train# step  393, loss = 1.0086, cross_entropy loss = 1.0086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:47.839334 #train# step  394, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:49.384723 #train# step  395, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:50.945835 #train# step  396, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:52.483934 #train# step  397, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:54.036974 #train# step  398, loss = 0.9976, cross_entropy loss = 0.9976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:55.591741 #train# step  399, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:57.142105 #train# step  400, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:23:58.664641 #train# step  401, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:00.233186 #train# step  402, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:01.765926 #train# step  403, loss = 0.9988, cross_entropy loss = 0.9988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:03.337202 #train# step  404, loss = 0.9992, cross_entropy loss = 0.9992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:04.897664 #train# step  405, loss = 1.0030, cross_entropy loss = 1.0030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:06.480084 #train# step  406, loss = 1.0050, cross_entropy loss = 1.0050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:08.016313 #train# step  407, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:09.545822 #train# step  408, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:11.085905 #train# step  409, loss = 0.9966, cross_entropy loss = 0.9966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:12.634367 #train# step  410, loss = 1.0095, cross_entropy loss = 1.0095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:14.176510 #train# step  411, loss = 1.0003, cross_entropy loss = 1.0003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:15.716796 #train# step  412, loss = 1.0073, cross_entropy loss = 1.0073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:17.251215 #train# step  413, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:18.812918 #train# step  414, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:20.334542 #train# step  415, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:21.876994 #train# step  416, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:23.408912 #train# step  417, loss = 0.9914, cross_entropy loss = 0.9914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:24.926575 #train# step  418, loss = 0.9946, cross_entropy loss = 0.9946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:26.494205 #train# step  419, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:28.014847 #train# step  420, loss = 1.0217, cross_entropy loss = 1.0217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:29.593509 #train# step  421, loss = 0.9885, cross_entropy loss = 0.9885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:31.136108 #train# step  422, loss = 1.0001, cross_entropy loss = 1.0001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:32.665440 #train# step  423, loss = 1.0021, cross_entropy loss = 1.0021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:34.219369 #train# step  424, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:35.750195 #train# step  425, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:37.324312 #train# step  426, loss = 1.0055, cross_entropy loss = 1.0055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:38.870590 #train# step  427, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:40.416328 #train# step  428, loss = 0.9962, cross_entropy loss = 0.9962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:41.988420 #train# step  429, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:43.527199 #train# step  430, loss = 1.0054, cross_entropy loss = 1.0054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:45.091252 #train# step  431, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:46.625352 #train# step  432, loss = 0.9966, cross_entropy loss = 0.9966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:48.151775 #train# step  433, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:49.691026 #train# step  434, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:51.249381 #train# step  435, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:52.768915 #train# step  436, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:54.303802 #train# step  437, loss = 1.0000, cross_entropy loss = 1.0000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:55.855820 #train# step  438, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:57.394268 #train# step  439, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:24:58.956483 #train# step  440, loss = 0.9777, cross_entropy loss = 0.9777, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:00.497718 #train# step  441, loss = 0.9894, cross_entropy loss = 0.9894, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:02.073384 #train# step  442, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:03.571751 #train# step  443, loss = 0.9914, cross_entropy loss = 0.9914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:05.099336 #train# step  444, loss = 1.0076, cross_entropy loss = 1.0076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:06.665536 #train# step  445, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:08.219839 #train# step  446, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:09.784140 #train# step  447, loss = 1.0095, cross_entropy loss = 1.0095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:11.329295 #train# step  448, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:12.889126 #train# step  449, loss = 1.0022, cross_entropy loss = 1.0022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:14.462675 #train# step  450, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:16.007844 #train# step  451, loss = 1.0100, cross_entropy loss = 1.0100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:17.561929 #train# step  452, loss = 1.0019, cross_entropy loss = 1.0019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:19.097703 #train# step  453, loss = 1.0040, cross_entropy loss = 1.0040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:20.659655 #train# step  454, loss = 0.9865, cross_entropy loss = 0.9865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:22.228940 #train# step  455, loss = 0.9795, cross_entropy loss = 0.9795, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:23.743753 #train# step  456, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:25.290467 #train# step  457, loss = 1.0032, cross_entropy loss = 1.0032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:26.806223 #train# step  458, loss = 1.0029, cross_entropy loss = 1.0029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:28.355547 #train# step  459, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:29.877937 #train# step  460, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:31.399317 #train# step  461, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:32.947137 #train# step  462, loss = 0.9742, cross_entropy loss = 0.9742, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:34.450856 #train# step  463, loss = 1.0143, cross_entropy loss = 1.0143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:36.018042 #train# step  464, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:37.558463 #train# step  465, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:39.087232 #train# step  466, loss = 0.9817, cross_entropy loss = 0.9817, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:40.643145 #train# step  467, loss = 0.9811, cross_entropy loss = 0.9811, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:42.195164 #train# step  468, loss = 0.9890, cross_entropy loss = 0.9890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:43.726917 #train# step  469, loss = 0.9951, cross_entropy loss = 0.9951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:45.256476 #train# step  470, loss = 1.0058, cross_entropy loss = 1.0058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:46.789006 #train# step  471, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:48.376437 #train# step  472, loss = 0.9903, cross_entropy loss = 0.9903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:49.916627 #train# step  473, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:51.459852 #train# step  474, loss = 0.9907, cross_entropy loss = 0.9907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:52.995243 #train# step  475, loss = 0.9883, cross_entropy loss = 0.9883, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:54.554476 #train# step  476, loss = 0.9888, cross_entropy loss = 0.9888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:56.121650 #train# step  477, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:57.682931 #train# step  478, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:25:59.235434 #train# step  479, loss = 0.9980, cross_entropy loss = 0.9980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:00.756707 #train# step  480, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:02.287853 #train# step  481, loss = 1.0045, cross_entropy loss = 1.0045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:03.845228 #train# step  482, loss = 1.0001, cross_entropy loss = 1.0001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:05.418285 #train# step  483, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:06.940429 #train# step  484, loss = 1.0018, cross_entropy loss = 1.0018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:08.499405 #train# step  485, loss = 1.0116, cross_entropy loss = 1.0116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:10.038875 #train# step  486, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:11.580391 #train# step  487, loss = 0.9919, cross_entropy loss = 0.9919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:13.126404 #train# step  488, loss = 0.9945, cross_entropy loss = 0.9945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:14.688970 #train# step  489, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:16.231135 #train# step  490, loss = 1.0036, cross_entropy loss = 1.0036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:17.784688 #train# step  491, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:19.317434 #train# step  492, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:20.835108 #train# step  493, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:22.373981 #train# step  494, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:23.916642 #train# step  495, loss = 1.0020, cross_entropy loss = 1.0020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:25.476697 #train# step  496, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:26.984369 #train# step  497, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:28.511516 #train# step  498, loss = 0.9919, cross_entropy loss = 0.9919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:30.071260 #train# step  499, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:31.607750 #train# step  500, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:33.144585 #train# step  501, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:34.655841 #train# step  502, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:36.189290 #train# step  503, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:37.718251 #train# step  504, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:39.270412 #train# step  505, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:40.847776 #train# step  506, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:42.407013 #train# step  507, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:43.949841 #train# step  508, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:45.458567 #train# step  509, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:47.010506 #train# step  510, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:48.568055 #train# step  511, loss = 0.9933, cross_entropy loss = 0.9933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:50.114847 #train# step  512, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:51.639930 #train# step  513, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:53.171631 #train# step  514, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:54.744738 #train# step  515, loss = 0.9975, cross_entropy loss = 0.9975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:56.277539 #train# step  516, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:57.854049 #train# step  517, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:26:59.385738 #train# step  518, loss = 0.9925, cross_entropy loss = 0.9925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:00.910281 #train# step  519, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:02.477353 #train# step  520, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:04.006937 #train# step  521, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:05.535392 #train# step  522, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:07.067992 #train# step  523, loss = 0.9895, cross_entropy loss = 0.9895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:08.606585 #train# step  524, loss = 1.0038, cross_entropy loss = 1.0038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:10.148063 #train# step  525, loss = 1.0021, cross_entropy loss = 1.0021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:11.687883 #train# step  526, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:13.228940 #train# step  527, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:14.800601 #train# step  528, loss = 0.9922, cross_entropy loss = 0.9922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:16.333954 #train# step  529, loss = 0.9928, cross_entropy loss = 0.9928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:17.888107 #train# step  530, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:19.430583 #train# step  531, loss = 0.9946, cross_entropy loss = 0.9946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:21.008160 #train# step  532, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:22.532481 #train# step  533, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:24.065985 #train# step  534, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:25.619139 #train# step  535, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:27.159168 #train# step  536, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:28.700610 #train# step  537, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:30.253666 #train# step  538, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:31.814945 #train# step  539, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:33.365701 #train# step  540, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:34.903057 #train# step  541, loss = 0.9845, cross_entropy loss = 0.9845, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:36.439525 #train# step  542, loss = 0.9923, cross_entropy loss = 0.9923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:37.961052 #train# step  543, loss = 0.9945, cross_entropy loss = 0.9945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:39.508836 #train# step  544, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:41.022205 #train# step  545, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:42.591662 #train# step  546, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:44.155670 #train# step  547, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:45.700200 #train# step  548, loss = 0.9962, cross_entropy loss = 0.9962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:47.265704 #train# step  549, loss = 0.9861, cross_entropy loss = 0.9861, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:48.796720 #train# step  550, loss = 0.9885, cross_entropy loss = 0.9885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:50.336341 #train# step  551, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:51.891179 #train# step  552, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:53.461205 #train# step  553, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:54.984374 #train# step  554, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:56.541890 #train# step  555, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:58.087951 #train# step  556, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:27:59.624655 #train# step  557, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:01.166052 #train# step  558, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:02.696767 #train# step  559, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:04.210846 #train# step  560, loss = 0.9957, cross_entropy loss = 0.9957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:05.794049 #train# step  561, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:07.357091 #train# step  562, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:08.897383 #train# step  563, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:10.437568 #train# step  564, loss = 1.0081, cross_entropy loss = 1.0081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:11.983963 #train# step  565, loss = 0.9845, cross_entropy loss = 0.9845, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:13.549870 #train# step  566, loss = 0.9975, cross_entropy loss = 0.9975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:15.101245 #train# step  567, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:16.676797 #train# step  568, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:18.206409 #train# step  569, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:19.772129 #train# step  570, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:21.319651 #train# step  571, loss = 0.9923, cross_entropy loss = 0.9923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:22.817773 #train# step  572, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:24.367150 #train# step  573, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:25.930654 #train# step  574, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:27.500860 #train# step  575, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:29.042412 #train# step  576, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:30.606816 #train# step  577, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:32.136836 #train# step  578, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:33.657198 #train# step  579, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:35.205574 #train# step  580, loss = 0.9894, cross_entropy loss = 0.9894, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:36.757710 #train# step  581, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:38.293681 #train# step  582, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:39.806978 #train# step  583, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:41.336019 #train# step  584, loss = 0.9974, cross_entropy loss = 0.9974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:42.912361 #train# step  585, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:44.438538 #train# step  586, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:46.008180 #train# step  587, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:47.566234 #train# step  588, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:49.134763 #train# step  589, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:50.647262 #train# step  590, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:52.206096 #train# step  591, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:53.728298 #train# step  592, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:55.283256 #train# step  593, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:56.796160 #train# step  594, loss = 1.0028, cross_entropy loss = 1.0028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:58.395421 #train# step  595, loss = 0.9827, cross_entropy loss = 0.9827, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:28:59.945582 #train# step  596, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:01.456656 #train# step  597, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:03.031191 #train# step  598, loss = 0.9960, cross_entropy loss = 0.9960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:04.592478 #train# step  599, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:06.119171 #train# step  600, loss = 1.0123, cross_entropy loss = 1.0123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:07.641711 #train# step  601, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:09.189308 #train# step  602, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:10.747648 #train# step  603, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:12.307459 #train# step  604, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:13.842599 #train# step  605, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:15.356634 #train# step  606, loss = 0.9824, cross_entropy loss = 0.9824, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:16.912621 #train# step  607, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:18.464973 #train# step  608, loss = 0.9861, cross_entropy loss = 0.9861, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:20.000792 #train# step  609, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:21.550744 #train# step  610, loss = 0.9869, cross_entropy loss = 0.9869, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:23.116421 #train# step  611, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:24.688569 #train# step  612, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:26.234518 #train# step  613, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:27.793472 #train# step  614, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:29.332112 #train# step  615, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:30.861012 #train# step  616, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:32.398418 #train# step  617, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:33.907994 #train# step  618, loss = 0.9865, cross_entropy loss = 0.9865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:35.477953 #train# step  619, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:37.011266 #train# step  620, loss = 0.9913, cross_entropy loss = 0.9913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:38.530979 #train# step  621, loss = 0.9845, cross_entropy loss = 0.9845, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:40.091207 #train# step  622, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:41.669933 #train# step  623, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:43.219922 #train# step  624, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:44.766303 #train# step  625, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:46.315272 #train# step  626, loss = 0.9879, cross_entropy loss = 0.9879, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:47.902396 #train# step  627, loss = 0.9777, cross_entropy loss = 0.9777, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:49.450407 #train# step  628, loss = 0.9919, cross_entropy loss = 0.9919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:50.972477 #train# step  629, loss = 0.9883, cross_entropy loss = 0.9883, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:52.506790 #train# step  630, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:54.051595 #train# step  631, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:55.574270 #train# step  632, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:57.140464 #train# step  633, loss = 0.9874, cross_entropy loss = 0.9874, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:29:58.697665 #train# step  634, loss = 0.9817, cross_entropy loss = 0.9817, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:00.246260 #train# step  635, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:01.799886 #train# step  636, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:03.294188 #train# step  637, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:04.841826 #train# step  638, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:06.364861 #train# step  639, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:07.916503 #train# step  640, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:09.480097 #train# step  641, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:11.029708 #train# step  642, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:12.574164 #train# step  643, loss = 0.9918, cross_entropy loss = 0.9918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:14.142173 #train# step  644, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:15.697730 #train# step  645, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:17.245697 #train# step  646, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:18.793566 #train# step  647, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:20.332315 #train# step  648, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:21.915440 #train# step  649, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:23.476855 #train# step  650, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:24.985378 #train# step  651, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:26.564001 #train# step  652, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:28.116131 #train# step  653, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:29.656673 #train# step  654, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:31.184935 #train# step  655, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:32.721468 #train# step  656, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:34.291288 #train# step  657, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:35.853996 #train# step  658, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:37.424849 #train# step  659, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:38.957410 #train# step  660, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:40.513432 #train# step  661, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:42.034584 #train# step  662, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:43.577726 #train# step  663, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:45.126546 #train# step  664, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:46.664216 #train# step  665, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:48.203522 #train# step  666, loss = 0.9945, cross_entropy loss = 0.9945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:49.786375 #train# step  667, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:51.348965 #train# step  668, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:52.883143 #train# step  669, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:54.445521 #train# step  670, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:56.015786 #train# step  671, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:57.547557 #train# step  672, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:30:59.070322 #train# step  673, loss = 0.9811, cross_entropy loss = 0.9811, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:00.634320 #train# step  674, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:02.186622 #train# step  675, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:03.707035 #train# step  676, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:05.257706 #train# step  677, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:06.804336 #train# step  678, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:08.319457 #train# step  679, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:09.846670 #train# step  680, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:11.413001 #train# step  681, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:12.952280 #train# step  682, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:14.526173 #train# step  683, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:16.075622 #train# step  684, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:17.628505 #train# step  685, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:19.178072 #train# step  686, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:20.722632 #train# step  687, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:22.225800 #train# step  688, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:23.805672 #train# step  689, loss = 0.9742, cross_entropy loss = 0.9742, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:25.353072 #train# step  690, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:26.893452 #train# step  691, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:28.413216 #train# step  692, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:29.941090 #train# step  693, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:31.505844 #train# step  694, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:33.057243 #train# step  695, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:34.579154 #train# step  696, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:36.125629 #train# step  697, loss = 1.0027, cross_entropy loss = 1.0027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:37.692394 #train# step  698, loss = 0.9966, cross_entropy loss = 0.9966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:39.218408 #train# step  699, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:40.753125 #train# step  700, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:42.338793 #train# step  701, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:43.858859 #train# step  702, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:45.396535 #train# step  703, loss = 0.9742, cross_entropy loss = 0.9742, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:46.956852 #train# step  704, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:48.479498 #train# step  705, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:50.043328 #train# step  706, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:51.579214 #train# step  707, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:53.111840 #train# step  708, loss = 0.9752, cross_entropy loss = 0.9752, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:54.668412 #train# step  709, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:56.242141 #train# step  710, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:57.761581 #train# step  711, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:31:59.311591 #train# step  712, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:00.852190 #train# step  713, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:02.398973 #train# step  714, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:03.968619 #train# step  715, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:05.514850 #train# step  716, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:07.055367 #train# step  717, loss = 0.9863, cross_entropy loss = 0.9863, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:08.592513 #train# step  718, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:10.164183 #train# step  719, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:11.709771 #train# step  720, loss = 0.9861, cross_entropy loss = 0.9861, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:13.221374 #train# step  721, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:14.767782 #train# step  722, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:16.315489 #train# step  723, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:17.846569 #train# step  724, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:19.416495 #train# step  725, loss = 0.9891, cross_entropy loss = 0.9891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:20.983410 #train# step  726, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:22.526526 #train# step  727, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:24.042444 #train# step  728, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:25.539947 #train# step  729, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:27.079601 #train# step  730, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:28.638018 #train# step  731, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:30.194363 #train# step  732, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:31.750366 #train# step  733, loss = 0.9788, cross_entropy loss = 0.9788, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:33.269805 #train# step  734, loss = 0.9827, cross_entropy loss = 0.9827, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:34.817773 #train# step  735, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:36.381144 #train# step  736, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:37.930665 #train# step  737, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:39.455858 #train# step  738, loss = 0.9924, cross_entropy loss = 0.9924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:41.012908 #train# step  739, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:42.548217 #train# step  740, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:44.109982 #train# step  741, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:45.650359 #train# step  742, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:47.224567 #train# step  743, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:48.768438 #train# step  744, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:50.307431 #train# step  745, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:51.872595 #train# step  746, loss = 0.9917, cross_entropy loss = 0.9917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:53.427558 #train# step  747, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:54.976510 #train# step  748, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:56.523344 #train# step  749, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:58.062389 #train# step  750, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:32:59.611990 #train# step  751, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:01.191767 #train# step  752, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:02.713987 #train# step  753, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:04.253290 #train# step  754, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:05.777845 #train# step  755, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:07.339374 #train# step  756, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:08.879990 #train# step  757, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:10.451339 #train# step  758, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:11.996378 #train# step  759, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:13.565998 #train# step  760, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:15.123247 #train# step  761, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:16.677771 #train# step  762, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:18.221249 #train# step  763, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:19.803579 #train# step  764, loss = 0.9865, cross_entropy loss = 0.9865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:21.338407 #train# step  765, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:22.874524 #train# step  766, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:24.396545 #train# step  767, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:25.932289 #train# step  768, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:27.498812 #train# step  769, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:29.015623 #train# step  770, loss = 1.0029, cross_entropy loss = 1.0029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:30.578762 #train# step  771, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:32.128924 #train# step  772, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:33.693599 #train# step  773, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:35.238147 #train# step  774, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:36.777788 #train# step  775, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:38.312123 #train# step  776, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:39.844390 #train# step  777, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:41.407352 #train# step  778, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:42.938922 #train# step  779, loss = 0.9817, cross_entropy loss = 0.9817, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:44.485916 #train# step  780, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:46.046231 #train# step  781, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:47.565583 #train# step  782, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:49.089451 #train# step  783, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:50.608474 #train# step  784, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:52.149193 #train# step  785, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:53.697246 #train# step  786, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:55.257866 #train# step  787, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:56.807367 #train# step  788, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:58.337346 #train# step  789, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:33:59.894022 #train# step  790, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:01.445007 #train# step  791, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:02.988182 #train# step  792, loss = 0.9848, cross_entropy loss = 0.9848, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:04.544969 #train# step  793, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:06.082441 #train# step  794, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:07.625378 #train# step  795, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:09.195209 #train# step  796, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:10.727468 #train# step  797, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:12.256122 #train# step  798, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:13.791051 #train# step  799, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:15.345212 #train# step  800, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:16.897445 #train# step  801, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:18.439506 #train# step  802, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:19.943796 #train# step  803, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:21.486085 #train# step  804, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:23.032881 #train# step  805, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:24.567937 #train# step  806, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:26.119359 #train# step  807, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:27.638545 #train# step  808, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:29.189971 #train# step  809, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:30.724139 #train# step  810, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:32.266915 #train# step  811, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:33.781767 #train# step  812, loss = 0.9742, cross_entropy loss = 0.9742, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:35.302980 #train# step  813, loss = 0.9820, cross_entropy loss = 0.9820, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:36.865742 #train# step  814, loss = 0.9827, cross_entropy loss = 0.9827, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:38.445601 #train# step  815, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:39.986191 #train# step  816, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:41.522164 #train# step  817, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:43.056920 #train# step  818, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:44.591220 #train# step  819, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:46.152725 #train# step  820, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:47.720467 #train# step  821, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:49.270199 #train# step  822, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:50.832094 #train# step  823, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:52.329061 #train# step  824, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:53.863886 #train# step  825, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:55.428912 #train# step  826, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:56.999929 #train# step  827, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:34:58.537757 #train# step  828, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:00.080095 #train# step  829, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:01.651011 #train# step  830, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:03.209489 #train# step  831, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:04.777466 #train# step  832, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:06.304278 #train# step  833, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:07.813487 #train# step  834, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:09.362469 #train# step  835, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:10.934263 #train# step  836, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:12.461697 #train# step  837, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:14.012549 #train# step  838, loss = 0.9811, cross_entropy loss = 0.9811, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:15.547987 #train# step  839, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:17.100313 #train# step  840, loss = 0.9748, cross_entropy loss = 0.9748, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:18.666637 #train# step  841, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:20.201524 #train# step  842, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:21.726302 #train# step  843, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:23.285189 #train# step  844, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:24.849941 #train# step  845, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:26.392747 #train# step  846, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:27.947266 #train# step  847, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:29.505424 #train# step  848, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:31.047480 #train# step  849, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:32.585506 #train# step  850, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:34.126723 #train# step  851, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:35.658843 #train# step  852, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:37.201266 #train# step  853, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:38.740964 #train# step  854, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:40.307448 #train# step  855, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:41.878003 #train# step  856, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:43.453212 #train# step  857, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:44.999247 #train# step  858, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:46.528400 #train# step  859, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:48.046495 #train# step  860, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:49.575813 #train# step  861, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:51.132005 #train# step  862, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:52.658712 #train# step  863, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:54.213307 #train# step  864, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:55.733785 #train# step  865, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:57.288777 #train# step  866, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:35:58.828679 #train# step  867, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:00.349324 #train# step  868, loss = 0.9832, cross_entropy loss = 0.9832, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:01.935369 #train# step  869, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:03.510957 #train# step  870, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:05.063414 #train# step  871, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:06.612124 #train# step  872, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:08.128385 #train# step  873, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:09.694602 #train# step  874, loss = 0.9895, cross_entropy loss = 0.9895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:11.234628 #train# step  875, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:12.787140 #train# step  876, loss = 0.9916, cross_entropy loss = 0.9916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:14.327132 #train# step  877, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:15.870408 #train# step  878, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:17.401212 #train# step  879, loss = 0.9775, cross_entropy loss = 0.9775, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:18.935975 #train# step  880, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:20.504149 #train# step  881, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:22.061206 #train# step  882, loss = 0.9817, cross_entropy loss = 0.9817, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:23.593941 #train# step  883, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:25.155392 #train# step  884, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:26.683326 #train# step  885, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:28.215600 #train# step  886, loss = 0.9872, cross_entropy loss = 0.9872, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:29.761103 #train# step  887, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:31.324819 #train# step  888, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:32.851449 #train# step  889, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:34.401123 #train# step  890, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:35.947037 #train# step  891, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:37.472405 #train# step  892, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:39.034220 #train# step  893, loss = 0.9802, cross_entropy loss = 0.9802, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:40.580559 #train# step  894, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:42.159788 #train# step  895, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:43.699023 #train# step  896, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:45.239420 #train# step  897, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:46.777014 #train# step  898, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:48.334644 #train# step  899, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:49.872261 #train# step  900, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:51.417838 #train# step  901, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:52.980220 #train# step  902, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:54.500392 #train# step  903, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:56.057309 #train# step  904, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:57.645399 #train# step  905, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:36:59.210073 #train# step  906, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:00.768546 #train# step  907, loss = 0.9697, cross_entropy loss = 0.9697, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:02.307112 #train# step  908, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:03.844501 #train# step  909, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:05.387424 #train# step  910, loss = 0.9845, cross_entropy loss = 0.9845, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:06.930798 #train# step  911, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:08.475167 #train# step  912, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:09.980370 #train# step  913, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:11.499882 #train# step  914, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:13.024449 #train# step  915, loss = 0.9911, cross_entropy loss = 0.9911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:14.531320 #train# step  916, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:16.067493 #train# step  917, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:17.653772 #train# step  918, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:19.195002 #train# step  919, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:20.734918 #train# step  920, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:22.302794 #train# step  921, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:23.848007 #train# step  922, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:25.361193 #train# step  923, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:26.914911 #train# step  924, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:28.416770 #train# step  925, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:29.958519 #train# step  926, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:31.507648 #train# step  927, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:33.032265 #train# step  928, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:34.609894 #train# step  929, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:36.141553 #train# step  930, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:37.705838 #train# step  931, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:39.243648 #train# step  932, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:40.814004 #train# step  933, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:42.385526 #train# step  934, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:43.945612 #train# step  935, loss = 0.9797, cross_entropy loss = 0.9797, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:45.498434 #train# step  936, loss = 0.9786, cross_entropy loss = 0.9786, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:47.069721 #train# step  937, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:48.634913 #train# step  938, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:50.185495 #train# step  939, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:51.722158 #train# step  940, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:53.288730 #train# step  941, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:54.848230 #train# step  942, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:56.406828 #train# step  943, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:57.937257 #train# step  944, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:37:59.445869 #train# step  945, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:01.011939 #train# step  946, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:02.609761 #train# step  947, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:04.149318 #train# step  948, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:05.676616 #train# step  949, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:07.248145 #train# step  950, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:08.804929 #train# step  951, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:10.370798 #train# step  952, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:11.896655 #train# step  953, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:13.438149 #train# step  954, loss = 0.9752, cross_entropy loss = 0.9752, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:14.983539 #train# step  955, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:16.517239 #train# step  956, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:18.064181 #train# step  957, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:19.607159 #train# step  958, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:21.166914 #train# step  959, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:22.707688 #train# step  960, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:24.264721 #train# step  961, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:25.796219 #train# step  962, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:27.306589 #train# step  963, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:28.873157 #train# step  964, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:30.404300 #train# step  965, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:31.954571 #train# step  966, loss = 0.9817, cross_entropy loss = 0.9817, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:33.465867 #train# step  967, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:35.011026 #train# step  968, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:36.570715 #train# step  969, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:38.137481 #train# step  970, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:39.684757 #train# step  971, loss = 0.9673, cross_entropy loss = 0.9673, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:41.220214 #train# step  972, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:42.762348 #train# step  973, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:44.287096 #train# step  974, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:45.830714 #train# step  975, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:47.388452 #train# step  976, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:48.921385 #train# step  977, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:50.476104 #train# step  978, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:52.024315 #train# step  979, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:53.589500 #train# step  980, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:55.137780 #train# step  981, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:56.695838 #train# step  982, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:58.221551 #train# step  983, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:38:59.770924 #train# step  984, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:01.324591 #train# step  985, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:02.875934 #train# step  986, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:04.423733 #train# step  987, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:05.949563 #train# step  988, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:07.489686 #train# step  989, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:09.008329 #train# step  990, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:10.603101 #train# step  991, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:12.168298 #train# step  992, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:13.729024 #train# step  993, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:15.276248 #train# step  994, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:16.816175 #train# step  995, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:18.348697 #train# step  996, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:19.891648 #train# step  997, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:21.420333 #train# step  998, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:23.003025 #train# step  999, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:24.523060 #train# step 1000, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:26.063390 #train# step 1001, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:27.615861 #train# step 1002, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:29.151909 #train# step 1003, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:30.722072 #train# step 1004, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:32.227876 #train# step 1005, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:33.772742 #train# step 1006, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:35.322652 #train# step 1007, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:36.874779 #train# step 1008, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:38.405837 #train# step 1009, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:39.939430 #train# step 1010, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:41.464317 #train# step 1011, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:43.014694 #train# step 1012, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:44.561137 #train# step 1013, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:46.099774 #train# step 1014, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:47.659862 #train# step 1015, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:49.217272 #train# step 1016, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:50.819786 #train# step 1017, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:52.358146 #train# step 1018, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:53.908816 #train# step 1019, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:55.461296 #train# step 1020, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:57.016672 #train# step 1021, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:39:58.557996 #train# step 1022, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:00.110479 #train# step 1023, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:01.633588 #train# step 1024, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:03.183396 #train# step 1025, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:04.747708 #train# step 1026, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:06.293466 #train# step 1027, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:07.819132 #train# step 1028, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:09.376192 #train# step 1029, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:10.935983 #train# step 1030, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:12.458997 #train# step 1031, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:13.985581 #train# step 1032, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:15.505628 #train# step 1033, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:17.054684 #train# step 1034, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:18.566952 #train# step 1035, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:20.101707 #train# step 1036, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:21.650144 #train# step 1037, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:23.196114 #train# step 1038, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:24.709959 #train# step 1039, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:26.276280 #train# step 1040, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:27.824957 #train# step 1041, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:29.358199 #train# step 1042, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:30.875180 #train# step 1043, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:32.422334 #train# step 1044, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:33.951553 #train# step 1045, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:35.497050 #train# step 1046, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:37.039116 #train# step 1047, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:38.585631 #train# step 1048, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:40.156595 #train# step 1049, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:41.709277 #train# step 1050, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:43.232817 #train# step 1051, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:44.761089 #train# step 1052, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:46.319419 #train# step 1053, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:47.895197 #train# step 1054, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:49.466963 #train# step 1055, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:51.007777 #train# step 1056, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:52.564325 #train# step 1057, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:54.141933 #train# step 1058, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:55.697302 #train# step 1059, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:57.240355 #train# step 1060, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:40:58.748065 #train# step 1061, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:00.307933 #train# step 1062, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:01.856786 #train# step 1063, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:03.401057 #train# step 1064, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:04.947721 #train# step 1065, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:06.477313 #train# step 1066, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:08.023440 #train# step 1067, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:09.557561 #train# step 1068, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:11.101282 #train# step 1069, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:12.651742 #train# step 1070, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:14.196598 #train# step 1071, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:15.746846 #train# step 1072, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:17.322386 #train# step 1073, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:18.847271 #train# step 1074, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:20.392459 #train# step 1075, loss = 0.9724, cross_entropy loss = 0.9724, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:21.931422 #train# step 1076, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:23.491008 #train# step 1077, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:25.042121 #train# step 1078, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:26.626418 #train# step 1079, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:28.187560 #train# step 1080, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:29.748186 #train# step 1081, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:31.289835 #train# step 1082, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:32.815653 #train# step 1083, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:34.376751 #train# step 1084, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:35.926760 #train# step 1085, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:37.456067 #train# step 1086, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:38.992630 #train# step 1087, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:40.538090 #train# step 1088, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:42.079579 #train# step 1089, loss = 0.9673, cross_entropy loss = 0.9673, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:43.618059 #train# step 1090, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:45.163956 #train# step 1091, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:46.714676 #train# step 1092, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:48.250544 #train# step 1093, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:49.811021 #train# step 1094, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:51.341352 #train# step 1095, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:52.849884 #train# step 1096, loss = 0.9775, cross_entropy loss = 0.9775, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:54.404581 #train# step 1097, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:55.945413 #train# step 1098, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:57.491343 #train# step 1099, loss = 0.9721, cross_entropy loss = 0.9721, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:41:59.067228 #train# step 1100, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:00.632071 #train# step 1101, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:02.180164 #train# step 1102, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:03.717641 #train# step 1103, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:05.282213 #train# step 1104, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:06.821827 #train# step 1105, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:08.376744 #train# step 1106, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:09.919756 #train# step 1107, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:11.458027 #train# step 1108, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:13.000275 #train# step 1109, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:14.552598 #train# step 1110, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:16.081947 #train# step 1111, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:17.597432 #train# step 1112, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:19.160389 #train# step 1113, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:20.724151 #train# step 1114, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:22.254168 #train# step 1115, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:23.802324 #train# step 1116, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:25.349380 #train# step 1117, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:27.056425 #train# step 1118, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:28.629485 #train# step 1119, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:30.172005 #train# step 1120, loss = 0.9778, cross_entropy loss = 0.9778, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:31.728841 #train# step 1121, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:33.278045 #train# step 1122, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:34.833065 #train# step 1123, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:36.386034 #train# step 1124, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:37.938357 #train# step 1125, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:39.490226 #train# step 1126, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:41.028462 #train# step 1127, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:42.551831 #train# step 1128, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:44.100267 #train# step 1129, loss = 0.9898, cross_entropy loss = 0.9898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:45.623771 #train# step 1130, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:47.176167 #train# step 1131, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:48.727862 #train# step 1132, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:50.252780 #train# step 1133, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:51.783781 #train# step 1134, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:53.327594 #train# step 1135, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:54.856095 #train# step 1136, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:56.400511 #train# step 1137, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:57.964719 #train# step 1138, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:42:59.513677 #train# step 1139, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:01.067647 #train# step 1140, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:02.619597 #train# step 1141, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:04.153451 #train# step 1142, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:05.685089 #train# step 1143, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:07.244614 #train# step 1144, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:08.768124 #train# step 1145, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:10.355233 #train# step 1146, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:11.936891 #train# step 1147, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:13.482799 #train# step 1148, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:15.033551 #train# step 1149, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:16.573055 #train# step 1150, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:18.114965 #train# step 1151, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:19.640807 #train# step 1152, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:21.204282 #train# step 1153, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:22.759303 #train# step 1154, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:24.295999 #train# step 1155, loss = 0.9673, cross_entropy loss = 0.9673, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:25.865881 #train# step 1156, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:27.399514 #train# step 1157, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:28.942589 #train# step 1158, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:30.497110 #train# step 1159, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:32.027012 #train# step 1160, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:33.582826 #train# step 1161, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:35.137840 #train# step 1162, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:36.659622 #train# step 1163, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:38.218047 #train# step 1164, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:39.756813 #train# step 1165, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:41.326039 #train# step 1166, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:42.868884 #train# step 1167, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:44.402415 #train# step 1168, loss = 0.9742, cross_entropy loss = 0.9742, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:45.922091 #train# step 1169, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:47.469867 #train# step 1170, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:49.046059 #train# step 1171, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:50.628810 #train# step 1172, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:52.165841 #train# step 1173, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:53.727054 #train# step 1174, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:55.290299 #train# step 1175, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:56.851641 #train# step 1176, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:58.424405 #train# step 1177, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:43:59.996854 #train# step 1178, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:01.543396 #train# step 1179, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:03.105196 #train# step 1180, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:04.654601 #train# step 1181, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:06.192749 #train# step 1182, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:07.744978 #train# step 1183, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:09.318772 #train# step 1184, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:10.843148 #train# step 1185, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:12.385025 #train# step 1186, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:13.934939 #train# step 1187, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:15.460543 #train# step 1188, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:17.010209 #train# step 1189, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:18.581346 #train# step 1190, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:20.140536 #train# step 1191, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:21.691186 #train# step 1192, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:23.245201 #train# step 1193, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:24.817541 #train# step 1194, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:26.386193 #train# step 1195, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:27.920701 #train# step 1196, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:29.474145 #train# step 1197, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:31.046191 #train# step 1198, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:32.584305 #train# step 1199, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:34.152572 #train# step 1200, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:35.685004 #train# step 1201, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:37.222967 #train# step 1202, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:38.765455 #train# step 1203, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:40.338337 #train# step 1204, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:41.857846 #train# step 1205, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:43.389165 #train# step 1206, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:44.918162 #train# step 1207, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:46.474291 #train# step 1208, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:48.034550 #train# step 1209, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:49.569216 #train# step 1210, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:51.073757 #train# step 1211, loss = 0.9775, cross_entropy loss = 0.9775, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:52.617499 #train# step 1212, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:54.178289 #train# step 1213, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:55.716316 #train# step 1214, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:57.287173 #train# step 1215, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:44:58.849718 #train# step 1216, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:00.383383 #train# step 1217, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:01.903435 #train# step 1218, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:03.413070 #train# step 1219, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:04.923842 #train# step 1220, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:06.471096 #train# step 1221, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:08.020117 #train# step 1222, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:09.594519 #train# step 1223, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:11.133801 #train# step 1224, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:12.675066 #train# step 1225, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:14.248339 #train# step 1226, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:15.813715 #train# step 1227, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:17.360775 #train# step 1228, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:18.876922 #train# step 1229, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:20.432666 #train# step 1230, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:21.957885 #train# step 1231, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:23.520811 #train# step 1232, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:25.064311 #train# step 1233, loss = 0.9746, cross_entropy loss = 0.9746, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:26.619010 #train# step 1234, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:28.170230 #train# step 1235, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:29.684691 #train# step 1236, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:31.221485 #train# step 1237, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:32.798936 #train# step 1238, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:34.339020 #train# step 1239, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:35.885251 #train# step 1240, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:37.413477 #train# step 1241, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:38.980661 #train# step 1242, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:40.524372 #train# step 1243, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:42.075924 #train# step 1244, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:43.614109 #train# step 1245, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:45.146493 #train# step 1246, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:46.718146 #train# step 1247, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:48.274512 #train# step 1248, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:49.837302 #train# step 1249, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:51.423690 #train# step 1250, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:52.938617 #train# step 1251, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:54.543465 #train# step 1252, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:56.093128 #train# step 1253, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:57.647428 #train# step 1254, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:45:59.184458 #train# step 1255, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:00.717536 #train# step 1256, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:02.246111 #train# step 1257, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:03.766531 #train# step 1258, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:05.341493 #train# step 1259, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:06.879120 #train# step 1260, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:08.419348 #train# step 1261, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:09.949902 #train# step 1262, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:11.477905 #train# step 1263, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:13.041195 #train# step 1264, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:14.575109 #train# step 1265, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:16.094545 #train# step 1266, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:17.649998 #train# step 1267, loss = 0.9617, cross_entropy loss = 0.9617, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:19.189047 #train# step 1268, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:20.746200 #train# step 1269, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:22.328935 #train# step 1270, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:23.902122 #train# step 1271, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:25.421855 #train# step 1272, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:26.952142 #train# step 1273, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:28.508825 #train# step 1274, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:30.021970 #train# step 1275, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:31.567984 #train# step 1276, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:33.099704 #train# step 1277, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:34.648221 #train# step 1278, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:36.176123 #train# step 1279, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:37.720653 #train# step 1280, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:39.287493 #train# step 1281, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:40.850169 #train# step 1282, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:42.379682 #train# step 1283, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:43.904254 #train# step 1284, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:45.457951 #train# step 1285, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:46.995216 #train# step 1286, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:48.543972 #train# step 1287, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:50.099469 #train# step 1288, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:51.645751 #train# step 1289, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:53.194823 #train# step 1290, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:54.728626 #train# step 1291, loss = 0.9777, cross_entropy loss = 0.9777, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:56.295942 #train# step 1292, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:57.864278 #train# step 1293, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:46:59.422888 #train# step 1294, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:00.964624 #train# step 1295, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:02.499632 #train# step 1296, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:04.064531 #train# step 1297, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:05.618169 #train# step 1298, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:07.169790 #train# step 1299, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:08.688160 #train# step 1300, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:10.254732 #train# step 1301, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:11.784060 #train# step 1302, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:13.289422 #train# step 1303, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:14.847220 #train# step 1304, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:16.418497 #train# step 1305, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:17.993634 #train# step 1306, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:19.524018 #train# step 1307, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:21.058248 #train# step 1308, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:22.603976 #train# step 1309, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:24.151838 #train# step 1310, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:25.682302 #train# step 1311, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:27.239006 #train# step 1312, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:28.798404 #train# step 1313, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:30.353879 #train# step 1314, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:31.885457 #train# step 1315, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:33.420261 #train# step 1316, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:34.984681 #train# step 1317, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:36.514008 #train# step 1318, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:38.019001 #train# step 1319, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:39.534876 #train# step 1320, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:41.079553 #train# step 1321, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:42.651467 #train# step 1322, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:44.191069 #train# step 1323, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:45.737520 #train# step 1324, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:47.312594 #train# step 1325, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:48.882673 #train# step 1326, loss = 0.9684, cross_entropy loss = 0.9684, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:50.420245 #train# step 1327, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:51.941972 #train# step 1328, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:53.497153 #train# step 1329, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:55.050011 #train# step 1330, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:56.608947 #train# step 1331, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:58.159219 #train# step 1332, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:47:59.691175 #train# step 1333, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:01.283769 #train# step 1334, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:02.843783 #train# step 1335, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:04.384471 #train# step 1336, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:05.937046 #train# step 1337, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:07.483049 #train# step 1338, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:09.028638 #train# step 1339, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:10.568335 #train# step 1340, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:12.133480 #train# step 1341, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:13.669947 #train# step 1342, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:15.247730 #train# step 1343, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:16.769657 #train# step 1344, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:18.324629 #train# step 1345, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:19.862308 #train# step 1346, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:21.441927 #train# step 1347, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:23.010910 #train# step 1348, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:24.535209 #train# step 1349, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:26.089518 #train# step 1350, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:27.654984 #train# step 1351, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:29.194527 #train# step 1352, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:30.712175 #train# step 1353, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:32.227292 #train# step 1354, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:33.792417 #train# step 1355, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:35.320360 #train# step 1356, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:36.885515 #train# step 1357, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:38.422401 #train# step 1358, loss = 0.9803, cross_entropy loss = 0.9803, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:39.981858 #train# step 1359, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:41.514965 #train# step 1360, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:43.079095 #train# step 1361, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:44.599556 #train# step 1362, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:46.152650 #train# step 1363, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:47.706761 #train# step 1364, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:49.218320 #train# step 1365, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:50.754682 #train# step 1366, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:52.282748 #train# step 1367, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:53.829109 #train# step 1368, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:55.377760 #train# step 1369, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:56.945529 #train# step 1370, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:48:58.470825 #train# step 1371, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:00.005192 #train# step 1372, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:01.560395 #train# step 1373, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:03.121690 #train# step 1374, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:04.675567 #train# step 1375, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:06.240863 #train# step 1376, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:07.780483 #train# step 1377, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:09.300408 #train# step 1378, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:10.915294 #train# step 1379, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:12.483187 #train# step 1380, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:14.016477 #train# step 1381, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:15.571569 #train# step 1382, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:17.150147 #train# step 1383, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:18.693451 #train# step 1384, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:20.238879 #train# step 1385, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:21.793424 #train# step 1386, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:23.332495 #train# step 1387, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:24.866143 #train# step 1388, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:26.422626 #train# step 1389, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:27.965535 #train# step 1390, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:29.517091 #train# step 1391, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:31.063956 #train# step 1392, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:32.589716 #train# step 1393, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:34.137631 #train# step 1394, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:35.674327 #train# step 1395, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:37.259452 #train# step 1396, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:38.781450 #train# step 1397, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:40.328874 #train# step 1398, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:41.865160 #train# step 1399, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:43.435701 #train# step 1400, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:44.975635 #train# step 1401, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:46.496922 #train# step 1402, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:48.029890 #train# step 1403, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:49.601221 #train# step 1404, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:51.137609 #train# step 1405, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:52.672222 #train# step 1406, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:54.212012 #train# step 1407, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:55.736052 #train# step 1408, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:57.276433 #train# step 1409, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:49:58.836608 #train# step 1410, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:00.387606 #train# step 1411, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:01.919060 #train# step 1412, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:03.503101 #train# step 1413, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:05.001850 #train# step 1414, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:06.561061 #train# step 1415, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:08.085831 #train# step 1416, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:09.662796 #train# step 1417, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:11.251192 #train# step 1418, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:12.794573 #train# step 1419, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:14.344777 #train# step 1420, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:15.906902 #train# step 1421, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:17.439670 #train# step 1422, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:18.952908 #train# step 1423, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:20.502532 #train# step 1424, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:22.039066 #train# step 1425, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:23.535537 #train# step 1426, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:25.078464 #train# step 1427, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:26.642966 #train# step 1428, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:28.193976 #train# step 1429, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:29.744447 #train# step 1430, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:31.291490 #train# step 1431, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:32.807374 #train# step 1432, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:34.354431 #train# step 1433, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:35.929330 #train# step 1434, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:37.485574 #train# step 1435, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:39.018012 #train# step 1436, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:40.600445 #train# step 1437, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:42.131533 #train# step 1438, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:43.675647 #train# step 1439, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:45.227766 #train# step 1440, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:46.781596 #train# step 1441, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:48.316567 #train# step 1442, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:49.860150 #train# step 1443, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:51.390573 #train# step 1444, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:52.938851 #train# step 1445, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:54.487425 #train# step 1446, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:56.046503 #train# step 1447, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:57.579250 #train# step 1448, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:50:59.149242 #train# step 1449, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:00.704202 #train# step 1450, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:02.250822 #train# step 1451, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:03.811429 #train# step 1452, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:05.363062 #train# step 1453, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:06.900716 #train# step 1454, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:08.433768 #train# step 1455, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:09.988038 #train# step 1456, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:11.530488 #train# step 1457, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:13.110590 #train# step 1458, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:14.660892 #train# step 1459, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:16.202518 #train# step 1460, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:17.773616 #train# step 1461, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:19.386752 #train# step 1462, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:20.961956 #train# step 1463, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:22.511899 #train# step 1464, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:24.046979 #train# step 1465, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:25.587025 #train# step 1466, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:27.130952 #train# step 1467, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:28.679815 #train# step 1468, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:30.220143 #train# step 1469, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:31.784801 #train# step 1470, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:33.338804 #train# step 1471, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:34.849461 #train# step 1472, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:36.394655 #train# step 1473, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:37.966291 #train# step 1474, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:39.500793 #train# step 1475, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:41.020539 #train# step 1476, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:42.572014 #train# step 1477, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:44.105228 #train# step 1478, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:45.636607 #train# step 1479, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:47.194931 #train# step 1480, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:48.734512 #train# step 1481, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:50.281862 #train# step 1482, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:51.820939 #train# step 1483, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:53.396500 #train# step 1484, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:54.966944 #train# step 1485, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:56.537217 #train# step 1486, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:58.077152 #train# step 1487, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:51:59.610650 #train# step 1488, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:01.202312 #train# step 1489, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:02.750253 #train# step 1490, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:04.279455 #train# step 1491, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:05.827312 #train# step 1492, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:07.362206 #train# step 1493, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:08.882547 #train# step 1494, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:10.438910 #train# step 1495, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:11.999626 #train# step 1496, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:13.509795 #train# step 1497, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:15.052778 #train# step 1498, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:16.572286 #train# step 1499, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:18.128406 #train# step 1500, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:19.671600 #train# step 1501, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:21.183278 #train# step 1502, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:22.720701 #train# step 1503, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:24.276614 #train# step 1504, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:25.832125 #train# step 1505, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:27.386568 #train# step 1506, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:28.939356 #train# step 1507, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:30.511428 #train# step 1508, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:32.045288 #train# step 1509, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:33.573998 #train# step 1510, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:35.130860 #train# step 1511, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:36.695951 #train# step 1512, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:38.239439 #train# step 1513, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:39.809725 #train# step 1514, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:41.364482 #train# step 1515, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:42.931358 #train# step 1516, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:44.450830 #train# step 1517, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:45.992578 #train# step 1518, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:47.536373 #train# step 1519, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:49.071983 #train# step 1520, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:50.606849 #train# step 1521, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:52.148337 #train# step 1522, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:53.676993 #train# step 1523, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:55.251155 #train# step 1524, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:56.865792 #train# step 1525, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:52:58.419157 #train# step 1526, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:00.004990 #train# step 1527, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:01.549244 #train# step 1528, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:03.097966 #train# step 1529, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:04.651241 #train# step 1530, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:06.186336 #train# step 1531, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:07.716168 #train# step 1532, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:09.259773 #train# step 1533, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:10.840545 #train# step 1534, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:12.399623 #train# step 1535, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:13.924689 #train# step 1536, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:15.475825 #train# step 1537, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:17.034834 #train# step 1538, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:18.573970 #train# step 1539, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:20.111270 #train# step 1540, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:21.630108 #train# step 1541, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:23.153304 #train# step 1542, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:24.662879 #train# step 1543, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:26.209143 #train# step 1544, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:27.760005 #train# step 1545, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:29.324549 #train# step 1546, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:30.869773 #train# step 1547, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:32.410040 #train# step 1548, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:33.952783 #train# step 1549, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:35.494875 #train# step 1550, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:37.026375 #train# step 1551, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:38.584167 #train# step 1552, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:40.126870 #train# step 1553, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:41.659719 #train# step 1554, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:43.186561 #train# step 1555, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:44.727688 #train# step 1556, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:46.261759 #train# step 1557, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:47.812617 #train# step 1558, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:49.369059 #train# step 1559, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:50.917335 #train# step 1560, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:52.469214 #train# step 1561, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:54.023963 #train# step 1562, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:55.572236 #train# step 1563, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:57.104183 #train# step 1564, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:53:58.663202 #train# step 1565, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:00.225644 #train# step 1566, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:01.747585 #train# step 1567, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:03.256682 #train# step 1568, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:04.825428 #train# step 1569, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:06.377370 #train# step 1570, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:07.925458 #train# step 1571, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:09.484442 #train# step 1572, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:11.013723 #train# step 1573, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:12.581841 #train# step 1574, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:14.148350 #train# step 1575, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:15.685697 #train# step 1576, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:17.255665 #train# step 1577, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:18.780554 #train# step 1578, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:20.332758 #train# step 1579, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:21.887528 #train# step 1580, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:23.461178 #train# step 1581, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:25.026828 #train# step 1582, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:26.569520 #train# step 1583, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:28.137460 #train# step 1584, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:29.669378 #train# step 1585, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:31.235960 #train# step 1586, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:32.775711 #train# step 1587, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:34.347030 #train# step 1588, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:35.879259 #train# step 1589, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:37.402555 #train# step 1590, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:38.977585 #train# step 1591, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:40.533107 #train# step 1592, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:42.074285 #train# step 1593, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:43.603751 #train# step 1594, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:45.155825 #train# step 1595, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:46.692908 #train# step 1596, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:48.233725 #train# step 1597, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:49.786496 #train# step 1598, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:51.371250 #train# step 1599, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:52.920948 #train# step 1600, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:54.443195 #train# step 1601, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:55.976419 #train# step 1602, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:57.538161 #train# step 1603, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:54:59.058837 #train# step 1604, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:00.582787 #train# step 1605, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:02.138553 #train# step 1606, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:03.694845 #train# step 1607, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:05.253668 #train# step 1608, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:06.797856 #train# step 1609, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:08.337160 #train# step 1610, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:09.877954 #train# step 1611, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:11.424383 #train# step 1612, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:12.989690 #train# step 1613, loss = 0.9751, cross_entropy loss = 0.9751, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:14.516210 #train# step 1614, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:16.109111 #train# step 1615, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:17.641890 #train# step 1616, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:19.175953 #train# step 1617, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:20.729879 #train# step 1618, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:22.278954 #train# step 1619, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:23.831377 #train# step 1620, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:25.374487 #train# step 1621, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:26.926697 #train# step 1622, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:28.441448 #train# step 1623, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:29.978072 #train# step 1624, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:31.513776 #train# step 1625, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:33.051339 #train# step 1626, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:34.624117 #train# step 1627, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:36.163934 #train# step 1628, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:37.711660 #train# step 1629, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:39.274090 #train# step 1630, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:40.843140 #train# step 1631, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:42.376843 #train# step 1632, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:43.907012 #train# step 1633, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:45.449649 #train# step 1634, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:47.001764 #train# step 1635, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:48.543437 #train# step 1636, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:50.098282 #train# step 1637, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:51.652273 #train# step 1638, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:53.200930 #train# step 1639, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:54.735531 #train# step 1640, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:56.238013 #train# step 1641, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:57.799949 #train# step 1642, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:55:59.356189 #train# step 1643, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:00.927877 #train# step 1644, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:02.509527 #train# step 1645, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:04.045792 #train# step 1646, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:05.599474 #train# step 1647, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:07.145363 #train# step 1648, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:08.686035 #train# step 1649, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:10.244083 #train# step 1650, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:11.797801 #train# step 1651, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:13.324726 #train# step 1652, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:14.856425 #train# step 1653, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:16.368308 #train# step 1654, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:17.921282 #train# step 1655, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:19.493504 #train# step 1656, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:21.024335 #train# step 1657, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:22.575128 #train# step 1658, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:24.116437 #train# step 1659, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:25.630108 #train# step 1660, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:27.200201 #train# step 1661, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:28.763150 #train# step 1662, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:30.304599 #train# step 1663, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:31.822530 #train# step 1664, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:33.397959 #train# step 1665, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:34.933784 #train# step 1666, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:36.479894 #train# step 1667, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:38.055676 #train# step 1668, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:39.602859 #train# step 1669, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:41.152580 #train# step 1670, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:42.721675 #train# step 1671, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:44.298441 #train# step 1672, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:45.844377 #train# step 1673, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:47.387442 #train# step 1674, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:48.941390 #train# step 1675, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:50.487718 #train# step 1676, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:52.027923 #train# step 1677, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:53.588047 #train# step 1678, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:55.121333 #train# step 1679, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:56.665994 #train# step 1680, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:58.227625 #train# step 1681, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:56:59.758768 #train# step 1682, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:01.330219 #train# step 1683, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:02.890837 #train# step 1684, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:04.418995 #train# step 1685, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:05.965595 #train# step 1686, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:07.502796 #train# step 1687, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:09.019710 #train# step 1688, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:10.553427 #train# step 1689, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:12.108072 #train# step 1690, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:13.692471 #train# step 1691, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:15.252786 #train# step 1692, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:16.792799 #train# step 1693, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:18.327331 #train# step 1694, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:19.859934 #train# step 1695, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:21.399803 #train# step 1696, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:22.948400 #train# step 1697, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:24.482815 #train# step 1698, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:26.030774 #train# step 1699, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:27.582757 #train# step 1700, loss = 0.9752, cross_entropy loss = 0.9752, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:29.090214 #train# step 1701, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:30.650404 #train# step 1702, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:32.179774 #train# step 1703, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:33.723805 #train# step 1704, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:35.289416 #train# step 1705, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:36.846873 #train# step 1706, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:38.404116 #train# step 1707, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:39.966639 #train# step 1708, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:41.553020 #train# step 1709, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:43.116384 #train# step 1710, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:44.686855 #train# step 1711, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:46.230780 #train# step 1712, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:47.773985 #train# step 1713, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:49.283096 #train# step 1714, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:50.821540 #train# step 1715, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:52.344914 #train# step 1716, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:53.906651 #train# step 1717, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:55.446752 #train# step 1718, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:56.967201 #train# step 1719, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:57:58.482248 #train# step 1720, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:00.000547 #train# step 1721, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:01.563965 #train# step 1722, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:03.126020 #train# step 1723, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:04.686864 #train# step 1724, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:06.205726 #train# step 1725, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:07.753199 #train# step 1726, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:09.335593 #train# step 1727, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:10.913161 #train# step 1728, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:12.456609 #train# step 1729, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:14.020022 #train# step 1730, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:15.568289 #train# step 1731, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:17.094889 #train# step 1732, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:18.626653 #train# step 1733, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:20.197215 #train# step 1734, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:21.732018 #train# step 1735, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:23.275203 #train# step 1736, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:24.824269 #train# step 1737, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:26.377391 #train# step 1738, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:27.907942 #train# step 1739, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:29.429734 #train# step 1740, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:30.958271 #train# step 1741, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:32.526974 #train# step 1742, loss = 0.9741, cross_entropy loss = 0.9741, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:34.048798 #train# step 1743, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:35.579459 #train# step 1744, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:37.147934 #train# step 1745, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:38.704042 #train# step 1746, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:40.229053 #train# step 1747, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:41.777129 #train# step 1748, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:43.325830 #train# step 1749, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:44.897716 #train# step 1750, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:46.450384 #train# step 1751, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:47.997628 #train# step 1752, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:49.562500 #train# step 1753, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:51.090188 #train# step 1754, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:52.627413 #train# step 1755, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:54.179928 #train# step 1756, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:55.742297 #train# step 1757, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:57.291285 #train# step 1758, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:58:58.823527 #train# step 1759, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:00.387296 #train# step 1760, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:01.902360 #train# step 1761, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:03.471124 #train# step 1762, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:04.991401 #train# step 1763, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:06.577487 #train# step 1764, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:08.141507 #train# step 1765, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:09.677048 #train# step 1766, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:11.240471 #train# step 1767, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:12.780017 #train# step 1768, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:14.308446 #train# step 1769, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:15.872682 #train# step 1770, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:17.406837 #train# step 1771, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:18.938979 #train# step 1772, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:20.485985 #train# step 1773, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:22.046654 #train# step 1774, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:23.604575 #train# step 1775, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:25.180094 #train# step 1776, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:26.739855 #train# step 1777, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:28.276053 #train# step 1778, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:29.846094 #train# step 1779, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:31.390658 #train# step 1780, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:32.916321 #train# step 1781, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:34.490092 #train# step 1782, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:36.027439 #train# step 1783, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:37.558303 #train# step 1784, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:39.108760 #train# step 1785, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:40.640541 #train# step 1786, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:42.191682 #train# step 1787, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:43.732032 #train# step 1788, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:45.286501 #train# step 1789, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:46.782057 #train# step 1790, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:48.346301 #train# step 1791, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:49.935545 #train# step 1792, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:51.481985 #train# step 1793, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:53.038254 #train# step 1794, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:54.572812 #train# step 1795, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:56.133130 #train# step 1796, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:57.710202 #train# step 1797, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 01:59:59.270496 #train# step 1798, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:00.797777 #train# step 1799, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:02.354772 #train# step 1800, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:03.891888 #train# step 1801, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:05.441518 #train# step 1802, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:06.984877 #train# step 1803, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:08.524751 #train# step 1804, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:10.065211 #train# step 1805, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:11.642993 #train# step 1806, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:13.187512 #train# step 1807, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:14.751986 #train# step 1808, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:16.284276 #train# step 1809, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:17.808774 #train# step 1810, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:19.321387 #train# step 1811, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:20.844492 #train# step 1812, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:22.408300 #train# step 1813, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:23.986523 #train# step 1814, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:25.533041 #train# step 1815, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:27.095225 #train# step 1816, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:28.631468 #train# step 1817, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:30.191575 #train# step 1818, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:31.725753 #train# step 1819, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:33.284017 #train# step 1820, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:34.850975 #train# step 1821, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:36.395889 #train# step 1822, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:37.917641 #train# step 1823, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:39.434696 #train# step 1824, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:40.986370 #train# step 1825, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:42.536411 #train# step 1826, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:44.079926 #train# step 1827, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:45.631530 #train# step 1828, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:47.196827 #train# step 1829, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:48.767889 #train# step 1830, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:50.294887 #train# step 1831, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:51.854739 #train# step 1832, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:53.386100 #train# step 1833, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:54.950024 #train# step 1834, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:56.517905 #train# step 1835, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:58.074912 #train# step 1836, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:00:59.624039 #train# step 1837, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:01.195853 #train# step 1838, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:02.729952 #train# step 1839, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:04.254166 #train# step 1840, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:05.776639 #train# step 1841, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:07.319666 #train# step 1842, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:08.848405 #train# step 1843, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:10.395088 #train# step 1844, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:11.942218 #train# step 1845, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:13.529163 #train# step 1846, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:15.097936 #train# step 1847, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:16.634866 #train# step 1848, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:18.215413 #train# step 1849, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:19.755376 #train# step 1850, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:21.328035 #train# step 1851, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:22.870781 #train# step 1852, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:24.413473 #train# step 1853, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:25.927803 #train# step 1854, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:27.453167 #train# step 1855, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:28.988933 #train# step 1856, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:30.530719 #train# step 1857, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:32.082108 #train# step 1858, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:33.608238 #train# step 1859, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:35.159741 #train# step 1860, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:36.691667 #train# step 1861, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:38.249822 #train# step 1862, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:39.821687 #train# step 1863, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:41.402022 #train# step 1864, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:42.959549 #train# step 1865, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:44.495231 #train# step 1866, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:46.051598 #train# step 1867, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:47.584363 #train# step 1868, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:49.101430 #train# step 1869, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:50.673318 #train# step 1870, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:52.200805 #train# step 1871, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:53.767609 #train# step 1872, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:55.288965 #train# step 1873, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:56.842336 #train# step 1874, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:58.385143 #train# step 1875, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:01:59.906979 #train# step 1876, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:01.431125 #train# step 1877, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:02.986653 #train# step 1878, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:04.520834 #train# step 1879, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:06.105891 #train# step 1880, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:07.649899 #train# step 1881, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:09.213308 #train# step 1882, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:10.786435 #train# step 1883, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:12.361502 #train# step 1884, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:13.904926 #train# step 1885, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:15.428865 #train# step 1886, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:16.981255 #train# step 1887, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:18.549563 #train# step 1888, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:20.141542 #train# step 1889, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:21.695201 #train# step 1890, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:23.233902 #train# step 1891, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:24.777059 #train# step 1892, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:26.318657 #train# step 1893, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:27.872286 #train# step 1894, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:29.408901 #train# step 1895, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:30.943009 #train# step 1896, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:32.486192 #train# step 1897, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:34.047994 #train# step 1898, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:35.621000 #train# step 1899, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:37.153761 #train# step 1900, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:38.727304 #train# step 1901, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:40.261592 #train# step 1902, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:41.785855 #train# step 1903, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:43.293554 #train# step 1904, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:44.856549 #train# step 1905, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:46.379256 #train# step 1906, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:47.937779 #train# step 1907, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:49.463691 #train# step 1908, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:51.017730 #train# step 1909, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:52.603621 #train# step 1910, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:54.136685 #train# step 1911, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:55.661887 #train# step 1912, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:57.196064 #train# step 1913, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:02:58.750650 #train# step 1914, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:00.274169 #train# step 1915, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:01.833331 #train# step 1916, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:03.369692 #train# step 1917, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:04.914512 #train# step 1918, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:06.468810 #train# step 1919, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:08.041803 #train# step 1920, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:09.584888 #train# step 1921, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:11.157735 #train# step 1922, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:12.708686 #train# step 1923, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:14.237885 #train# step 1924, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:15.772729 #train# step 1925, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:17.331824 #train# step 1926, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:18.871835 #train# step 1927, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:20.419889 #train# step 1928, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:21.960484 #train# step 1929, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:23.528289 #train# step 1930, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:25.061006 #train# step 1931, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:26.607751 #train# step 1932, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:28.153226 #train# step 1933, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:29.707612 #train# step 1934, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:31.247099 #train# step 1935, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:32.826203 #train# step 1936, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:34.377234 #train# step 1937, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:35.960848 #train# step 1938, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:37.526857 #train# step 1939, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:39.104069 #train# step 1940, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:40.652742 #train# step 1941, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:42.207085 #train# step 1942, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:43.763154 #train# step 1943, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:45.289484 #train# step 1944, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:46.825238 #train# step 1945, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:48.387499 #train# step 1946, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:49.907510 #train# step 1947, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:51.449724 #train# step 1948, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:52.969724 #train# step 1949, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:54.528444 #train# step 1950, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:56.078922 #train# step 1951, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:57.618041 #train# step 1952, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:03:59.164008 #train# step 1953, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:00.696813 #train# step 1954, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:02.291066 #train# step 1955, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:03.830583 #train# step 1956, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:05.393758 #train# step 1957, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:06.958536 #train# step 1958, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:08.495706 #train# step 1959, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:10.068526 #train# step 1960, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:11.626824 #train# step 1961, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:13.165325 #train# step 1962, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:14.733140 #train# step 1963, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:16.240714 #train# step 1964, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:17.804477 #train# step 1965, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:19.321158 #train# step 1966, loss = 0.9700, cross_entropy loss = 0.9700, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:20.881858 #train# step 1967, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:22.410743 #train# step 1968, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:23.967918 #train# step 1969, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:25.505299 #train# step 1970, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:27.023783 #train# step 1971, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:28.578720 #train# step 1972, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:30.107776 #train# step 1973, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:31.643051 #train# step 1974, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:33.193960 #train# step 1975, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:34.747576 #train# step 1976, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:36.294985 #train# step 1977, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:37.869476 #train# step 1978, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:39.452948 #train# step 1979, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:41.033352 #train# step 1980, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:42.552080 #train# step 1981, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:44.107800 #train# step 1982, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:45.647237 #train# step 1983, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:47.177149 #train# step 1984, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:48.703418 #train# step 1985, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:50.198352 #train# step 1986, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:51.732387 #train# step 1987, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:53.269752 #train# step 1988, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:54.833527 #train# step 1989, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:56.375694 #train# step 1990, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:57.925746 #train# step 1991, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:04:59.485186 #train# step 1992, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:01.030289 #train# step 1993, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:02.565740 #train# step 1994, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:04.115994 #train# step 1995, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:05.647188 #train# step 1996, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:07.174547 #train# step 1997, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:08.724995 #train# step 1998, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:10.292111 #train# step 1999, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:11.831454 #train# step 2000, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:13.356099 #train# step 2001, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:14.897429 #train# step 2002, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:16.440565 #train# step 2003, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:17.981651 #train# step 2004, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:19.505227 #train# step 2005, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:21.017513 #train# step 2006, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:22.567950 #train# step 2007, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:24.140221 #train# step 2008, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:25.720787 #train# step 2009, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:27.300560 #train# step 2010, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:28.847488 #train# step 2011, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:30.403479 #train# step 2012, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:31.947256 #train# step 2013, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:33.503760 #train# step 2014, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:35.056048 #train# step 2015, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:36.572645 #train# step 2016, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:38.141466 #train# step 2017, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:39.679090 #train# step 2018, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:41.211941 #train# step 2019, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:42.774755 #train# step 2020, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:44.381910 #train# step 2021, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:45.936443 #train# step 2022, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:47.474058 #train# step 2023, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:49.021616 #train# step 2024, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:50.561643 #train# step 2025, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:52.150645 #train# step 2026, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:53.694263 #train# step 2027, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:55.235328 #train# step 2028, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:56.790199 #train# step 2029, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:58.324728 #train# step 2030, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:05:59.895133 #train# step 2031, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:01.444262 #train# step 2032, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:03.010869 #train# step 2033, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:04.550742 #train# step 2034, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:06.093093 #train# step 2035, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:07.664908 #train# step 2036, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:09.215255 #train# step 2037, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:10.761617 #train# step 2038, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:12.314028 #train# step 2039, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:13.864486 #train# step 2040, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:15.413164 #train# step 2041, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:16.957702 #train# step 2042, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:18.502869 #train# step 2043, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:20.043060 #train# step 2044, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:21.601844 #train# step 2045, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:23.169195 #train# step 2046, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:24.736768 #train# step 2047, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:26.269211 #train# step 2048, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:27.821592 #train# step 2049, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:29.374980 #train# step 2050, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:30.912413 #train# step 2051, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:32.435411 #train# step 2052, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:33.971979 #train# step 2053, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:35.518121 #train# step 2054, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:37.048691 #train# step 2055, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:38.576506 #train# step 2056, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:40.154419 #train# step 2057, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:41.714716 #train# step 2058, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:43.265110 #train# step 2059, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:44.802750 #train# step 2060, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:46.366643 #train# step 2061, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:47.911014 #train# step 2062, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:49.430109 #train# step 2063, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:51.006962 #train# step 2064, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:52.548305 #train# step 2065, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:54.094244 #train# step 2066, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:55.625259 #train# step 2067, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:57.176826 #train# step 2068, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:06:58.712793 #train# step 2069, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:00.272621 #train# step 2070, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:01.792877 #train# step 2071, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:03.339448 #train# step 2072, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:04.877082 #train# step 2073, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:06.387143 #train# step 2074, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:07.907935 #train# step 2075, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:09.439504 #train# step 2076, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:10.985886 #train# step 2077, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:12.547830 #train# step 2078, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:14.072250 #train# step 2079, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:15.625456 #train# step 2080, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:17.215806 #train# step 2081, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:18.770459 #train# step 2082, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:20.280003 #train# step 2083, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:21.827160 #train# step 2084, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:23.367541 #train# step 2085, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:24.881569 #train# step 2086, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:26.441871 #train# step 2087, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:28.018673 #train# step 2088, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:29.564982 #train# step 2089, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:31.127303 #train# step 2090, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:32.673258 #train# step 2091, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:34.206034 #train# step 2092, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:35.760566 #train# step 2093, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:37.332042 #train# step 2094, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:38.843033 #train# step 2095, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:40.391943 #train# step 2096, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:41.960821 #train# step 2097, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:43.502887 #train# step 2098, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:45.084286 #train# step 2099, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:46.649818 #train# step 2100, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:48.226641 #train# step 2101, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:49.806837 #train# step 2102, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:51.335044 #train# step 2103, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:52.891886 #train# step 2104, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:54.426754 #train# step 2105, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:56.001834 #train# step 2106, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:57.544715 #train# step 2107, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:07:59.105418 #train# step 2108, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:00.632404 #train# step 2109, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:02.173330 #train# step 2110, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:03.713021 #train# step 2111, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:05.307688 #train# step 2112, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:06.868410 #train# step 2113, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:08.389094 #train# step 2114, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:09.955073 #train# step 2115, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:11.477809 #train# step 2116, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:13.015577 #train# step 2117, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:14.535805 #train# step 2118, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:16.071874 #train# step 2119, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:17.630552 #train# step 2120, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:19.165125 #train# step 2121, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:20.714645 #train# step 2122, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:22.290428 #train# step 2123, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:23.863731 #train# step 2124, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:25.418444 #train# step 2125, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:26.967060 #train# step 2126, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:28.535602 #train# step 2127, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:30.088302 #train# step 2128, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:31.646115 #train# step 2129, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:33.164573 #train# step 2130, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:34.691040 #train# step 2131, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:36.265882 #train# step 2132, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:37.797109 #train# step 2133, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:39.376571 #train# step 2134, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:40.905910 #train# step 2135, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:42.440981 #train# step 2136, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:44.005501 #train# step 2137, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:45.545069 #train# step 2138, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:47.074186 #train# step 2139, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:48.620200 #train# step 2140, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:50.151561 #train# step 2141, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:51.710963 #train# step 2142, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:53.263939 #train# step 2143, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:54.832508 #train# step 2144, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:56.361924 #train# step 2145, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:57.911346 #train# step 2146, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:08:59.461606 #train# step 2147, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:01.034787 #train# step 2148, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:02.592508 #train# step 2149, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:04.122857 #train# step 2150, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:05.654359 #train# step 2151, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:07.181714 #train# step 2152, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:08.757387 #train# step 2153, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:10.321252 #train# step 2154, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:11.846084 #train# step 2155, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:13.421810 #train# step 2156, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:14.992220 #train# step 2157, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:16.541116 #train# step 2158, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:18.098216 #train# step 2159, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:19.665005 #train# step 2160, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:21.201998 #train# step 2161, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:22.723765 #train# step 2162, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:24.286295 #train# step 2163, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:25.843118 #train# step 2164, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:27.406750 #train# step 2165, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:28.946774 #train# step 2166, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:30.501748 #train# step 2167, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:32.055743 #train# step 2168, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:33.630163 #train# step 2169, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:35.188992 #train# step 2170, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:36.728142 #train# step 2171, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:38.265259 #train# step 2172, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:39.801202 #train# step 2173, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:41.390113 #train# step 2174, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:42.959821 #train# step 2175, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:44.523460 #train# step 2176, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:46.069086 #train# step 2177, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:47.595305 #train# step 2178, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:49.132143 #train# step 2179, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:50.680304 #train# step 2180, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:52.240960 #train# step 2181, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:53.826118 #train# step 2182, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:55.374717 #train# step 2183, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:56.904913 #train# step 2184, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:09:58.459021 #train# step 2185, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:00.026854 #train# step 2186, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:01.584194 #train# step 2187, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:03.144627 #train# step 2188, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:04.673054 #train# step 2189, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:06.224861 #train# step 2190, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:07.752822 #train# step 2191, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:09.266334 #train# step 2192, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:10.819622 #train# step 2193, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:12.380434 #train# step 2194, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:13.923372 #train# step 2195, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:15.499501 #train# step 2196, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:17.071325 #train# step 2197, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:18.578439 #train# step 2198, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:20.115971 #train# step 2199, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:21.648799 #train# step 2200, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:23.215749 #train# step 2201, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:24.776451 #train# step 2202, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:26.368845 #train# step 2203, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:27.863269 #train# step 2204, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:29.377255 #train# step 2205, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:30.929117 #train# step 2206, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:32.516780 #train# step 2207, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:34.025472 #train# step 2208, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:35.568069 #train# step 2209, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:37.113205 #train# step 2210, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:38.656901 #train# step 2211, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:40.182800 #train# step 2212, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:41.709434 #train# step 2213, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:43.268968 #train# step 2214, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:44.830217 #train# step 2215, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:46.377165 #train# step 2216, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:47.944443 #train# step 2217, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:49.498540 #train# step 2218, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:51.046931 #train# step 2219, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:52.596949 #train# step 2220, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:54.157133 #train# step 2221, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:55.703487 #train# step 2222, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:57.242161 #train# step 2223, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:10:58.777992 #train# step 2224, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:00.330498 #train# step 2225, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:01.886523 #train# step 2226, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:03.444612 #train# step 2227, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:04.995965 #train# step 2228, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:06.520640 #train# step 2229, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:08.046355 #train# step 2230, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:09.598719 #train# step 2231, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:11.133240 #train# step 2232, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:12.709649 #train# step 2233, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:14.275048 #train# step 2234, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:15.820316 #train# step 2235, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:17.350246 #train# step 2236, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:18.912316 #train# step 2237, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:20.483214 #train# step 2238, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:22.013045 #train# step 2239, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:23.573518 #train# step 2240, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:25.119421 #train# step 2241, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:26.671091 #train# step 2242, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:28.204090 #train# step 2243, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:29.736155 #train# step 2244, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:31.282318 #train# step 2245, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:32.826118 #train# step 2246, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:34.400728 #train# step 2247, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:35.961557 #train# step 2248, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:37.515706 #train# step 2249, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:39.050567 #train# step 2250, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:40.590630 #train# step 2251, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:42.133479 #train# step 2252, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:43.713505 #train# step 2253, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:45.276364 #train# step 2254, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:46.830730 #train# step 2255, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:48.381154 #train# step 2256, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:49.932724 #train# step 2257, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:51.494429 #train# step 2258, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:53.042993 #train# step 2259, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:54.613958 #train# step 2260, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:56.165977 #train# step 2261, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:57.737358 #train# step 2262, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:11:59.312085 #train# step 2263, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:00.860200 #train# step 2264, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:02.431216 #train# step 2265, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:04.011987 #train# step 2266, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:05.574612 #train# step 2267, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:07.130388 #train# step 2268, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:08.649274 #train# step 2269, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:10.181998 #train# step 2270, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:11.731316 #train# step 2271, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:13.254129 #train# step 2272, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:14.804673 #train# step 2273, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:16.348261 #train# step 2274, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:17.866075 #train# step 2275, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:19.426638 #train# step 2276, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:20.960017 #train# step 2277, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:22.512762 #train# step 2278, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:24.068867 #train# step 2279, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:25.625764 #train# step 2280, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:27.203385 #train# step 2281, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:28.763888 #train# step 2282, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:30.297755 #train# step 2283, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:31.808002 #train# step 2284, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:33.376928 #train# step 2285, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:34.908542 #train# step 2286, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:36.472805 #train# step 2287, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:37.972276 #train# step 2288, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:39.517894 #train# step 2289, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:41.061108 #train# step 2290, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:42.593196 #train# step 2291, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:44.156934 #train# step 2292, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:45.699947 #train# step 2293, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:47.210818 #train# step 2294, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:48.735621 #train# step 2295, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:50.303731 #train# step 2296, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:51.862258 #train# step 2297, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:53.436037 #train# step 2298, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:54.989511 #train# step 2299, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:56.539611 #train# step 2300, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:58.100910 #train# step 2301, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:12:59.618353 #train# step 2302, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:01.146937 #train# step 2303, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:02.678417 #train# step 2304, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:04.212912 #train# step 2305, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:05.779184 #train# step 2306, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:07.341493 #train# step 2307, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:08.900167 #train# step 2308, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:10.486272 #train# step 2309, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:12.092892 #train# step 2310, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:13.670456 #train# step 2311, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:15.217493 #train# step 2312, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:16.752949 #train# step 2313, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:18.272079 #train# step 2314, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:19.833295 #train# step 2315, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:21.388334 #train# step 2316, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:22.927655 #train# step 2317, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:24.439796 #train# step 2318, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:25.963619 #train# step 2319, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:27.513295 #train# step 2320, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:29.064235 #train# step 2321, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:30.648975 #train# step 2322, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:32.215763 #train# step 2323, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:33.774532 #train# step 2324, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:35.306754 #train# step 2325, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:36.844920 #train# step 2326, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:38.396651 #train# step 2327, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:39.979679 #train# step 2328, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:41.523601 #train# step 2329, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:43.094600 #train# step 2330, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:44.625347 #train# step 2331, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:46.167932 #train# step 2332, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:47.680545 #train# step 2333, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:49.253779 #train# step 2334, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:50.789594 #train# step 2335, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:52.358831 #train# step 2336, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:53.925894 #train# step 2337, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:55.484406 #train# step 2338, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:57.045223 #train# step 2339, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:13:58.589572 #train# step 2340, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:00.119171 #train# step 2341, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:01.648923 #train# step 2342, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:03.173026 #train# step 2343, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:04.715468 #train# step 2344, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:06.278294 #train# step 2345, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:07.815895 #train# step 2346, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:09.377780 #train# step 2347, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:10.913065 #train# step 2348, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:12.447674 #train# step 2349, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:14.008139 #train# step 2350, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:15.521691 #train# step 2351, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:17.078415 #train# step 2352, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:18.607813 #train# step 2353, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:20.186212 #train# step 2354, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:21.754166 #train# step 2355, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:23.308877 #train# step 2356, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:24.844134 #train# step 2357, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:26.370527 #train# step 2358, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:27.936385 #train# step 2359, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:29.489754 #train# step 2360, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:31.019475 #train# step 2361, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:32.564462 #train# step 2362, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:34.115814 #train# step 2363, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:35.653101 #train# step 2364, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:37.174875 #train# step 2365, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:38.742839 #train# step 2366, loss = 0.9470, cross_entropy loss = 0.9470, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:40.317586 #train# step 2367, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:41.867292 #train# step 2368, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:43.401916 #train# step 2369, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:44.967710 #train# step 2370, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:46.504677 #train# step 2371, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:48.087062 #train# step 2372, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:49.638038 #train# step 2373, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:51.182990 #train# step 2374, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:52.733321 #train# step 2375, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:54.270968 #train# step 2376, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:55.811890 #train# step 2377, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:57.354878 #train# step 2378, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:14:58.904424 #train# step 2379, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:00.456094 #train# step 2380, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:01.993423 #train# step 2381, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:03.524307 #train# step 2382, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:05.103194 #train# step 2383, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:06.636558 #train# step 2384, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:08.164968 #train# step 2385, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:09.741126 #train# step 2386, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:11.317337 #train# step 2387, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:12.886241 #train# step 2388, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:14.465986 #train# step 2389, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:16.025636 #train# step 2390, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:17.569531 #train# step 2391, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:19.121008 #train# step 2392, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:20.637272 #train# step 2393, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:22.181411 #train# step 2394, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:23.751186 #train# step 2395, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:25.293860 #train# step 2396, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:26.834169 #train# step 2397, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:28.358045 #train# step 2398, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:29.924098 #train# step 2399, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:31.477204 #train# step 2400, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:33.018291 #train# step 2401, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:34.559822 #train# step 2402, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:36.107171 #train# step 2403, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:37.676846 #train# step 2404, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:39.241444 #train# step 2405, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:40.791797 #train# step 2406, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:42.307160 #train# step 2407, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:43.880812 #train# step 2408, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:45.437819 #train# step 2409, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:46.967426 #train# step 2410, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:48.514511 #train# step 2411, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:50.044303 #train# step 2412, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:51.598280 #train# step 2413, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:53.184456 #train# step 2414, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:54.748336 #train# step 2415, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:56.325488 #train# step 2416, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:57.892531 #train# step 2417, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:15:59.429645 #train# step 2418, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:00.991478 #train# step 2419, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:02.520866 #train# step 2420, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:04.072190 #train# step 2421, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:05.650599 #train# step 2422, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:07.209550 #train# step 2423, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:08.738173 #train# step 2424, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:10.299325 #train# step 2425, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:11.847574 #train# step 2426, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:13.377249 #train# step 2427, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:14.925618 #train# step 2428, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:16.477049 #train# step 2429, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:18.015790 #train# step 2430, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:19.572614 #train# step 2431, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:21.131255 #train# step 2432, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:22.665859 #train# step 2433, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:24.226138 #train# step 2434, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:25.775827 #train# step 2435, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:27.301222 #train# step 2436, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:28.845535 #train# step 2437, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:30.422506 #train# step 2438, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:31.942885 #train# step 2439, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:33.478415 #train# step 2440, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:35.055836 #train# step 2441, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:36.571886 #train# step 2442, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:38.128937 #train# step 2443, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:39.671054 #train# step 2444, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:41.230443 #train# step 2445, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:42.769435 #train# step 2446, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:44.309699 #train# step 2447, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:45.872897 #train# step 2448, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:47.442530 #train# step 2449, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:49.012481 #train# step 2450, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:50.548391 #train# step 2451, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:52.078173 #train# step 2452, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:53.630556 #train# step 2453, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:55.201748 #train# step 2454, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:56.760134 #train# step 2455, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:58.333609 #train# step 2456, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:16:59.882763 #train# step 2457, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:01.436533 #train# step 2458, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:03.008080 #train# step 2459, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:04.573638 #train# step 2460, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:06.131305 #train# step 2461, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:07.660459 #train# step 2462, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:09.203168 #train# step 2463, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:10.783827 #train# step 2464, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:12.347381 #train# step 2465, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:13.899264 #train# step 2466, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:15.435065 #train# step 2467, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:16.974000 #train# step 2468, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:18.516015 #train# step 2469, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:20.072672 #train# step 2470, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:21.615354 #train# step 2471, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:23.169880 #train# step 2472, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:24.705701 #train# step 2473, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:26.220726 #train# step 2474, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:27.747943 #train# step 2475, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:29.300383 #train# step 2476, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:30.833298 #train# step 2477, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:32.377156 #train# step 2478, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:33.936230 #train# step 2479, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:35.501031 #train# step 2480, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:37.054750 #train# step 2481, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:38.591069 #train# step 2482, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:40.145203 #train# step 2483, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:41.647707 #train# step 2484, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:43.187962 #train# step 2485, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:44.762657 #train# step 2486, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:46.280814 #train# step 2487, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:47.831356 #train# step 2488, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:49.409111 #train# step 2489, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:50.934380 #train# step 2490, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:52.463072 #train# step 2491, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:53.993669 #train# step 2492, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:55.543015 #train# step 2493, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:57.075632 #train# step 2494, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:17:58.615496 #train# step 2495, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:00.183252 #train# step 2496, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:01.732366 #train# step 2497, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:03.268046 #train# step 2498, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:04.809546 #train# step 2499, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:06.341674 #train# step 2500, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:07.906525 #train# step 2501, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:09.468315 #train# step 2502, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:11.042345 #train# step 2503, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:12.576220 #train# step 2504, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:14.115443 #train# step 2505, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:15.642044 #train# step 2506, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:17.169052 #train# step 2507, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:18.732089 #train# step 2508, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:20.301249 #train# step 2509, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:21.825831 #train# step 2510, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:23.389622 #train# step 2511, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:24.942635 #train# step 2512, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:26.481135 #train# step 2513, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:28.037303 #train# step 2514, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:29.566777 #train# step 2515, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:31.124779 #train# step 2516, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:32.673409 #train# step 2517, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:34.212095 #train# step 2518, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:35.741166 #train# step 2519, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:37.287687 #train# step 2520, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:38.837712 #train# step 2521, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:40.386952 #train# step 2522, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:41.922116 #train# step 2523, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:43.456970 #train# step 2524, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:44.996975 #train# step 2525, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:46.553238 #train# step 2526, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:48.081489 #train# step 2527, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:49.608042 #train# step 2528, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:51.157637 #train# step 2529, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:52.735406 #train# step 2530, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:54.294045 #train# step 2531, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:55.855895 #train# step 2532, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:57.410901 #train# step 2533, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:18:58.919507 #train# step 2534, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:00.511356 #train# step 2535, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:02.098083 #train# step 2536, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:03.697124 #train# step 2537, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:05.269998 #train# step 2538, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:06.809254 #train# step 2539, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:08.330658 #train# step 2540, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:09.897224 #train# step 2541, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:11.448653 #train# step 2542, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:12.977092 #train# step 2543, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:14.519470 #train# step 2544, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:16.081688 #train# step 2545, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:17.643999 #train# step 2546, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:19.188244 #train# step 2547, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:20.739541 #train# step 2548, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:22.268401 #train# step 2549, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:23.820452 #train# step 2550, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:25.362993 #train# step 2551, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:26.890453 #train# step 2552, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:28.442194 #train# step 2553, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:29.972972 #train# step 2554, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:31.533305 #train# step 2555, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:33.050688 #train# step 2556, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:34.587872 #train# step 2557, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:36.134813 #train# step 2558, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:37.681640 #train# step 2559, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:39.224318 #train# step 2560, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:40.795487 #train# step 2561, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:42.365295 #train# step 2562, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:43.922713 #train# step 2563, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:45.473522 #train# step 2564, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:47.030518 #train# step 2565, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:48.602828 #train# step 2566, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:50.174413 #train# step 2567, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:51.722957 #train# step 2568, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:53.289304 #train# step 2569, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:54.851728 #train# step 2570, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:56.439703 #train# step 2571, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:58.018548 #train# step 2572, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:19:59.560246 #train# step 2573, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:01.123216 #train# step 2574, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:02.694629 #train# step 2575, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:04.258878 #train# step 2576, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:05.827780 #train# step 2577, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:07.367293 #train# step 2578, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:08.939417 #train# step 2579, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:10.476844 #train# step 2580, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:12.013151 #train# step 2581, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:13.556986 #train# step 2582, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:15.104068 #train# step 2583, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:16.650819 #train# step 2584, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:18.194765 #train# step 2585, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:19.735087 #train# step 2586, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:21.296621 #train# step 2587, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:22.820197 #train# step 2588, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:24.353672 #train# step 2589, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:25.904247 #train# step 2590, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:27.448146 #train# step 2591, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:28.973767 #train# step 2592, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:30.520515 #train# step 2593, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:32.065834 #train# step 2594, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:33.611264 #train# step 2595, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:35.145781 #train# step 2596, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:36.715152 #train# step 2597, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:38.256316 #train# step 2598, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:39.839772 #train# step 2599, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:41.357069 #train# step 2600, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:42.931409 #train# step 2601, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:44.484205 #train# step 2602, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:46.041909 #train# step 2603, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:47.604562 #train# step 2604, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:49.179220 #train# step 2605, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:50.715066 #train# step 2606, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:52.274884 #train# step 2607, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:53.809024 #train# step 2608, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:55.334176 #train# step 2609, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:56.884980 #train# step 2610, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:20:58.448223 #train# step 2611, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:00.028253 #train# step 2612, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:01.546391 #train# step 2613, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:03.096929 #train# step 2614, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:04.647903 #train# step 2615, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:06.193603 #train# step 2616, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:07.725388 #train# step 2617, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:09.311728 #train# step 2618, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:10.875349 #train# step 2619, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:12.410937 #train# step 2620, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:13.952335 #train# step 2621, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:15.501009 #train# step 2622, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:17.063570 #train# step 2623, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:18.647301 #train# step 2624, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:20.216525 #train# step 2625, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:21.817725 #train# step 2626, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:23.373979 #train# step 2627, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:24.933802 #train# step 2628, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:26.464589 #train# step 2629, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:28.007948 #train# step 2630, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:29.541979 #train# step 2631, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:31.063459 #train# step 2632, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:32.650081 #train# step 2633, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:34.213339 #train# step 2634, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:35.779014 #train# step 2635, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:37.319139 #train# step 2636, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:38.847568 #train# step 2637, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:40.392830 #train# step 2638, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:41.975388 #train# step 2639, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:43.502877 #train# step 2640, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:45.041975 #train# step 2641, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:46.598849 #train# step 2642, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:48.127761 #train# step 2643, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:49.682948 #train# step 2644, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:51.232278 #train# step 2645, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:52.770891 #train# step 2646, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:54.308409 #train# step 2647, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:55.890663 #train# step 2648, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:57.449629 #train# step 2649, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:21:59.013780 #train# step 2650, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:00.563603 #train# step 2651, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:02.095972 #train# step 2652, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:03.646265 #train# step 2653, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:05.197939 #train# step 2654, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:06.761515 #train# step 2655, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:08.305741 #train# step 2656, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:09.851967 #train# step 2657, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:11.398686 #train# step 2658, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:12.962222 #train# step 2659, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:14.502797 #train# step 2660, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:16.069123 #train# step 2661, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:17.632324 #train# step 2662, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:19.187105 #train# step 2663, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:20.750977 #train# step 2664, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:22.315462 #train# step 2665, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:23.830502 #train# step 2666, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:25.382531 #train# step 2667, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:26.891580 #train# step 2668, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:28.418756 #train# step 2669, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:29.959806 #train# step 2670, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:31.521522 #train# step 2671, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:33.050756 #train# step 2672, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:34.621469 #train# step 2673, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:36.169139 #train# step 2674, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:37.751440 #train# step 2675, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:39.296350 #train# step 2676, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:40.806275 #train# step 2677, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:42.337031 #train# step 2678, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:43.904998 #train# step 2679, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:45.413378 #train# step 2680, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:46.990778 #train# step 2681, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:48.599573 #train# step 2682, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:50.147480 #train# step 2683, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:51.680502 #train# step 2684, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:53.241859 #train# step 2685, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:54.788390 #train# step 2686, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:56.342575 #train# step 2687, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:57.895411 #train# step 2688, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:22:59.454621 #train# step 2689, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:00.976445 #train# step 2690, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:02.511887 #train# step 2691, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:04.045940 #train# step 2692, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:05.556390 #train# step 2693, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:07.125781 #train# step 2694, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:08.683992 #train# step 2695, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:10.231736 #train# step 2696, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:11.773273 #train# step 2697, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:13.308302 #train# step 2698, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:14.829712 #train# step 2699, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:16.376520 #train# step 2700, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:17.958331 #train# step 2701, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:19.503509 #train# step 2702, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:21.036147 #train# step 2703, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:22.598899 #train# step 2704, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:24.132925 #train# step 2705, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:25.675214 #train# step 2706, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:27.245997 #train# step 2707, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:28.792801 #train# step 2708, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:30.367596 #train# step 2709, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:31.899910 #train# step 2710, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:33.413097 #train# step 2711, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:34.959966 #train# step 2712, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:36.501194 #train# step 2713, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:38.063482 #train# step 2714, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:39.597844 #train# step 2715, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:41.136383 #train# step 2716, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:42.671827 #train# step 2717, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:44.238135 #train# step 2718, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:45.803475 #train# step 2719, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:47.336108 #train# step 2720, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:48.871829 #train# step 2721, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:50.423693 #train# step 2722, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:51.998431 #train# step 2723, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:53.575073 #train# step 2724, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:55.145121 #train# step 2725, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:56.703214 #train# step 2726, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:58.251814 #train# step 2727, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:23:59.802006 #train# step 2728, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:01.362865 #train# step 2729, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:02.909005 #train# step 2730, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:04.475522 #train# step 2731, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:06.018004 #train# step 2732, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:07.588089 #train# step 2733, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:09.116671 #train# step 2734, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:10.700956 #train# step 2735, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:12.239849 #train# step 2736, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:13.814579 #train# step 2737, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:15.360840 #train# step 2738, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:16.902179 #train# step 2739, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:18.465833 #train# step 2740, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:20.031771 #train# step 2741, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:21.563164 #train# step 2742, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:23.112419 #train# step 2743, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:24.656093 #train# step 2744, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:26.200501 #train# step 2745, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:27.755818 #train# step 2746, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:29.325378 #train# step 2747, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:30.886158 #train# step 2748, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:32.449654 #train# step 2749, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:33.990667 #train# step 2750, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:35.551538 #train# step 2751, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:37.102313 #train# step 2752, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:38.641549 #train# step 2753, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:40.209575 #train# step 2754, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:41.748832 #train# step 2755, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:43.267995 #train# step 2756, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:44.832806 #train# step 2757, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:46.373315 #train# step 2758, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:47.931006 #train# step 2759, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:49.499089 #train# step 2760, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:51.068289 #train# step 2761, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:52.627502 #train# step 2762, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:54.151721 #train# step 2763, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:55.727326 #train# step 2764, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:57.301698 #train# step 2765, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:24:58.842178 #train# step 2766, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:00.391638 #train# step 2767, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:01.939585 #train# step 2768, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:03.452036 #train# step 2769, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:04.954056 #train# step 2770, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:06.523400 #train# step 2771, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:08.072562 #train# step 2772, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:09.591782 #train# step 2773, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:11.129733 #train# step 2774, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:12.675895 #train# step 2775, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:14.270890 #train# step 2776, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:15.795261 #train# step 2777, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:17.343550 #train# step 2778, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:18.892515 #train# step 2779, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:20.459992 #train# step 2780, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:22.020578 #train# step 2781, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:23.610613 #train# step 2782, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:25.136566 #train# step 2783, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:26.706729 #train# step 2784, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:28.258623 #train# step 2785, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:29.783546 #train# step 2786, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:31.345715 #train# step 2787, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:32.869563 #train# step 2788, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:34.421697 #train# step 2789, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:35.958409 #train# step 2790, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:37.510252 #train# step 2791, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:39.086713 #train# step 2792, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:40.677014 #train# step 2793, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:42.207487 #train# step 2794, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:43.740375 #train# step 2795, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:45.270267 #train# step 2796, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:46.825294 #train# step 2797, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:48.340908 #train# step 2798, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:49.861815 #train# step 2799, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:51.374146 #train# step 2800, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:52.949437 #train# step 2801, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:54.498817 #train# step 2802, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:56.060208 #train# step 2803, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:57.609163 #train# step 2804, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:25:59.137651 #train# step 2805, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:00.689342 #train# step 2806, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:02.239621 #train# step 2807, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:03.802101 #train# step 2808, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:05.360236 #train# step 2809, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:06.899366 #train# step 2810, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:08.463538 #train# step 2811, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:10.003352 #train# step 2812, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:11.550880 #train# step 2813, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:13.077463 #train# step 2814, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:14.659797 #train# step 2815, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:16.202498 #train# step 2816, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:17.767400 #train# step 2817, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:19.312653 #train# step 2818, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:20.863853 #train# step 2819, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:22.393204 #train# step 2820, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:23.946713 #train# step 2821, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:25.470254 #train# step 2822, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:27.022129 #train# step 2823, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:28.575153 #train# step 2824, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:30.141803 #train# step 2825, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:31.690084 #train# step 2826, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:33.237928 #train# step 2827, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:34.817619 #train# step 2828, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:36.375282 #train# step 2829, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:37.905691 #train# step 2830, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:39.471378 #train# step 2831, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:41.022380 #train# step 2832, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:42.568725 #train# step 2833, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:44.148500 #train# step 2834, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:45.685816 #train# step 2835, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:47.222300 #train# step 2836, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:48.766806 #train# step 2837, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:50.314170 #train# step 2838, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:51.912596 #train# step 2839, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:53.454026 #train# step 2840, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:55.017262 #train# step 2841, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:56.595863 #train# step 2842, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:58.135877 #train# step 2843, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:26:59.679553 #train# step 2844, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:01.212657 #train# step 2845, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:02.738268 #train# step 2846, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:04.301686 #train# step 2847, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:05.834288 #train# step 2848, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:07.390526 #train# step 2849, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:08.936951 #train# step 2850, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:10.487307 #train# step 2851, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:11.992801 #train# step 2852, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:13.541496 #train# step 2853, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:15.089915 #train# step 2854, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:16.609247 #train# step 2855, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:18.189440 #train# step 2856, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:19.728758 #train# step 2857, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:21.295165 #train# step 2858, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:22.863527 #train# step 2859, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:24.403844 #train# step 2860, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:25.984853 #train# step 2861, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:27.544564 #train# step 2862, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:29.076423 #train# step 2863, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:30.645481 #train# step 2864, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:32.180111 #train# step 2865, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:33.721578 #train# step 2866, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:35.262180 #train# step 2867, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:36.798427 #train# step 2868, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:38.317736 #train# step 2869, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:39.852106 #train# step 2870, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:41.390506 #train# step 2871, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:42.937856 #train# step 2872, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:44.491472 #train# step 2873, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:46.077146 #train# step 2874, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:47.606744 #train# step 2875, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:49.159628 #train# step 2876, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:50.721748 #train# step 2877, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:52.292441 #train# step 2878, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:53.829619 #train# step 2879, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:55.369054 #train# step 2880, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:56.910464 #train# step 2881, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:27:58.435070 #train# step 2882, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:00.019554 #train# step 2883, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:01.570779 #train# step 2884, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:03.121665 #train# step 2885, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:04.671298 #train# step 2886, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:06.228150 #train# step 2887, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:07.786762 #train# step 2888, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:09.302774 #train# step 2889, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:10.832666 #train# step 2890, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:12.382531 #train# step 2891, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:13.921221 #train# step 2892, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:15.462458 #train# step 2893, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:17.023355 #train# step 2894, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:18.557005 #train# step 2895, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:20.108364 #train# step 2896, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:21.670598 #train# step 2897, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:23.194252 #train# step 2898, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:24.769203 #train# step 2899, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:26.330444 #train# step 2900, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:27.904007 #train# step 2901, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:29.467756 #train# step 2902, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:30.999640 #train# step 2903, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:32.559148 #train# step 2904, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:34.121145 #train# step 2905, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:35.676535 #train# step 2906, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:37.254380 #train# step 2907, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:38.800120 #train# step 2908, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:40.350894 #train# step 2909, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:41.929921 #train# step 2910, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:43.479138 #train# step 2911, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:45.009245 #train# step 2912, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:46.590181 #train# step 2913, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:48.122487 #train# step 2914, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:49.660970 #train# step 2915, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:51.199219 #train# step 2916, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:52.758396 #train# step 2917, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:54.315684 #train# step 2918, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:55.856918 #train# step 2919, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:57.416561 #train# step 2920, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:28:58.961536 #train# step 2921, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:00.525156 #train# step 2922, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:02.052165 #train# step 2923, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:03.598060 #train# step 2924, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:05.150293 #train# step 2925, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:06.708430 #train# step 2926, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:08.266330 #train# step 2927, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:09.828587 #train# step 2928, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:11.371288 #train# step 2929, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:12.908526 #train# step 2930, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:14.467637 #train# step 2931, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:15.969624 #train# step 2932, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:17.580849 #train# step 2933, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:19.136164 #train# step 2934, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:20.707830 #train# step 2935, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:22.245187 #train# step 2936, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:23.813316 #train# step 2937, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:25.353029 #train# step 2938, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:26.908012 #train# step 2939, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:28.461654 #train# step 2940, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:30.009561 #train# step 2941, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:31.578647 #train# step 2942, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:33.139258 #train# step 2943, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:34.708527 #train# step 2944, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:36.238159 #train# step 2945, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:37.770690 #train# step 2946, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:39.337513 #train# step 2947, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:40.879931 #train# step 2948, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:42.417724 #train# step 2949, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:43.970182 #train# step 2950, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:45.558481 #train# step 2951, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:47.109993 #train# step 2952, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:48.696167 #train# step 2953, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:50.277788 #train# step 2954, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:51.821847 #train# step 2955, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:53.361237 #train# step 2956, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:54.909658 #train# step 2957, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:56.420556 #train# step 2958, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:57.965871 #train# step 2959, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:29:59.470527 #train# step 2960, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:01.017407 #train# step 2961, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:02.557866 #train# step 2962, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:04.107434 #train# step 2963, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:05.659034 #train# step 2964, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:07.180948 #train# step 2965, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:08.722707 #train# step 2966, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:10.305811 #train# step 2967, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:11.884046 #train# step 2968, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:13.448085 #train# step 2969, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:14.997971 #train# step 2970, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:16.536051 #train# step 2971, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:18.091645 #train# step 2972, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:19.618488 #train# step 2973, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:21.177819 #train# step 2974, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:22.731919 #train# step 2975, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:24.290481 #train# step 2976, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:25.839807 #train# step 2977, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:27.369322 #train# step 2978, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:28.907763 #train# step 2979, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:30.481664 #train# step 2980, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:32.024062 #train# step 2981, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:33.571456 #train# step 2982, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:35.095270 #train# step 2983, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:36.641241 #train# step 2984, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:38.188453 #train# step 2985, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:39.725485 #train# step 2986, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:41.259428 #train# step 2987, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:42.817119 #train# step 2988, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:44.379681 #train# step 2989, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:45.902837 #train# step 2990, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:47.433908 #train# step 2991, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:48.983400 #train# step 2992, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:50.544784 #train# step 2993, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:52.100390 #train# step 2994, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:53.673772 #train# step 2995, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:55.203306 #train# step 2996, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:56.782495 #train# step 2997, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:58.331919 #train# step 2998, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:30:59.871167 #train# step 2999, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:01.394887 #train# step 3000, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:02.933581 #train# step 3001, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:04.507523 #train# step 3002, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:06.060773 #train# step 3003, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:07.600875 #train# step 3004, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:09.190736 #train# step 3005, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:10.768506 #train# step 3006, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:12.304774 #train# step 3007, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:13.848140 #train# step 3008, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:15.423381 #train# step 3009, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:16.947424 #train# step 3010, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:18.485298 #train# step 3011, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:20.034078 #train# step 3012, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:21.608722 #train# step 3013, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:23.168887 #train# step 3014, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:24.728912 #train# step 3015, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:26.264196 #train# step 3016, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:27.810056 #train# step 3017, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:29.366240 #train# step 3018, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:30.921757 #train# step 3019, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:32.449977 #train# step 3020, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:34.000941 #train# step 3021, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:35.533119 #train# step 3022, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:37.077693 #train# step 3023, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:38.583934 #train# step 3024, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:40.158654 #train# step 3025, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:41.709887 #train# step 3026, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:43.254298 #train# step 3027, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:44.784734 #train# step 3028, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:46.351473 #train# step 3029, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:47.894010 #train# step 3030, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:49.447927 #train# step 3031, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:50.996865 #train# step 3032, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:52.566310 #train# step 3033, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:54.130798 #train# step 3034, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:55.670117 #train# step 3035, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:57.211245 #train# step 3036, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:31:58.739337 #train# step 3037, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:00.312190 #train# step 3038, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:01.894028 #train# step 3039, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:03.430846 #train# step 3040, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:04.963715 #train# step 3041, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:06.500774 #train# step 3042, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:08.056414 #train# step 3043, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:09.610154 #train# step 3044, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:11.196936 #train# step 3045, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:12.754604 #train# step 3046, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:14.330421 #train# step 3047, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:15.869668 #train# step 3048, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:17.403705 #train# step 3049, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:18.981269 #train# step 3050, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:20.521830 #train# step 3051, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:22.084912 #train# step 3052, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:23.659410 #train# step 3053, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:25.185284 #train# step 3054, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:26.726856 #train# step 3055, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:28.248316 #train# step 3056, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:29.799223 #train# step 3057, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:31.365041 #train# step 3058, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:32.888417 #train# step 3059, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:34.444396 #train# step 3060, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:35.979011 #train# step 3061, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:37.518843 #train# step 3062, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:39.080106 #train# step 3063, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:40.604753 #train# step 3064, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:42.156396 #train# step 3065, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:43.736032 #train# step 3066, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:45.273906 #train# step 3067, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:46.850389 #train# step 3068, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:48.404089 #train# step 3069, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:49.938279 #train# step 3070, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:51.473155 #train# step 3071, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:53.028028 #train# step 3072, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:54.592559 #train# step 3073, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:56.150525 #train# step 3074, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:57.711013 #train# step 3075, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:32:59.217055 #train# step 3076, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:00.775117 #train# step 3077, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:02.311633 #train# step 3078, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:03.847151 #train# step 3079, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:05.376332 #train# step 3080, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:06.944122 #train# step 3081, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:08.516218 #train# step 3082, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:10.032835 #train# step 3083, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:11.609821 #train# step 3084, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:13.181899 #train# step 3085, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:14.720712 #train# step 3086, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:16.286312 #train# step 3087, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:17.815719 #train# step 3088, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:19.357995 #train# step 3089, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:20.937080 #train# step 3090, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:22.482670 #train# step 3091, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:24.016302 #train# step 3092, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:25.573324 #train# step 3093, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:27.097745 #train# step 3094, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:28.650564 #train# step 3095, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:30.217853 #train# step 3096, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:31.786802 #train# step 3097, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:33.358519 #train# step 3098, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:34.902770 #train# step 3099, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:36.486472 #train# step 3100, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:38.034421 #train# step 3101, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:39.589132 #train# step 3102, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:41.083305 #train# step 3103, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:42.632914 #train# step 3104, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:44.220017 #train# step 3105, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:45.777338 #train# step 3106, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:47.305576 #train# step 3107, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:48.856454 #train# step 3108, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:50.411097 #train# step 3109, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:51.925009 #train# step 3110, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:53.476952 #train# step 3111, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:55.007681 #train# step 3112, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:56.557598 #train# step 3113, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:58.121451 #train# step 3114, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:33:59.688301 #train# step 3115, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:01.254278 #train# step 3116, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:02.838199 #train# step 3117, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:04.392378 #train# step 3118, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:05.942996 #train# step 3119, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:07.488310 #train# step 3120, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:09.024792 #train# step 3121, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:10.534805 #train# step 3122, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:12.124100 #train# step 3123, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:13.684781 #train# step 3124, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:15.224557 #train# step 3125, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:16.757589 #train# step 3126, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:18.317818 #train# step 3127, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:19.875623 #train# step 3128, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:21.412345 #train# step 3129, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:22.964363 #train# step 3130, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:24.530613 #train# step 3131, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:26.100617 #train# step 3132, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:27.631922 #train# step 3133, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:29.214863 #train# step 3134, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:30.756643 #train# step 3135, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:32.328182 #train# step 3136, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:33.873601 #train# step 3137, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:35.394521 #train# step 3138, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:36.949897 #train# step 3139, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:38.478211 #train# step 3140, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:40.029020 #train# step 3141, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:41.606188 #train# step 3142, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:43.149503 #train# step 3143, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:44.711488 #train# step 3144, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:46.251431 #train# step 3145, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:47.797956 #train# step 3146, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:49.340575 #train# step 3147, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:50.905527 #train# step 3148, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:52.458539 #train# step 3149, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:54.001533 #train# step 3150, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:55.552543 #train# step 3151, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:57.093740 #train# step 3152, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:34:58.624694 #train# step 3153, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:00.148016 #train# step 3154, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:01.696808 #train# step 3155, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:03.231764 #train# step 3156, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:04.788536 #train# step 3157, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:06.359262 #train# step 3158, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:07.913707 #train# step 3159, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:09.453385 #train# step 3160, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:10.993544 #train# step 3161, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:12.551272 #train# step 3162, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:14.089197 #train# step 3163, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:15.645635 #train# step 3164, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:17.190189 #train# step 3165, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:18.737213 #train# step 3166, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:20.280228 #train# step 3167, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:21.785511 #train# step 3168, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:23.332200 #train# step 3169, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:24.863025 #train# step 3170, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:26.410912 #train# step 3171, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:27.974839 #train# step 3172, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:29.517565 #train# step 3173, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:31.059054 #train# step 3174, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:32.608893 #train# step 3175, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:34.165645 #train# step 3176, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:35.731282 #train# step 3177, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:37.263125 #train# step 3178, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:38.815905 #train# step 3179, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:40.370794 #train# step 3180, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:41.961734 #train# step 3181, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:43.519986 #train# step 3182, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:45.061158 #train# step 3183, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:46.626580 #train# step 3184, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:48.162736 #train# step 3185, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:49.728766 #train# step 3186, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:51.294544 #train# step 3187, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:52.847921 #train# step 3188, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:54.415398 #train# step 3189, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:55.950491 #train# step 3190, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:57.504422 #train# step 3191, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:35:59.063964 #train# step 3192, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:00.617381 #train# step 3193, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:02.167878 #train# step 3194, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:03.715585 #train# step 3195, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:05.280059 #train# step 3196, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:06.830362 #train# step 3197, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:08.410719 #train# step 3198, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:09.972961 #train# step 3199, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:11.514666 #train# step 3200, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:13.077337 #train# step 3201, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:14.635440 #train# step 3202, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:16.178334 #train# step 3203, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:17.719041 #train# step 3204, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:19.260942 #train# step 3205, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:20.802699 #train# step 3206, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:22.365193 #train# step 3207, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:23.902817 #train# step 3208, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:25.443522 #train# step 3209, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:27.001442 #train# step 3210, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:28.548834 #train# step 3211, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:30.094043 #train# step 3212, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:31.618132 #train# step 3213, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:33.153095 #train# step 3214, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:34.724122 #train# step 3215, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:36.270076 #train# step 3216, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:37.807774 #train# step 3217, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:39.329280 #train# step 3218, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:40.889679 #train# step 3219, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:42.450864 #train# step 3220, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:44.011712 #train# step 3221, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:45.550902 #train# step 3222, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:47.125432 #train# step 3223, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:48.719400 #train# step 3224, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:50.254891 #train# step 3225, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:51.807131 #train# step 3226, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:53.316536 #train# step 3227, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:54.873058 #train# step 3228, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:56.414423 #train# step 3229, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:57.991007 #train# step 3230, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:36:59.524813 #train# step 3231, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:01.066676 #train# step 3232, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:02.592571 #train# step 3233, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:04.146066 #train# step 3234, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:05.658833 #train# step 3235, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:07.222070 #train# step 3236, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:08.793792 #train# step 3237, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:10.350220 #train# step 3238, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:11.946982 #train# step 3239, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:13.488246 #train# step 3240, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:15.051362 #train# step 3241, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:16.589569 #train# step 3242, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:18.144254 #train# step 3243, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:19.688890 #train# step 3244, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:21.232177 #train# step 3245, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:22.772296 #train# step 3246, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:24.345543 #train# step 3247, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:25.889909 #train# step 3248, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:27.445328 #train# step 3249, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:29.046503 #train# step 3250, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:30.600978 #train# step 3251, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:32.143665 #train# step 3252, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:33.707991 #train# step 3253, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:35.284972 #train# step 3254, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:36.836687 #train# step 3255, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:38.414293 #train# step 3256, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:39.962518 #train# step 3257, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:41.492696 #train# step 3258, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:43.031678 #train# step 3259, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:44.599515 #train# step 3260, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:46.187962 #train# step 3261, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:47.732217 #train# step 3262, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:49.282768 #train# step 3263, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:50.815816 #train# step 3264, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:52.355025 #train# step 3265, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:53.914943 #train# step 3266, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:55.448660 #train# step 3267, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:57.023149 #train# step 3268, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:37:58.574670 #train# step 3269, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:00.115706 #train# step 3270, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:01.679374 #train# step 3271, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:03.219685 #train# step 3272, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:04.734445 #train# step 3273, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:06.297139 #train# step 3274, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:07.859810 #train# step 3275, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:09.408896 #train# step 3276, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:10.951796 #train# step 3277, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:12.483522 #train# step 3278, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:14.022441 #train# step 3279, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:15.550640 #train# step 3280, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:17.119483 #train# step 3281, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:18.678989 #train# step 3282, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:20.242960 #train# step 3283, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:21.790660 #train# step 3284, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:23.313462 #train# step 3285, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:24.855572 #train# step 3286, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:26.388332 #train# step 3287, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:27.936832 #train# step 3288, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:29.496126 #train# step 3289, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:31.049019 #train# step 3290, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:32.605245 #train# step 3291, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:34.172398 #train# step 3292, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:35.736745 #train# step 3293, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:37.267394 #train# step 3294, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:38.829373 #train# step 3295, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:40.360775 #train# step 3296, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:41.892096 #train# step 3297, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:43.443414 #train# step 3298, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:45.009762 #train# step 3299, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:46.522697 #train# step 3300, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:48.070405 #train# step 3301, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:49.633087 #train# step 3302, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:51.159618 #train# step 3303, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:52.722143 #train# step 3304, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:54.265556 #train# step 3305, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:55.844040 #train# step 3306, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:57.371400 #train# step 3307, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:38:58.910430 #train# step 3308, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:00.483257 #train# step 3309, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:02.005677 #train# step 3310, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:03.529662 #train# step 3311, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:05.068881 #train# step 3312, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:06.625219 #train# step 3313, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:08.199551 #train# step 3314, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:09.719936 #train# step 3315, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:11.282999 #train# step 3316, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:12.802189 #train# step 3317, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:14.331044 #train# step 3318, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:15.899225 #train# step 3319, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:17.471666 #train# step 3320, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:19.010707 #train# step 3321, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:20.579013 #train# step 3322, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:22.157669 #train# step 3323, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:23.722832 #train# step 3324, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:25.297685 #train# step 3325, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:26.850069 #train# step 3326, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:28.433687 #train# step 3327, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:29.963012 #train# step 3328, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:31.525730 #train# step 3329, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:33.068930 #train# step 3330, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:34.643869 #train# step 3331, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:36.166028 #train# step 3332, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:37.740840 #train# step 3333, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:39.269285 #train# step 3334, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:40.827632 #train# step 3335, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:42.387831 #train# step 3336, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:43.947637 #train# step 3337, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:45.492617 #train# step 3338, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:47.069635 #train# step 3339, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:48.605300 #train# step 3340, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:50.162160 #train# step 3341, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:51.719069 #train# step 3342, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:53.256853 #train# step 3343, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:54.790314 #train# step 3344, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:56.338317 #train# step 3345, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:57.872400 #train# step 3346, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:39:59.398271 #train# step 3347, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:00.942098 #train# step 3348, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:02.495894 #train# step 3349, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:04.082599 #train# step 3350, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:05.630980 #train# step 3351, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:07.156481 #train# step 3352, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:08.714811 #train# step 3353, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:10.277844 #train# step 3354, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:11.813576 #train# step 3355, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:13.370104 #train# step 3356, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:14.914195 #train# step 3357, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:16.459327 #train# step 3358, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:18.019898 #train# step 3359, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:19.608911 #train# step 3360, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:21.119789 #train# step 3361, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:22.674632 #train# step 3362, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:24.221220 #train# step 3363, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:25.760046 #train# step 3364, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:27.297654 #train# step 3365, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:28.828391 #train# step 3366, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:30.358598 #train# step 3367, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:31.959672 #train# step 3368, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:33.527318 #train# step 3369, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:35.055850 #train# step 3370, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:36.625156 #train# step 3371, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:38.171892 #train# step 3372, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:39.701254 #train# step 3373, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:41.243412 #train# step 3374, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:42.772174 #train# step 3375, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:44.334702 #train# step 3376, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:45.886289 #train# step 3377, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:47.433158 #train# step 3378, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:48.989333 #train# step 3379, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:50.553282 #train# step 3380, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:52.154629 #train# step 3381, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:53.712457 #train# step 3382, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:55.271009 #train# step 3383, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:56.842418 #train# step 3384, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:58.433100 #train# step 3385, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:40:59.994322 #train# step 3386, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:01.526746 #train# step 3387, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:03.090519 #train# step 3388, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:04.617993 #train# step 3389, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:06.139182 #train# step 3390, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:07.672583 #train# step 3391, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:09.230624 #train# step 3392, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:10.780903 #train# step 3393, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:12.344378 #train# step 3394, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:13.908536 #train# step 3395, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:15.479985 #train# step 3396, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:17.033912 #train# step 3397, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:18.571163 #train# step 3398, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:20.128373 #train# step 3399, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:21.651436 #train# step 3400, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:23.181618 #train# step 3401, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:24.738608 #train# step 3402, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:26.303996 #train# step 3403, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:27.864817 #train# step 3404, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:29.432359 #train# step 3405, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:30.966847 #train# step 3406, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:32.512682 #train# step 3407, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:34.072610 #train# step 3408, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:35.586296 #train# step 3409, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:37.165183 #train# step 3410, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:38.739650 #train# step 3411, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:40.288771 #train# step 3412, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:41.847500 #train# step 3413, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:43.416722 #train# step 3414, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:44.948283 #train# step 3415, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:46.534728 #train# step 3416, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:48.066083 #train# step 3417, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:49.608128 #train# step 3418, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:51.178766 #train# step 3419, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:52.737883 #train# step 3420, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:54.285015 #train# step 3421, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:55.838684 #train# step 3422, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:57.395126 #train# step 3423, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:41:58.934899 #train# step 3424, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:00.494391 #train# step 3425, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:02.040761 #train# step 3426, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:03.579632 #train# step 3427, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:05.113709 #train# step 3428, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:06.632005 #train# step 3429, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:08.179318 #train# step 3430, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:09.724841 #train# step 3431, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:11.295785 #train# step 3432, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:12.849254 #train# step 3433, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:14.395395 #train# step 3434, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:15.940413 #train# step 3435, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:17.493838 #train# step 3436, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:19.023740 #train# step 3437, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:20.561299 #train# step 3438, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:22.090047 #train# step 3439, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:23.654516 #train# step 3440, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:25.250867 #train# step 3441, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:26.824893 #train# step 3442, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:28.351952 #train# step 3443, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:29.884033 #train# step 3444, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:31.430456 #train# step 3445, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:32.979034 #train# step 3446, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:34.526067 #train# step 3447, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:36.062400 #train# step 3448, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:37.596060 #train# step 3449, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:39.151500 #train# step 3450, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:40.728151 #train# step 3451, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:42.252790 #train# step 3452, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:43.779605 #train# step 3453, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:45.313196 #train# step 3454, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:46.878403 #train# step 3455, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:48.417974 #train# step 3456, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:50.005316 #train# step 3457, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:51.534856 #train# step 3458, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:53.065298 #train# step 3459, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:54.632356 #train# step 3460, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:56.181237 #train# step 3461, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:57.730378 #train# step 3462, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:42:59.265723 #train# step 3463, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:00.812704 #train# step 3464, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:02.368117 #train# step 3465, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:03.927970 #train# step 3466, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:05.473996 #train# step 3467, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:07.007765 #train# step 3468, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:08.575649 #train# step 3469, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:10.166895 #train# step 3470, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:11.709318 #train# step 3471, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:13.262847 #train# step 3472, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:14.821544 #train# step 3473, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:16.417645 #train# step 3474, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:17.968601 #train# step 3475, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:19.533781 #train# step 3476, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:21.072296 #train# step 3477, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:22.607717 #train# step 3478, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:24.166574 #train# step 3479, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:25.724110 #train# step 3480, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:27.289172 #train# step 3481, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:28.811799 #train# step 3482, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:30.331968 #train# step 3483, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:31.854728 #train# step 3484, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:33.408566 #train# step 3485, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:34.947615 #train# step 3486, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:36.538063 #train# step 3487, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:38.065947 #train# step 3488, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:39.584744 #train# step 3489, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:41.145149 #train# step 3490, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:42.688662 #train# step 3491, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:44.238970 #train# step 3492, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:45.773000 #train# step 3493, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:47.304479 #train# step 3494, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:48.882924 #train# step 3495, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:50.441885 #train# step 3496, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:51.996596 #train# step 3497, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:53.535123 #train# step 3498, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:55.078324 #train# step 3499, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:56.656770 #train# step 3500, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:58.195772 #train# step 3501, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:43:59.741937 #train# step 3502, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:01.310966 #train# step 3503, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:02.836019 #train# step 3504, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:04.418083 #train# step 3505, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:05.933316 #train# step 3506, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:07.490427 #train# step 3507, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:09.028284 #train# step 3508, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:10.563384 #train# step 3509, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:12.123021 #train# step 3510, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:13.695369 #train# step 3511, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:15.242303 #train# step 3512, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:16.776209 #train# step 3513, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:18.323116 #train# step 3514, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:19.882669 #train# step 3515, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:21.439821 #train# step 3516, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:22.987692 #train# step 3517, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:24.548632 #train# step 3518, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:26.094050 #train# step 3519, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:27.655240 #train# step 3520, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:29.212059 #train# step 3521, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:30.775127 #train# step 3522, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:32.356310 #train# step 3523, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:33.931211 #train# step 3524, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:35.485764 #train# step 3525, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:37.039957 #train# step 3526, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:38.621518 #train# step 3527, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:40.217514 #train# step 3528, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:41.793626 #train# step 3529, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:43.344618 #train# step 3530, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:44.904020 #train# step 3531, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:46.453342 #train# step 3532, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:48.015131 #train# step 3533, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:49.559237 #train# step 3534, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:51.125061 #train# step 3535, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:52.670323 #train# step 3536, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:54.235167 #train# step 3537, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:55.792027 #train# step 3538, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:57.344311 #train# step 3539, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:44:58.905279 #train# step 3540, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:00.481591 #train# step 3541, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:02.046029 #train# step 3542, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:03.591250 #train# step 3543, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:05.146355 #train# step 3544, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:06.685576 #train# step 3545, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:08.269066 #train# step 3546, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:09.811370 #train# step 3547, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:11.358582 #train# step 3548, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:12.917654 #train# step 3549, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:14.443452 #train# step 3550, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:16.021351 #train# step 3551, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:17.581597 #train# step 3552, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:19.102014 #train# step 3553, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:20.664419 #train# step 3554, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:22.211582 #train# step 3555, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:23.772188 #train# step 3556, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:25.299202 #train# step 3557, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:26.817835 #train# step 3558, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:28.380355 #train# step 3559, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:29.907401 #train# step 3560, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:31.456611 #train# step 3561, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:32.985405 #train# step 3562, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:34.544363 #train# step 3563, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:36.047996 #train# step 3564, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:37.569480 #train# step 3565, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:39.118458 #train# step 3566, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:40.659849 #train# step 3567, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:42.222220 #train# step 3568, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:43.757722 #train# step 3569, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:45.306497 #train# step 3570, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:46.879807 #train# step 3571, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:48.398358 #train# step 3572, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:49.949115 #train# step 3573, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:51.497129 #train# step 3574, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:53.040454 #train# step 3575, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:54.596962 #train# step 3576, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:56.174001 #train# step 3577, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:57.757628 #train# step 3578, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:45:59.329753 #train# step 3579, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:00.882722 #train# step 3580, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:02.453861 #train# step 3581, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:03.998148 #train# step 3582, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:05.548675 #train# step 3583, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:07.093853 #train# step 3584, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:08.641882 #train# step 3585, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:10.205860 #train# step 3586, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:11.749185 #train# step 3587, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:13.324798 #train# step 3588, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:14.879013 #train# step 3589, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:16.425803 #train# step 3590, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:17.974548 #train# step 3591, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:19.559150 #train# step 3592, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:21.090632 #train# step 3593, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:22.645415 #train# step 3594, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:24.219696 #train# step 3595, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:25.802173 #train# step 3596, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:27.333067 #train# step 3597, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:28.857898 #train# step 3598, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:30.375597 #train# step 3599, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:31.959343 #train# step 3600, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:33.476628 #train# step 3601, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:35.033402 #train# step 3602, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:36.570040 #train# step 3603, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:38.095036 #train# step 3604, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:39.654676 #train# step 3605, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:41.208645 #train# step 3606, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:42.774505 #train# step 3607, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:44.327217 #train# step 3608, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:45.856370 #train# step 3609, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:47.380877 #train# step 3610, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:48.908058 #train# step 3611, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:50.455759 #train# step 3612, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:52.036379 #train# step 3613, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:53.599615 #train# step 3614, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:55.136704 #train# step 3615, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:56.706718 #train# step 3616, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:58.250888 #train# step 3617, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:46:59.811834 #train# step 3618, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:01.346185 #train# step 3619, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:02.902735 #train# step 3620, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:04.440840 #train# step 3621, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:05.964594 #train# step 3622, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:07.529553 #train# step 3623, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:09.092516 #train# step 3624, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:10.667935 #train# step 3625, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:12.200479 #train# step 3626, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:13.761306 #train# step 3627, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:15.313715 #train# step 3628, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:16.878973 #train# step 3629, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:18.421530 #train# step 3630, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:19.950999 #train# step 3631, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:21.522053 #train# step 3632, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:23.090035 #train# step 3633, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:24.657905 #train# step 3634, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:26.191304 #train# step 3635, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:27.715088 #train# step 3636, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:29.245567 #train# step 3637, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:30.804442 #train# step 3638, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:32.345466 #train# step 3639, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:33.907375 #train# step 3640, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:35.459020 #train# step 3641, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:36.997323 #train# step 3642, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:38.546326 #train# step 3643, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:40.102329 #train# step 3644, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:41.647937 #train# step 3645, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:43.186317 #train# step 3646, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:44.735183 #train# step 3647, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:46.271425 #train# step 3648, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:47.847792 #train# step 3649, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:49.388590 #train# step 3650, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:50.925040 #train# step 3651, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:52.492418 #train# step 3652, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:54.017672 #train# step 3653, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:55.567843 #train# step 3654, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:57.145311 #train# step 3655, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:47:58.682432 #train# step 3656, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:00.233286 #train# step 3657, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:01.814770 #train# step 3658, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:03.382517 #train# step 3659, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:04.955013 #train# step 3660, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:06.546761 #train# step 3661, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:08.082467 #train# step 3662, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:09.638707 #train# step 3663, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:11.189480 #train# step 3664, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:12.742454 #train# step 3665, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:14.286423 #train# step 3666, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:15.843427 #train# step 3667, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:17.370349 #train# step 3668, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:18.926046 #train# step 3669, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:20.470608 #train# step 3670, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:22.040252 #train# step 3671, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:23.587097 #train# step 3672, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:25.131899 #train# step 3673, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:26.716679 #train# step 3674, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:28.257026 #train# step 3675, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:29.794796 #train# step 3676, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:31.373456 #train# step 3677, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:32.937155 #train# step 3678, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:34.497486 #train# step 3679, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:36.032845 #train# step 3680, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:37.573678 #train# step 3681, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:39.129242 #train# step 3682, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:40.658751 #train# step 3683, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:42.203433 #train# step 3684, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:43.733118 #train# step 3685, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:45.290756 #train# step 3686, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:46.834565 #train# step 3687, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:48.365986 #train# step 3688, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:49.902909 #train# step 3689, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:51.479677 #train# step 3690, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:53.029411 #train# step 3691, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:54.587850 #train# step 3692, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:56.148302 #train# step 3693, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:57.691643 #train# step 3694, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:48:59.247568 #train# step 3695, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:00.800806 #train# step 3696, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:02.352115 #train# step 3697, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:03.890318 #train# step 3698, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:05.456071 #train# step 3699, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:06.998198 #train# step 3700, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:08.537064 #train# step 3701, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:10.152543 #train# step 3702, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:11.697527 #train# step 3703, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:13.246725 #train# step 3704, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:14.813923 #train# step 3705, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:16.366325 #train# step 3706, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:17.899356 #train# step 3707, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:19.448768 #train# step 3708, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:21.011999 #train# step 3709, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:22.581191 #train# step 3710, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:24.133117 #train# step 3711, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:25.671374 #train# step 3712, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:27.216376 #train# step 3713, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:28.772455 #train# step 3714, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:30.352592 #train# step 3715, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:31.884769 #train# step 3716, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:33.434471 #train# step 3717, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:34.992109 #train# step 3718, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:36.544249 #train# step 3719, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:38.093901 #train# step 3720, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:39.661488 #train# step 3721, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:41.223450 #train# step 3722, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:42.787697 #train# step 3723, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:44.329094 #train# step 3724, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:45.854223 #train# step 3725, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:47.385107 #train# step 3726, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:48.938472 #train# step 3727, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:50.509513 #train# step 3728, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:52.080812 #train# step 3729, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:53.638077 #train# step 3730, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:55.172896 #train# step 3731, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:56.723830 #train# step 3732, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:58.274463 #train# step 3733, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:49:59.838084 #train# step 3734, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:01.401104 #train# step 3735, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:02.956464 #train# step 3736, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:04.512122 #train# step 3737, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:06.077422 #train# step 3738, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:07.609716 #train# step 3739, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:09.198866 #train# step 3740, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:10.765166 #train# step 3741, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:12.330247 #train# step 3742, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:13.860117 #train# step 3743, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:15.402761 #train# step 3744, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:16.913669 #train# step 3745, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:18.461537 #train# step 3746, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:20.025524 #train# step 3747, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:21.595526 #train# step 3748, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:23.131084 #train# step 3749, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:24.684918 #train# step 3750, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:26.188397 #train# step 3751, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:27.741817 #train# step 3752, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:29.271841 #train# step 3753, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:30.818319 #train# step 3754, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:32.349461 #train# step 3755, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:33.898239 #train# step 3756, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:35.448299 #train# step 3757, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:37.000728 #train# step 3758, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:38.542385 #train# step 3759, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:40.106799 #train# step 3760, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:41.655599 #train# step 3761, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:43.200812 #train# step 3762, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:44.767829 #train# step 3763, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:46.296214 #train# step 3764, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:47.855479 #train# step 3765, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:49.418517 #train# step 3766, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:50.957005 #train# step 3767, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:52.512920 #train# step 3768, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:54.069742 #train# step 3769, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:55.593792 #train# step 3770, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:57.157987 #train# step 3771, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:50:58.693509 #train# step 3772, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:00.222736 #train# step 3773, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:01.793301 #train# step 3774, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:03.373995 #train# step 3775, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:04.975579 #train# step 3776, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:06.541153 #train# step 3777, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:08.063428 #train# step 3778, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:09.589802 #train# step 3779, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:11.186675 #train# step 3780, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:12.741544 #train# step 3781, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:14.310321 #train# step 3782, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:15.855910 #train# step 3783, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:17.421789 #train# step 3784, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:18.973214 #train# step 3785, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:20.536192 #train# step 3786, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:22.054954 #train# step 3787, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:23.623279 #train# step 3788, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:25.162135 #train# step 3789, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:26.687237 #train# step 3790, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:28.225484 #train# step 3791, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:29.778503 #train# step 3792, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:31.314055 #train# step 3793, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:32.885359 #train# step 3794, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:34.462455 #train# step 3795, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:36.003707 #train# step 3796, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:37.570543 #train# step 3797, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:39.103516 #train# step 3798, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:40.646625 #train# step 3799, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:42.187613 #train# step 3800, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:43.718086 #train# step 3801, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:45.275045 #train# step 3802, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:46.824510 #train# step 3803, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:48.388694 #train# step 3804, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:49.915953 #train# step 3805, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:51.489352 #train# step 3806, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:53.004053 #train# step 3807, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:54.558047 #train# step 3808, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:56.115275 #train# step 3809, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:57.653604 #train# step 3810, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:51:59.236797 #train# step 3811, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:00.762220 #train# step 3812, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:02.316274 #train# step 3813, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:03.870593 #train# step 3814, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:05.438036 #train# step 3815, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:06.958823 #train# step 3816, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:08.539166 #train# step 3817, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:10.091755 #train# step 3818, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:11.684845 #train# step 3819, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:13.239792 #train# step 3820, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:14.791630 #train# step 3821, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:16.357786 #train# step 3822, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:17.887166 #train# step 3823, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:19.445007 #train# step 3824, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:20.983249 #train# step 3825, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:22.531324 #train# step 3826, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:24.078034 #train# step 3827, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:25.623444 #train# step 3828, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:27.177277 #train# step 3829, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:28.729479 #train# step 3830, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:30.266032 #train# step 3831, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:31.803337 #train# step 3832, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:33.354092 #train# step 3833, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:34.945076 #train# step 3834, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:36.491338 #train# step 3835, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:38.035804 #train# step 3836, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:39.562870 #train# step 3837, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:41.109973 #train# step 3838, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:42.659372 #train# step 3839, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:44.228260 #train# step 3840, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:45.759456 #train# step 3841, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:47.290271 #train# step 3842, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:48.863580 #train# step 3843, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:50.395266 #train# step 3844, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:51.965120 #train# step 3845, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:53.522679 #train# step 3846, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:55.080464 #train# step 3847, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:56.608834 #train# step 3848, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:58.172473 #train# step 3849, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:52:59.725559 #train# step 3850, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:01.255578 #train# step 3851, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:02.818716 #train# step 3852, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:04.375122 #train# step 3853, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:05.918692 #train# step 3854, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:07.443240 #train# step 3855, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:09.004550 #train# step 3856, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:10.533065 #train# step 3857, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:12.078444 #train# step 3858, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:13.576417 #train# step 3859, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:15.135220 #train# step 3860, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:16.679514 #train# step 3861, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:18.211136 #train# step 3862, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:19.764221 #train# step 3863, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:21.306795 #train# step 3864, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:22.875630 #train# step 3865, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:24.408247 #train# step 3866, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:25.947869 #train# step 3867, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:27.483589 #train# step 3868, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:29.045733 #train# step 3869, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:30.588401 #train# step 3870, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:32.182372 #train# step 3871, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:33.762950 #train# step 3872, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:35.325736 #train# step 3873, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:36.878153 #train# step 3874, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:38.432472 #train# step 3875, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:39.986461 #train# step 3876, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:41.529069 #train# step 3877, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:43.082162 #train# step 3878, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:44.619590 #train# step 3879, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:46.141261 #train# step 3880, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:47.675345 #train# step 3881, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:49.260470 #train# step 3882, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:50.821377 #train# step 3883, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:52.378108 #train# step 3884, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:53.922953 #train# step 3885, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:55.479343 #train# step 3886, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:57.008826 #train# step 3887, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:53:58.551268 #train# step 3888, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:00.100260 #train# step 3889, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:01.645603 #train# step 3890, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:03.240478 #train# step 3891, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:04.785868 #train# step 3892, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:06.339801 #train# step 3893, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:07.883770 #train# step 3894, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:09.418148 #train# step 3895, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:10.975808 #train# step 3896, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:12.564103 #train# step 3897, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:14.135963 #train# step 3898, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:15.662008 #train# step 3899, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:17.229601 #train# step 3900, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:18.827083 #train# step 3901, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:20.372240 #train# step 3902, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:21.892006 #train# step 3903, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:23.446945 #train# step 3904, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:25.011157 #train# step 3905, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:26.540379 #train# step 3906, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:28.102275 #train# step 3907, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:29.630875 #train# step 3908, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:31.171806 #train# step 3909, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:32.715371 #train# step 3910, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:34.258823 #train# step 3911, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:35.789289 #train# step 3912, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:37.323820 #train# step 3913, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:38.852239 #train# step 3914, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:40.425398 #train# step 3915, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:41.980352 #train# step 3916, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:43.549607 #train# step 3917, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:45.130410 #train# step 3918, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:46.668242 #train# step 3919, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:48.217405 #train# step 3920, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:49.764473 #train# step 3921, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:51.338972 #train# step 3922, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:52.893664 #train# step 3923, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:54.454996 #train# step 3924, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:56.016761 #train# step 3925, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:57.584679 #train# step 3926, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:54:59.147130 #train# step 3927, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:00.699312 #train# step 3928, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:02.280806 #train# step 3929, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:03.824729 #train# step 3930, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:05.385904 #train# step 3931, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:06.927392 #train# step 3932, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:08.498119 #train# step 3933, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:10.069644 #train# step 3934, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:11.614562 #train# step 3935, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:13.170471 #train# step 3936, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:14.759083 #train# step 3937, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:16.309512 #train# step 3938, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:17.846599 #train# step 3939, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:19.441971 #train# step 3940, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:20.992027 #train# step 3941, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:22.526193 #train# step 3942, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:24.058763 #train# step 3943, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:25.618568 #train# step 3944, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:27.165598 #train# step 3945, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:28.689785 #train# step 3946, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:30.212160 #train# step 3947, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:31.764790 #train# step 3948, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:33.299755 #train# step 3949, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:34.811240 #train# step 3950, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:36.375520 #train# step 3951, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:37.906635 #train# step 3952, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:39.477350 #train# step 3953, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:41.050051 #train# step 3954, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:42.625657 #train# step 3955, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:44.158635 #train# step 3956, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:45.698471 #train# step 3957, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:47.229010 #train# step 3958, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:48.793076 #train# step 3959, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:50.360203 #train# step 3960, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:51.894423 #train# step 3961, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:53.444021 #train# step 3962, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:54.999301 #train# step 3963, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:56.550167 #train# step 3964, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:58.124717 #train# step 3965, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:55:59.659323 #train# step 3966, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:01.220114 #train# step 3967, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:02.777663 #train# step 3968, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:04.316967 #train# step 3969, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:05.856041 #train# step 3970, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:07.403900 #train# step 3971, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:08.960480 #train# step 3972, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:10.499658 #train# step 3973, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:12.054504 #train# step 3974, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:13.587461 #train# step 3975, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:15.157938 #train# step 3976, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:16.684350 #train# step 3977, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:18.238261 #train# step 3978, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:19.773134 #train# step 3979, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:21.317771 #train# step 3980, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:22.886436 #train# step 3981, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:24.433963 #train# step 3982, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:25.988243 #train# step 3983, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:27.553624 #train# step 3984, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:29.098683 #train# step 3985, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:30.669424 #train# step 3986, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:32.216555 #train# step 3987, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:33.751960 #train# step 3988, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:35.296298 #train# step 3989, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:36.903662 #train# step 3990, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:38.436421 #train# step 3991, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:39.999730 #train# step 3992, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:41.525021 #train# step 3993, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:43.054373 #train# step 3994, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:44.634945 #train# step 3995, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:46.204158 #train# step 3996, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:47.727574 #train# step 3997, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:49.278924 #train# step 3998, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:50.833241 #train# step 3999, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:52.374531 #train# step 4000, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:53.926428 #train# step 4001, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:55.471760 #train# step 4002, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:57.010785 #train# step 4003, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:56:58.609230 #train# step 4004, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:00.155813 #train# step 4005, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:01.686967 #train# step 4006, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:03.264639 #train# step 4007, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:04.805959 #train# step 4008, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:06.347817 #train# step 4009, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:07.925978 #train# step 4010, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:09.494006 #train# step 4011, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:11.050116 #train# step 4012, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:12.600154 #train# step 4013, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:14.146556 #train# step 4014, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:15.703653 #train# step 4015, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:17.260094 #train# step 4016, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:18.833137 #train# step 4017, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:20.363885 #train# step 4018, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:21.917881 #train# step 4019, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:23.450393 #train# step 4020, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:25.005676 #train# step 4021, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:26.562983 #train# step 4022, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:28.112232 #train# step 4023, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:29.669251 #train# step 4024, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:31.225673 #train# step 4025, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:32.778362 #train# step 4026, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:34.306568 #train# step 4027, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:35.835521 #train# step 4028, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:37.372633 #train# step 4029, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:38.937710 #train# step 4030, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:40.489546 #train# step 4031, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:42.056452 #train# step 4032, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:43.614581 #train# step 4033, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:45.161916 #train# step 4034, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:46.691951 #train# step 4035, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:48.235429 #train# step 4036, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:49.775047 #train# step 4037, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:51.293767 #train# step 4038, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:52.863032 #train# step 4039, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:54.410917 #train# step 4040, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:55.975691 #train# step 4041, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:57.534581 #train# step 4042, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:57:59.083102 #train# step 4043, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:00.642903 #train# step 4044, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:02.214087 #train# step 4045, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:03.762914 #train# step 4046, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:05.331233 #train# step 4047, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:06.899476 #train# step 4048, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:08.454492 #train# step 4049, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:10.033343 #train# step 4050, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:11.605749 #train# step 4051, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:13.173623 #train# step 4052, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:14.741488 #train# step 4053, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:16.275640 #train# step 4054, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:17.791767 #train# step 4055, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:19.350270 #train# step 4056, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:20.874398 #train# step 4057, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:22.449904 #train# step 4058, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:24.004745 #train# step 4059, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:25.560985 #train# step 4060, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:27.114520 #train# step 4061, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:28.693602 #train# step 4062, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:30.206856 #train# step 4063, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:31.775579 #train# step 4064, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:33.330721 #train# step 4065, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:34.839470 #train# step 4066, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:36.357049 #train# step 4067, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:37.917062 #train# step 4068, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:39.445052 #train# step 4069, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:41.004278 #train# step 4070, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:42.546989 #train# step 4071, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:44.112637 #train# step 4072, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:45.680926 #train# step 4073, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:47.226270 #train# step 4074, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:48.782169 #train# step 4075, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:50.374877 #train# step 4076, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:51.923948 #train# step 4077, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:53.450747 #train# step 4078, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:54.979481 #train# step 4079, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:56.516417 #train# step 4080, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:58.068671 #train# step 4081, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:58:59.671975 #train# step 4082, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:01.234108 #train# step 4083, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:02.790138 #train# step 4084, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:04.336698 #train# step 4085, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:05.876105 #train# step 4086, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:07.403436 #train# step 4087, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:08.911495 #train# step 4088, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:10.468683 #train# step 4089, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:12.048084 #train# step 4090, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:13.629282 #train# step 4091, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:15.153995 #train# step 4092, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:16.672759 #train# step 4093, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:18.252335 #train# step 4094, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:19.785464 #train# step 4095, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:21.331279 #train# step 4096, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:22.897307 #train# step 4097, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:24.440310 #train# step 4098, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:25.994489 #train# step 4099, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:27.561949 #train# step 4100, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:29.130160 #train# step 4101, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:30.684196 #train# step 4102, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:32.216488 #train# step 4103, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:33.757869 #train# step 4104, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:35.316990 #train# step 4105, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:36.860862 #train# step 4106, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:38.388271 #train# step 4107, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:39.954915 #train# step 4108, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:41.497795 #train# step 4109, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:43.055979 #train# step 4110, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:44.613554 #train# step 4111, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:46.154744 #train# step 4112, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:47.724952 #train# step 4113, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:49.249972 #train# step 4114, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:50.825143 #train# step 4115, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:52.337900 #train# step 4116, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:53.905392 #train# step 4117, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:55.464229 #train# step 4118, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:56.988660 #train# step 4119, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 02:59:58.570572 #train# step 4120, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:00.109548 #train# step 4121, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:01.667830 #train# step 4122, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:03.198690 #train# step 4123, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:04.755877 #train# step 4124, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:06.347923 #train# step 4125, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:07.885495 #train# step 4126, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:09.427822 #train# step 4127, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:11.003909 #train# step 4128, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:12.585537 #train# step 4129, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:14.120864 #train# step 4130, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:15.644421 #train# step 4131, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:17.193074 #train# step 4132, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:18.742205 #train# step 4133, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:20.285465 #train# step 4134, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:21.854624 #train# step 4135, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:23.396276 #train# step 4136, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:24.963529 #train# step 4137, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:26.521163 #train# step 4138, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:28.070173 #train# step 4139, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:29.614781 #train# step 4140, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:31.146667 #train# step 4141, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:32.684568 #train# step 4142, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:34.226678 #train# step 4143, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:35.772289 #train# step 4144, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:37.288182 #train# step 4145, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:38.873619 #train# step 4146, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:40.461680 #train# step 4147, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:41.997015 #train# step 4148, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:43.568209 #train# step 4149, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:45.128825 #train# step 4150, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:46.696318 #train# step 4151, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:48.286986 #train# step 4152, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:49.838563 #train# step 4153, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:51.359307 #train# step 4154, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:52.869304 #train# step 4155, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:54.446751 #train# step 4156, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:55.976784 #train# step 4157, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:57.503013 #train# step 4158, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:00:59.056041 #train# step 4159, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:00.605622 #train# step 4160, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:02.137650 #train# step 4161, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:03.694375 #train# step 4162, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:05.267407 #train# step 4163, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:06.848852 #train# step 4164, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:08.417255 #train# step 4165, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:09.940227 #train# step 4166, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:11.490533 #train# step 4167, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:13.035244 #train# step 4168, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:14.566825 #train# step 4169, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:16.106252 #train# step 4170, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:17.669001 #train# step 4171, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:19.200282 #train# step 4172, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:20.772730 #train# step 4173, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:22.315546 #train# step 4174, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:23.839982 #train# step 4175, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:25.406034 #train# step 4176, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:26.936397 #train# step 4177, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:28.499507 #train# step 4178, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:30.035828 #train# step 4179, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:31.592111 #train# step 4180, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:33.130777 #train# step 4181, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:34.718887 #train# step 4182, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:36.271466 #train# step 4183, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:37.836794 #train# step 4184, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:39.401503 #train# step 4185, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:40.940904 #train# step 4186, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:42.488790 #train# step 4187, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:44.060197 #train# step 4188, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:45.603387 #train# step 4189, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:47.150370 #train# step 4190, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:48.699165 #train# step 4191, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:50.250332 #train# step 4192, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:51.787152 #train# step 4193, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:53.384304 #train# step 4194, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:54.961258 #train# step 4195, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:56.529843 #train# step 4196, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:58.088884 #train# step 4197, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:01:59.644771 #train# step 4198, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:01.196983 #train# step 4199, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:02.739336 #train# step 4200, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:04.303227 #train# step 4201, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:05.845316 #train# step 4202, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:07.391758 #train# step 4203, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:08.958639 #train# step 4204, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:10.538407 #train# step 4205, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:12.069119 #train# step 4206, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:13.625496 #train# step 4207, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:15.203994 #train# step 4208, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:16.744881 #train# step 4209, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:18.282381 #train# step 4210, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:19.851671 #train# step 4211, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:21.407430 #train# step 4212, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:22.966210 #train# step 4213, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:24.510751 #train# step 4214, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:26.081958 #train# step 4215, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:27.609833 #train# step 4216, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:29.168018 #train# step 4217, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:30.735018 #train# step 4218, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:32.265116 #train# step 4219, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:33.785378 #train# step 4220, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:35.329328 #train# step 4221, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:36.872947 #train# step 4222, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:38.398118 #train# step 4223, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:39.963067 #train# step 4224, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:41.494539 #train# step 4225, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:43.029081 #train# step 4226, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:44.576186 #train# step 4227, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:46.119902 #train# step 4228, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:47.657086 #train# step 4229, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:49.239921 #train# step 4230, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:50.790739 #train# step 4231, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:52.334108 #train# step 4232, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:53.881489 #train# step 4233, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:55.459548 #train# step 4234, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:56.996444 #train# step 4235, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:02:58.579820 #train# step 4236, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:00.141735 #train# step 4237, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:01.707238 #train# step 4238, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:03.269629 #train# step 4239, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:04.828114 #train# step 4240, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:06.381936 #train# step 4241, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:07.928325 #train# step 4242, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:09.480574 #train# step 4243, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:11.050626 #train# step 4244, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:12.613503 #train# step 4245, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:14.169933 #train# step 4246, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:15.721555 #train# step 4247, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:17.286257 #train# step 4248, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:18.830931 #train# step 4249, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:20.394175 #train# step 4250, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:21.934738 #train# step 4251, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:23.485511 #train# step 4252, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:25.061002 #train# step 4253, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:26.595057 #train# step 4254, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:28.108275 #train# step 4255, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:29.644032 #train# step 4256, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:31.195055 #train# step 4257, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:32.729084 #train# step 4258, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:34.269457 #train# step 4259, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:35.803352 #train# step 4260, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:37.358791 #train# step 4261, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:38.918992 #train# step 4262, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:40.480272 #train# step 4263, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:42.034838 #train# step 4264, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:43.584492 #train# step 4265, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:45.140861 #train# step 4266, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:46.706086 #train# step 4267, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:48.298592 #train# step 4268, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:49.834238 #train# step 4269, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:51.360456 #train# step 4270, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:52.888391 #train# step 4271, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:54.427245 #train# step 4272, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:55.977840 #train# step 4273, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:57.534535 #train# step 4274, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:03:59.102113 #train# step 4275, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:00.667834 #train# step 4276, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:02.207306 #train# step 4277, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:03.773030 #train# step 4278, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:05.360382 #train# step 4279, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:06.914683 #train# step 4280, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:08.488589 #train# step 4281, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:10.036303 #train# step 4282, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:11.599806 #train# step 4283, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:13.168138 #train# step 4284, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:14.706783 #train# step 4285, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:16.276532 #train# step 4286, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:17.866599 #train# step 4287, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:19.433241 #train# step 4288, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:20.979044 #train# step 4289, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:22.525308 #train# step 4290, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:24.083696 #train# step 4291, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:25.612996 #train# step 4292, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:27.193599 #train# step 4293, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:28.722869 #train# step 4294, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:30.276510 #train# step 4295, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:31.839701 #train# step 4296, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:33.381283 #train# step 4297, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:34.904846 #train# step 4298, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:36.461919 #train# step 4299, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:38.006524 #train# step 4300, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:39.585296 #train# step 4301, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:41.128822 #train# step 4302, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:42.684983 #train# step 4303, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:44.226659 #train# step 4304, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:45.768073 #train# step 4305, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:47.325838 #train# step 4306, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:48.895341 #train# step 4307, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:50.434597 #train# step 4308, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:51.966531 #train# step 4309, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:53.516591 #train# step 4310, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:55.065889 #train# step 4311, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:56.610986 #train# step 4312, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:58.198080 #train# step 4313, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:04:59.738836 #train# step 4314, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:01.243198 #train# step 4315, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:02.766121 #train# step 4316, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:04.302488 #train# step 4317, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:05.862405 #train# step 4318, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:07.383416 #train# step 4319, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:08.933840 #train# step 4320, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:10.478274 #train# step 4321, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:12.068145 #train# step 4322, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:13.595324 #train# step 4323, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:15.161988 #train# step 4324, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:16.687596 #train# step 4325, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:18.257057 #train# step 4326, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:19.804055 #train# step 4327, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:21.314410 #train# step 4328, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:22.894614 #train# step 4329, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:24.446404 #train# step 4330, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:25.993061 #train# step 4331, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:27.567762 #train# step 4332, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:29.133597 #train# step 4333, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:30.677649 #train# step 4334, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:32.258526 #train# step 4335, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:33.777698 #train# step 4336, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:35.332766 #train# step 4337, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:36.895733 #train# step 4338, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:38.467503 #train# step 4339, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:40.010966 #train# step 4340, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:41.542323 #train# step 4341, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:43.115730 #train# step 4342, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:44.649132 #train# step 4343, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:46.186589 #train# step 4344, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:47.717094 #train# step 4345, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:49.281469 #train# step 4346, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:50.831660 #train# step 4347, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:52.362020 #train# step 4348, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:53.919351 #train# step 4349, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:55.458338 #train# step 4350, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:57.037238 #train# step 4351, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:05:58.569270 #train# step 4352, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:00.132419 #train# step 4353, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:01.671483 #train# step 4354, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:03.256341 #train# step 4355, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:04.779674 #train# step 4356, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:06.357433 #train# step 4357, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:07.941696 #train# step 4358, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:09.519617 #train# step 4359, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:11.079528 #train# step 4360, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:12.616192 #train# step 4361, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:14.170077 #train# step 4362, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:15.725024 #train# step 4363, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:17.278959 #train# step 4364, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:18.808450 #train# step 4365, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:20.373074 #train# step 4366, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:21.900235 #train# step 4367, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:23.450218 #train# step 4368, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:25.009121 #train# step 4369, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:26.554048 #train# step 4370, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:28.103524 #train# step 4371, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:29.662317 #train# step 4372, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:31.234455 #train# step 4373, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:32.811956 #train# step 4374, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:34.346772 #train# step 4375, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:35.917631 #train# step 4376, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:37.458946 #train# step 4377, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:39.019935 #train# step 4378, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:40.537337 #train# step 4379, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:42.102587 #train# step 4380, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:43.686483 #train# step 4381, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:45.230367 #train# step 4382, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:46.776274 #train# step 4383, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:48.334916 #train# step 4384, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:49.926705 #train# step 4385, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:51.472978 #train# step 4386, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:53.000767 #train# step 4387, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:54.520376 #train# step 4388, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:56.077961 #train# step 4389, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:57.643416 #train# step 4390, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:06:59.197913 #train# step 4391, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:00.770901 #train# step 4392, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:02.291198 #train# step 4393, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:03.826382 #train# step 4394, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:05.380626 #train# step 4395, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:06.932135 #train# step 4396, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:08.488725 #train# step 4397, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:10.044057 #train# step 4398, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:11.567744 #train# step 4399, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:13.076033 #train# step 4400, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:14.646206 #train# step 4401, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:16.206388 #train# step 4402, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:17.786734 #train# step 4403, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:19.363870 #train# step 4404, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:20.892635 #train# step 4405, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:22.423327 #train# step 4406, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:23.949991 #train# step 4407, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:25.522742 #train# step 4408, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:27.092255 #train# step 4409, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:28.638026 #train# step 4410, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:30.162226 #train# step 4411, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:31.707857 #train# step 4412, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:33.259648 #train# step 4413, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:34.796682 #train# step 4414, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:36.345533 #train# step 4415, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:37.923210 #train# step 4416, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:39.493907 #train# step 4417, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:41.043623 #train# step 4418, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:42.610595 #train# step 4419, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:44.138582 #train# step 4420, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:45.698498 #train# step 4421, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:47.246920 #train# step 4422, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:48.791722 #train# step 4423, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:50.324175 #train# step 4424, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:51.885580 #train# step 4425, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:53.429504 #train# step 4426, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:54.982075 #train# step 4427, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:56.542621 #train# step 4428, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:58.129960 #train# step 4429, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:07:59.672161 #train# step 4430, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:01.219468 #train# step 4431, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:02.782861 #train# step 4432, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:04.385366 #train# step 4433, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:05.913683 #train# step 4434, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:07.466423 #train# step 4435, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:09.030883 #train# step 4436, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:10.546802 #train# step 4437, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:12.119607 #train# step 4438, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:13.680308 #train# step 4439, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:15.221052 #train# step 4440, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:16.774625 #train# step 4441, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:18.299380 #train# step 4442, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:19.859510 #train# step 4443, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:21.414994 #train# step 4444, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:22.952606 #train# step 4445, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:24.503927 #train# step 4446, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:26.055503 #train# step 4447, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:27.574661 #train# step 4448, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:29.115711 #train# step 4449, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:30.665155 #train# step 4450, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:32.236988 #train# step 4451, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:33.751663 #train# step 4452, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:35.341223 #train# step 4453, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:36.898199 #train# step 4454, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:38.469060 #train# step 4455, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:40.033376 #train# step 4456, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:41.589328 #train# step 4457, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:43.127069 #train# step 4458, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:44.684169 #train# step 4459, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:46.252781 #train# step 4460, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:47.792354 #train# step 4461, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:49.399654 #train# step 4462, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:50.918648 #train# step 4463, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:52.462812 #train# step 4464, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:54.001560 #train# step 4465, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:55.561357 #train# step 4466, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:57.121143 #train# step 4467, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:08:58.704344 #train# step 4468, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:00.245523 #train# step 4469, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:01.804482 #train# step 4470, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:03.299037 #train# step 4471, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:04.830309 #train# step 4472, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:06.424353 #train# step 4473, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:07.975992 #train# step 4474, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:09.537554 #train# step 4475, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:11.076252 #train# step 4476, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:12.612964 #train# step 4477, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:14.144622 #train# step 4478, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:15.749200 #train# step 4479, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:17.299639 #train# step 4480, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:18.887168 #train# step 4481, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:20.418133 #train# step 4482, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:21.941140 #train# step 4483, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:23.477901 #train# step 4484, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:25.027214 #train# step 4485, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:26.525748 #train# step 4486, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:28.068278 #train# step 4487, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:29.589783 #train# step 4488, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:31.150213 #train# step 4489, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:32.722514 #train# step 4490, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:34.266129 #train# step 4491, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:35.836123 #train# step 4492, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:37.400349 #train# step 4493, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:38.958307 #train# step 4494, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:40.523381 #train# step 4495, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:42.063593 #train# step 4496, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:43.631428 #train# step 4497, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:45.167308 #train# step 4498, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:46.725083 #train# step 4499, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:48.279686 #train# step 4500, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:49.856836 #train# step 4501, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:51.414094 #train# step 4502, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:52.969541 #train# step 4503, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:54.512612 #train# step 4504, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:56.105705 #train# step 4505, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:57.634578 #train# step 4506, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:09:59.197727 #train# step 4507, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:00.760552 #train# step 4508, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:02.305704 #train# step 4509, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:03.840696 #train# step 4510, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:05.412543 #train# step 4511, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:06.962115 #train# step 4512, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:08.508211 #train# step 4513, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:10.073120 #train# step 4514, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:11.670770 #train# step 4515, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:13.251592 #train# step 4516, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:14.774549 #train# step 4517, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:16.343466 #train# step 4518, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:17.882135 #train# step 4519, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:19.451831 #train# step 4520, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:21.012155 #train# step 4521, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:22.572017 #train# step 4522, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:24.131743 #train# step 4523, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:25.690375 #train# step 4524, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:27.213184 #train# step 4525, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:28.735208 #train# step 4526, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:30.299919 #train# step 4527, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:31.844507 #train# step 4528, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:33.381419 #train# step 4529, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:34.945450 #train# step 4530, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:36.498266 #train# step 4531, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:38.034351 #train# step 4532, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:39.580410 #train# step 4533, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:41.128031 #train# step 4534, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:42.672495 #train# step 4535, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:44.222151 #train# step 4536, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:45.794209 #train# step 4537, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:47.339697 #train# step 4538, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:48.879585 #train# step 4539, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:50.413108 #train# step 4540, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:51.972484 #train# step 4541, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:53.534335 #train# step 4542, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:55.107964 #train# step 4543, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:56.649818 #train# step 4544, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:58.196759 #train# step 4545, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:10:59.745948 #train# step 4546, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:01.324476 #train# step 4547, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:02.851542 #train# step 4548, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:04.413320 #train# step 4549, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:05.937114 #train# step 4550, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:07.482629 #train# step 4551, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:09.053673 #train# step 4552, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:10.633222 #train# step 4553, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:12.173756 #train# step 4554, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:13.747550 #train# step 4555, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:15.259764 #train# step 4556, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:16.819676 #train# step 4557, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:18.357568 #train# step 4558, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:19.926864 #train# step 4559, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:21.444786 #train# step 4560, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:22.997497 #train# step 4561, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:24.542210 #train# step 4562, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:26.079638 #train# step 4563, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:27.646517 #train# step 4564, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:29.184593 #train# step 4565, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:30.713645 #train# step 4566, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:32.264954 #train# step 4567, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:33.827516 #train# step 4568, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:35.358289 #train# step 4569, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:36.896132 #train# step 4570, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:38.441184 #train# step 4571, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:39.975812 #train# step 4572, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:41.525622 #train# step 4573, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:43.044584 #train# step 4574, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:44.626175 #train# step 4575, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:46.182172 #train# step 4576, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:47.718255 #train# step 4577, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:49.260937 #train# step 4578, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:50.793988 #train# step 4579, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:52.318736 #train# step 4580, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:53.867759 #train# step 4581, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:55.409169 #train# step 4582, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:56.950670 #train# step 4583, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:11:58.503006 #train# step 4584, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:00.060871 #train# step 4585, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:01.602255 #train# step 4586, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:03.191778 #train# step 4587, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:04.724903 #train# step 4588, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:06.286078 #train# step 4589, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:07.856650 #train# step 4590, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:09.406568 #train# step 4591, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:11.022445 #train# step 4592, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:12.574119 #train# step 4593, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:14.115767 #train# step 4594, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:15.648511 #train# step 4595, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:17.176600 #train# step 4596, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:18.729616 #train# step 4597, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:20.298398 #train# step 4598, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:21.850490 #train# step 4599, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:23.403687 #train# step 4600, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:24.963598 #train# step 4601, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:26.523301 #train# step 4602, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:28.069564 #train# step 4603, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:29.673965 #train# step 4604, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:31.208023 #train# step 4605, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:32.749253 #train# step 4606, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:34.312823 #train# step 4607, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:35.879064 #train# step 4608, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:37.439799 #train# step 4609, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:39.010273 #train# step 4610, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:40.593980 #train# step 4611, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:42.164137 #train# step 4612, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:43.738043 #train# step 4613, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:45.311328 #train# step 4614, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:46.864938 #train# step 4615, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:48.429790 #train# step 4616, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:49.956979 #train# step 4617, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:51.507885 #train# step 4618, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:53.058589 #train# step 4619, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:54.569689 #train# step 4620, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:56.144806 #train# step 4621, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:57.696975 #train# step 4622, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:12:59.243066 #train# step 4623, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:00.794254 #train# step 4624, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:02.332281 #train# step 4625, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:03.893588 #train# step 4626, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:05.469820 #train# step 4627, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:07.036754 #train# step 4628, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:08.619594 #train# step 4629, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:10.162960 #train# step 4630, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:11.682923 #train# step 4631, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:13.219005 #train# step 4632, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:14.741192 #train# step 4633, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:16.286991 #train# step 4634, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:17.849108 #train# step 4635, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:19.415724 #train# step 4636, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:20.980582 #train# step 4637, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:22.537996 #train# step 4638, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:24.043105 #train# step 4639, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:25.635922 #train# step 4640, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:27.207366 #train# step 4641, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:28.734328 #train# step 4642, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:30.266067 #train# step 4643, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:31.815506 #train# step 4644, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:33.372513 #train# step 4645, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:34.903490 #train# step 4646, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:36.441400 #train# step 4647, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:37.955879 #train# step 4648, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:39.508355 #train# step 4649, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:41.023603 #train# step 4650, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:42.566716 #train# step 4651, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:44.137472 #train# step 4652, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:45.650082 #train# step 4653, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:47.227889 #train# step 4654, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:48.765226 #train# step 4655, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:50.322716 #train# step 4656, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:51.875631 #train# step 4657, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:53.422155 #train# step 4658, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:54.954969 #train# step 4659, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:56.493246 #train# step 4660, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:58.068998 #train# step 4661, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:13:59.640918 #train# step 4662, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:01.183213 #train# step 4663, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:02.751005 #train# step 4664, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:04.300499 #train# step 4665, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:05.822958 #train# step 4666, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:07.404332 #train# step 4667, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:08.964217 #train# step 4668, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:10.504684 #train# step 4669, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:12.061038 #train# step 4670, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:13.600021 #train# step 4671, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:15.182190 #train# step 4672, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:16.729516 #train# step 4673, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:18.254428 #train# step 4674, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:19.806979 #train# step 4675, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:21.357093 #train# step 4676, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:22.914501 #train# step 4677, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:24.480599 #train# step 4678, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:26.034102 #train# step 4679, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:27.606462 #train# step 4680, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:29.128668 #train# step 4681, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:30.675735 #train# step 4682, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:32.202306 #train# step 4683, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:33.766473 #train# step 4684, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:35.330814 #train# step 4685, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:36.888163 #train# step 4686, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:38.459549 #train# step 4687, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:39.997016 #train# step 4688, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:41.556088 #train# step 4689, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:43.075464 #train# step 4690, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:44.623101 #train# step 4691, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:46.177229 #train# step 4692, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:47.738021 #train# step 4693, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:49.274402 #train# step 4694, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:50.806300 #train# step 4695, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:52.320759 #train# step 4696, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:53.877854 #train# step 4697, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:55.436153 #train# step 4698, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:56.966375 #train# step 4699, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:14:58.529262 #train# step 4700, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:00.077096 #train# step 4701, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:01.601012 #train# step 4702, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:03.193543 #train# step 4703, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:04.737558 #train# step 4704, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:06.264693 #train# step 4705, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:07.800324 #train# step 4706, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:09.371273 #train# step 4707, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:10.891286 #train# step 4708, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:12.479612 #train# step 4709, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:14.009357 #train# step 4710, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:15.550733 #train# step 4711, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:17.103397 #train# step 4712, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:18.653166 #train# step 4713, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:20.198088 #train# step 4714, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:21.724025 #train# step 4715, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:23.278227 #train# step 4716, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:24.806506 #train# step 4717, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:26.362502 #train# step 4718, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:27.965623 #train# step 4719, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:29.507732 #train# step 4720, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:31.040802 #train# step 4721, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:32.585686 #train# step 4722, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:34.122168 #train# step 4723, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:35.707121 #train# step 4724, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:37.228580 #train# step 4725, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:38.767833 #train# step 4726, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:40.309402 #train# step 4727, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:41.844900 #train# step 4728, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:43.397766 #train# step 4729, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:44.950588 #train# step 4730, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:46.532245 #train# step 4731, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:48.126124 #train# step 4732, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:49.671521 #train# step 4733, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:51.222489 #train# step 4734, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:52.769935 #train# step 4735, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:54.329176 #train# step 4736, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:55.896496 #train# step 4737, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:57.438232 #train# step 4738, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:15:58.991598 #train# step 4739, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:00.544488 #train# step 4740, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:02.088661 #train# step 4741, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:03.635001 #train# step 4742, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:05.165969 #train# step 4743, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:06.750249 #train# step 4744, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:08.276028 #train# step 4745, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:09.833993 #train# step 4746, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:11.380932 #train# step 4747, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:12.934866 #train# step 4748, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:14.503085 #train# step 4749, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:16.064861 #train# step 4750, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:17.611589 #train# step 4751, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:19.170171 #train# step 4752, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:20.733502 #train# step 4753, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:22.269358 #train# step 4754, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:23.821007 #train# step 4755, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:25.412490 #train# step 4756, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:26.930459 #train# step 4757, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:28.500939 #train# step 4758, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:30.086370 #train# step 4759, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:31.638499 #train# step 4760, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:33.187415 #train# step 4761, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:34.731129 #train# step 4762, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:36.304009 #train# step 4763, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:37.860715 #train# step 4764, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:39.399659 #train# step 4765, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:40.951164 #train# step 4766, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:42.506762 #train# step 4767, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:44.032245 #train# step 4768, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:45.579845 #train# step 4769, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:47.111431 #train# step 4770, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:48.664427 #train# step 4771, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:50.194449 #train# step 4772, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:51.736703 #train# step 4773, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:53.281504 #train# step 4774, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:54.819953 #train# step 4775, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:56.359662 #train# step 4776, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:57.889050 #train# step 4777, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:16:59.422523 #train# step 4778, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:00.952224 #train# step 4779, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:02.514243 #train# step 4780, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:04.088173 #train# step 4781, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:05.629595 #train# step 4782, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:07.192274 #train# step 4783, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:08.745797 #train# step 4784, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:10.340514 #train# step 4785, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:11.888851 #train# step 4786, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:13.474751 #train# step 4787, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:14.998986 #train# step 4788, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:16.553957 #train# step 4789, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:18.111874 #train# step 4790, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:19.669464 #train# step 4791, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:21.226286 #train# step 4792, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:22.769450 #train# step 4793, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:24.325747 #train# step 4794, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:25.888270 #train# step 4795, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:27.470698 #train# step 4796, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:29.023822 #train# step 4797, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:30.525490 #train# step 4798, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:32.081062 #train# step 4799, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:33.654723 #train# step 4800, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:35.210305 #train# step 4801, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:36.791639 #train# step 4802, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:38.391429 #train# step 4803, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:39.929409 #train# step 4804, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:41.464183 #train# step 4805, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:43.016578 #train# step 4806, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:44.563928 #train# step 4807, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:46.092833 #train# step 4808, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:47.642583 #train# step 4809, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:49.195204 #train# step 4810, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:50.734147 #train# step 4811, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:52.307372 #train# step 4812, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:53.853715 #train# step 4813, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:55.392760 #train# step 4814, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:56.887200 #train# step 4815, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:58.448216 #train# step 4816, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:17:59.979490 #train# step 4817, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:01.539336 #train# step 4818, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:03.101251 #train# step 4819, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:04.641051 #train# step 4820, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:06.185408 #train# step 4821, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:07.723527 #train# step 4822, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:09.280019 #train# step 4823, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:10.808802 #train# step 4824, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:12.357171 #train# step 4825, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:13.879428 #train# step 4826, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:15.443726 #train# step 4827, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:17.024313 #train# step 4828, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:18.585022 #train# step 4829, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:20.127979 #train# step 4830, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:21.724765 #train# step 4831, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:23.288530 #train# step 4832, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:24.860955 #train# step 4833, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:26.383778 #train# step 4834, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:27.956944 #train# step 4835, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:29.513840 #train# step 4836, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:31.068298 #train# step 4837, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:32.601634 #train# step 4838, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:34.149965 #train# step 4839, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:35.699970 #train# step 4840, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:37.245995 #train# step 4841, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:38.813509 #train# step 4842, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:40.351168 #train# step 4843, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:41.879404 #train# step 4844, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:43.478201 #train# step 4845, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:45.039361 #train# step 4846, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:46.594247 #train# step 4847, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:48.150628 #train# step 4848, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:49.716338 #train# step 4849, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:51.275184 #train# step 4850, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:52.833155 #train# step 4851, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:54.381724 #train# step 4852, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:55.938829 #train# step 4853, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:57.481672 #train# step 4854, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:18:59.014805 #train# step 4855, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:00.542505 #train# step 4856, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:02.031063 #train# step 4857, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:03.599955 #train# step 4858, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:05.131359 #train# step 4859, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:06.695334 #train# step 4860, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:08.240290 #train# step 4861, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:09.787300 #train# step 4862, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:11.355021 #train# step 4863, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:12.947045 #train# step 4864, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:14.488257 #train# step 4865, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:16.059039 #train# step 4866, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:17.617000 #train# step 4867, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:19.174216 #train# step 4868, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:20.704302 #train# step 4869, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:22.276638 #train# step 4870, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:23.852929 #train# step 4871, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:25.389827 #train# step 4872, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:26.940788 #train# step 4873, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:28.505559 #train# step 4874, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:30.065902 #train# step 4875, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:31.606701 #train# step 4876, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:33.153088 #train# step 4877, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:34.710667 #train# step 4878, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:36.227821 #train# step 4879, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:37.787986 #train# step 4880, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:39.346165 #train# step 4881, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:40.904628 #train# step 4882, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:42.456610 #train# step 4883, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:44.005047 #train# step 4884, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:45.529103 #train# step 4885, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:47.084798 #train# step 4886, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:48.645290 #train# step 4887, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:50.203412 #train# step 4888, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:51.769876 #train# step 4889, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:53.321030 #train# step 4890, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:54.918498 #train# step 4891, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:56.493483 #train# step 4892, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:58.052502 #train# step 4893, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:19:59.590839 #train# step 4894, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:01.161259 #train# step 4895, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:02.711965 #train# step 4896, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:04.240783 #train# step 4897, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:05.793185 #train# step 4898, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:07.355850 #train# step 4899, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:08.883781 #train# step 4900, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:10.436170 #train# step 4901, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:11.989561 #train# step 4902, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:13.571907 #train# step 4903, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:15.123111 #train# step 4904, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:16.666088 #train# step 4905, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:18.234131 #train# step 4906, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:19.755801 #train# step 4907, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:21.316599 #train# step 4908, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:22.896757 #train# step 4909, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:24.451468 #train# step 4910, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:25.987147 #train# step 4911, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:27.501028 #train# step 4912, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:29.044226 #train# step 4913, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:30.569420 #train# step 4914, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:32.099178 #train# step 4915, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:33.683262 #train# step 4916, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:35.237592 #train# step 4917, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:36.801474 #train# step 4918, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:38.376081 #train# step 4919, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:39.940660 #train# step 4920, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:41.490794 #train# step 4921, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:43.045483 #train# step 4922, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:44.582577 #train# step 4923, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:46.144116 #train# step 4924, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:47.667870 #train# step 4925, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:49.227657 #train# step 4926, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:50.774345 #train# step 4927, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:52.331364 #train# step 4928, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:53.866109 #train# step 4929, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:55.421264 #train# step 4930, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:56.957390 #train# step 4931, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:20:58.499283 #train# step 4932, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:00.077045 #train# step 4933, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:01.603752 #train# step 4934, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:03.128732 #train# step 4935, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:04.639718 #train# step 4936, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:06.176887 #train# step 4937, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:07.768776 #train# step 4938, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:09.357461 #train# step 4939, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:10.881033 #train# step 4940, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:12.465783 #train# step 4941, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:13.992044 #train# step 4942, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:15.554381 #train# step 4943, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:17.082001 #train# step 4944, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:18.617633 #train# step 4945, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:20.166441 #train# step 4946, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:21.729482 #train# step 4947, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:23.281589 #train# step 4948, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:24.848958 #train# step 4949, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:26.401365 #train# step 4950, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:28.013356 #train# step 4951, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:29.550575 #train# step 4952, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:31.119636 #train# step 4953, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:32.658725 #train# step 4954, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:34.222989 #train# step 4955, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:35.766728 #train# step 4956, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:37.318758 #train# step 4957, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:38.861768 #train# step 4958, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:40.391207 #train# step 4959, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:41.921840 #train# step 4960, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:43.496713 #train# step 4961, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:45.035454 #train# step 4962, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:46.598942 #train# step 4963, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:48.136591 #train# step 4964, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:49.681285 #train# step 4965, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:51.240817 #train# step 4966, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:52.769803 #train# step 4967, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:54.310792 #train# step 4968, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:55.858987 #train# step 4969, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:57.394336 #train# step 4970, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:21:58.923343 #train# step 4971, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:00.484240 #train# step 4972, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:02.020164 #train# step 4973, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:03.601913 #train# step 4974, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:05.143008 #train# step 4975, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:06.702387 #train# step 4976, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:08.260700 #train# step 4977, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:09.804578 #train# step 4978, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:11.379323 #train# step 4979, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:12.922944 #train# step 4980, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:14.498286 #train# step 4981, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:16.051224 #train# step 4982, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:17.617383 #train# step 4983, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:19.144783 #train# step 4984, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:20.720428 #train# step 4985, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:22.278555 #train# step 4986, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:23.812788 #train# step 4987, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:25.382753 #train# step 4988, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:26.936642 #train# step 4989, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:28.489670 #train# step 4990, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:30.052615 #train# step 4991, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:31.618206 #train# step 4992, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:33.170669 #train# step 4993, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:34.734852 #train# step 4994, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:36.263259 #train# step 4995, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:37.829762 #train# step 4996, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:39.368755 #train# step 4997, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:40.897492 #train# step 4998, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:42.454598 #train# step 4999, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:44.021776 #train# step 5000, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:45.593464 #train# step 5001, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:47.136063 #train# step 5002, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:48.690592 #train# step 5003, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:50.243224 #train# step 5004, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:51.821271 #train# step 5005, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:53.361611 #train# step 5006, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:54.895707 #train# step 5007, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:56.426183 #train# step 5008, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:57.938355 #train# step 5009, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:22:59.466749 #train# step 5010, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:01.008671 #train# step 5011, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:02.563776 #train# step 5012, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:04.108635 #train# step 5013, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:05.661229 #train# step 5014, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:07.226707 #train# step 5015, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:08.767511 #train# step 5016, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:10.340522 #train# step 5017, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:11.914560 #train# step 5018, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:13.486081 #train# step 5019, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:15.058969 #train# step 5020, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:16.615971 #train# step 5021, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:18.129148 #train# step 5022, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:19.702923 #train# step 5023, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:21.252610 #train# step 5024, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:22.811365 #train# step 5025, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:24.370005 #train# step 5026, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:25.932788 #train# step 5027, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:27.448289 #train# step 5028, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:29.002310 #train# step 5029, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:30.560095 #train# step 5030, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:32.144379 #train# step 5031, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:33.694980 #train# step 5032, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:35.272168 #train# step 5033, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:36.824808 #train# step 5034, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:38.356850 #train# step 5035, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:39.895034 #train# step 5036, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:41.455527 #train# step 5037, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:42.991846 #train# step 5038, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:44.543385 #train# step 5039, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:46.111328 #train# step 5040, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:47.688123 #train# step 5041, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:49.203948 #train# step 5042, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:50.768608 #train# step 5043, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:52.351001 #train# step 5044, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:53.904413 #train# step 5045, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:55.445242 #train# step 5046, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:56.953559 #train# step 5047, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:23:58.521531 #train# step 5048, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:00.092153 #train# step 5049, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:01.687239 #train# step 5050, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:03.189631 #train# step 5051, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:04.753689 #train# step 5052, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:06.307734 #train# step 5053, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:07.852610 #train# step 5054, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:09.446683 #train# step 5055, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:11.002725 #train# step 5056, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:12.565025 #train# step 5057, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:14.125586 #train# step 5058, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:15.665862 #train# step 5059, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:17.191397 #train# step 5060, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:18.759129 #train# step 5061, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:20.306631 #train# step 5062, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:21.844930 #train# step 5063, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:23.393321 #train# step 5064, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:24.960862 #train# step 5065, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:26.494023 #train# step 5066, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:28.077203 #train# step 5067, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:29.610679 #train# step 5068, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:31.137541 #train# step 5069, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:32.664265 #train# step 5070, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:34.220133 #train# step 5071, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:35.757535 #train# step 5072, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:37.309790 #train# step 5073, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:38.868084 #train# step 5074, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:40.415441 #train# step 5075, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:41.930662 #train# step 5076, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:43.473778 #train# step 5077, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:45.021499 #train# step 5078, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:46.568331 #train# step 5079, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:48.109232 #train# step 5080, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:49.661761 #train# step 5081, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:51.250663 #train# step 5082, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:52.799508 #train# step 5083, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:54.368054 #train# step 5084, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:55.922190 #train# step 5085, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:57.465077 #train# step 5086, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:24:58.974855 #train# step 5087, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:00.527113 #train# step 5088, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:02.081864 #train# step 5089, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:03.619172 #train# step 5090, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:05.160045 #train# step 5091, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:06.722314 #train# step 5092, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:08.314294 #train# step 5093, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:09.853665 #train# step 5094, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:11.375751 #train# step 5095, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:12.941535 #train# step 5096, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:14.515137 #train# step 5097, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:16.048358 #train# step 5098, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:17.599824 #train# step 5099, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:19.174939 #train# step 5100, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:20.694082 #train# step 5101, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:22.250407 #train# step 5102, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:23.781390 #train# step 5103, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:25.346545 #train# step 5104, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:26.901794 #train# step 5105, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:28.442009 #train# step 5106, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:29.994440 #train# step 5107, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:31.561083 #train# step 5108, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:33.122555 #train# step 5109, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:34.662862 #train# step 5110, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:36.197732 #train# step 5111, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:37.749738 #train# step 5112, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:39.297842 #train# step 5113, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:40.867511 #train# step 5114, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:42.424075 #train# step 5115, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:44.000680 #train# step 5116, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:45.556643 #train# step 5117, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:47.122799 #train# step 5118, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:48.665471 #train# step 5119, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:50.203037 #train# step 5120, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:51.763813 #train# step 5121, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:53.350870 #train# step 5122, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:54.906715 #train# step 5123, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:56.460347 #train# step 5124, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:58.040481 #train# step 5125, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:25:59.609186 #train# step 5126, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:01.131818 #train# step 5127, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:02.693995 #train# step 5128, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:04.234224 #train# step 5129, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:05.820818 #train# step 5130, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:07.339999 #train# step 5131, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:08.889035 #train# step 5132, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:10.445026 #train# step 5133, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:12.008472 #train# step 5134, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:13.553649 #train# step 5135, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:15.097483 #train# step 5136, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:16.665851 #train# step 5137, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:18.195387 #train# step 5138, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:19.725196 #train# step 5139, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:21.267754 #train# step 5140, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:22.797133 #train# step 5141, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:24.349644 #train# step 5142, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:25.883453 #train# step 5143, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:27.462545 #train# step 5144, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:29.053250 #train# step 5145, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:30.616843 #train# step 5146, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:32.180526 #train# step 5147, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:33.742584 #train# step 5148, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:35.281876 #train# step 5149, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:36.855356 #train# step 5150, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:38.419221 #train# step 5151, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:39.996248 #train# step 5152, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:41.529808 #train# step 5153, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:43.057051 #train# step 5154, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:44.613928 #train# step 5155, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:46.186130 #train# step 5156, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:47.722740 #train# step 5157, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:49.282499 #train# step 5158, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:50.829608 #train# step 5159, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:52.364756 #train# step 5160, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:53.900667 #train# step 5161, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:55.421866 #train# step 5162, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:56.933924 #train# step 5163, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:26:58.495342 #train# step 5164, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:00.078609 #train# step 5165, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:01.617071 #train# step 5166, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:03.190566 #train# step 5167, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:04.713341 #train# step 5168, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:06.240635 #train# step 5169, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:07.806624 #train# step 5170, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:09.372201 #train# step 5171, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:10.928626 #train# step 5172, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:12.483315 #train# step 5173, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:14.037507 #train# step 5174, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:15.592031 #train# step 5175, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:17.127114 #train# step 5176, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:18.678017 #train# step 5177, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:20.231881 #train# step 5178, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:21.805893 #train# step 5179, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:23.363964 #train# step 5180, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:24.901655 #train# step 5181, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:26.457014 #train# step 5182, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:27.970689 #train# step 5183, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:29.520550 #train# step 5184, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:31.056459 #train# step 5185, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:32.602591 #train# step 5186, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:34.150335 #train# step 5187, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:35.674304 #train# step 5188, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:37.227515 #train# step 5189, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:38.797600 #train# step 5190, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:40.361007 #train# step 5191, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:41.905018 #train# step 5192, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:43.464425 #train# step 5193, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:45.030160 #train# step 5194, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:46.570170 #train# step 5195, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:48.098807 #train# step 5196, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:49.627302 #train# step 5197, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:51.179789 #train# step 5198, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:52.753254 #train# step 5199, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:54.282548 #train# step 5200, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:55.831602 #train# step 5201, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:57.402785 #train# step 5202, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:27:58.986102 #train# step 5203, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:00.550120 #train# step 5204, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:02.115821 #train# step 5205, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:03.684163 #train# step 5206, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:05.221795 #train# step 5207, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:06.754512 #train# step 5208, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:08.318617 #train# step 5209, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:09.868450 #train# step 5210, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:11.397869 #train# step 5211, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:12.934316 #train# step 5212, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:14.497239 #train# step 5213, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:16.053013 #train# step 5214, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:17.576896 #train# step 5215, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:19.138247 #train# step 5216, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:20.690648 #train# step 5217, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:22.230887 #train# step 5218, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:23.772481 #train# step 5219, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:25.306253 #train# step 5220, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:26.850817 #train# step 5221, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:28.405617 #train# step 5222, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:29.968518 #train# step 5223, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:31.553130 #train# step 5224, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:33.133550 #train# step 5225, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:34.694179 #train# step 5226, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:36.206117 #train# step 5227, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:37.780318 #train# step 5228, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:39.296525 #train# step 5229, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:40.827001 #train# step 5230, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:42.355489 #train# step 5231, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:43.901227 #train# step 5232, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:45.508729 #train# step 5233, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:47.065845 #train# step 5234, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:48.639648 #train# step 5235, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:50.152565 #train# step 5236, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:51.730078 #train# step 5237, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:53.265206 #train# step 5238, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:54.799558 #train# step 5239, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:56.347490 #train# step 5240, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:57.921238 #train# step 5241, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:28:59.468954 #train# step 5242, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:01.058650 #train# step 5243, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:02.614510 #train# step 5244, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:04.182000 #train# step 5245, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:05.687980 #train# step 5246, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:07.199941 #train# step 5247, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:08.757223 #train# step 5248, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:10.358609 #train# step 5249, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:11.883746 #train# step 5250, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:13.445744 #train# step 5251, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:15.042710 #train# step 5252, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:16.583112 #train# step 5253, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:18.133604 #train# step 5254, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:19.675751 #train# step 5255, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:21.218909 #train# step 5256, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:22.767783 #train# step 5257, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:24.323954 #train# step 5258, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:25.867446 #train# step 5259, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:27.425712 #train# step 5260, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:28.994090 #train# step 5261, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:30.558486 #train# step 5262, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:32.110012 #train# step 5263, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:33.671843 #train# step 5264, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:35.200810 #train# step 5265, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:36.749549 #train# step 5266, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:38.298004 #train# step 5267, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:39.867750 #train# step 5268, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:41.470210 #train# step 5269, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:43.036424 #train# step 5270, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:44.591992 #train# step 5271, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:46.148859 #train# step 5272, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:47.693180 #train# step 5273, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:49.261572 #train# step 5274, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:50.790115 #train# step 5275, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:52.327414 #train# step 5276, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:53.885430 #train# step 5277, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:55.435547 #train# step 5278, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:56.986745 #train# step 5279, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:29:58.578670 #train# step 5280, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:00.136546 #train# step 5281, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:01.682170 #train# step 5282, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:03.267698 #train# step 5283, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:04.791641 #train# step 5284, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:06.303517 #train# step 5285, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:07.882694 #train# step 5286, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:09.431433 #train# step 5287, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:10.945803 #train# step 5288, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:12.497744 #train# step 5289, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:14.030890 #train# step 5290, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:15.608587 #train# step 5291, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:17.154888 #train# step 5292, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:18.722750 #train# step 5293, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:20.291704 #train# step 5294, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:21.845340 #train# step 5295, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:23.372107 #train# step 5296, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:24.938881 #train# step 5297, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:26.499945 #train# step 5298, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:28.052501 #train# step 5299, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:29.612066 #train# step 5300, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:31.165391 #train# step 5301, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:32.679148 #train# step 5302, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:34.234730 #train# step 5303, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:35.760727 #train# step 5304, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:37.302013 #train# step 5305, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:38.850106 #train# step 5306, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:40.400817 #train# step 5307, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:41.977808 #train# step 5308, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:43.501168 #train# step 5309, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:45.057211 #train# step 5310, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:46.636085 #train# step 5311, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:48.181321 #train# step 5312, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:49.739970 #train# step 5313, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:51.245085 #train# step 5314, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:52.797197 #train# step 5315, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:54.388538 #train# step 5316, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:55.904830 #train# step 5317, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:57.471432 #train# step 5318, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:30:59.034858 #train# step 5319, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:00.593334 #train# step 5320, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:02.115873 #train# step 5321, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:03.647223 #train# step 5322, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:05.206744 #train# step 5323, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:06.754772 #train# step 5324, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:08.319908 #train# step 5325, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:09.854083 #train# step 5326, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:11.390305 #train# step 5327, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:12.916750 #train# step 5328, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:14.485885 #train# step 5329, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:16.045960 #train# step 5330, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:17.621939 #train# step 5331, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:19.183812 #train# step 5332, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:20.748151 #train# step 5333, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:22.294963 #train# step 5334, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:23.859743 #train# step 5335, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:25.401709 #train# step 5336, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:26.964792 #train# step 5337, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:28.489259 #train# step 5338, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:30.058643 #train# step 5339, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:31.613284 #train# step 5340, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:33.160561 #train# step 5341, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:34.727321 #train# step 5342, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:36.257012 #train# step 5343, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:37.822380 #train# step 5344, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:39.350191 #train# step 5345, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:40.899923 #train# step 5346, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:42.460855 #train# step 5347, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:44.029919 #train# step 5348, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:45.565431 #train# step 5349, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:47.124494 #train# step 5350, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:48.676643 #train# step 5351, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:50.232148 #train# step 5352, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:51.755695 #train# step 5353, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:53.295746 #train# step 5354, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:54.842508 #train# step 5355, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:56.409633 #train# step 5356, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:57.960197 #train# step 5357, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:31:59.522144 #train# step 5358, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:01.048183 #train# step 5359, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:02.599956 #train# step 5360, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:04.153931 #train# step 5361, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:05.702682 #train# step 5362, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:07.215987 #train# step 5363, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:08.811282 #train# step 5364, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:10.374478 #train# step 5365, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:11.964596 #train# step 5366, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:13.502303 #train# step 5367, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:15.049389 #train# step 5368, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:16.645114 #train# step 5369, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:18.207425 #train# step 5370, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:19.735474 #train# step 5371, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:21.300317 #train# step 5372, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:22.840801 #train# step 5373, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:24.379904 #train# step 5374, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:25.937271 #train# step 5375, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:27.477436 #train# step 5376, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:29.048976 #train# step 5377, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:30.612115 #train# step 5378, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:32.144548 #train# step 5379, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:33.726486 #train# step 5380, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:35.254137 #train# step 5381, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:36.824733 #train# step 5382, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:38.351469 #train# step 5383, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:39.872021 #train# step 5384, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:41.451224 #train# step 5385, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:42.977357 #train# step 5386, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:44.534975 #train# step 5387, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:46.073982 #train# step 5388, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:47.640809 #train# step 5389, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:49.178008 #train# step 5390, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:50.720898 #train# step 5391, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:52.245656 #train# step 5392, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:53.819050 #train# step 5393, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:55.381894 #train# step 5394, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:56.931907 #train# step 5395, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:32:58.459834 #train# step 5396, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:00.017081 #train# step 5397, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:01.559422 #train# step 5398, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:03.111319 #train# step 5399, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:04.672777 #train# step 5400, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:06.250908 #train# step 5401, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:07.801801 #train# step 5402, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:09.358019 #train# step 5403, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:10.909716 #train# step 5404, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:12.448535 #train# step 5405, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:13.985559 #train# step 5406, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:15.529615 #train# step 5407, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:17.084459 #train# step 5408, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:18.633142 #train# step 5409, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:20.170648 #train# step 5410, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:21.704159 #train# step 5411, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:23.270167 #train# step 5412, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:24.828056 #train# step 5413, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:26.371417 #train# step 5414, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:27.939703 #train# step 5415, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:29.506852 #train# step 5416, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:31.063760 #train# step 5417, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:32.630793 #train# step 5418, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:34.209479 #train# step 5419, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:35.764337 #train# step 5420, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:37.316261 #train# step 5421, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:38.871001 #train# step 5422, loss = 0.8874, cross_entropy loss = 0.8874, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:40.413665 #train# step 5423, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:41.997593 #train# step 5424, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:43.566150 #train# step 5425, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:45.156161 #train# step 5426, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:46.690631 #train# step 5427, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:48.230833 #train# step 5428, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:49.782233 #train# step 5429, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:51.340928 #train# step 5430, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:52.900463 #train# step 5431, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:54.438295 #train# step 5432, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:55.987407 #train# step 5433, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:57.496207 #train# step 5434, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:33:59.035292 #train# step 5435, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:00.575187 #train# step 5436, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:02.135307 #train# step 5437, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:03.649811 #train# step 5438, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:05.186660 #train# step 5439, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:06.730136 #train# step 5440, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:08.270620 #train# step 5441, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:09.835373 #train# step 5442, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:11.361215 #train# step 5443, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:12.902607 #train# step 5444, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:14.437492 #train# step 5445, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:16.001169 #train# step 5446, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:17.570470 #train# step 5447, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:19.150231 #train# step 5448, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:20.703108 #train# step 5449, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:22.264080 #train# step 5450, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:23.823510 #train# step 5451, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:25.396688 #train# step 5452, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:26.960000 #train# step 5453, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:28.491865 #train# step 5454, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:30.074235 #train# step 5455, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:31.614965 #train# step 5456, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:33.182607 #train# step 5457, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:34.745912 #train# step 5458, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:36.297872 #train# step 5459, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:37.830776 #train# step 5460, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:39.426362 #train# step 5461, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:40.984212 #train# step 5462, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:42.524675 #train# step 5463, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:44.077955 #train# step 5464, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:45.618098 #train# step 5465, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:47.168231 #train# step 5466, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:48.729658 #train# step 5467, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:50.272157 #train# step 5468, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:51.779807 #train# step 5469, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:53.356467 #train# step 5470, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:54.931147 #train# step 5471, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:56.490610 #train# step 5472, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:58.087211 #train# step 5473, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:34:59.656475 #train# step 5474, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:01.247837 #train# step 5475, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:02.798631 #train# step 5476, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:04.350414 #train# step 5477, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:05.925317 #train# step 5478, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:07.456820 #train# step 5479, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:09.015957 #train# step 5480, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:10.545146 #train# step 5481, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:12.090944 #train# step 5482, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:13.631413 #train# step 5483, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:15.159557 #train# step 5484, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:16.718416 #train# step 5485, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:18.286382 #train# step 5486, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:19.838411 #train# step 5487, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:21.369011 #train# step 5488, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:22.925417 #train# step 5489, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:24.467676 #train# step 5490, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:26.024781 #train# step 5491, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:27.569634 #train# step 5492, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:29.118607 #train# step 5493, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:30.649537 #train# step 5494, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:32.186928 #train# step 5495, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:33.724259 #train# step 5496, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:35.252096 #train# step 5497, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:36.805345 #train# step 5498, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:38.348713 #train# step 5499, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:39.896927 #train# step 5500, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:41.419419 #train# step 5501, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:42.950028 #train# step 5502, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:44.493419 #train# step 5503, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:46.036011 #train# step 5504, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:47.581257 #train# step 5505, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:49.117927 #train# step 5506, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:50.624595 #train# step 5507, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:52.194418 #train# step 5508, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:53.751035 #train# step 5509, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:55.291041 #train# step 5510, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:56.830769 #train# step 5511, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:58.383597 #train# step 5512, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:35:59.941627 #train# step 5513, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:01.488928 #train# step 5514, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:03.017941 #train# step 5515, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:04.585042 #train# step 5516, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:06.155872 #train# step 5517, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:07.728849 #train# step 5518, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:09.257972 #train# step 5519, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:10.839947 #train# step 5520, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:12.393448 #train# step 5521, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:13.951556 #train# step 5522, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:15.500637 #train# step 5523, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:17.062734 #train# step 5524, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:18.630816 #train# step 5525, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:20.194351 #train# step 5526, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:21.735837 #train# step 5527, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:23.263494 #train# step 5528, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:24.817845 #train# step 5529, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:26.351220 #train# step 5530, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:27.872204 #train# step 5531, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:29.427955 #train# step 5532, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:30.956699 #train# step 5533, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:32.523221 #train# step 5534, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:34.061447 #train# step 5535, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:35.613188 #train# step 5536, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:37.177430 #train# step 5537, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:38.724931 #train# step 5538, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:40.278015 #train# step 5539, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:41.845594 #train# step 5540, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:43.424355 #train# step 5541, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:44.996797 #train# step 5542, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:46.538474 #train# step 5543, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:48.138231 #train# step 5544, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:49.701820 #train# step 5545, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:51.267786 #train# step 5546, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:52.781546 #train# step 5547, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:54.378985 #train# step 5548, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:55.909258 #train# step 5549, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:57.461722 #train# step 5550, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:36:58.994690 #train# step 5551, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:00.532299 #train# step 5552, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:02.095728 #train# step 5553, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:03.671005 #train# step 5554, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:05.231807 #train# step 5555, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:06.766158 #train# step 5556, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:08.294275 #train# step 5557, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:09.837764 #train# step 5558, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:11.382793 #train# step 5559, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:12.905267 #train# step 5560, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:14.491905 #train# step 5561, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:16.040472 #train# step 5562, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:17.595219 #train# step 5563, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:19.188906 #train# step 5564, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:20.728629 #train# step 5565, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:22.288038 #train# step 5566, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:23.840453 #train# step 5567, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:25.370952 #train# step 5568, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:26.947954 #train# step 5569, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:28.506602 #train# step 5570, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:30.073333 #train# step 5571, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:31.656444 #train# step 5572, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:33.199189 #train# step 5573, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:34.745928 #train# step 5574, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:36.323151 #train# step 5575, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:37.878245 #train# step 5576, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:39.417133 #train# step 5577, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:40.952322 #train# step 5578, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:42.506539 #train# step 5579, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:44.054104 #train# step 5580, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:45.594406 #train# step 5581, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:47.137792 #train# step 5582, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:48.695557 #train# step 5583, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:50.242023 #train# step 5584, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:51.790001 #train# step 5585, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:53.343884 #train# step 5586, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:54.887935 #train# step 5587, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:56.423309 #train# step 5588, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:57.989783 #train# step 5589, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:37:59.569307 #train# step 5590, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:01.163569 #train# step 5591, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:02.714003 #train# step 5592, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:04.270731 #train# step 5593, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:05.807007 #train# step 5594, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:07.374533 #train# step 5595, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:08.939537 #train# step 5596, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:10.506920 #train# step 5597, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:12.082909 #train# step 5598, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:13.634867 #train# step 5599, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:15.200467 #train# step 5600, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:16.749094 #train# step 5601, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:18.269130 #train# step 5602, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:19.807061 #train# step 5603, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:21.327576 #train# step 5604, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:22.908957 #train# step 5605, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:24.456522 #train# step 5606, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:25.989534 #train# step 5607, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:27.564453 #train# step 5608, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:29.119390 #train# step 5609, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:30.693691 #train# step 5610, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:32.257756 #train# step 5611, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:33.813624 #train# step 5612, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:35.353454 #train# step 5613, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:36.905093 #train# step 5614, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:38.462330 #train# step 5615, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:39.990546 #train# step 5616, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:41.530844 #train# step 5617, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:43.072371 #train# step 5618, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:44.622202 #train# step 5619, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:46.182059 #train# step 5620, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:47.718254 #train# step 5621, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:49.268285 #train# step 5622, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:50.825933 #train# step 5623, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:52.368375 #train# step 5624, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:53.934364 #train# step 5625, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:55.497188 #train# step 5626, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:57.026922 #train# step 5627, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:38:58.594098 #train# step 5628, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:00.155322 #train# step 5629, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:01.704646 #train# step 5630, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:03.297306 #train# step 5631, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:04.844664 #train# step 5632, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:06.382797 #train# step 5633, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:07.938019 #train# step 5634, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:09.481083 #train# step 5635, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:11.028993 #train# step 5636, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:12.579292 #train# step 5637, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:14.131334 #train# step 5638, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:15.680642 #train# step 5639, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:17.241259 #train# step 5640, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:18.794710 #train# step 5641, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:20.359982 #train# step 5642, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:21.903128 #train# step 5643, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:23.490750 #train# step 5644, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:25.053705 #train# step 5645, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:26.588751 #train# step 5646, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:28.144726 #train# step 5647, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:29.698953 #train# step 5648, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:31.240887 #train# step 5649, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:32.794959 #train# step 5650, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:34.352380 #train# step 5651, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:35.911586 #train# step 5652, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:37.457905 #train# step 5653, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:39.011064 #train# step 5654, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:40.551262 #train# step 5655, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:42.130659 #train# step 5656, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:43.662272 #train# step 5657, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:45.217070 #train# step 5658, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:46.765094 #train# step 5659, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:48.340069 #train# step 5660, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:49.895937 #train# step 5661, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:51.474839 #train# step 5662, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:53.030519 #train# step 5663, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:54.571604 #train# step 5664, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:56.131196 #train# step 5665, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:57.684727 #train# step 5666, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:39:59.249277 #train# step 5667, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:00.778916 #train# step 5668, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:02.327770 #train# step 5669, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:03.861518 #train# step 5670, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:05.381052 #train# step 5671, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:06.898143 #train# step 5672, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:08.488269 #train# step 5673, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:10.072018 #train# step 5674, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:11.619006 #train# step 5675, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:13.163386 #train# step 5676, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:14.689555 #train# step 5677, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:16.236894 #train# step 5678, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:17.749700 #train# step 5679, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:19.303170 #train# step 5680, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:20.850402 #train# step 5681, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:22.378639 #train# step 5682, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:23.960483 #train# step 5683, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:25.537899 #train# step 5684, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:27.102968 #train# step 5685, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:28.666137 #train# step 5686, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:30.239718 #train# step 5687, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:31.775451 #train# step 5688, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:33.296030 #train# step 5689, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:34.827560 #train# step 5690, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:36.357968 #train# step 5691, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:37.919356 #train# step 5692, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:39.495620 #train# step 5693, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:41.050027 #train# step 5694, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:42.617988 #train# step 5695, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:44.170828 #train# step 5696, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:45.715678 #train# step 5697, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:47.272780 #train# step 5698, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:48.862731 #train# step 5699, loss = 0.8854, cross_entropy loss = 0.8854, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:50.415888 #train# step 5700, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:51.941888 #train# step 5701, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:53.484221 #train# step 5702, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:55.054270 #train# step 5703, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:56.638128 #train# step 5704, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:58.188772 #train# step 5705, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:40:59.720433 #train# step 5706, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:01.273574 #train# step 5707, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:02.856076 #train# step 5708, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:04.407221 #train# step 5709, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:05.986000 #train# step 5710, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:07.534070 #train# step 5711, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:09.067439 #train# step 5712, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:10.630631 #train# step 5713, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:12.153382 #train# step 5714, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:13.714858 #train# step 5715, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:15.282628 #train# step 5716, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:16.821322 #train# step 5717, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:18.384895 #train# step 5718, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:19.938306 #train# step 5719, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:21.502145 #train# step 5720, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:23.035409 #train# step 5721, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:24.605575 #train# step 5722, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:26.189219 #train# step 5723, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:27.764122 #train# step 5724, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:29.327142 #train# step 5725, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:30.890177 #train# step 5726, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:32.427640 #train# step 5727, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:33.978473 #train# step 5728, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:35.504537 #train# step 5729, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:37.054317 #train# step 5730, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:38.601983 #train# step 5731, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:40.129098 #train# step 5732, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:41.664539 #train# step 5733, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:43.200882 #train# step 5734, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:44.761001 #train# step 5735, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:46.297962 #train# step 5736, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:47.833504 #train# step 5737, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:49.369942 #train# step 5738, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:50.895989 #train# step 5739, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:52.463859 #train# step 5740, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:54.043680 #train# step 5741, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:55.605995 #train# step 5742, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:57.137372 #train# step 5743, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:41:58.700645 #train# step 5744, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:00.216216 #train# step 5745, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:01.797822 #train# step 5746, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:03.385215 #train# step 5747, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:04.954424 #train# step 5748, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:06.495389 #train# step 5749, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:08.055919 #train# step 5750, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:09.647295 #train# step 5751, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:11.209569 #train# step 5752, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:12.751481 #train# step 5753, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:14.284218 #train# step 5754, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:15.828073 #train# step 5755, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:17.374032 #train# step 5756, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:18.966846 #train# step 5757, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:20.536180 #train# step 5758, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:22.093657 #train# step 5759, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:23.638590 #train# step 5760, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:25.215515 #train# step 5761, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:26.761004 #train# step 5762, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:28.333244 #train# step 5763, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:29.905000 #train# step 5764, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:31.430673 #train# step 5765, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:32.963016 #train# step 5766, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:34.510572 #train# step 5767, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:36.060030 #train# step 5768, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:37.619936 #train# step 5769, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:39.175930 #train# step 5770, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:40.691536 #train# step 5771, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:42.243743 #train# step 5772, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:43.790389 #train# step 5773, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:45.338517 #train# step 5774, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:46.890720 #train# step 5775, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:48.428323 #train# step 5776, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:49.980734 #train# step 5777, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:51.539772 #train# step 5778, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:53.089385 #train# step 5779, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:54.673522 #train# step 5780, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:56.210669 #train# step 5781, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:57.754569 #train# step 5782, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:42:59.307245 #train# step 5783, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:00.831065 #train# step 5784, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:02.384942 #train# step 5785, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:03.973350 #train# step 5786, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:05.537535 #train# step 5787, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:07.066098 #train# step 5788, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:08.627169 #train# step 5789, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:10.178791 #train# step 5790, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:11.739227 #train# step 5791, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:13.337196 #train# step 5792, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:14.879061 #train# step 5793, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:16.428682 #train# step 5794, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:17.989660 #train# step 5795, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:19.515413 #train# step 5796, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:21.066205 #train# step 5797, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:22.573330 #train# step 5798, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:24.111119 #train# step 5799, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:25.673581 #train# step 5800, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:27.209203 #train# step 5801, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:28.744328 #train# step 5802, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:30.295038 #train# step 5803, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:31.836542 #train# step 5804, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:33.431854 #train# step 5805, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:35.000113 #train# step 5806, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:36.529066 #train# step 5807, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:38.091893 #train# step 5808, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:39.638949 #train# step 5809, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:41.173849 #train# step 5810, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:42.749435 #train# step 5811, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:44.288960 #train# step 5812, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:45.821719 #train# step 5813, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:47.364623 #train# step 5814, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:48.894549 #train# step 5815, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:50.442129 #train# step 5816, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:52.004913 #train# step 5817, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:53.533191 #train# step 5818, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:55.087563 #train# step 5819, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:56.654952 #train# step 5820, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:58.220841 #train# step 5821, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:43:59.764573 #train# step 5822, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:01.324258 #train# step 5823, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:02.911545 #train# step 5824, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:04.484417 #train# step 5825, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:06.058788 #train# step 5826, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:07.625423 #train# step 5827, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:09.182295 #train# step 5828, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:10.775272 #train# step 5829, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:12.328953 #train# step 5830, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:13.871036 #train# step 5831, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:15.414140 #train# step 5832, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:16.951180 #train# step 5833, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:18.543785 #train# step 5834, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:20.127102 #train# step 5835, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:21.664909 #train# step 5836, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:23.212498 #train# step 5837, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:24.768577 #train# step 5838, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:26.307876 #train# step 5839, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:27.829286 #train# step 5840, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:29.396935 #train# step 5841, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:30.946787 #train# step 5842, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:32.504601 #train# step 5843, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:34.064297 #train# step 5844, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:35.617267 #train# step 5845, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:37.202637 #train# step 5846, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:38.761124 #train# step 5847, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:40.296917 #train# step 5848, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:41.836829 #train# step 5849, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:43.348501 #train# step 5850, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:44.899102 #train# step 5851, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:46.444514 #train# step 5852, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:48.004749 #train# step 5853, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:49.555002 #train# step 5854, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:51.097814 #train# step 5855, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:52.686148 #train# step 5856, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:54.240588 #train# step 5857, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:55.802010 #train# step 5858, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:57.382351 #train# step 5859, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:44:58.935211 #train# step 5860, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:00.480587 #train# step 5861, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:02.050188 #train# step 5862, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:03.637117 #train# step 5863, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:05.195599 #train# step 5864, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:06.757147 #train# step 5865, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:08.298937 #train# step 5866, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:09.838457 #train# step 5867, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:11.398694 #train# step 5868, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:12.967224 #train# step 5869, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:14.513858 #train# step 5870, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:16.054264 #train# step 5871, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:17.586507 #train# step 5872, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:19.132706 #train# step 5873, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:20.665770 #train# step 5874, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:22.222133 #train# step 5875, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:23.803111 #train# step 5876, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:25.351342 #train# step 5877, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:26.890735 #train# step 5878, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:28.433708 #train# step 5879, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:29.985070 #train# step 5880, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:31.526150 #train# step 5881, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:33.065817 #train# step 5882, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:34.643928 #train# step 5883, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:36.187273 #train# step 5884, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:37.718497 #train# step 5885, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:39.302607 #train# step 5886, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:40.868542 #train# step 5887, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:42.441667 #train# step 5888, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:44.026830 #train# step 5889, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:45.543595 #train# step 5890, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:47.066669 #train# step 5891, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:48.610606 #train# step 5892, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:50.168237 #train# step 5893, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:51.728476 #train# step 5894, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:53.274952 #train# step 5895, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:54.860073 #train# step 5896, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:56.415562 #train# step 5897, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:57.959403 #train# step 5898, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:45:59.490239 #train# step 5899, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:01.048658 #train# step 5900, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:02.610186 #train# step 5901, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:04.131427 #train# step 5902, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:05.688043 #train# step 5903, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:07.221104 #train# step 5904, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:08.789501 #train# step 5905, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:10.368881 #train# step 5906, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:11.926080 #train# step 5907, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:13.455615 #train# step 5908, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:15.043736 #train# step 5909, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:16.610752 #train# step 5910, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:18.141880 #train# step 5911, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:19.677243 #train# step 5912, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:21.211353 #train# step 5913, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:22.767116 #train# step 5914, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:24.301346 #train# step 5915, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:25.879288 #train# step 5916, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:27.414660 #train# step 5917, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:28.951268 #train# step 5918, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:30.523646 #train# step 5919, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:32.077298 #train# step 5920, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:33.610125 #train# step 5921, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:35.175295 #train# step 5922, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:36.720480 #train# step 5923, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:38.299035 #train# step 5924, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:39.872377 #train# step 5925, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:41.456178 #train# step 5926, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:42.983560 #train# step 5927, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:44.545205 #train# step 5928, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:46.089661 #train# step 5929, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:47.636847 #train# step 5930, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:49.201427 #train# step 5931, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:50.760993 #train# step 5932, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:52.302088 #train# step 5933, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:53.837662 #train# step 5934, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:55.405156 #train# step 5935, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:56.938466 #train# step 5936, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:46:58.505299 #train# step 5937, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:00.071373 #train# step 5938, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:01.622017 #train# step 5939, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:03.173083 #train# step 5940, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:04.713489 #train# step 5941, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:06.271363 #train# step 5942, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:07.830239 #train# step 5943, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:09.423341 #train# step 5944, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:10.970579 #train# step 5945, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:12.523500 #train# step 5946, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:14.064554 #train# step 5947, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:15.605950 #train# step 5948, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:17.149975 #train# step 5949, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:18.693225 #train# step 5950, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:20.253977 #train# step 5951, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:21.823464 #train# step 5952, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:23.386815 #train# step 5953, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:24.936347 #train# step 5954, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:26.481243 #train# step 5955, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:28.021360 #train# step 5956, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:29.554366 #train# step 5957, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:31.080094 #train# step 5958, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:32.644633 #train# step 5959, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:34.166447 #train# step 5960, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:35.719519 #train# step 5961, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:37.299261 #train# step 5962, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:38.837713 #train# step 5963, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:40.379142 #train# step 5964, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:41.969067 #train# step 5965, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:43.525622 #train# step 5966, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:45.039839 #train# step 5967, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:46.615227 #train# step 5968, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:48.176188 #train# step 5969, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:49.727486 #train# step 5970, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:51.268520 #train# step 5971, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:52.838809 #train# step 5972, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:54.378652 #train# step 5973, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:55.975939 #train# step 5974, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:57.595640 #train# step 5975, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:47:59.151391 #train# step 5976, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:00.695886 #train# step 5977, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:02.226370 #train# step 5978, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:03.813593 #train# step 5979, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:05.378096 #train# step 5980, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:06.925041 #train# step 5981, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:08.486902 #train# step 5982, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:10.066567 #train# step 5983, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:11.592207 #train# step 5984, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:13.152085 #train# step 5985, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:14.700884 #train# step 5986, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:16.281765 #train# step 5987, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:17.832919 #train# step 5988, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:19.375835 #train# step 5989, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:20.929073 #train# step 5990, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:22.489713 #train# step 5991, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:24.010548 #train# step 5992, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:25.532123 #train# step 5993, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:27.092282 #train# step 5994, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:28.624008 #train# step 5995, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:30.164846 #train# step 5996, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:31.725600 #train# step 5997, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:33.248489 #train# step 5998, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:34.862940 #train# step 5999, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:36.394344 #train# step 6000, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:37.966169 #train# step 6001, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:39.494487 #train# step 6002, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:41.048623 #train# step 6003, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:42.595287 #train# step 6004, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:44.158751 #train# step 6005, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:45.692744 #train# step 6006, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:47.237817 #train# step 6007, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:48.803375 #train# step 6008, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:50.364540 #train# step 6009, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:51.926619 #train# step 6010, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:53.484994 #train# step 6011, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:55.025239 #train# step 6012, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:56.558647 #train# step 6013, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:58.103334 #train# step 6014, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:48:59.657409 #train# step 6015, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:01.203971 #train# step 6016, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:02.754046 #train# step 6017, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:04.329602 #train# step 6018, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:05.906972 #train# step 6019, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:07.476993 #train# step 6020, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:09.032255 #train# step 6021, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:10.606988 #train# step 6022, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:12.133856 #train# step 6023, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:13.658367 #train# step 6024, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:15.222226 #train# step 6025, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:16.790810 #train# step 6026, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:18.349269 #train# step 6027, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:19.891335 #train# step 6028, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:21.448096 #train# step 6029, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:22.993632 #train# step 6030, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:24.541897 #train# step 6031, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:26.099086 #train# step 6032, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:27.646601 #train# step 6033, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:29.182655 #train# step 6034, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:30.730318 #train# step 6035, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:32.264133 #train# step 6036, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:33.815760 #train# step 6037, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:35.388531 #train# step 6038, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:36.943749 #train# step 6039, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:38.492197 #train# step 6040, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:40.041227 #train# step 6041, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:41.587492 #train# step 6042, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:43.151227 #train# step 6043, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:44.684539 #train# step 6044, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:46.259887 #train# step 6045, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:47.791879 #train# step 6046, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:49.352170 #train# step 6047, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:50.919916 #train# step 6048, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:52.462921 #train# step 6049, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:54.020841 #train# step 6050, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:55.566821 #train# step 6051, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:57.124424 #train# step 6052, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:49:58.664553 #train# step 6053, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:00.243037 #train# step 6054, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:01.784926 #train# step 6055, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:03.336867 #train# step 6056, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:04.874482 #train# step 6057, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:06.417570 #train# step 6058, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:07.941732 #train# step 6059, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:09.509056 #train# step 6060, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:11.110660 #train# step 6061, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:12.673503 #train# step 6062, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:14.227610 #train# step 6063, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:15.778344 #train# step 6064, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:17.349053 #train# step 6065, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:18.885020 #train# step 6066, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:20.438138 #train# step 6067, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:22.017210 #train# step 6068, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:23.536926 #train# step 6069, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:25.078584 #train# step 6070, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:26.634863 #train# step 6071, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:28.222598 #train# step 6072, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:29.780876 #train# step 6073, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:31.357694 #train# step 6074, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:32.908716 #train# step 6075, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:34.478599 #train# step 6076, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:36.031589 #train# step 6077, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:37.580326 #train# step 6078, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:39.125383 #train# step 6079, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:40.691952 #train# step 6080, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:42.222124 #train# step 6081, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:43.798680 #train# step 6082, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:45.383993 #train# step 6083, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:46.929257 #train# step 6084, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:48.471376 #train# step 6085, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:50.025534 #train# step 6086, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:51.585498 #train# step 6087, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:53.158349 #train# step 6088, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:54.724486 #train# step 6089, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:56.289207 #train# step 6090, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:57.821009 #train# step 6091, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:50:59.382496 #train# step 6092, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:00.961404 #train# step 6093, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:02.533155 #train# step 6094, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:04.058244 #train# step 6095, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:05.593408 #train# step 6096, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:07.152111 #train# step 6097, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:08.704889 #train# step 6098, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:10.223045 #train# step 6099, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:11.762948 #train# step 6100, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:13.306403 #train# step 6101, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:14.865595 #train# step 6102, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:16.401537 #train# step 6103, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:17.931639 #train# step 6104, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:19.527583 #train# step 6105, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:21.053631 #train# step 6106, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:22.600162 #train# step 6107, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:24.152492 #train# step 6108, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:25.719053 #train# step 6109, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:27.261575 #train# step 6110, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:28.838886 #train# step 6111, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:30.420058 #train# step 6112, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:31.995714 #train# step 6113, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:33.535935 #train# step 6114, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:35.066361 #train# step 6115, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:36.631525 #train# step 6116, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:38.173947 #train# step 6117, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:39.708725 #train# step 6118, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:41.277133 #train# step 6119, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:42.822952 #train# step 6120, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:44.367163 #train# step 6121, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:45.897776 #train# step 6122, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:47.449848 #train# step 6123, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:49.009267 #train# step 6124, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:50.546452 #train# step 6125, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:52.095816 #train# step 6126, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:53.620771 #train# step 6127, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:55.156216 #train# step 6128, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:56.674956 #train# step 6129, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:58.235820 #train# step 6130, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:51:59.801451 #train# step 6131, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:01.355683 #train# step 6132, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:02.912557 #train# step 6133, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:04.445468 #train# step 6134, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:05.982106 #train# step 6135, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:07.525883 #train# step 6136, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:09.091290 #train# step 6137, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:10.655940 #train# step 6138, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:12.179482 #train# step 6139, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:13.744732 #train# step 6140, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:15.303474 #train# step 6141, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:16.860688 #train# step 6142, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:18.452199 #train# step 6143, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:19.982913 #train# step 6144, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:21.559619 #train# step 6145, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:23.126274 #train# step 6146, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:24.698867 #train# step 6147, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:26.285365 #train# step 6148, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:27.825418 #train# step 6149, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:29.345251 #train# step 6150, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:30.902775 #train# step 6151, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:32.455149 #train# step 6152, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:34.038322 #train# step 6153, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:35.595051 #train# step 6154, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:37.147627 #train# step 6155, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:38.685175 #train# step 6156, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:40.249409 #train# step 6157, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:41.821854 #train# step 6158, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:43.383541 #train# step 6159, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:44.956368 #train# step 6160, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:46.478428 #train# step 6161, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:48.038717 #train# step 6162, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:49.628339 #train# step 6163, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:51.221260 #train# step 6164, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:52.776375 #train# step 6165, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:54.325987 #train# step 6166, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:55.840899 #train# step 6167, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:57.404071 #train# step 6168, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:52:58.952047 #train# step 6169, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:00.479716 #train# step 6170, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:02.028174 #train# step 6171, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:03.583051 #train# step 6172, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:05.143353 #train# step 6173, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:06.692650 #train# step 6174, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:08.258550 #train# step 6175, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:09.831003 #train# step 6176, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:11.394105 #train# step 6177, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:12.923579 #train# step 6178, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:14.465228 #train# step 6179, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:16.025188 #train# step 6180, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:17.556756 #train# step 6181, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:19.077903 #train# step 6182, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:20.644673 #train# step 6183, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:22.175607 #train# step 6184, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:23.726233 #train# step 6185, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:25.285718 #train# step 6186, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:26.834671 #train# step 6187, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:28.368403 #train# step 6188, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:29.912083 #train# step 6189, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:31.451519 #train# step 6190, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:32.998291 #train# step 6191, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:34.542887 #train# step 6192, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:36.110276 #train# step 6193, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:37.670599 #train# step 6194, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:39.220756 #train# step 6195, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:40.764141 #train# step 6196, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:42.315059 #train# step 6197, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:43.860831 #train# step 6198, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:45.426592 #train# step 6199, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:46.992702 #train# step 6200, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:48.562318 #train# step 6201, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:50.090942 #train# step 6202, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:51.677489 #train# step 6203, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:53.239767 #train# step 6204, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:54.783526 #train# step 6205, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:56.371363 #train# step 6206, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:57.941367 #train# step 6207, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:53:59.502930 #train# step 6208, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:01.088350 #train# step 6209, loss = 0.8886, cross_entropy loss = 0.8886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:02.649674 #train# step 6210, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:04.209571 #train# step 6211, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:05.797710 #train# step 6212, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:07.335580 #train# step 6213, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:08.864276 #train# step 6214, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:10.421564 #train# step 6215, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:11.963039 #train# step 6216, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:13.501549 #train# step 6217, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:15.044655 #train# step 6218, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:16.595383 #train# step 6219, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:18.143779 #train# step 6220, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:19.695873 #train# step 6221, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:21.232978 #train# step 6222, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:22.803817 #train# step 6223, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:24.351091 #train# step 6224, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:25.925449 #train# step 6225, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:27.452558 #train# step 6226, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:29.004923 #train# step 6227, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:30.548643 #train# step 6228, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:32.118921 #train# step 6229, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:33.682580 #train# step 6230, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:35.204787 #train# step 6231, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:36.758976 #train# step 6232, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:38.331374 #train# step 6233, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:39.848753 #train# step 6234, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:41.397770 #train# step 6235, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:42.924053 #train# step 6236, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:44.439836 #train# step 6237, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:46.012196 #train# step 6238, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:47.618099 #train# step 6239, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:49.173798 #train# step 6240, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:50.692179 #train# step 6241, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:52.236493 #train# step 6242, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:53.797622 #train# step 6243, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:55.367066 #train# step 6244, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:56.932854 #train# step 6245, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:54:58.490865 #train# step 6246, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:00.075268 #train# step 6247, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:01.629616 #train# step 6248, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:03.217306 #train# step 6249, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:04.782818 #train# step 6250, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:06.321675 #train# step 6251, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:07.876651 #train# step 6252, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:09.419272 #train# step 6253, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:10.974219 #train# step 6254, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:12.523763 #train# step 6255, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:14.072483 #train# step 6256, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:15.590151 #train# step 6257, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:17.147044 #train# step 6258, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:18.692839 #train# step 6259, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:20.250713 #train# step 6260, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:21.781506 #train# step 6261, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:23.358218 #train# step 6262, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:24.903495 #train# step 6263, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:26.442720 #train# step 6264, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:27.978803 #train# step 6265, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:29.532612 #train# step 6266, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:31.084065 #train# step 6267, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:32.636717 #train# step 6268, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:34.197277 #train# step 6269, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:35.739945 #train# step 6270, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:37.317217 #train# step 6271, loss = 0.8896, cross_entropy loss = 0.8896, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:38.871017 #train# step 6272, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:40.428847 #train# step 6273, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:41.967590 #train# step 6274, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:43.501245 #train# step 6275, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:45.044922 #train# step 6276, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:46.581733 #train# step 6277, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:48.167349 #train# step 6278, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:49.720854 #train# step 6279, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:51.290802 #train# step 6280, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:52.830928 #train# step 6281, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:54.434081 #train# step 6282, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:55.966141 #train# step 6283, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:57.514161 #train# step 6284, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:55:59.085178 #train# step 6285, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:00.616523 #train# step 6286, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:02.151083 #train# step 6287, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:03.712053 #train# step 6288, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:05.275740 #train# step 6289, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:06.825351 #train# step 6290, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:08.401483 #train# step 6291, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:09.991208 #train# step 6292, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:11.529579 #train# step 6293, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:13.082263 #train# step 6294, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:14.641190 #train# step 6295, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:16.209971 #train# step 6296, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:17.747410 #train# step 6297, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:19.329238 #train# step 6298, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:20.859786 #train# step 6299, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:22.421748 #train# step 6300, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:23.948808 #train# step 6301, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:25.485033 #train# step 6302, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:27.035764 #train# step 6303, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:28.560494 #train# step 6304, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:30.123347 #train# step 6305, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:31.709720 #train# step 6306, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:33.238130 #train# step 6307, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:34.838516 #train# step 6308, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:36.383941 #train# step 6309, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:37.944737 #train# step 6310, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:39.461302 #train# step 6311, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:41.008335 #train# step 6312, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:42.549707 #train# step 6313, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:44.115736 #train# step 6314, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:45.656558 #train# step 6315, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:47.232319 #train# step 6316, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:48.778602 #train# step 6317, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:50.356287 #train# step 6318, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:51.898896 #train# step 6319, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:53.438806 #train# step 6320, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:54.982052 #train# step 6321, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:56.524557 #train# step 6322, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:58.080577 #train# step 6323, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:56:59.651781 #train# step 6324, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:01.209323 #train# step 6325, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:02.748254 #train# step 6326, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:04.285400 #train# step 6327, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:05.888722 #train# step 6328, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:07.439713 #train# step 6329, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:08.984574 #train# step 6330, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:10.577839 #train# step 6331, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:12.100118 #train# step 6332, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:13.644546 #train# step 6333, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:15.187810 #train# step 6334, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:16.764043 #train# step 6335, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:18.306017 #train# step 6336, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:19.840969 #train# step 6337, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:21.455345 #train# step 6338, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:23.001443 #train# step 6339, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:24.573591 #train# step 6340, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:26.124561 #train# step 6341, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:27.712993 #train# step 6342, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:29.298392 #train# step 6343, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:30.858563 #train# step 6344, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:32.379981 #train# step 6345, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:33.957770 #train# step 6346, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:35.515768 #train# step 6347, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:37.078862 #train# step 6348, loss = 0.8892, cross_entropy loss = 0.8892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:38.650251 #train# step 6349, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:40.207281 #train# step 6350, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:41.753169 #train# step 6351, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:43.298921 #train# step 6352, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:44.902698 #train# step 6353, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:46.472035 #train# step 6354, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:48.032421 #train# step 6355, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:49.547058 #train# step 6356, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:51.114412 #train# step 6357, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:52.644282 #train# step 6358, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:54.197620 #train# step 6359, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:55.769490 #train# step 6360, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:57.311990 #train# step 6361, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:57:58.852421 #train# step 6362, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:00.407976 #train# step 6363, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:01.908761 #train# step 6364, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:03.455011 #train# step 6365, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:04.996316 #train# step 6366, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:06.541786 #train# step 6367, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:08.119168 #train# step 6368, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:09.668654 #train# step 6369, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:11.244841 #train# step 6370, loss = 0.8829, cross_entropy loss = 0.8829, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:12.804800 #train# step 6371, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:14.328667 #train# step 6372, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:15.901047 #train# step 6373, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:17.471251 #train# step 6374, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:19.020308 #train# step 6375, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:20.592731 #train# step 6376, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:22.135392 #train# step 6377, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:23.681989 #train# step 6378, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:25.239709 #train# step 6379, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:26.784948 #train# step 6380, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:28.332790 #train# step 6381, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:29.909344 #train# step 6382, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:31.453544 #train# step 6383, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:32.987908 #train# step 6384, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:34.532365 #train# step 6385, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:36.104580 #train# step 6386, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:37.673921 #train# step 6387, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:39.245379 #train# step 6388, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:40.801628 #train# step 6389, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:42.374257 #train# step 6390, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:43.929394 #train# step 6391, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:45.469598 #train# step 6392, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:47.008104 #train# step 6393, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:48.534080 #train# step 6394, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:50.059925 #train# step 6395, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:51.637266 #train# step 6396, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:53.235156 #train# step 6397, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:54.781037 #train# step 6398, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:56.334681 #train# step 6399, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:57.874119 #train# step 6400, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:58:59.443227 #train# step 6401, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:01.015853 #train# step 6402, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:02.573610 #train# step 6403, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:04.118524 #train# step 6404, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:05.660459 #train# step 6405, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:07.223386 #train# step 6406, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:08.793544 #train# step 6407, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:10.375219 #train# step 6408, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:11.966607 #train# step 6409, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:13.522536 #train# step 6410, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:15.064332 #train# step 6411, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:16.637065 #train# step 6412, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:18.176082 #train# step 6413, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:19.739687 #train# step 6414, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:21.286057 #train# step 6415, loss = 0.8902, cross_entropy loss = 0.8902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:22.837076 #train# step 6416, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:24.405644 #train# step 6417, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:25.961640 #train# step 6418, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:27.499961 #train# step 6419, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:29.045351 #train# step 6420, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:30.642536 #train# step 6421, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:32.210880 #train# step 6422, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:33.797678 #train# step 6423, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:35.344118 #train# step 6424, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:36.911414 #train# step 6425, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:38.482898 #train# step 6426, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:40.018482 #train# step 6427, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:41.561235 #train# step 6428, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:43.097710 #train# step 6429, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:44.671649 #train# step 6430, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:46.210923 #train# step 6431, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:47.746772 #train# step 6432, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:49.299669 #train# step 6433, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:50.838897 #train# step 6434, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:52.379613 #train# step 6435, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:53.953843 #train# step 6436, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:55.534499 #train# step 6437, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:57.055344 #train# step 6438, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 03:59:58.566960 #train# step 6439, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:00.108874 #train# step 6440, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:01.647235 #train# step 6441, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:03.178603 #train# step 6442, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:04.742070 #train# step 6443, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:06.309283 #train# step 6444, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:07.870306 #train# step 6445, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:09.457094 #train# step 6446, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:10.991584 #train# step 6447, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:12.531636 #train# step 6448, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:14.077402 #train# step 6449, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:15.633352 #train# step 6450, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:17.183000 #train# step 6451, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:18.735500 #train# step 6452, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:20.285646 #train# step 6453, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:21.855416 #train# step 6454, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:23.388749 #train# step 6455, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:24.929091 #train# step 6456, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:26.473969 #train# step 6457, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:28.014974 #train# step 6458, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:29.596049 #train# step 6459, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:31.136226 #train# step 6460, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:32.690551 #train# step 6461, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:34.259064 #train# step 6462, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:35.798729 #train# step 6463, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:37.339100 #train# step 6464, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:38.920635 #train# step 6465, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:40.465948 #train# step 6466, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:42.028877 #train# step 6467, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:43.584606 #train# step 6468, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:45.104062 #train# step 6469, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:46.664939 #train# step 6470, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:48.219531 #train# step 6471, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:49.758761 #train# step 6472, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:51.322584 #train# step 6473, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:52.877454 #train# step 6474, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:54.413576 #train# step 6475, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:55.991667 #train# step 6476, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:57.538483 #train# step 6477, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:00:59.119598 #train# step 6478, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:00.675576 #train# step 6479, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:02.243835 #train# step 6480, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:03.810636 #train# step 6481, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:05.404897 #train# step 6482, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:06.952293 #train# step 6483, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:08.525741 #train# step 6484, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:10.093192 #train# step 6485, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:11.646456 #train# step 6486, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:13.189428 #train# step 6487, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:14.799555 #train# step 6488, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:16.366603 #train# step 6489, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:17.920645 #train# step 6490, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:19.462721 #train# step 6491, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:21.045032 #train# step 6492, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:22.593028 #train# step 6493, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:24.164255 #train# step 6494, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:25.707187 #train# step 6495, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:27.264804 #train# step 6496, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:28.826363 #train# step 6497, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:30.371178 #train# step 6498, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:31.891483 #train# step 6499, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:33.441857 #train# step 6500, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:34.987938 #train# step 6501, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:36.558710 #train# step 6502, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:38.137901 #train# step 6503, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:39.711884 #train# step 6504, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:41.262303 #train# step 6505, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:42.821061 #train# step 6506, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:44.357457 #train# step 6507, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:45.905556 #train# step 6508, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:47.470953 #train# step 6509, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:48.995303 #train# step 6510, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:50.549467 #train# step 6511, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:52.086696 #train# step 6512, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:53.638741 #train# step 6513, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:55.198354 #train# step 6514, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:56.749957 #train# step 6515, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:58.287366 #train# step 6516, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:01:59.851301 #train# step 6517, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:01.419961 #train# step 6518, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:02.958362 #train# step 6519, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:04.539761 #train# step 6520, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:06.106472 #train# step 6521, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:07.680419 #train# step 6522, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:09.238491 #train# step 6523, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:10.782550 #train# step 6524, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:12.308280 #train# step 6525, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:13.856157 #train# step 6526, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:15.404968 #train# step 6527, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:16.945461 #train# step 6528, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:18.490707 #train# step 6529, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:20.064025 #train# step 6530, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:21.650175 #train# step 6531, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:23.187881 #train# step 6532, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:24.738001 #train# step 6533, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:26.307490 #train# step 6534, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:27.872751 #train# step 6535, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:29.428407 #train# step 6536, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:30.951663 #train# step 6537, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:32.510412 #train# step 6538, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:34.069768 #train# step 6539, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:35.637729 #train# step 6540, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:37.206412 #train# step 6541, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:38.761428 #train# step 6542, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:40.320347 #train# step 6543, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:41.892990 #train# step 6544, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:43.416871 #train# step 6545, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:44.957285 #train# step 6546, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:46.521597 #train# step 6547, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:48.052190 #train# step 6548, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:49.608831 #train# step 6549, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:51.164367 #train# step 6550, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:52.704128 #train# step 6551, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:54.255884 #train# step 6552, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:55.831606 #train# step 6553, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:57.426542 #train# step 6554, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:02:58.961740 #train# step 6555, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:00.510898 #train# step 6556, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:02.074873 #train# step 6557, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:03.631816 #train# step 6558, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:05.181203 #train# step 6559, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:06.734527 #train# step 6560, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:08.267539 #train# step 6561, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:09.830908 #train# step 6562, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:11.387767 #train# step 6563, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:12.970083 #train# step 6564, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:14.491965 #train# step 6565, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:16.060687 #train# step 6566, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:17.620194 #train# step 6567, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:19.171024 #train# step 6568, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:20.725300 #train# step 6569, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:22.280279 #train# step 6570, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:23.816206 #train# step 6571, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:25.355387 #train# step 6572, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:26.923913 #train# step 6573, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:28.489390 #train# step 6574, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:30.015719 #train# step 6575, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:31.549303 #train# step 6576, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:33.089532 #train# step 6577, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:34.692878 #train# step 6578, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:36.252176 #train# step 6579, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:37.806712 #train# step 6580, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:39.379724 #train# step 6581, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:40.938544 #train# step 6582, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:42.496486 #train# step 6583, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:44.030032 #train# step 6584, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:45.594759 #train# step 6585, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:47.158777 #train# step 6586, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:48.700649 #train# step 6587, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:50.231208 #train# step 6588, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:51.771924 #train# step 6589, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:53.325801 #train# step 6590, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:54.863699 #train# step 6591, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:56.423356 #train# step 6592, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:57.984013 #train# step 6593, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:03:59.516034 #train# step 6594, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:01.103115 #train# step 6595, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:02.640631 #train# step 6596, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:04.177478 #train# step 6597, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:05.702336 #train# step 6598, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:07.254777 #train# step 6599, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:08.812203 #train# step 6600, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:10.381977 #train# step 6601, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:11.941635 #train# step 6602, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:13.513006 #train# step 6603, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:15.084399 #train# step 6604, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:16.649301 #train# step 6605, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:18.227610 #train# step 6606, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:19.790146 #train# step 6607, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:21.357156 #train# step 6608, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:22.911502 #train# step 6609, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:24.448536 #train# step 6610, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:26.001747 #train# step 6611, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:27.538409 #train# step 6612, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:29.098160 #train# step 6613, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:30.636972 #train# step 6614, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:32.340506 #train# step 6615, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:33.911112 #train# step 6616, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:35.439425 #train# step 6617, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:36.963370 #train# step 6618, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:38.529075 #train# step 6619, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:40.101690 #train# step 6620, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:41.659956 #train# step 6621, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:43.196165 #train# step 6622, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:44.762077 #train# step 6623, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:46.305092 #train# step 6624, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:47.893271 #train# step 6625, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:49.432837 #train# step 6626, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:50.984710 #train# step 6627, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:52.523401 #train# step 6628, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:54.094873 #train# step 6629, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:55.642649 #train# step 6630, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:57.196887 #train# step 6631, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:04:58.761940 #train# step 6632, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:00.335388 #train# step 6633, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:01.849248 #train# step 6634, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:03.456606 #train# step 6635, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:05.033228 #train# step 6636, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:06.584369 #train# step 6637, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:08.116126 #train# step 6638, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:09.656627 #train# step 6639, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:11.243105 #train# step 6640, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:12.806062 #train# step 6641, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:14.407499 #train# step 6642, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:15.972255 #train# step 6643, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:17.508798 #train# step 6644, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:19.039123 #train# step 6645, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:20.593377 #train# step 6646, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:22.143991 #train# step 6647, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:23.688645 #train# step 6648, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:25.244540 #train# step 6649, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:26.791813 #train# step 6650, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:28.347788 #train# step 6651, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:29.880123 #train# step 6652, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:31.427851 #train# step 6653, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:32.986136 #train# step 6654, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:34.534278 #train# step 6655, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:36.071660 #train# step 6656, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:37.612800 #train# step 6657, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:39.194728 #train# step 6658, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:40.711828 #train# step 6659, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:42.297603 #train# step 6660, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:43.850934 #train# step 6661, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:45.390121 #train# step 6662, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:46.949655 #train# step 6663, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:48.511686 #train# step 6664, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:50.039940 #train# step 6665, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:51.582497 #train# step 6666, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:53.128640 #train# step 6667, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:54.716644 #train# step 6668, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:56.272660 #train# step 6669, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:57.802975 #train# step 6670, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:05:59.345182 #train# step 6671, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:00.877276 #train# step 6672, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:02.439547 #train# step 6673, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:03.990857 #train# step 6674, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:05.579375 #train# step 6675, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:07.134654 #train# step 6676, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:08.692119 #train# step 6677, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:10.260785 #train# step 6678, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:11.803996 #train# step 6679, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:13.322343 #train# step 6680, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:14.932485 #train# step 6681, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:16.523910 #train# step 6682, loss = 0.8848, cross_entropy loss = 0.8848, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:18.077973 #train# step 6683, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:19.598230 #train# step 6684, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:21.121214 #train# step 6685, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:22.684376 #train# step 6686, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:24.265425 #train# step 6687, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:25.867460 #train# step 6688, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:27.417715 #train# step 6689, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:28.953472 #train# step 6690, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:30.506635 #train# step 6691, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:32.047527 #train# step 6692, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:33.626699 #train# step 6693, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:35.162448 #train# step 6694, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:36.729770 #train# step 6695, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:38.292003 #train# step 6696, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:39.835254 #train# step 6697, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:41.373434 #train# step 6698, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:42.934236 #train# step 6699, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:44.486314 #train# step 6700, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:46.064248 #train# step 6701, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:47.653815 #train# step 6702, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:49.196785 #train# step 6703, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:50.772777 #train# step 6704, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:52.299214 #train# step 6705, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:53.829874 #train# step 6706, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:55.385610 #train# step 6707, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:56.951363 #train# step 6708, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:06:58.503520 #train# step 6709, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:00.050498 #train# step 6710, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:01.609932 #train# step 6711, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:03.124975 #train# step 6712, loss = 0.8893, cross_entropy loss = 0.8893, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:04.655019 #train# step 6713, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:06.199974 #train# step 6714, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:07.741549 #train# step 6715, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:09.311171 #train# step 6716, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:10.875474 #train# step 6717, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:12.412119 #train# step 6718, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:13.994415 #train# step 6719, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:15.516021 #train# step 6720, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:17.025492 #train# step 6721, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:18.591956 #train# step 6722, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:20.139645 #train# step 6723, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:21.677983 #train# step 6724, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:23.245457 #train# step 6725, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:24.803388 #train# step 6726, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:26.343398 #train# step 6727, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:27.876915 #train# step 6728, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:29.449805 #train# step 6729, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:31.002498 #train# step 6730, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:32.599285 #train# step 6731, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:34.137285 #train# step 6732, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:35.667603 #train# step 6733, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:37.200047 #train# step 6734, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:38.768335 #train# step 6735, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:40.301937 #train# step 6736, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:41.864424 #train# step 6737, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:43.446747 #train# step 6738, loss = 0.8879, cross_entropy loss = 0.8879, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:44.993860 #train# step 6739, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:46.534609 #train# step 6740, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:48.061234 #train# step 6741, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:49.627254 #train# step 6742, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:51.177795 #train# step 6743, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:52.735694 #train# step 6744, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:54.284683 #train# step 6745, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:55.838370 #train# step 6746, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:57.390054 #train# step 6747, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:07:58.966919 #train# step 6748, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:00.533500 #train# step 6749, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:02.107874 #train# step 6750, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:03.658901 #train# step 6751, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:05.225321 #train# step 6752, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:06.792652 #train# step 6753, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:08.352013 #train# step 6754, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:09.875148 #train# step 6755, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:11.403807 #train# step 6756, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:12.942967 #train# step 6757, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:14.519736 #train# step 6758, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:16.065143 #train# step 6759, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:17.622223 #train# step 6760, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:19.153905 #train# step 6761, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:20.738119 #train# step 6762, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:22.296794 #train# step 6763, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:23.848773 #train# step 6764, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:25.409145 #train# step 6765, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:26.970361 #train# step 6766, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:28.515240 #train# step 6767, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:30.043038 #train# step 6768, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:31.603789 #train# step 6769, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:33.156505 #train# step 6770, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:34.699767 #train# step 6771, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:36.238122 #train# step 6772, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:37.791144 #train# step 6773, loss = 0.8873, cross_entropy loss = 0.8873, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:39.339270 #train# step 6774, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:40.914417 #train# step 6775, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:42.504625 #train# step 6776, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:44.057630 #train# step 6777, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:45.622419 #train# step 6778, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:47.166202 #train# step 6779, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:48.756572 #train# step 6780, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:50.282129 #train# step 6781, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:51.867681 #train# step 6782, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:53.419090 #train# step 6783, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:54.967985 #train# step 6784, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:56.550328 #train# step 6785, loss = 0.8902, cross_entropy loss = 0.8902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:58.108958 #train# step 6786, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:08:59.669595 #train# step 6787, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:01.218655 #train# step 6788, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:02.760274 #train# step 6789, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:04.297287 #train# step 6790, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:05.889717 #train# step 6791, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:07.428755 #train# step 6792, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:08.994276 #train# step 6793, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:10.536708 #train# step 6794, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:12.086332 #train# step 6795, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:13.662574 #train# step 6796, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:15.199561 #train# step 6797, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:16.779204 #train# step 6798, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:18.323893 #train# step 6799, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:19.879621 #train# step 6800, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:21.460317 #train# step 6801, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:23.010188 #train# step 6802, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:24.552852 #train# step 6803, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:26.087316 #train# step 6804, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:27.637314 #train# step 6805, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:29.186933 #train# step 6806, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:30.726248 #train# step 6807, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:32.278357 #train# step 6808, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:33.814877 #train# step 6809, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:35.367803 #train# step 6810, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:36.922478 #train# step 6811, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:38.457875 #train# step 6812, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:40.005980 #train# step 6813, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:41.549876 #train# step 6814, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:43.093412 #train# step 6815, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:44.644128 #train# step 6816, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:46.182008 #train# step 6817, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:47.748037 #train# step 6818, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:49.306675 #train# step 6819, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:50.890442 #train# step 6820, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:52.438119 #train# step 6821, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:53.980654 #train# step 6822, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:55.569136 #train# step 6823, loss = 0.8902, cross_entropy loss = 0.8902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:57.104924 #train# step 6824, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:09:58.636045 #train# step 6825, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:00.152224 #train# step 6826, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:01.694829 #train# step 6827, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:03.271800 #train# step 6828, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:04.845612 #train# step 6829, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:06.392569 #train# step 6830, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:07.941281 #train# step 6831, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:09.477767 #train# step 6832, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:11.048557 #train# step 6833, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:12.593670 #train# step 6834, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:14.163848 #train# step 6835, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:15.704652 #train# step 6836, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:17.287611 #train# step 6837, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:18.827857 #train# step 6838, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:20.361786 #train# step 6839, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:21.919346 #train# step 6840, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:23.462430 #train# step 6841, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:25.014662 #train# step 6842, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:26.595711 #train# step 6843, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:28.123346 #train# step 6844, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:29.683342 #train# step 6845, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:31.262609 #train# step 6846, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:32.840374 #train# step 6847, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:34.382491 #train# step 6848, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:35.916899 #train# step 6849, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:37.475608 #train# step 6850, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:39.040633 #train# step 6851, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:40.602369 #train# step 6852, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:42.163711 #train# step 6853, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:43.736752 #train# step 6854, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:45.310132 #train# step 6855, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:46.869166 #train# step 6856, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:48.412898 #train# step 6857, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:49.939785 #train# step 6858, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:51.531870 #train# step 6859, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:53.089096 #train# step 6860, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:54.611822 #train# step 6861, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:56.145179 #train# step 6862, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:57.681315 #train# step 6863, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:10:59.235660 #train# step 6864, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:00.805927 #train# step 6865, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:02.372766 #train# step 6866, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:03.931005 #train# step 6867, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:05.481061 #train# step 6868, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:07.007200 #train# step 6869, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:08.596373 #train# step 6870, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:10.156680 #train# step 6871, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:11.727184 #train# step 6872, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:13.331384 #train# step 6873, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:14.854439 #train# step 6874, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:16.405801 #train# step 6875, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:17.937916 #train# step 6876, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:19.470478 #train# step 6877, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:21.056927 #train# step 6878, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:22.586674 #train# step 6879, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:24.133526 #train# step 6880, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:25.700965 #train# step 6881, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:27.249124 #train# step 6882, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:28.779192 #train# step 6883, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:30.298044 #train# step 6884, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:31.831000 #train# step 6885, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:33.393421 #train# step 6886, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:34.936987 #train# step 6887, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:36.496060 #train# step 6888, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:38.057480 #train# step 6889, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:39.632517 #train# step 6890, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:41.169466 #train# step 6891, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:42.762925 #train# step 6892, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:44.303442 #train# step 6893, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:45.882347 #train# step 6894, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:47.435862 #train# step 6895, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:49.039473 #train# step 6896, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:50.623566 #train# step 6897, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:52.174325 #train# step 6898, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:53.714416 #train# step 6899, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:55.253690 #train# step 6900, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:56.790129 #train# step 6901, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:58.323947 #train# step 6902, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:11:59.875995 #train# step 6903, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:01.433955 #train# step 6904, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:02.971902 #train# step 6905, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:04.542613 #train# step 6906, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:06.108318 #train# step 6907, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:07.657427 #train# step 6908, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:09.229080 #train# step 6909, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:10.800407 #train# step 6910, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:12.351517 #train# step 6911, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:13.916589 #train# step 6912, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:15.463940 #train# step 6913, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:17.032461 #train# step 6914, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:18.603646 #train# step 6915, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:20.164915 #train# step 6916, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:21.720550 #train# step 6917, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:23.330527 #train# step 6918, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:24.898343 #train# step 6919, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:26.427389 #train# step 6920, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:27.976470 #train# step 6921, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:29.551311 #train# step 6922, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:31.054530 #train# step 6923, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:32.590727 #train# step 6924, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:34.133966 #train# step 6925, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:35.655738 #train# step 6926, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:37.195622 #train# step 6927, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:38.754717 #train# step 6928, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:40.327299 #train# step 6929, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:41.909065 #train# step 6930, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:43.458840 #train# step 6931, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:45.016224 #train# step 6932, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:46.580022 #train# step 6933, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:48.112768 #train# step 6934, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:49.659740 #train# step 6935, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:51.208223 #train# step 6936, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:52.772592 #train# step 6937, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:54.347720 #train# step 6938, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:55.887103 #train# step 6939, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:57.431146 #train# step 6940, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:12:58.951101 #train# step 6941, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:00.512861 #train# step 6942, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:02.050054 #train# step 6943, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:03.604855 #train# step 6944, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:05.176316 #train# step 6945, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:06.693340 #train# step 6946, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:08.243372 #train# step 6947, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:09.785929 #train# step 6948, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:11.338261 #train# step 6949, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:12.881874 #train# step 6950, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:14.446859 #train# step 6951, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:15.981908 #train# step 6952, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:17.553385 #train# step 6953, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:19.097030 #train# step 6954, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:20.676407 #train# step 6955, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:22.221810 #train# step 6956, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:23.764595 #train# step 6957, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:25.307070 #train# step 6958, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:26.837697 #train# step 6959, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:28.432750 #train# step 6960, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:30.020259 #train# step 6961, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:31.582083 #train# step 6962, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:33.109884 #train# step 6963, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:34.644408 #train# step 6964, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:36.193728 #train# step 6965, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:37.754899 #train# step 6966, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:39.339964 #train# step 6967, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:40.884308 #train# step 6968, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:42.473954 #train# step 6969, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:44.039824 #train# step 6970, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:45.588712 #train# step 6971, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:47.150713 #train# step 6972, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:48.708257 #train# step 6973, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:50.276574 #train# step 6974, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:51.837187 #train# step 6975, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:53.356704 #train# step 6976, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:54.885199 #train# step 6977, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:56.444322 #train# step 6978, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:57.995029 #train# step 6979, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:13:59.522858 #train# step 6980, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:01.049084 #train# step 6981, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:02.599150 #train# step 6982, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:04.149024 #train# step 6983, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:05.711311 #train# step 6984, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:07.252696 #train# step 6985, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:08.758122 #train# step 6986, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:10.336011 #train# step 6987, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:11.916990 #train# step 6988, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:13.471287 #train# step 6989, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:15.021079 #train# step 6990, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:16.585087 #train# step 6991, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:18.147932 #train# step 6992, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:19.723170 #train# step 6993, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:21.291527 #train# step 6994, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:22.825225 #train# step 6995, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:24.372418 #train# step 6996, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:25.942305 #train# step 6997, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:27.475874 #train# step 6998, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:29.005912 #train# step 6999, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:30.584256 #train# step 7000, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:32.147418 #train# step 7001, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:33.703968 #train# step 7002, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:35.268109 #train# step 7003, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:36.809978 #train# step 7004, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:38.391430 #train# step 7005, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:39.943537 #train# step 7006, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:41.492814 #train# step 7007, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:43.047695 #train# step 7008, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:44.594265 #train# step 7009, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:46.154539 #train# step 7010, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:47.682277 #train# step 7011, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:49.229290 #train# step 7012, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:50.760901 #train# step 7013, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:52.327146 #train# step 7014, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:53.887251 #train# step 7015, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:55.448392 #train# step 7016, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:57.004386 #train# step 7017, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:14:58.581127 #train# step 7018, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:00.137980 #train# step 7019, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:01.659916 #train# step 7020, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:03.225909 #train# step 7021, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:04.750785 #train# step 7022, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:06.306270 #train# step 7023, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:07.877667 #train# step 7024, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:09.430723 #train# step 7025, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:10.975385 #train# step 7026, loss = 0.8850, cross_entropy loss = 0.8850, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:12.501395 #train# step 7027, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:14.041924 #train# step 7028, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:15.625870 #train# step 7029, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:17.216305 #train# step 7030, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:18.774889 #train# step 7031, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:20.298941 #train# step 7032, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:21.844548 #train# step 7033, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:23.434320 #train# step 7034, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:25.017563 #train# step 7035, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:26.550242 #train# step 7036, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:28.115119 #train# step 7037, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:29.696262 #train# step 7038, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:31.253953 #train# step 7039, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:32.818650 #train# step 7040, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:34.371446 #train# step 7041, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:35.912046 #train# step 7042, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:37.448838 #train# step 7043, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:38.989048 #train# step 7044, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:40.529656 #train# step 7045, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:42.083771 #train# step 7046, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:43.637131 #train# step 7047, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:45.193243 #train# step 7048, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:46.742268 #train# step 7049, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:48.264924 #train# step 7050, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:49.813298 #train# step 7051, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:51.333859 #train# step 7052, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:52.889307 #train# step 7053, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:54.445804 #train# step 7054, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:55.986877 #train# step 7055, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:57.554424 #train# step 7056, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:15:59.120700 #train# step 7057, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:00.660467 #train# step 7058, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:02.171510 #train# step 7059, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:03.728157 #train# step 7060, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:05.267587 #train# step 7061, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:06.819482 #train# step 7062, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:08.391978 #train# step 7063, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:09.949464 #train# step 7064, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:11.492982 #train# step 7065, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:13.038151 #train# step 7066, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:14.595351 #train# step 7067, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:16.141727 #train# step 7068, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:17.682083 #train# step 7069, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:19.222642 #train# step 7070, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:20.777372 #train# step 7071, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:22.319958 #train# step 7072, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:23.852470 #train# step 7073, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:25.376268 #train# step 7074, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:26.948694 #train# step 7075, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:28.500469 #train# step 7076, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:30.089594 #train# step 7077, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:31.655958 #train# step 7078, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:33.193052 #train# step 7079, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:34.726460 #train# step 7080, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:36.294535 #train# step 7081, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:37.870180 #train# step 7082, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:39.438758 #train# step 7083, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:40.986452 #train# step 7084, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:42.534634 #train# step 7085, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:44.094991 #train# step 7086, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:45.687792 #train# step 7087, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:47.244526 #train# step 7088, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:48.797610 #train# step 7089, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:50.334181 #train# step 7090, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:51.895427 #train# step 7091, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:53.423972 #train# step 7092, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:54.995965 #train# step 7093, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:56.565215 #train# step 7094, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:58.155516 #train# step 7095, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:16:59.697724 #train# step 7096, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:01.275238 #train# step 7097, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:02.814850 #train# step 7098, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:04.329948 #train# step 7099, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:05.881350 #train# step 7100, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:07.460805 #train# step 7101, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:09.002471 #train# step 7102, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:10.546494 #train# step 7103, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:12.135749 #train# step 7104, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:13.678383 #train# step 7105, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:15.231247 #train# step 7106, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:16.783716 #train# step 7107, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:18.334259 #train# step 7108, loss = 0.8843, cross_entropy loss = 0.8843, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:19.901392 #train# step 7109, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:21.457245 #train# step 7110, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:23.035770 #train# step 7111, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:24.602375 #train# step 7112, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:26.171032 #train# step 7113, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:27.705673 #train# step 7114, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:29.262651 #train# step 7115, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:30.807436 #train# step 7116, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:32.355390 #train# step 7117, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:33.916542 #train# step 7118, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:35.462662 #train# step 7119, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:37.004348 #train# step 7120, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:38.559206 #train# step 7121, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:40.107561 #train# step 7122, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:41.643908 #train# step 7123, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:43.178559 #train# step 7124, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:44.735600 #train# step 7125, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:46.299324 #train# step 7126, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:47.855434 #train# step 7127, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:49.411702 #train# step 7128, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:50.985234 #train# step 7129, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:52.558617 #train# step 7130, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:54.110410 #train# step 7131, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:55.640944 #train# step 7132, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:57.175956 #train# step 7133, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:17:58.760486 #train# step 7134, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:00.319304 #train# step 7135, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:01.890960 #train# step 7136, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:03.427229 #train# step 7137, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:04.985788 #train# step 7138, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:06.526307 #train# step 7139, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:08.096493 #train# step 7140, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:09.615890 #train# step 7141, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:11.174179 #train# step 7142, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:12.738776 #train# step 7143, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:14.287925 #train# step 7144, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:15.855953 #train# step 7145, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:17.389841 #train# step 7146, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:18.935104 #train# step 7147, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:20.462126 #train# step 7148, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:22.035568 #train# step 7149, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:23.597123 #train# step 7150, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:25.147435 #train# step 7151, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:26.722942 #train# step 7152, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:28.282318 #train# step 7153, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:29.857323 #train# step 7154, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:31.394533 #train# step 7155, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:32.925059 #train# step 7156, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:34.449207 #train# step 7157, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:36.022241 #train# step 7158, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:37.583521 #train# step 7159, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:39.156234 #train# step 7160, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:40.698100 #train# step 7161, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:42.244683 #train# step 7162, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:43.803064 #train# step 7163, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:45.355120 #train# step 7164, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:46.890606 #train# step 7165, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:48.439601 #train# step 7166, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:49.983516 #train# step 7167, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:51.550072 #train# step 7168, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:53.075176 #train# step 7169, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:54.645070 #train# step 7170, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:56.235018 #train# step 7171, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:57.770709 #train# step 7172, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:18:59.322935 #train# step 7173, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:00.875682 #train# step 7174, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:02.418290 #train# step 7175, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:03.956684 #train# step 7176, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:05.512377 #train# step 7177, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:07.080559 #train# step 7178, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:08.639695 #train# step 7179, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:10.196939 #train# step 7180, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:11.739774 #train# step 7181, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:13.278016 #train# step 7182, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:14.836133 #train# step 7183, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:16.406350 #train# step 7184, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:17.966782 #train# step 7185, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:19.506423 #train# step 7186, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:21.086029 #train# step 7187, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:22.617970 #train# step 7188, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:24.201773 #train# step 7189, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:25.727783 #train# step 7190, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:27.283934 #train# step 7191, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:28.851646 #train# step 7192, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:30.448129 #train# step 7193, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:31.981201 #train# step 7194, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:33.522474 #train# step 7195, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:35.080206 #train# step 7196, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:36.657867 #train# step 7197, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:38.221028 #train# step 7198, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:39.769035 #train# step 7199, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:41.324252 #train# step 7200, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:42.875956 #train# step 7201, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:44.461240 #train# step 7202, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:46.003560 #train# step 7203, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:47.557445 #train# step 7204, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:49.120504 #train# step 7205, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:50.652220 #train# step 7206, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:52.201679 #train# step 7207, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:53.743474 #train# step 7208, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:55.298987 #train# step 7209, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:56.846569 #train# step 7210, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:58.362814 #train# step 7211, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:19:59.917585 #train# step 7212, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:01.461711 #train# step 7213, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:03.012131 #train# step 7214, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:04.554757 #train# step 7215, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:06.103016 #train# step 7216, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:07.637795 #train# step 7217, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:09.208563 #train# step 7218, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:10.770381 #train# step 7219, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:12.336019 #train# step 7220, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:13.911808 #train# step 7221, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:15.450443 #train# step 7222, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:17.007230 #train# step 7223, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:18.557711 #train# step 7224, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:20.096722 #train# step 7225, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:21.656326 #train# step 7226, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:23.212404 #train# step 7227, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:24.770498 #train# step 7228, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:26.341761 #train# step 7229, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:27.904233 #train# step 7230, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:29.453143 #train# step 7231, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:31.003605 #train# step 7232, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:32.545216 #train# step 7233, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:34.098786 #train# step 7234, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:35.660444 #train# step 7235, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:37.225053 #train# step 7236, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:38.771737 #train# step 7237, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:40.302862 #train# step 7238, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:41.850460 #train# step 7239, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:43.404537 #train# step 7240, loss = 0.8878, cross_entropy loss = 0.8878, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:44.981456 #train# step 7241, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:46.536187 #train# step 7242, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:48.066534 #train# step 7243, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:49.592078 #train# step 7244, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:51.138679 #train# step 7245, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:52.692165 #train# step 7246, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:54.243254 #train# step 7247, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:55.806943 #train# step 7248, loss = 0.8892, cross_entropy loss = 0.8892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:57.336454 #train# step 7249, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:20:58.901214 #train# step 7250, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:00.448952 #train# step 7251, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:02.020668 #train# step 7252, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:03.615159 #train# step 7253, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:05.152489 #train# step 7254, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:06.725335 #train# step 7255, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:08.252361 #train# step 7256, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:09.815798 #train# step 7257, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:11.372048 #train# step 7258, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:12.959850 #train# step 7259, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:14.514439 #train# step 7260, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:16.069025 #train# step 7261, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:17.597681 #train# step 7262, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:19.166835 #train# step 7263, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:20.734908 #train# step 7264, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:22.293641 #train# step 7265, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:23.833698 #train# step 7266, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:25.384574 #train# step 7267, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:26.930224 #train# step 7268, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:28.465149 #train# step 7269, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:30.012328 #train# step 7270, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:31.520031 #train# step 7271, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:33.078757 #train# step 7272, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:34.600535 #train# step 7273, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:36.162724 #train# step 7274, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:37.740119 #train# step 7275, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:39.272553 #train# step 7276, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:40.840148 #train# step 7277, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:42.381341 #train# step 7278, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:43.932360 #train# step 7279, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:45.484059 #train# step 7280, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:47.056990 #train# step 7281, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:48.624313 #train# step 7282, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:50.177461 #train# step 7283, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:51.724799 #train# step 7284, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:53.301567 #train# step 7285, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:54.836862 #train# step 7286, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:56.404024 #train# step 7287, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:57.941530 #train# step 7288, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:21:59.516953 #train# step 7289, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:01.042154 #train# step 7290, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:02.593426 #train# step 7291, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:04.145882 #train# step 7292, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:05.717857 #train# step 7293, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:07.269797 #train# step 7294, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:08.807227 #train# step 7295, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:10.375193 #train# step 7296, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:11.925153 #train# step 7297, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:13.471012 #train# step 7298, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:15.014826 #train# step 7299, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:16.588307 #train# step 7300, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:18.120978 #train# step 7301, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:19.677847 #train# step 7302, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:21.203913 #train# step 7303, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:22.771854 #train# step 7304, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:24.306203 #train# step 7305, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:25.870550 #train# step 7306, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:27.436359 #train# step 7307, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:28.983039 #train# step 7308, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:30.537768 #train# step 7309, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:32.090617 #train# step 7310, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:33.669217 #train# step 7311, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:35.221128 #train# step 7312, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:36.804068 #train# step 7313, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:38.356392 #train# step 7314, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:39.916228 #train# step 7315, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:41.499306 #train# step 7316, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:43.046101 #train# step 7317, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:44.570534 #train# step 7318, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:46.149966 #train# step 7319, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:47.685548 #train# step 7320, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:49.252140 #train# step 7321, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:50.811514 #train# step 7322, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:52.385685 #train# step 7323, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:53.925235 #train# step 7324, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:55.465433 #train# step 7325, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:57.012107 #train# step 7326, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:22:58.574959 #train# step 7327, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:00.102531 #train# step 7328, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:01.650383 #train# step 7329, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:03.202107 #train# step 7330, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:04.764974 #train# step 7331, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:06.295481 #train# step 7332, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:07.846752 #train# step 7333, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:09.402360 #train# step 7334, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:10.940722 #train# step 7335, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:12.525835 #train# step 7336, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:14.093221 #train# step 7337, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:15.659064 #train# step 7338, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:17.186207 #train# step 7339, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:18.730421 #train# step 7340, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:20.275570 #train# step 7341, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:21.807816 #train# step 7342, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:23.381619 #train# step 7343, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:24.919924 #train# step 7344, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:26.494914 #train# step 7345, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:28.022748 #train# step 7346, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:29.581919 #train# step 7347, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:31.142523 #train# step 7348, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:32.688465 #train# step 7349, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:34.212636 #train# step 7350, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:35.772155 #train# step 7351, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:37.333708 #train# step 7352, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:38.918037 #train# step 7353, loss = 0.8855, cross_entropy loss = 0.8855, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:40.524179 #train# step 7354, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:42.065436 #train# step 7355, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:43.634728 #train# step 7356, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:45.181444 #train# step 7357, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:46.742581 #train# step 7358, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:48.279052 #train# step 7359, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:49.808050 #train# step 7360, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:51.348081 #train# step 7361, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:52.875359 #train# step 7362, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:54.432260 #train# step 7363, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:55.983143 #train# step 7364, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:57.549346 #train# step 7365, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:23:59.128351 #train# step 7366, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:00.663103 #train# step 7367, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:02.205244 #train# step 7368, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:03.739296 #train# step 7369, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:05.296060 #train# step 7370, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:06.861737 #train# step 7371, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:08.442043 #train# step 7372, loss = 0.8899, cross_entropy loss = 0.8899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:09.979058 #train# step 7373, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:11.547861 #train# step 7374, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:13.113366 #train# step 7375, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:14.657204 #train# step 7376, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:16.219526 #train# step 7377, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:17.780384 #train# step 7378, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:19.356894 #train# step 7379, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:20.910303 #train# step 7380, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:22.461596 #train# step 7381, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:23.996622 #train# step 7382, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:25.544205 #train# step 7383, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:27.080066 #train# step 7384, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:28.642558 #train# step 7385, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:30.198784 #train# step 7386, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:31.784417 #train# step 7387, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:33.335674 #train# step 7388, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:34.863219 #train# step 7389, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:36.427479 #train# step 7390, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:38.000894 #train# step 7391, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:39.544435 #train# step 7392, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:41.106137 #train# step 7393, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:42.652042 #train# step 7394, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:44.192572 #train# step 7395, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:45.734763 #train# step 7396, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:47.300103 #train# step 7397, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:48.846185 #train# step 7398, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:50.386336 #train# step 7399, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:51.977877 #train# step 7400, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:53.534160 #train# step 7401, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:55.090357 #train# step 7402, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:56.647734 #train# step 7403, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:58.178393 #train# step 7404, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:24:59.748490 #train# step 7405, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:01.319660 #train# step 7406, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:02.883107 #train# step 7407, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:04.449593 #train# step 7408, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:06.000122 #train# step 7409, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:07.539166 #train# step 7410, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:09.078658 #train# step 7411, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:10.630366 #train# step 7412, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:12.222225 #train# step 7413, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:13.767378 #train# step 7414, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:15.288503 #train# step 7415, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:16.855736 #train# step 7416, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:18.418421 #train# step 7417, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:19.989994 #train# step 7418, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:21.550769 #train# step 7419, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:23.066477 #train# step 7420, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:24.631968 #train# step 7421, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:26.173932 #train# step 7422, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:27.692818 #train# step 7423, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:29.253761 #train# step 7424, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:30.818451 #train# step 7425, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:32.389174 #train# step 7426, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:33.969561 #train# step 7427, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:35.531108 #train# step 7428, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:37.064769 #train# step 7429, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:38.590176 #train# step 7430, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:40.118443 #train# step 7431, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:41.665552 #train# step 7432, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:43.226014 #train# step 7433, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:44.803974 #train# step 7434, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:46.345012 #train# step 7435, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:47.907721 #train# step 7436, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:49.461820 #train# step 7437, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:51.020124 #train# step 7438, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:52.558592 #train# step 7439, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:54.135141 #train# step 7440, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:55.701942 #train# step 7441, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:57.276918 #train# step 7442, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:25:58.829074 #train# step 7443, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:00.367506 #train# step 7444, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:01.909981 #train# step 7445, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:03.468016 #train# step 7446, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:05.013971 #train# step 7447, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:06.561584 #train# step 7448, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:08.133623 #train# step 7449, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:09.694431 #train# step 7450, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:11.246253 #train# step 7451, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:12.793304 #train# step 7452, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:14.347033 #train# step 7453, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:15.889594 #train# step 7454, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:17.430940 #train# step 7455, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:18.993822 #train# step 7456, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:20.561764 #train# step 7457, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:22.084839 #train# step 7458, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:23.653424 #train# step 7459, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:25.204328 #train# step 7460, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:26.776417 #train# step 7461, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:28.333623 #train# step 7462, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:29.886359 #train# step 7463, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:31.439968 #train# step 7464, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:32.990765 #train# step 7465, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:34.519962 #train# step 7466, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:36.051471 #train# step 7467, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:37.623253 #train# step 7468, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:39.221175 #train# step 7469, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:40.792507 #train# step 7470, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:42.342334 #train# step 7471, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:43.891644 #train# step 7472, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:45.427788 #train# step 7473, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:47.017801 #train# step 7474, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:48.546837 #train# step 7475, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:50.085507 #train# step 7476, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:51.606683 #train# step 7477, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:53.144212 #train# step 7478, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:54.711450 #train# step 7479, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:56.286799 #train# step 7480, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:57.871588 #train# step 7481, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:26:59.462140 #train# step 7482, loss = 0.8867, cross_entropy loss = 0.8867, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:01.018157 #train# step 7483, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:02.565266 #train# step 7484, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:04.123140 #train# step 7485, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:05.652229 #train# step 7486, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:07.216181 #train# step 7487, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:08.772349 #train# step 7488, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:10.334388 #train# step 7489, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:11.888322 #train# step 7490, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:13.436396 #train# step 7491, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:15.016554 #train# step 7492, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:16.569570 #train# step 7493, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:18.106838 #train# step 7494, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:19.644721 #train# step 7495, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:21.183201 #train# step 7496, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:22.736484 #train# step 7497, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:24.293039 #train# step 7498, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:25.827312 #train# step 7499, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:27.373784 #train# step 7500, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:28.934403 #train# step 7501, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:30.491111 #train# step 7502, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:32.033473 #train# step 7503, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:33.589164 #train# step 7504, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:35.199310 #train# step 7505, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:36.765787 #train# step 7506, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:38.308793 #train# step 7507, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:39.842399 #train# step 7508, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:41.383889 #train# step 7509, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:42.956123 #train# step 7510, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:44.513718 #train# step 7511, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:46.038933 #train# step 7512, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:47.608801 #train# step 7513, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:49.141254 #train# step 7514, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:50.678865 #train# step 7515, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:52.243959 #train# step 7516, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:53.794078 #train# step 7517, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:55.349457 #train# step 7518, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:56.895085 #train# step 7519, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:58.433023 #train# step 7520, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:27:59.997530 #train# step 7521, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:01.561503 #train# step 7522, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:03.095696 #train# step 7523, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:04.659642 #train# step 7524, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:06.201293 #train# step 7525, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:07.738600 #train# step 7526, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:09.274141 #train# step 7527, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:10.841585 #train# step 7528, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:12.401004 #train# step 7529, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:13.988524 #train# step 7530, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:15.520975 #train# step 7531, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:17.063342 #train# step 7532, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:18.625571 #train# step 7533, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:20.167235 #train# step 7534, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:21.708637 #train# step 7535, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:23.284707 #train# step 7536, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:24.833404 #train# step 7537, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:26.384762 #train# step 7538, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:27.920545 #train# step 7539, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:29.478478 #train# step 7540, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:31.067349 #train# step 7541, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:32.633354 #train# step 7542, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:34.187820 #train# step 7543, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:35.709576 #train# step 7544, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:37.263696 #train# step 7545, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:38.803122 #train# step 7546, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:40.364773 #train# step 7547, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:41.921823 #train# step 7548, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:43.465098 #train# step 7549, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:45.001442 #train# step 7550, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:46.530461 #train# step 7551, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:48.061923 #train# step 7552, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:49.646726 #train# step 7553, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:51.206111 #train# step 7554, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:52.772897 #train# step 7555, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:54.323396 #train# step 7556, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:55.837463 #train# step 7557, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:57.384769 #train# step 7558, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:28:58.923796 #train# step 7559, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:00.486553 #train# step 7560, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:02.051479 #train# step 7561, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:03.619713 #train# step 7562, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:05.203525 #train# step 7563, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:06.748894 #train# step 7564, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:08.309217 #train# step 7565, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:09.881910 #train# step 7566, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:11.442048 #train# step 7567, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:12.980370 #train# step 7568, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:14.546230 #train# step 7569, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:16.107473 #train# step 7570, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:17.651427 #train# step 7571, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:19.237077 #train# step 7572, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:20.803360 #train# step 7573, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:22.321079 #train# step 7574, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:23.858075 #train# step 7575, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:25.398536 #train# step 7576, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:26.981632 #train# step 7577, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:28.524730 #train# step 7578, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:30.104710 #train# step 7579, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:31.644769 #train# step 7580, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:33.181715 #train# step 7581, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:34.780615 #train# step 7582, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:36.344721 #train# step 7583, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:37.908862 #train# step 7584, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:39.445124 #train# step 7585, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:41.018954 #train# step 7586, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:42.553145 #train# step 7587, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:44.124174 #train# step 7588, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:45.675845 #train# step 7589, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:47.212134 #train# step 7590, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:48.812697 #train# step 7591, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:50.380110 #train# step 7592, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:51.893028 #train# step 7593, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:53.434577 #train# step 7594, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:54.989481 #train# step 7595, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:56.559485 #train# step 7596, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:58.137762 #train# step 7597, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:29:59.693319 #train# step 7598, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:01.258382 #train# step 7599, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:02.836611 #train# step 7600, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:04.358688 #train# step 7601, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:05.872890 #train# step 7602, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:07.412920 #train# step 7603, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:08.953810 #train# step 7604, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:10.543307 #train# step 7605, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:12.099498 #train# step 7606, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:13.633865 #train# step 7607, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:15.195046 #train# step 7608, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:16.707975 #train# step 7609, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:18.267259 #train# step 7610, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:19.795803 #train# step 7611, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:21.353131 #train# step 7612, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:22.907587 #train# step 7613, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:24.461482 #train# step 7614, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:26.014872 #train# step 7615, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:27.545571 #train# step 7616, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:29.094117 #train# step 7617, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:30.616258 #train# step 7618, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:32.176625 #train# step 7619, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:33.749650 #train# step 7620, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:35.311114 #train# step 7621, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:36.856461 #train# step 7622, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:38.413937 #train# step 7623, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:40.001629 #train# step 7624, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:41.550868 #train# step 7625, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:43.121088 #train# step 7626, loss = 0.8843, cross_entropy loss = 0.8843, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:44.665253 #train# step 7627, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:46.219381 #train# step 7628, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:47.758670 #train# step 7629, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:49.284190 #train# step 7630, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:50.830896 #train# step 7631, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:52.374997 #train# step 7632, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:53.928703 #train# step 7633, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:55.446240 #train# step 7634, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:57.008843 #train# step 7635, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:30:58.578291 #train# step 7636, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:00.138082 #train# step 7637, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:01.669963 #train# step 7638, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:03.190701 #train# step 7639, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:04.745658 #train# step 7640, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:06.289931 #train# step 7641, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:07.846713 #train# step 7642, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:09.429170 #train# step 7643, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:10.980430 #train# step 7644, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:12.545315 #train# step 7645, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:14.114311 #train# step 7646, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:15.682192 #train# step 7647, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:17.267789 #train# step 7648, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:18.869089 #train# step 7649, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:20.406684 #train# step 7650, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:21.950263 #train# step 7651, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:23.501494 #train# step 7652, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:25.033762 #train# step 7653, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:26.602505 #train# step 7654, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:28.182351 #train# step 7655, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:29.739685 #train# step 7656, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:31.284631 #train# step 7657, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:32.823771 #train# step 7658, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:34.374607 #train# step 7659, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:35.939660 #train# step 7660, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:37.498284 #train# step 7661, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:39.092222 #train# step 7662, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:40.684942 #train# step 7663, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:42.254502 #train# step 7664, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:43.814448 #train# step 7665, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:45.385739 #train# step 7666, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:46.913073 #train# step 7667, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:48.468516 #train# step 7668, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:50.023625 #train# step 7669, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:51.587833 #train# step 7670, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:53.146064 #train# step 7671, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:54.677248 #train# step 7672, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:56.194360 #train# step 7673, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:57.761866 #train# step 7674, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:31:59.319381 #train# step 7675, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:00.884957 #train# step 7676, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:02.443410 #train# step 7677, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:03.989531 #train# step 7678, loss = 0.8893, cross_entropy loss = 0.8893, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:05.525850 #train# step 7679, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:07.060269 #train# step 7680, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:08.588921 #train# step 7681, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:10.138204 #train# step 7682, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:11.684122 #train# step 7683, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:13.248613 #train# step 7684, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:14.787229 #train# step 7685, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:16.328339 #train# step 7686, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:17.881546 #train# step 7687, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:19.445833 #train# step 7688, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:20.985843 #train# step 7689, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:22.550680 #train# step 7690, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:24.115594 #train# step 7691, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:25.664850 #train# step 7692, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:27.223987 #train# step 7693, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:28.761745 #train# step 7694, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:30.354312 #train# step 7695, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:31.924711 #train# step 7696, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:33.474910 #train# step 7697, loss = 0.8872, cross_entropy loss = 0.8872, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:35.012303 #train# step 7698, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:36.576606 #train# step 7699, loss = 0.8883, cross_entropy loss = 0.8883, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:38.115800 #train# step 7700, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:39.684626 #train# step 7701, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:41.233095 #train# step 7702, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:42.776499 #train# step 7703, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:44.328826 #train# step 7704, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:45.869676 #train# step 7705, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:47.422099 #train# step 7706, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:48.959709 #train# step 7707, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:50.523013 #train# step 7708, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:52.067582 #train# step 7709, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:53.602281 #train# step 7710, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:55.198062 #train# step 7711, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:56.755182 #train# step 7712, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:58.271960 #train# step 7713, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:32:59.847791 #train# step 7714, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:01.407976 #train# step 7715, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:02.952051 #train# step 7716, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:04.470496 #train# step 7717, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:06.043148 #train# step 7718, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:07.630611 #train# step 7719, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:09.186606 #train# step 7720, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:10.754016 #train# step 7721, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:12.312357 #train# step 7722, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:13.898681 #train# step 7723, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:15.458420 #train# step 7724, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:17.021168 #train# step 7725, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:18.574257 #train# step 7726, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:20.121459 #train# step 7727, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:21.679615 #train# step 7728, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:23.242962 #train# step 7729, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:24.771693 #train# step 7730, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:26.319310 #train# step 7731, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:27.881917 #train# step 7732, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:29.439177 #train# step 7733, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:30.969941 #train# step 7734, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:32.519206 #train# step 7735, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:34.070305 #train# step 7736, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:35.660010 #train# step 7737, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:37.208908 #train# step 7738, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:38.747757 #train# step 7739, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:40.287138 #train# step 7740, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:41.846935 #train# step 7741, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:43.361151 #train# step 7742, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:44.906303 #train# step 7743, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:46.439674 #train# step 7744, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:48.013954 #train# step 7745, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:49.559140 #train# step 7746, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:51.129432 #train# step 7747, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:52.699598 #train# step 7748, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:54.217695 #train# step 7749, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:55.748415 #train# step 7750, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:57.291464 #train# step 7751, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:33:58.858970 #train# step 7752, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:00.425698 #train# step 7753, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:01.951249 #train# step 7754, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:03.514749 #train# step 7755, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:05.079517 #train# step 7756, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:06.635528 #train# step 7757, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:08.217190 #train# step 7758, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:09.773799 #train# step 7759, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:11.309462 #train# step 7760, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:12.863162 #train# step 7761, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:14.380753 #train# step 7762, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:15.948077 #train# step 7763, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:17.503854 #train# step 7764, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:19.061643 #train# step 7765, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:20.609678 #train# step 7766, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:22.151499 #train# step 7767, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:23.687889 #train# step 7768, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:25.248444 #train# step 7769, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:26.795808 #train# step 7770, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:28.362344 #train# step 7771, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:29.913876 #train# step 7772, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:31.463678 #train# step 7773, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:33.016076 #train# step 7774, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:34.581926 #train# step 7775, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:36.119524 #train# step 7776, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:37.689757 #train# step 7777, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:39.258709 #train# step 7778, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:40.800605 #train# step 7779, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:42.320702 #train# step 7780, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:43.857926 #train# step 7781, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:45.431705 #train# step 7782, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:46.985231 #train# step 7783, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:48.570590 #train# step 7784, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:50.146303 #train# step 7785, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:51.699224 #train# step 7786, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:53.267536 #train# step 7787, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:54.835459 #train# step 7788, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:56.386885 #train# step 7789, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:57.944908 #train# step 7790, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:34:59.470786 #train# step 7791, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:01.027399 #train# step 7792, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:02.597906 #train# step 7793, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:04.173092 #train# step 7794, loss = 0.8877, cross_entropy loss = 0.8877, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:05.741450 #train# step 7795, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:07.255376 #train# step 7796, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:08.828855 #train# step 7797, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:10.380909 #train# step 7798, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:11.941095 #train# step 7799, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:13.508109 #train# step 7800, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:15.045849 #train# step 7801, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:16.569046 #train# step 7802, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:18.141774 #train# step 7803, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:19.665436 #train# step 7804, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:21.242078 #train# step 7805, loss = 0.8868, cross_entropy loss = 0.8868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:22.792910 #train# step 7806, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:24.319699 #train# step 7807, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:25.857505 #train# step 7808, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:27.414477 #train# step 7809, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:28.991540 #train# step 7810, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:30.551652 #train# step 7811, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:32.112718 #train# step 7812, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:33.663205 #train# step 7813, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:35.222618 #train# step 7814, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:36.757421 #train# step 7815, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:38.268628 #train# step 7816, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:39.822615 #train# step 7817, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:41.367174 #train# step 7818, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:42.906839 #train# step 7819, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:44.487495 #train# step 7820, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:46.035168 #train# step 7821, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:47.585765 #train# step 7822, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:49.149175 #train# step 7823, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:50.719040 #train# step 7824, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:52.299866 #train# step 7825, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:53.818579 #train# step 7826, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:55.355764 #train# step 7827, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:56.924250 #train# step 7828, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:35:58.481493 #train# step 7829, loss = 0.8845, cross_entropy loss = 0.8845, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:00.016597 #train# step 7830, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:01.589099 #train# step 7831, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:03.140290 #train# step 7832, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:04.700568 #train# step 7833, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:06.259027 #train# step 7834, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:07.825036 #train# step 7835, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:09.422390 #train# step 7836, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:10.978304 #train# step 7837, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:12.510049 #train# step 7838, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:14.072358 #train# step 7839, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:15.604445 #train# step 7840, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:17.141420 #train# step 7841, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:18.666433 #train# step 7842, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:20.246439 #train# step 7843, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:21.803453 #train# step 7844, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:23.362558 #train# step 7845, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:24.907544 #train# step 7846, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:26.462455 #train# step 7847, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:27.984264 #train# step 7848, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:29.551469 #train# step 7849, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:31.100274 #train# step 7850, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:32.645586 #train# step 7851, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:34.203103 #train# step 7852, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:35.779653 #train# step 7853, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:37.328667 #train# step 7854, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:38.882090 #train# step 7855, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:40.427187 #train# step 7856, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:41.972042 #train# step 7857, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:43.532159 #train# step 7858, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:45.063860 #train# step 7859, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:46.604601 #train# step 7860, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:48.124733 #train# step 7861, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:49.683767 #train# step 7862, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:51.260816 #train# step 7863, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:52.807292 #train# step 7864, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:54.370602 #train# step 7865, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:55.937507 #train# step 7866, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:57.490061 #train# step 7867, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:36:59.010893 #train# step 7868, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:00.554303 #train# step 7869, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:02.123511 #train# step 7870, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:03.672327 #train# step 7871, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:05.264367 #train# step 7872, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:06.792409 #train# step 7873, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:08.342683 #train# step 7874, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:09.905528 #train# step 7875, loss = 0.8819, cross_entropy loss = 0.8819, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:11.461825 #train# step 7876, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:13.028016 #train# step 7877, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:14.565490 #train# step 7878, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:16.110964 #train# step 7879, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:17.669939 #train# step 7880, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:19.206043 #train# step 7881, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:20.739930 #train# step 7882, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:22.316428 #train# step 7883, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:23.885577 #train# step 7884, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:25.437815 #train# step 7885, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:27.003636 #train# step 7886, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:28.557112 #train# step 7887, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:30.130174 #train# step 7888, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:31.672202 #train# step 7889, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:33.201471 #train# step 7890, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:34.778816 #train# step 7891, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:36.301073 #train# step 7892, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:37.843139 #train# step 7893, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:39.387106 #train# step 7894, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:40.938088 #train# step 7895, loss = 0.8847, cross_entropy loss = 0.8847, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:42.509695 #train# step 7896, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:44.051861 #train# step 7897, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:45.639417 #train# step 7898, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:47.178673 #train# step 7899, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:48.744994 #train# step 7900, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:50.313611 #train# step 7901, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:51.837747 #train# step 7902, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:53.356530 #train# step 7903, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:54.905894 #train# step 7904, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:56.491120 #train# step 7905, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:58.044719 #train# step 7906, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:37:59.610088 #train# step 7907, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:01.133814 #train# step 7908, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:02.674586 #train# step 7909, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:04.248538 #train# step 7910, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:05.792462 #train# step 7911, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:07.330140 #train# step 7912, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:08.880333 #train# step 7913, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:10.412677 #train# step 7914, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:11.954791 #train# step 7915, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:13.505471 #train# step 7916, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:15.084670 #train# step 7917, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:16.630483 #train# step 7918, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:18.192563 #train# step 7919, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:19.751786 #train# step 7920, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:21.314643 #train# step 7921, loss = 0.8866, cross_entropy loss = 0.8866, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:22.872031 #train# step 7922, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:24.431775 #train# step 7923, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:25.961799 #train# step 7924, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:27.522032 #train# step 7925, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:29.067595 #train# step 7926, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:30.622093 #train# step 7927, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:32.172966 #train# step 7928, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:33.742802 #train# step 7929, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:35.314674 #train# step 7930, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:36.882554 #train# step 7931, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:38.414867 #train# step 7932, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:39.981444 #train# step 7933, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:41.566072 #train# step 7934, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:43.125582 #train# step 7935, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:44.709922 #train# step 7936, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:46.266228 #train# step 7937, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:47.826751 #train# step 7938, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:49.352593 #train# step 7939, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:50.875119 #train# step 7940, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:52.415214 #train# step 7941, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:53.968643 #train# step 7942, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:55.526818 #train# step 7943, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:57.098690 #train# step 7944, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:38:58.658406 #train# step 7945, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:00.208845 #train# step 7946, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:01.747243 #train# step 7947, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:03.308836 #train# step 7948, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:04.888918 #train# step 7949, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:06.442203 #train# step 7950, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:07.967025 #train# step 7951, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:09.548491 #train# step 7952, loss = 0.8870, cross_entropy loss = 0.8870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:11.074570 #train# step 7953, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:12.611721 #train# step 7954, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:14.145817 #train# step 7955, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:15.696246 #train# step 7956, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:17.241838 #train# step 7957, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:18.761039 #train# step 7958, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:20.333389 #train# step 7959, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:21.914747 #train# step 7960, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:23.483433 #train# step 7961, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:25.054302 #train# step 7962, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:26.601450 #train# step 7963, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:28.172680 #train# step 7964, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:29.682346 #train# step 7965, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:31.211509 #train# step 7966, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:32.829809 #train# step 7967, loss = 0.8888, cross_entropy loss = 0.8888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:34.379529 #train# step 7968, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:35.948472 #train# step 7969, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:37.481126 #train# step 7970, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:38.999424 #train# step 7971, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:40.537861 #train# step 7972, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:42.049104 #train# step 7973, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:43.587207 #train# step 7974, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:45.121289 #train# step 7975, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:46.683065 #train# step 7976, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:48.285516 #train# step 7977, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:49.849700 #train# step 7978, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:51.403286 #train# step 7979, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:52.952778 #train# step 7980, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:54.509569 #train# step 7981, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:56.053360 #train# step 7982, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:57.619674 #train# step 7983, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:39:59.193205 #train# step 7984, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:00.730213 #train# step 7985, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:02.296082 #train# step 7986, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:03.844518 #train# step 7987, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:05.365346 #train# step 7988, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:06.909631 #train# step 7989, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:08.524535 #train# step 7990, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:10.109403 #train# step 7991, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:11.644886 #train# step 7992, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:13.186908 #train# step 7993, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:14.695026 #train# step 7994, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:16.247223 #train# step 7995, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:17.793625 #train# step 7996, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:19.337233 #train# step 7997, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:20.899427 #train# step 7998, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:22.426119 #train# step 7999, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:23.992864 #train# step 8000, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:25.555383 #train# step 8001, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:27.075375 #train# step 8002, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:28.646353 #train# step 8003, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:30.181097 #train# step 8004, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:31.723234 #train# step 8005, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:33.273221 #train# step 8006, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:34.848626 #train# step 8007, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:36.421963 #train# step 8008, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:37.992370 #train# step 8009, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:39.534720 #train# step 8010, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:41.100505 #train# step 8011, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:42.648748 #train# step 8012, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:44.197020 #train# step 8013, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:45.718279 #train# step 8014, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:47.272140 #train# step 8015, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:48.805341 #train# step 8016, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:50.369251 #train# step 8017, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:51.931966 #train# step 8018, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:53.488262 #train# step 8019, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:55.020257 #train# step 8020, loss = 0.8877, cross_entropy loss = 0.8877, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:56.557560 #train# step 8021, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:58.100867 #train# step 8022, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:40:59.647648 #train# step 8023, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:01.223788 #train# step 8024, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:02.807270 #train# step 8025, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:04.387346 #train# step 8026, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:05.949096 #train# step 8027, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:07.507809 #train# step 8028, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:09.052079 #train# step 8029, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:10.594942 #train# step 8030, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:12.139130 #train# step 8031, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:13.674072 #train# step 8032, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:15.236889 #train# step 8033, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:16.809944 #train# step 8034, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:18.387320 #train# step 8035, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:19.946654 #train# step 8036, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:21.522973 #train# step 8037, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:23.063688 #train# step 8038, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:24.617472 #train# step 8039, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:26.156931 #train# step 8040, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:27.702263 #train# step 8041, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:29.269667 #train# step 8042, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:30.848910 #train# step 8043, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:32.406012 #train# step 8044, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:33.951708 #train# step 8045, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:35.529842 #train# step 8046, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:37.075459 #train# step 8047, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:38.631224 #train# step 8048, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:40.166769 #train# step 8049, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:41.724949 #train# step 8050, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:43.315892 #train# step 8051, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:44.855132 #train# step 8052, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:46.415968 #train# step 8053, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:47.951405 #train# step 8054, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:49.499652 #train# step 8055, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:51.054393 #train# step 8056, loss = 0.8882, cross_entropy loss = 0.8882, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:52.571162 #train# step 8057, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:54.117216 #train# step 8058, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:55.648084 #train# step 8059, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:57.203894 #train# step 8060, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:41:58.744075 #train# step 8061, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:00.317743 #train# step 8062, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:01.891421 #train# step 8063, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:03.403394 #train# step 8064, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:04.960291 #train# step 8065, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:06.523764 #train# step 8066, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:08.087754 #train# step 8067, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:09.659180 #train# step 8068, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:11.231580 #train# step 8069, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:12.757179 #train# step 8070, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:14.332998 #train# step 8071, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:15.887800 #train# step 8072, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:17.454420 #train# step 8073, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:19.038269 #train# step 8074, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:20.568690 #train# step 8075, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:22.098264 #train# step 8076, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:23.646076 #train# step 8077, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:25.229183 #train# step 8078, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:26.774983 #train# step 8079, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:28.322708 #train# step 8080, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:29.870278 #train# step 8081, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:31.422377 #train# step 8082, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:32.972258 #train# step 8083, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:34.498855 #train# step 8084, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:36.025757 #train# step 8085, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:37.562614 #train# step 8086, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:39.123244 #train# step 8087, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:40.662230 #train# step 8088, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:42.220939 #train# step 8089, loss = 0.8895, cross_entropy loss = 0.8895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:43.768708 #train# step 8090, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:45.321860 #train# step 8091, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:46.879447 #train# step 8092, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:48.425030 #train# step 8093, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:49.991370 #train# step 8094, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:51.550032 #train# step 8095, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:53.115515 #train# step 8096, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:54.713727 #train# step 8097, loss = 0.8897, cross_entropy loss = 0.8897, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:56.286114 #train# step 8098, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:57.832112 #train# step 8099, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:42:59.375366 #train# step 8100, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:00.917367 #train# step 8101, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:02.483549 #train# step 8102, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:04.017270 #train# step 8103, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:05.562438 #train# step 8104, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:07.120892 #train# step 8105, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:08.655390 #train# step 8106, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:10.190858 #train# step 8107, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:11.778084 #train# step 8108, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:13.348544 #train# step 8109, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:14.930954 #train# step 8110, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:16.481823 #train# step 8111, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:18.058477 #train# step 8112, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:19.621258 #train# step 8113, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:21.172037 #train# step 8114, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:22.727144 #train# step 8115, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:24.254402 #train# step 8116, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:25.805072 #train# step 8117, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:27.367125 #train# step 8118, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:28.921548 #train# step 8119, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:30.454116 #train# step 8120, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:32.011269 #train# step 8121, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:33.559918 #train# step 8122, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:35.130138 #train# step 8123, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:36.682404 #train# step 8124, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:38.222664 #train# step 8125, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:39.813037 #train# step 8126, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:41.340448 #train# step 8127, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:42.858892 #train# step 8128, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:44.415444 #train# step 8129, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:45.977555 #train# step 8130, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:47.523067 #train# step 8131, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:49.076695 #train# step 8132, loss = 0.8826, cross_entropy loss = 0.8826, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:50.674975 #train# step 8133, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:52.206954 #train# step 8134, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:53.735733 #train# step 8135, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:55.290990 #train# step 8136, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:56.868435 #train# step 8137, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:58.463053 #train# step 8138, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:43:59.991421 #train# step 8139, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:01.546321 #train# step 8140, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:03.069879 #train# step 8141, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:04.615776 #train# step 8142, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:06.143722 #train# step 8143, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:07.687461 #train# step 8144, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:09.240423 #train# step 8145, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:10.791757 #train# step 8146, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:12.358812 #train# step 8147, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:13.938715 #train# step 8148, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:15.490195 #train# step 8149, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:17.042119 #train# step 8150, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:18.580827 #train# step 8151, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:20.130593 #train# step 8152, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:21.662948 #train# step 8153, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:23.216948 #train# step 8154, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:24.780940 #train# step 8155, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:26.379724 #train# step 8156, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:27.920029 #train# step 8157, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:29.479950 #train# step 8158, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:31.061802 #train# step 8159, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:32.609200 #train# step 8160, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:34.160652 #train# step 8161, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:35.738759 #train# step 8162, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:37.280100 #train# step 8163, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:38.856666 #train# step 8164, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:40.400156 #train# step 8165, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:41.988311 #train# step 8166, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:43.530112 #train# step 8167, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:45.072288 #train# step 8168, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:46.623673 #train# step 8169, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:48.194923 #train# step 8170, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:49.730510 #train# step 8171, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:51.290768 #train# step 8172, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:52.827000 #train# step 8173, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:54.396125 #train# step 8174, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:55.906651 #train# step 8175, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:57.463612 #train# step 8176, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:44:59.002215 #train# step 8177, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:00.555474 #train# step 8178, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:02.120843 #train# step 8179, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:03.688279 #train# step 8180, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:05.244132 #train# step 8181, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:06.807278 #train# step 8182, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:08.379753 #train# step 8183, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:09.903164 #train# step 8184, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:11.449714 #train# step 8185, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:12.966468 #train# step 8186, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:14.506150 #train# step 8187, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:16.044260 #train# step 8188, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:17.621494 #train# step 8189, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:19.178928 #train# step 8190, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:20.755933 #train# step 8191, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:22.299522 #train# step 8192, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:23.831694 #train# step 8193, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:25.368683 #train# step 8194, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:26.955201 #train# step 8195, loss = 0.8865, cross_entropy loss = 0.8865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:28.491728 #train# step 8196, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:30.038763 #train# step 8197, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:31.626110 #train# step 8198, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:33.192312 #train# step 8199, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:34.734962 #train# step 8200, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:36.298047 #train# step 8201, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:37.844478 #train# step 8202, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:39.416558 #train# step 8203, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:40.994506 #train# step 8204, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:42.538971 #train# step 8205, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:44.083609 #train# step 8206, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:45.634147 #train# step 8207, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:47.196894 #train# step 8208, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:48.748799 #train# step 8209, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:50.309419 #train# step 8210, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:51.861672 #train# step 8211, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:53.416562 #train# step 8212, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:54.970157 #train# step 8213, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:56.544841 #train# step 8214, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:58.122134 #train# step 8215, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:45:59.668242 #train# step 8216, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:01.203518 #train# step 8217, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:02.746962 #train# step 8218, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:04.267096 #train# step 8219, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:05.798029 #train# step 8220, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:07.354276 #train# step 8221, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:08.917764 #train# step 8222, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:10.466258 #train# step 8223, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:12.037595 #train# step 8224, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:13.598734 #train# step 8225, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:15.166862 #train# step 8226, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:16.718807 #train# step 8227, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:18.273745 #train# step 8228, loss = 0.8893, cross_entropy loss = 0.8893, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:19.828748 #train# step 8229, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:21.392151 #train# step 8230, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:22.967236 #train# step 8231, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:24.520847 #train# step 8232, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:26.064459 #train# step 8233, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:27.613484 #train# step 8234, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:29.159253 #train# step 8235, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:30.711232 #train# step 8236, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:32.279814 #train# step 8237, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:33.813373 #train# step 8238, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:35.341724 #train# step 8239, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:36.858185 #train# step 8240, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:38.415249 #train# step 8241, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:39.968556 #train# step 8242, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:41.512066 #train# step 8243, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:43.075402 #train# step 8244, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:44.663211 #train# step 8245, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:46.228498 #train# step 8246, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:47.769036 #train# step 8247, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:49.323754 #train# step 8248, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:50.873392 #train# step 8249, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:52.424886 #train# step 8250, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:53.991086 #train# step 8251, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:55.534436 #train# step 8252, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:57.042503 #train# step 8253, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:46:58.587644 #train# step 8254, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:00.142688 #train# step 8255, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:01.712255 #train# step 8256, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:03.303228 #train# step 8257, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:04.839529 #train# step 8258, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:06.377710 #train# step 8259, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:07.912413 #train# step 8260, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:09.485942 #train# step 8261, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:11.029377 #train# step 8262, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:12.612263 #train# step 8263, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:14.175847 #train# step 8264, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:15.726623 #train# step 8265, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:17.305468 #train# step 8266, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:18.877635 #train# step 8267, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:20.404088 #train# step 8268, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:21.943864 #train# step 8269, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:23.513637 #train# step 8270, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:25.068216 #train# step 8271, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:26.623726 #train# step 8272, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:28.184667 #train# step 8273, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:29.740626 #train# step 8274, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:31.281642 #train# step 8275, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:32.830462 #train# step 8276, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:34.365346 #train# step 8277, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:35.921841 #train# step 8278, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:37.495696 #train# step 8279, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:39.064407 #train# step 8280, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:40.620198 #train# step 8281, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:42.181430 #train# step 8282, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:43.742888 #train# step 8283, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:45.325473 #train# step 8284, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:46.886615 #train# step 8285, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:48.437411 #train# step 8286, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:49.971608 #train# step 8287, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:51.533974 #train# step 8288, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:53.061614 #train# step 8289, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:54.610441 #train# step 8290, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:56.132430 #train# step 8291, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:57.676701 #train# step 8292, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:47:59.205228 #train# step 8293, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:00.780042 #train# step 8294, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:02.325932 #train# step 8295, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:03.868525 #train# step 8296, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:05.414593 #train# step 8297, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:07.013378 #train# step 8298, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:08.598539 #train# step 8299, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:10.166455 #train# step 8300, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:11.735235 #train# step 8301, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:13.292187 #train# step 8302, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:14.844929 #train# step 8303, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:16.400163 #train# step 8304, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:17.953595 #train# step 8305, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:19.490709 #train# step 8306, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:21.044907 #train# step 8307, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:22.600369 #train# step 8308, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:24.153948 #train# step 8309, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:25.684973 #train# step 8310, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:27.220166 #train# step 8311, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:28.788481 #train# step 8312, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:30.326867 #train# step 8313, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:31.852815 #train# step 8314, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:33.436049 #train# step 8315, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:34.979307 #train# step 8316, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:36.495350 #train# step 8317, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:38.058032 #train# step 8318, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:39.625455 #train# step 8319, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:41.202210 #train# step 8320, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:42.768623 #train# step 8321, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:44.304626 #train# step 8322, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:45.864081 #train# step 8323, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:47.424472 #train# step 8324, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:48.995702 #train# step 8325, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:50.554339 #train# step 8326, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:52.082274 #train# step 8327, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:53.606539 #train# step 8328, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:55.136905 #train# step 8329, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:56.684363 #train# step 8330, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:58.235770 #train# step 8331, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:48:59.793657 #train# step 8332, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:01.333185 #train# step 8333, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:02.895008 #train# step 8334, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:04.479525 #train# step 8335, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:06.007641 #train# step 8336, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:07.588548 #train# step 8337, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:09.139148 #train# step 8338, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:10.692735 #train# step 8339, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:12.264195 #train# step 8340, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:13.820637 #train# step 8341, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:15.357973 #train# step 8342, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:16.914278 #train# step 8343, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:18.437279 #train# step 8344, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:19.972787 #train# step 8345, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:21.514199 #train# step 8346, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:23.064461 #train# step 8347, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:24.641394 #train# step 8348, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:26.191575 #train# step 8349, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:27.765085 #train# step 8350, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:29.339056 #train# step 8351, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:30.908428 #train# step 8352, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:32.483884 #train# step 8353, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:34.028626 #train# step 8354, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:35.585015 #train# step 8355, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:37.143571 #train# step 8356, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:38.700028 #train# step 8357, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:40.278782 #train# step 8358, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:41.836313 #train# step 8359, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:43.394105 #train# step 8360, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:44.968776 #train# step 8361, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:46.501668 #train# step 8362, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:48.044783 #train# step 8363, loss = 0.8902, cross_entropy loss = 0.8902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:49.596038 #train# step 8364, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:51.142785 #train# step 8365, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:52.675731 #train# step 8366, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:54.234159 #train# step 8367, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:55.775541 #train# step 8368, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:57.346299 #train# step 8369, loss = 0.8847, cross_entropy loss = 0.8847, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:49:58.910190 #train# step 8370, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:00.457181 #train# step 8371, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:02.011103 #train# step 8372, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:03.539955 #train# step 8373, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:05.118973 #train# step 8374, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:06.671999 #train# step 8375, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:08.216344 #train# step 8376, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:09.779649 #train# step 8377, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:11.339059 #train# step 8378, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:12.898629 #train# step 8379, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:14.441921 #train# step 8380, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:16.007896 #train# step 8381, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:17.578306 #train# step 8382, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:19.112854 #train# step 8383, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:20.659548 #train# step 8384, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:22.198338 #train# step 8385, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:23.766000 #train# step 8386, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:25.319852 #train# step 8387, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:26.868267 #train# step 8388, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:28.409818 #train# step 8389, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:29.969521 #train# step 8390, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:31.490760 #train# step 8391, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:33.040194 #train# step 8392, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:34.569677 #train# step 8393, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:36.091690 #train# step 8394, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:37.618272 #train# step 8395, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:39.166872 #train# step 8396, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:40.738263 #train# step 8397, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:42.332153 #train# step 8398, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:43.903151 #train# step 8399, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:45.506957 #train# step 8400, loss = 0.8850, cross_entropy loss = 0.8850, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:47.068925 #train# step 8401, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:48.623644 #train# step 8402, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:50.180224 #train# step 8403, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:51.738278 #train# step 8404, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:53.283610 #train# step 8405, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:54.859133 #train# step 8406, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:56.429868 #train# step 8407, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:57.941422 #train# step 8408, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:50:59.504756 #train# step 8409, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:01.062544 #train# step 8410, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:02.604180 #train# step 8411, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:04.171112 #train# step 8412, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:05.740585 #train# step 8413, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:07.307918 #train# step 8414, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:08.881519 #train# step 8415, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:10.452149 #train# step 8416, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:11.990134 #train# step 8417, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:13.551545 #train# step 8418, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:15.096651 #train# step 8419, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:16.623451 #train# step 8420, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:18.166123 #train# step 8421, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:19.710443 #train# step 8422, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:21.258008 #train# step 8423, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:22.838829 #train# step 8424, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:24.395697 #train# step 8425, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:25.938164 #train# step 8426, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:27.496121 #train# step 8427, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:29.061311 #train# step 8428, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:30.607826 #train# step 8429, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:32.174625 #train# step 8430, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:33.734623 #train# step 8431, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:35.297231 #train# step 8432, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:36.843280 #train# step 8433, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:38.382701 #train# step 8434, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:39.920511 #train# step 8435, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:41.474387 #train# step 8436, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:43.062020 #train# step 8437, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:44.597756 #train# step 8438, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:46.131848 #train# step 8439, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:47.706102 #train# step 8440, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:49.261760 #train# step 8441, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:50.827549 #train# step 8442, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:52.384653 #train# step 8443, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:53.900657 #train# step 8444, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:55.429206 #train# step 8445, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:57.011395 #train# step 8446, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:51:58.573560 #train# step 8447, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:00.100943 #train# step 8448, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:01.656035 #train# step 8449, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:03.178088 #train# step 8450, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:04.758087 #train# step 8451, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:06.316526 #train# step 8452, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:07.888145 #train# step 8453, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:09.453938 #train# step 8454, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:11.007157 #train# step 8455, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:12.587511 #train# step 8456, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:14.130915 #train# step 8457, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:15.654763 #train# step 8458, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:17.215718 #train# step 8459, loss = 0.8897, cross_entropy loss = 0.8897, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:18.788547 #train# step 8460, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:20.323697 #train# step 8461, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:21.912802 #train# step 8462, loss = 0.8899, cross_entropy loss = 0.8899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:23.482296 #train# step 8463, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:25.029489 #train# step 8464, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:26.581997 #train# step 8465, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:28.148295 #train# step 8466, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:29.729973 #train# step 8467, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:31.274122 #train# step 8468, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:32.854308 #train# step 8469, loss = 0.8849, cross_entropy loss = 0.8849, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:34.393435 #train# step 8470, loss = 0.8888, cross_entropy loss = 0.8888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:35.952274 #train# step 8471, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:37.491331 #train# step 8472, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:39.055354 #train# step 8473, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:40.638408 #train# step 8474, loss = 0.8897, cross_entropy loss = 0.8897, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:42.195235 #train# step 8475, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:43.756593 #train# step 8476, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:45.306685 #train# step 8477, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:46.872945 #train# step 8478, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:48.390769 #train# step 8479, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:49.960176 #train# step 8480, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:51.492603 #train# step 8481, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:53.026910 #train# step 8482, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:54.567735 #train# step 8483, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:56.126078 #train# step 8484, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:57.669579 #train# step 8485, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:52:59.247288 #train# step 8486, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:00.831979 #train# step 8487, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:02.396319 #train# step 8488, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:03.947361 #train# step 8489, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:05.495607 #train# step 8490, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:07.024378 #train# step 8491, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:08.592583 #train# step 8492, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:10.144045 #train# step 8493, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:11.669387 #train# step 8494, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:13.189458 #train# step 8495, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:14.733503 #train# step 8496, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:16.291294 #train# step 8497, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:17.842698 #train# step 8498, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:19.403307 #train# step 8499, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:20.924243 #train# step 8500, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:22.482319 #train# step 8501, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:24.044239 #train# step 8502, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:25.616397 #train# step 8503, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:27.168227 #train# step 8504, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:28.748253 #train# step 8505, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:30.282737 #train# step 8506, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:31.816767 #train# step 8507, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:33.375086 #train# step 8508, loss = 0.8871, cross_entropy loss = 0.8871, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:34.889834 #train# step 8509, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:36.419137 #train# step 8510, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:38.026723 #train# step 8511, loss = 0.8853, cross_entropy loss = 0.8853, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:39.563235 #train# step 8512, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:41.108833 #train# step 8513, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:42.621963 #train# step 8514, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:44.208395 #train# step 8515, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:45.764595 #train# step 8516, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:47.337598 #train# step 8517, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:48.883071 #train# step 8518, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:50.413205 #train# step 8519, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:51.957307 #train# step 8520, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:53.513364 #train# step 8521, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:55.059645 #train# step 8522, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:56.592156 #train# step 8523, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:58.135006 #train# step 8524, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:53:59.671903 #train# step 8525, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:01.231547 #train# step 8526, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:02.808038 #train# step 8527, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:04.349618 #train# step 8528, loss = 0.8884, cross_entropy loss = 0.8884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:05.868515 #train# step 8529, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:07.448041 #train# step 8530, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:09.010454 #train# step 8531, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:10.611006 #train# step 8532, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:12.171328 #train# step 8533, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:13.722066 #train# step 8534, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:15.304703 #train# step 8535, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:16.889704 #train# step 8536, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:18.433377 #train# step 8537, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:19.985972 #train# step 8538, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:21.560878 #train# step 8539, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:23.108466 #train# step 8540, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:24.664622 #train# step 8541, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:26.189295 #train# step 8542, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:27.739869 #train# step 8543, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:29.282064 #train# step 8544, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:30.846507 #train# step 8545, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:32.388232 #train# step 8546, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:33.937950 #train# step 8547, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:35.479026 #train# step 8548, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:37.033373 #train# step 8549, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:38.624442 #train# step 8550, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:40.161384 #train# step 8551, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:41.700049 #train# step 8552, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:43.271326 #train# step 8553, loss = 0.8892, cross_entropy loss = 0.8892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:44.833098 #train# step 8554, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:46.377231 #train# step 8555, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:47.909563 #train# step 8556, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:49.485174 #train# step 8557, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:51.053152 #train# step 8558, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:52.607111 #train# step 8559, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:54.159126 #train# step 8560, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:55.728252 #train# step 8561, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:57.276212 #train# step 8562, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:54:58.836666 #train# step 8563, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:00.379434 #train# step 8564, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:01.926697 #train# step 8565, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:03.483768 #train# step 8566, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:05.050278 #train# step 8567, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:06.580637 #train# step 8568, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:08.129364 #train# step 8569, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:09.724877 #train# step 8570, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:11.305967 #train# step 8571, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:12.821057 #train# step 8572, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:14.364015 #train# step 8573, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:15.929151 #train# step 8574, loss = 0.8888, cross_entropy loss = 0.8888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:17.482078 #train# step 8575, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:19.043928 #train# step 8576, loss = 0.8896, cross_entropy loss = 0.8896, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:20.623496 #train# step 8577, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:22.165825 #train# step 8578, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:23.711772 #train# step 8579, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:25.276279 #train# step 8580, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:26.861325 #train# step 8581, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:28.399986 #train# step 8582, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:29.969403 #train# step 8583, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:31.547478 #train# step 8584, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:33.073397 #train# step 8585, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:34.593581 #train# step 8586, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:36.168135 #train# step 8587, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:37.696367 #train# step 8588, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:39.245194 #train# step 8589, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:40.792808 #train# step 8590, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:42.341294 #train# step 8591, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:43.889440 #train# step 8592, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:45.421610 #train# step 8593, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:46.975802 #train# step 8594, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:48.542987 #train# step 8595, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:50.091447 #train# step 8596, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:51.638922 #train# step 8597, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:53.193258 #train# step 8598, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:54.765312 #train# step 8599, loss = 0.8887, cross_entropy loss = 0.8887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:56.296227 #train# step 8600, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:57.867161 #train# step 8601, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:55:59.416766 #train# step 8602, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:00.970783 #train# step 8603, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:02.503122 #train# step 8604, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:04.058220 #train# step 8605, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:05.582260 #train# step 8606, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:07.125822 #train# step 8607, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:08.711818 #train# step 8608, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:10.298070 #train# step 8609, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:11.853462 #train# step 8610, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:13.402204 #train# step 8611, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:14.969138 #train# step 8612, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:16.517726 #train# step 8613, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:18.055218 #train# step 8614, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:19.601540 #train# step 8615, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:21.153226 #train# step 8616, loss = 0.8845, cross_entropy loss = 0.8845, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:22.722800 #train# step 8617, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:24.276811 #train# step 8618, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:25.829293 #train# step 8619, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:27.388188 #train# step 8620, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:28.960131 #train# step 8621, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:30.543952 #train# step 8622, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:32.132142 #train# step 8623, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:33.690749 #train# step 8624, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:35.241306 #train# step 8625, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:36.769164 #train# step 8626, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:38.286835 #train# step 8627, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:39.846968 #train# step 8628, loss = 0.8899, cross_entropy loss = 0.8899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:41.426469 #train# step 8629, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:42.999286 #train# step 8630, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:44.567212 #train# step 8631, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:46.134490 #train# step 8632, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:47.654459 #train# step 8633, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:49.188377 #train# step 8634, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:50.731342 #train# step 8635, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:52.283643 #train# step 8636, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:53.854203 #train# step 8637, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:55.400117 #train# step 8638, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:56.993576 #train# step 8639, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:56:58.547108 #train# step 8640, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:00.095128 #train# step 8641, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:01.656876 #train# step 8642, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:03.216784 #train# step 8643, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:04.744800 #train# step 8644, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:06.307448 #train# step 8645, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:07.843257 #train# step 8646, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:09.368172 #train# step 8647, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:10.936368 #train# step 8648, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:12.485716 #train# step 8649, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:14.033015 #train# step 8650, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:15.582356 #train# step 8651, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:17.115352 #train# step 8652, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:18.664683 #train# step 8653, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:20.219963 #train# step 8654, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:21.740217 #train# step 8655, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:23.282918 #train# step 8656, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:24.833229 #train# step 8657, loss = 0.8834, cross_entropy loss = 0.8834, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:26.342712 #train# step 8658, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:27.954888 #train# step 8659, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:29.486339 #train# step 8660, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:31.006632 #train# step 8661, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:32.582823 #train# step 8662, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:34.148575 #train# step 8663, loss = 0.8887, cross_entropy loss = 0.8887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:35.670553 #train# step 8664, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:37.261230 #train# step 8665, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:38.847585 #train# step 8666, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:40.407220 #train# step 8667, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:41.959609 #train# step 8668, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:43.496828 #train# step 8669, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:45.094607 #train# step 8670, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:46.641403 #train# step 8671, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:48.173842 #train# step 8672, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:49.740699 #train# step 8673, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:51.277381 #train# step 8674, loss = 0.8890, cross_entropy loss = 0.8890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:52.842684 #train# step 8675, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:54.434155 #train# step 8676, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:56.020869 #train# step 8677, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:57.587649 #train# step 8678, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:57:59.126681 #train# step 8679, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:00.647069 #train# step 8680, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:02.220210 #train# step 8681, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:03.763848 #train# step 8682, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:05.324542 #train# step 8683, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:06.875241 #train# step 8684, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:08.418062 #train# step 8685, loss = 0.8851, cross_entropy loss = 0.8851, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:09.961409 #train# step 8686, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:11.508974 #train# step 8687, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:13.066958 #train# step 8688, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:14.665684 #train# step 8689, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:16.211212 #train# step 8690, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:17.767482 #train# step 8691, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:19.338144 #train# step 8692, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:20.882897 #train# step 8693, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:22.450367 #train# step 8694, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:23.968291 #train# step 8695, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:25.511736 #train# step 8696, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:27.072896 #train# step 8697, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:28.623544 #train# step 8698, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:30.161220 #train# step 8699, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:31.745690 #train# step 8700, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:33.292355 #train# step 8701, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:34.862935 #train# step 8702, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:36.427260 #train# step 8703, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:37.980430 #train# step 8704, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:39.503908 #train# step 8705, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:41.066449 #train# step 8706, loss = 0.8865, cross_entropy loss = 0.8865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:42.627246 #train# step 8707, loss = 0.8871, cross_entropy loss = 0.8871, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:44.194369 #train# step 8708, loss = 0.8890, cross_entropy loss = 0.8890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:45.732501 #train# step 8709, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:47.272389 #train# step 8710, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:48.814152 #train# step 8711, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:50.348576 #train# step 8712, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:51.925087 #train# step 8713, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:53.505297 #train# step 8714, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:55.088088 #train# step 8715, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:56.651352 #train# step 8716, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:58.200097 #train# step 8717, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:58:59.755899 #train# step 8718, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:01.310800 #train# step 8719, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:02.882671 #train# step 8720, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:04.438996 #train# step 8721, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:05.969082 #train# step 8722, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:07.502063 #train# step 8723, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:09.054964 #train# step 8724, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:10.599835 #train# step 8725, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:12.147353 #train# step 8726, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:13.724574 #train# step 8727, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:15.297851 #train# step 8728, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:16.851571 #train# step 8729, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:18.416676 #train# step 8730, loss = 0.8847, cross_entropy loss = 0.8847, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:19.977882 #train# step 8731, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:21.521926 #train# step 8732, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:23.083206 #train# step 8733, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:24.637342 #train# step 8734, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:26.191561 #train# step 8735, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:27.740571 #train# step 8736, loss = 0.8872, cross_entropy loss = 0.8872, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:29.284521 #train# step 8737, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:30.865240 #train# step 8738, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:32.400162 #train# step 8739, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:33.962381 #train# step 8740, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:35.510463 #train# step 8741, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:37.030651 #train# step 8742, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:38.603350 #train# step 8743, loss = 0.8879, cross_entropy loss = 0.8879, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:40.108410 #train# step 8744, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:41.675331 #train# step 8745, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:43.272093 #train# step 8746, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:44.867862 #train# step 8747, loss = 0.8845, cross_entropy loss = 0.8845, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:46.422232 #train# step 8748, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:47.986716 #train# step 8749, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:49.500858 #train# step 8750, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:51.069320 #train# step 8751, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:52.601362 #train# step 8752, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:54.155708 #train# step 8753, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:55.671613 #train# step 8754, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:57.242638 #train# step 8755, loss = 0.8873, cross_entropy loss = 0.8873, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 04:59:58.820322 #train# step 8756, loss = 0.8876, cross_entropy loss = 0.8876, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:00.393636 #train# step 8757, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:01.942545 #train# step 8758, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:03.464742 #train# step 8759, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:04.999560 #train# step 8760, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:06.600812 #train# step 8761, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:08.140258 #train# step 8762, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:09.675299 #train# step 8763, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:11.245245 #train# step 8764, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:12.811400 #train# step 8765, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:14.356846 #train# step 8766, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:15.934106 #train# step 8767, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:17.492371 #train# step 8768, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:19.068485 #train# step 8769, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:20.649334 #train# step 8770, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:22.181036 #train# step 8771, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:23.737931 #train# step 8772, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:25.282802 #train# step 8773, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:26.799372 #train# step 8774, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:28.345359 #train# step 8775, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:29.898605 #train# step 8776, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:31.442047 #train# step 8777, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:32.993388 #train# step 8778, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:34.556808 #train# step 8779, loss = 0.8866, cross_entropy loss = 0.8866, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:36.101052 #train# step 8780, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:37.638387 #train# step 8781, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:39.181907 #train# step 8782, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:40.737009 #train# step 8783, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:42.311352 #train# step 8784, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:43.864778 #train# step 8785, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:45.390714 #train# step 8786, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:46.941116 #train# step 8787, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:48.510613 #train# step 8788, loss = 0.8887, cross_entropy loss = 0.8887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:50.057194 #train# step 8789, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:51.625613 #train# step 8790, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:53.164170 #train# step 8791, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:54.729202 #train# step 8792, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:56.291040 #train# step 8793, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:57.871411 #train# step 8794, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:00:59.421601 #train# step 8795, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:01.007784 #train# step 8796, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:02.590917 #train# step 8797, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:04.123977 #train# step 8798, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:05.670724 #train# step 8799, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:07.250664 #train# step 8800, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:08.809165 #train# step 8801, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:10.363091 #train# step 8802, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:11.919046 #train# step 8803, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:13.480866 #train# step 8804, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:15.021779 #train# step 8805, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:16.569795 #train# step 8806, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:18.124522 #train# step 8807, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:19.648983 #train# step 8808, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:21.200646 #train# step 8809, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:22.735932 #train# step 8810, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:24.289394 #train# step 8811, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:25.832586 #train# step 8812, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:27.362088 #train# step 8813, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:28.911050 #train# step 8814, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:30.478736 #train# step 8815, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:32.037146 #train# step 8816, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:33.567996 #train# step 8817, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:35.115498 #train# step 8818, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:36.660153 #train# step 8819, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:38.215949 #train# step 8820, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:39.747854 #train# step 8821, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:41.320756 #train# step 8822, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:42.904022 #train# step 8823, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:44.460275 #train# step 8824, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:46.044735 #train# step 8825, loss = 0.8876, cross_entropy loss = 0.8876, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:47.603264 #train# step 8826, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:49.147894 #train# step 8827, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:50.715650 #train# step 8828, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:52.261618 #train# step 8829, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:53.838177 #train# step 8830, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:55.372262 #train# step 8831, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:56.918008 #train# step 8832, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:01:58.477354 #train# step 8833, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:00.003678 #train# step 8834, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:01.550079 #train# step 8835, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:03.100425 #train# step 8836, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:04.659620 #train# step 8837, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:06.240906 #train# step 8838, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:07.796223 #train# step 8839, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:09.332142 #train# step 8840, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:10.882027 #train# step 8841, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:12.440203 #train# step 8842, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:13.989527 #train# step 8843, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:15.561080 #train# step 8844, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:17.113591 #train# step 8845, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:18.656756 #train# step 8846, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:20.215843 #train# step 8847, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:21.739775 #train# step 8848, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:23.273568 #train# step 8849, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:24.837424 #train# step 8850, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:26.395280 #train# step 8851, loss = 0.8772, cross_entropy loss = 0.8772, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:27.946707 #train# step 8852, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:29.503059 #train# step 8853, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:31.039089 #train# step 8854, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:32.599178 #train# step 8855, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:34.157726 #train# step 8856, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:35.678568 #train# step 8857, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:37.230762 #train# step 8858, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:38.758726 #train# step 8859, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:40.314219 #train# step 8860, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:41.851416 #train# step 8861, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:43.436808 #train# step 8862, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:44.996839 #train# step 8863, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:46.563387 #train# step 8864, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:48.114745 #train# step 8865, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:49.662468 #train# step 8866, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:51.228469 #train# step 8867, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:52.808632 #train# step 8868, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:54.372378 #train# step 8869, loss = 0.8897, cross_entropy loss = 0.8897, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:55.938591 #train# step 8870, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:57.491820 #train# step 8871, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:02:59.048068 #train# step 8872, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:00.577565 #train# step 8873, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:02.149469 #train# step 8874, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:03.705566 #train# step 8875, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:05.261544 #train# step 8876, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:06.830076 #train# step 8877, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:08.384790 #train# step 8878, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:09.956071 #train# step 8879, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:11.512098 #train# step 8880, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:13.054085 #train# step 8881, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:14.605164 #train# step 8882, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:16.168144 #train# step 8883, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:17.742609 #train# step 8884, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:19.308685 #train# step 8885, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:20.882750 #train# step 8886, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:22.430207 #train# step 8887, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:24.003332 #train# step 8888, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:25.570191 #train# step 8889, loss = 0.8844, cross_entropy loss = 0.8844, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:27.128228 #train# step 8890, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:28.681384 #train# step 8891, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:30.238309 #train# step 8892, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:31.775492 #train# step 8893, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:33.372165 #train# step 8894, loss = 0.8833, cross_entropy loss = 0.8833, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:34.962041 #train# step 8895, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:36.521620 #train# step 8896, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:38.070373 #train# step 8897, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:39.643327 #train# step 8898, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:41.182426 #train# step 8899, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:42.718563 #train# step 8900, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:44.244588 #train# step 8901, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:45.783320 #train# step 8902, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:47.377357 #train# step 8903, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:48.931252 #train# step 8904, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:50.463395 #train# step 8905, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:52.018207 #train# step 8906, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:53.570595 #train# step 8907, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:55.121877 #train# step 8908, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:56.658536 #train# step 8909, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:58.222206 #train# step 8910, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:03:59.764565 #train# step 8911, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:01.337932 #train# step 8912, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:02.877412 #train# step 8913, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:04.408853 #train# step 8914, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:05.932175 #train# step 8915, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:07.466654 #train# step 8916, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:09.048544 #train# step 8917, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:10.601185 #train# step 8918, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:12.151657 #train# step 8919, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:13.707066 #train# step 8920, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:15.268494 #train# step 8921, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:16.800376 #train# step 8922, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:18.354247 #train# step 8923, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:19.878975 #train# step 8924, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:21.425804 #train# step 8925, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:22.986498 #train# step 8926, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:24.509743 #train# step 8927, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:26.018007 #train# step 8928, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:27.561238 #train# step 8929, loss = 0.8870, cross_entropy loss = 0.8870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:29.163760 #train# step 8930, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:30.712580 #train# step 8931, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:32.290841 #train# step 8932, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:33.858755 #train# step 8933, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:35.402348 #train# step 8934, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:36.960914 #train# step 8935, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:38.504892 #train# step 8936, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:40.068712 #train# step 8937, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:41.620824 #train# step 8938, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:43.147121 #train# step 8939, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:44.713081 #train# step 8940, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:46.253267 #train# step 8941, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:47.802144 #train# step 8942, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:49.393333 #train# step 8943, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:50.942414 #train# step 8944, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:52.511665 #train# step 8945, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:54.051900 #train# step 8946, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:55.614293 #train# step 8947, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:57.175762 #train# step 8948, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:04:58.725228 #train# step 8949, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:00.272685 #train# step 8950, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:01.807649 #train# step 8951, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:03.372953 #train# step 8952, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:04.934415 #train# step 8953, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:06.503517 #train# step 8954, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:08.052741 #train# step 8955, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:09.578196 #train# step 8956, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:11.151826 #train# step 8957, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:12.715556 #train# step 8958, loss = 0.8890, cross_entropy loss = 0.8890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:14.271343 #train# step 8959, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:15.835839 #train# step 8960, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:17.399906 #train# step 8961, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:18.977314 #train# step 8962, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:20.525723 #train# step 8963, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:22.101610 #train# step 8964, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:23.657100 #train# step 8965, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:25.207869 #train# step 8966, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:26.750497 #train# step 8967, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:28.282935 #train# step 8968, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:29.824026 #train# step 8969, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:31.357641 #train# step 8970, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:32.923219 #train# step 8971, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:34.487875 #train# step 8972, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:36.046875 #train# step 8973, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:37.592082 #train# step 8974, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:39.137199 #train# step 8975, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:40.686989 #train# step 8976, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:42.255136 #train# step 8977, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:43.812280 #train# step 8978, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:45.364845 #train# step 8979, loss = 0.8892, cross_entropy loss = 0.8892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:46.937512 #train# step 8980, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:48.466928 #train# step 8981, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:50.027343 #train# step 8982, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:51.587380 #train# step 8983, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:53.141726 #train# step 8984, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:54.695226 #train# step 8985, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:56.231320 #train# step 8986, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:57.775302 #train# step 8987, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:05:59.351385 #train# step 8988, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:00.878606 #train# step 8989, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:02.406206 #train# step 8990, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:03.948985 #train# step 8991, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:05.487457 #train# step 8992, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:07.086028 #train# step 8993, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:08.644710 #train# step 8994, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:10.207709 #train# step 8995, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:11.779564 #train# step 8996, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:13.313006 #train# step 8997, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:14.835270 #train# step 8998, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:16.368340 #train# step 8999, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:17.934538 #train# step 9000, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:19.502704 #train# step 9001, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:21.060053 #train# step 9002, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:22.606541 #train# step 9003, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:24.164559 #train# step 9004, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:25.710350 #train# step 9005, loss = 0.8888, cross_entropy loss = 0.8888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:27.249583 #train# step 9006, loss = 0.8902, cross_entropy loss = 0.8902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:28.815436 #train# step 9007, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:30.370990 #train# step 9008, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:31.905433 #train# step 9009, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:33.491921 #train# step 9010, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:35.060155 #train# step 9011, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:36.654475 #train# step 9012, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:38.235677 #train# step 9013, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:39.792081 #train# step 9014, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:41.347394 #train# step 9015, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:42.887400 #train# step 9016, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:44.427633 #train# step 9017, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:45.998318 #train# step 9018, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:47.577910 #train# step 9019, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:49.104074 #train# step 9020, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:50.661535 #train# step 9021, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:52.242251 #train# step 9022, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:53.789080 #train# step 9023, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:55.332724 #train# step 9024, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:56.922380 #train# step 9025, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:06:58.488903 #train# step 9026, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:00.064072 #train# step 9027, loss = 0.8881, cross_entropy loss = 0.8881, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:01.617404 #train# step 9028, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:03.192371 #train# step 9029, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:04.753049 #train# step 9030, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:06.294236 #train# step 9031, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:07.827889 #train# step 9032, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:09.389386 #train# step 9033, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:10.931585 #train# step 9034, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:12.445208 #train# step 9035, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:13.989114 #train# step 9036, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:15.566504 #train# step 9037, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:17.132306 #train# step 9038, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:18.700836 #train# step 9039, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:20.234821 #train# step 9040, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:21.787044 #train# step 9041, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:23.317539 #train# step 9042, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:24.870562 #train# step 9043, loss = 0.8870, cross_entropy loss = 0.8870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:26.440385 #train# step 9044, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:27.993611 #train# step 9045, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:29.545975 #train# step 9046, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:31.122053 #train# step 9047, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:32.704899 #train# step 9048, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:34.267876 #train# step 9049, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:35.819225 #train# step 9050, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:37.356495 #train# step 9051, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:38.892673 #train# step 9052, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:40.456985 #train# step 9053, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:42.024328 #train# step 9054, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:43.570432 #train# step 9055, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:45.093920 #train# step 9056, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:46.619360 #train# step 9057, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:48.155163 #train# step 9058, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:49.704431 #train# step 9059, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:51.269502 #train# step 9060, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:52.822426 #train# step 9061, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:54.393802 #train# step 9062, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:55.953644 #train# step 9063, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:57.470457 #train# step 9064, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:07:59.041175 #train# step 9065, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:00.630656 #train# step 9066, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:02.188141 #train# step 9067, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:03.713752 #train# step 9068, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:05.283305 #train# step 9069, loss = 0.8794, cross_entropy loss = 0.8794, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:06.826410 #train# step 9070, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:08.375062 #train# step 9071, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:09.941979 #train# step 9072, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:11.523194 #train# step 9073, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:13.082176 #train# step 9074, loss = 0.8904, cross_entropy loss = 0.8904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:14.627829 #train# step 9075, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:16.136694 #train# step 9076, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:17.700357 #train# step 9077, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:19.231616 #train# step 9078, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:20.757471 #train# step 9079, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:22.295020 #train# step 9080, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:23.822017 #train# step 9081, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:25.366425 #train# step 9082, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:26.942986 #train# step 9083, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:28.477936 #train# step 9084, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:30.033755 #train# step 9085, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:31.560935 #train# step 9086, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:33.087624 #train# step 9087, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:34.606545 #train# step 9088, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:36.158149 #train# step 9089, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:37.723409 #train# step 9090, loss = 0.8891, cross_entropy loss = 0.8891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:39.256731 #train# step 9091, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:40.810486 #train# step 9092, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:42.369557 #train# step 9093, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:43.929864 #train# step 9094, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:45.466045 #train# step 9095, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:47.031859 #train# step 9096, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:48.575049 #train# step 9097, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:50.151585 #train# step 9098, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:51.715019 #train# step 9099, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:53.289752 #train# step 9100, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:54.803295 #train# step 9101, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:56.378104 #train# step 9102, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:57.918494 #train# step 9103, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:08:59.463641 #train# step 9104, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:00.995810 #train# step 9105, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:02.559582 #train# step 9106, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:04.149633 #train# step 9107, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:05.691030 #train# step 9108, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:07.270334 #train# step 9109, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:08.863283 #train# step 9110, loss = 0.8852, cross_entropy loss = 0.8852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:10.421112 #train# step 9111, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:11.953876 #train# step 9112, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:13.522533 #train# step 9113, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:15.114348 #train# step 9114, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:16.648570 #train# step 9115, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:18.215747 #train# step 9116, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:19.760638 #train# step 9117, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:21.308589 #train# step 9118, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:22.917400 #train# step 9119, loss = 0.8891, cross_entropy loss = 0.8891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:24.496878 #train# step 9120, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:26.041408 #train# step 9121, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:27.561750 #train# step 9122, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:29.130280 #train# step 9123, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:30.717658 #train# step 9124, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:32.258400 #train# step 9125, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:33.817785 #train# step 9126, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:35.377259 #train# step 9127, loss = 0.8891, cross_entropy loss = 0.8891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:36.932567 #train# step 9128, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:38.489531 #train# step 9129, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:40.028941 #train# step 9130, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:41.595182 #train# step 9131, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:43.156118 #train# step 9132, loss = 0.8882, cross_entropy loss = 0.8882, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:44.735746 #train# step 9133, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:46.276232 #train# step 9134, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:47.800493 #train# step 9135, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:49.346075 #train# step 9136, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:50.885156 #train# step 9137, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:52.440157 #train# step 9138, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:53.985535 #train# step 9139, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:55.546886 #train# step 9140, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:57.087460 #train# step 9141, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:09:58.656246 #train# step 9142, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:00.213531 #train# step 9143, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:01.756002 #train# step 9144, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:03.320856 #train# step 9145, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:04.854680 #train# step 9146, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:06.421635 #train# step 9147, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:07.981592 #train# step 9148, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:09.562410 #train# step 9149, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:11.124494 #train# step 9150, loss = 0.8810, cross_entropy loss = 0.8810, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:12.672225 #train# step 9151, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:14.185464 #train# step 9152, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:15.756864 #train# step 9153, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:17.319381 #train# step 9154, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:18.856701 #train# step 9155, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:20.422878 #train# step 9156, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:21.964229 #train# step 9157, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:23.533111 #train# step 9158, loss = 0.8904, cross_entropy loss = 0.8904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:25.076007 #train# step 9159, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:26.616505 #train# step 9160, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:28.154983 #train# step 9161, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:29.679069 #train# step 9162, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:31.212753 #train# step 9163, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:32.780637 #train# step 9164, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:34.363140 #train# step 9165, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:35.907916 #train# step 9166, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:37.456342 #train# step 9167, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:39.029110 #train# step 9168, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:40.595977 #train# step 9169, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:42.177610 #train# step 9170, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:43.733803 #train# step 9171, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:45.272176 #train# step 9172, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:46.831085 #train# step 9173, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:48.360331 #train# step 9174, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:49.911349 #train# step 9175, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:51.461763 #train# step 9176, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:53.023732 #train# step 9177, loss = 0.8913, cross_entropy loss = 0.8913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:54.548877 #train# step 9178, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:56.057054 #train# step 9179, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:57.608296 #train# step 9180, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:10:59.146018 #train# step 9181, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:00.706857 #train# step 9182, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:02.255372 #train# step 9183, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:03.827141 #train# step 9184, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:05.360791 #train# step 9185, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:06.883584 #train# step 9186, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:08.438033 #train# step 9187, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:10.017000 #train# step 9188, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:11.584857 #train# step 9189, loss = 0.8894, cross_entropy loss = 0.8894, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:13.149083 #train# step 9190, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:14.735025 #train# step 9191, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:16.291122 #train# step 9192, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:17.826485 #train# step 9193, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:19.377618 #train# step 9194, loss = 0.8862, cross_entropy loss = 0.8862, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:20.918974 #train# step 9195, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:22.461578 #train# step 9196, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:24.002205 #train# step 9197, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:25.509571 #train# step 9198, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:27.078944 #train# step 9199, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:28.638928 #train# step 9200, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:30.173833 #train# step 9201, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:31.752828 #train# step 9202, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:33.360215 #train# step 9203, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:34.918520 #train# step 9204, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:36.489107 #train# step 9205, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:38.043887 #train# step 9206, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:39.606396 #train# step 9207, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:41.184535 #train# step 9208, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:42.753895 #train# step 9209, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:44.294610 #train# step 9210, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:45.815606 #train# step 9211, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:47.365458 #train# step 9212, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:48.952987 #train# step 9213, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:50.495691 #train# step 9214, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:52.037783 #train# step 9215, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:53.603953 #train# step 9216, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:55.162796 #train# step 9217, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:56.722406 #train# step 9218, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:58.256361 #train# step 9219, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:11:59.790293 #train# step 9220, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:01.355821 #train# step 9221, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:02.917144 #train# step 9222, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:04.432116 #train# step 9223, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:05.997317 #train# step 9224, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:07.568203 #train# step 9225, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:09.127740 #train# step 9226, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:10.655033 #train# step 9227, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:12.192674 #train# step 9228, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:13.730718 #train# step 9229, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:15.305505 #train# step 9230, loss = 0.8879, cross_entropy loss = 0.8879, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:16.848144 #train# step 9231, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:18.379938 #train# step 9232, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:19.924278 #train# step 9233, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:21.479199 #train# step 9234, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:23.063651 #train# step 9235, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:24.620582 #train# step 9236, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:26.150199 #train# step 9237, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:27.726477 #train# step 9238, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:29.259652 #train# step 9239, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:30.827024 #train# step 9240, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:32.363261 #train# step 9241, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:33.946065 #train# step 9242, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:35.528870 #train# step 9243, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:37.116477 #train# step 9244, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:38.676349 #train# step 9245, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:40.227798 #train# step 9246, loss = 0.8882, cross_entropy loss = 0.8882, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:41.748416 #train# step 9247, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:43.308063 #train# step 9248, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:44.834994 #train# step 9249, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:46.385270 #train# step 9250, loss = 0.8868, cross_entropy loss = 0.8868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:47.945016 #train# step 9251, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:49.500476 #train# step 9252, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:51.055610 #train# step 9253, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:52.602673 #train# step 9254, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:54.156778 #train# step 9255, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:55.700252 #train# step 9256, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:57.270299 #train# step 9257, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:12:58.826371 #train# step 9258, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:00.390530 #train# step 9259, loss = 0.8913, cross_entropy loss = 0.8913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:01.942306 #train# step 9260, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:03.485484 #train# step 9261, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:05.028661 #train# step 9262, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:06.593628 #train# step 9263, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:08.167452 #train# step 9264, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:09.731219 #train# step 9265, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:11.278368 #train# step 9266, loss = 0.8847, cross_entropy loss = 0.8847, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:12.831059 #train# step 9267, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:14.388851 #train# step 9268, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:15.922700 #train# step 9269, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:17.452738 #train# step 9270, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:18.970369 #train# step 9271, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:20.528498 #train# step 9272, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:22.114933 #train# step 9273, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:23.649604 #train# step 9274, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:25.225914 #train# step 9275, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:26.759573 #train# step 9276, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:28.303238 #train# step 9277, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:29.851256 #train# step 9278, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:31.400403 #train# step 9279, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:32.989503 #train# step 9280, loss = 0.8878, cross_entropy loss = 0.8878, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:34.547610 #train# step 9281, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:36.100274 #train# step 9282, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:37.648827 #train# step 9283, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:39.232394 #train# step 9284, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:40.763969 #train# step 9285, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:42.366198 #train# step 9286, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:43.919747 #train# step 9287, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:45.463457 #train# step 9288, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:47.034520 #train# step 9289, loss = 0.8831, cross_entropy loss = 0.8831, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:48.597639 #train# step 9290, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:50.138403 #train# step 9291, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:51.673869 #train# step 9292, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:53.241480 #train# step 9293, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:54.800212 #train# step 9294, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:56.352176 #train# step 9295, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:57.900061 #train# step 9296, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:13:59.438454 #train# step 9297, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:00.984766 #train# step 9298, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:02.555309 #train# step 9299, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:04.088900 #train# step 9300, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:05.649207 #train# step 9301, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:07.185094 #train# step 9302, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:08.717772 #train# step 9303, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:10.301117 #train# step 9304, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:11.839483 #train# step 9305, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:13.397163 #train# step 9306, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:14.948493 #train# step 9307, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:16.493846 #train# step 9308, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:17.982936 #train# step 9309, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:19.526820 #train# step 9310, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:21.106249 #train# step 9311, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:22.696763 #train# step 9312, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:24.211483 #train# step 9313, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:25.758648 #train# step 9314, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:27.324572 #train# step 9315, loss = 0.8833, cross_entropy loss = 0.8833, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:28.895805 #train# step 9316, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:30.478656 #train# step 9317, loss = 0.8881, cross_entropy loss = 0.8881, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:32.042764 #train# step 9318, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:33.600203 #train# step 9319, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:35.152544 #train# step 9320, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:36.715261 #train# step 9321, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:38.268770 #train# step 9322, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:39.826537 #train# step 9323, loss = 0.8884, cross_entropy loss = 0.8884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:41.385860 #train# step 9324, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:42.917404 #train# step 9325, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:44.441227 #train# step 9326, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:45.978850 #train# step 9327, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:47.541328 #train# step 9328, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:49.105098 #train# step 9329, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:50.654525 #train# step 9330, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:52.209328 #train# step 9331, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:53.782107 #train# step 9332, loss = 0.8891, cross_entropy loss = 0.8891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:55.334243 #train# step 9333, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:56.868188 #train# step 9334, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:58.397669 #train# step 9335, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:14:59.948429 #train# step 9336, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:01.515069 #train# step 9337, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:03.074725 #train# step 9338, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:04.630559 #train# step 9339, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:06.199161 #train# step 9340, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:07.754714 #train# step 9341, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:09.343263 #train# step 9342, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:10.899112 #train# step 9343, loss = 0.8863, cross_entropy loss = 0.8863, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:12.458631 #train# step 9344, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:14.024907 #train# step 9345, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:15.567564 #train# step 9346, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:17.138285 #train# step 9347, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:18.676161 #train# step 9348, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:20.225159 #train# step 9349, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:21.780763 #train# step 9350, loss = 0.8913, cross_entropy loss = 0.8913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:23.336302 #train# step 9351, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:24.896533 #train# step 9352, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:26.447771 #train# step 9353, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:27.994088 #train# step 9354, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:29.557811 #train# step 9355, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:31.106115 #train# step 9356, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:32.659084 #train# step 9357, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:34.192355 #train# step 9358, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:35.729744 #train# step 9359, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:37.262091 #train# step 9360, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:38.804302 #train# step 9361, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:40.332553 #train# step 9362, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:41.877910 #train# step 9363, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:43.424938 #train# step 9364, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:44.948205 #train# step 9365, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:46.506489 #train# step 9366, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:48.082709 #train# step 9367, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:49.633547 #train# step 9368, loss = 0.8883, cross_entropy loss = 0.8883, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:51.210331 #train# step 9369, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:52.764318 #train# step 9370, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:54.282501 #train# step 9371, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:55.847424 #train# step 9372, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:57.393610 #train# step 9373, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:15:58.968143 #train# step 9374, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:00.533664 #train# step 9375, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:02.055699 #train# step 9376, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:03.618683 #train# step 9377, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:05.153322 #train# step 9378, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:06.711039 #train# step 9379, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:08.286805 #train# step 9380, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:09.852182 #train# step 9381, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:11.409789 #train# step 9382, loss = 0.8867, cross_entropy loss = 0.8867, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:12.951391 #train# step 9383, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:14.520378 #train# step 9384, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:16.089438 #train# step 9385, loss = 0.8816, cross_entropy loss = 0.8816, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:17.645514 #train# step 9386, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:19.212881 #train# step 9387, loss = 0.8894, cross_entropy loss = 0.8894, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:20.793926 #train# step 9388, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:22.334820 #train# step 9389, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:23.865284 #train# step 9390, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:25.423410 #train# step 9391, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:26.982695 #train# step 9392, loss = 0.8894, cross_entropy loss = 0.8894, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:28.561136 #train# step 9393, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:30.102632 #train# step 9394, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:31.638858 #train# step 9395, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:33.190859 #train# step 9396, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:34.767971 #train# step 9397, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:36.338503 #train# step 9398, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:37.881354 #train# step 9399, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:39.428176 #train# step 9400, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:40.981334 #train# step 9401, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:42.570641 #train# step 9402, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:44.143407 #train# step 9403, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:45.672516 #train# step 9404, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:47.246888 #train# step 9405, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:48.779957 #train# step 9406, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:50.356698 #train# step 9407, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:51.908939 #train# step 9408, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:53.486737 #train# step 9409, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:55.031968 #train# step 9410, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:56.566088 #train# step 9411, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:58.127435 #train# step 9412, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:16:59.684130 #train# step 9413, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:01.210441 #train# step 9414, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:02.774077 #train# step 9415, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:04.353852 #train# step 9416, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:05.887135 #train# step 9417, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:07.461357 #train# step 9418, loss = 0.8824, cross_entropy loss = 0.8824, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:09.023663 #train# step 9419, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:10.561762 #train# step 9420, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:12.169193 #train# step 9421, loss = 0.8872, cross_entropy loss = 0.8872, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:13.697189 #train# step 9422, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:15.246022 #train# step 9423, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:16.814008 #train# step 9424, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:18.321000 #train# step 9425, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:19.872844 #train# step 9426, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:21.420337 #train# step 9427, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:22.976160 #train# step 9428, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:24.551565 #train# step 9429, loss = 0.8899, cross_entropy loss = 0.8899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:26.137182 #train# step 9430, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:27.653836 #train# step 9431, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:29.221188 #train# step 9432, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:30.755559 #train# step 9433, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:32.326116 #train# step 9434, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:33.880417 #train# step 9435, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:35.441604 #train# step 9436, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:36.970311 #train# step 9437, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:38.497404 #train# step 9438, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:40.042307 #train# step 9439, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:41.603622 #train# step 9440, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:43.163475 #train# step 9441, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:44.709448 #train# step 9442, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:46.307295 #train# step 9443, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:47.874515 #train# step 9444, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:49.399522 #train# step 9445, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:50.943474 #train# step 9446, loss = 0.8879, cross_entropy loss = 0.8879, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:52.493723 #train# step 9447, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:54.054578 #train# step 9448, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:55.614380 #train# step 9449, loss = 0.8891, cross_entropy loss = 0.8891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:57.155364 #train# step 9450, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:17:58.732264 #train# step 9451, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:00.286453 #train# step 9452, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:01.865389 #train# step 9453, loss = 0.8904, cross_entropy loss = 0.8904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:03.392004 #train# step 9454, loss = 0.8834, cross_entropy loss = 0.8834, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:04.961366 #train# step 9455, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:06.518355 #train# step 9456, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:08.048885 #train# step 9457, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:09.578946 #train# step 9458, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:11.168766 #train# step 9459, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:12.726018 #train# step 9460, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:14.320490 #train# step 9461, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:15.865808 #train# step 9462, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:17.422609 #train# step 9463, loss = 0.8890, cross_entropy loss = 0.8890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:18.949297 #train# step 9464, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:20.504170 #train# step 9465, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:22.040834 #train# step 9466, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:23.600729 #train# step 9467, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:25.143005 #train# step 9468, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:26.700792 #train# step 9469, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:28.245981 #train# step 9470, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:29.817233 #train# step 9471, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:31.370795 #train# step 9472, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:32.933089 #train# step 9473, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:34.500429 #train# step 9474, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:36.062680 #train# step 9475, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:37.586950 #train# step 9476, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:39.176705 #train# step 9477, loss = 0.8865, cross_entropy loss = 0.8865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:40.713813 #train# step 9478, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:42.261380 #train# step 9479, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:43.811400 #train# step 9480, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:45.356635 #train# step 9481, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:46.887916 #train# step 9482, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:48.419985 #train# step 9483, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:49.972928 #train# step 9484, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:51.525532 #train# step 9485, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:53.063004 #train# step 9486, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:54.599333 #train# step 9487, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:56.164514 #train# step 9488, loss = 0.8806, cross_entropy loss = 0.8806, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:57.735066 #train# step 9489, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:18:59.278611 #train# step 9490, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:00.863964 #train# step 9491, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:02.419331 #train# step 9492, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:03.967172 #train# step 9493, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:05.533359 #train# step 9494, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:07.097522 #train# step 9495, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:08.653331 #train# step 9496, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:10.206213 #train# step 9497, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:11.765001 #train# step 9498, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:13.314509 #train# step 9499, loss = 0.8853, cross_entropy loss = 0.8853, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:14.858719 #train# step 9500, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:16.371546 #train# step 9501, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:17.892500 #train# step 9502, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:19.419415 #train# step 9503, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:21.009933 #train# step 9504, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:22.573124 #train# step 9505, loss = 0.8869, cross_entropy loss = 0.8869, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:24.117421 #train# step 9506, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:25.662078 #train# step 9507, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:27.221802 #train# step 9508, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:28.755642 #train# step 9509, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:30.321894 #train# step 9510, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:31.863582 #train# step 9511, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:33.419395 #train# step 9512, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:34.950792 #train# step 9513, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:36.539115 #train# step 9514, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:38.125479 #train# step 9515, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:39.680028 #train# step 9516, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:41.242499 #train# step 9517, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:42.812413 #train# step 9518, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:44.324175 #train# step 9519, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:45.880158 #train# step 9520, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:47.459595 #train# step 9521, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:48.999911 #train# step 9522, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:50.524494 #train# step 9523, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:52.105860 #train# step 9524, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:53.650548 #train# step 9525, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:55.234916 #train# step 9526, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:56.824147 #train# step 9527, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:58.382613 #train# step 9528, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:19:59.940325 #train# step 9529, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:01.491724 #train# step 9530, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:03.049378 #train# step 9531, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:04.616730 #train# step 9532, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:06.158483 #train# step 9533, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:07.724440 #train# step 9534, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:09.280059 #train# step 9535, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:10.830956 #train# step 9536, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:12.393742 #train# step 9537, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:13.954465 #train# step 9538, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:15.517690 #train# step 9539, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:17.050359 #train# step 9540, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:18.574424 #train# step 9541, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:20.137744 #train# step 9542, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:21.729197 #train# step 9543, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:23.276514 #train# step 9544, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:24.832483 #train# step 9545, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:26.392670 #train# step 9546, loss = 0.8817, cross_entropy loss = 0.8817, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:27.959364 #train# step 9547, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:29.483096 #train# step 9548, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:31.056933 #train# step 9549, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:32.640395 #train# step 9550, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:34.223381 #train# step 9551, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:35.776511 #train# step 9552, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:37.327410 #train# step 9553, loss = 0.8888, cross_entropy loss = 0.8888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:38.874372 #train# step 9554, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:40.447019 #train# step 9555, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:41.974816 #train# step 9556, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:43.551341 #train# step 9557, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:45.096458 #train# step 9558, loss = 0.8887, cross_entropy loss = 0.8887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:46.671357 #train# step 9559, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:48.191997 #train# step 9560, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:49.743485 #train# step 9561, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:51.310757 #train# step 9562, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:52.846289 #train# step 9563, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:54.449796 #train# step 9564, loss = 0.8893, cross_entropy loss = 0.8893, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:55.993736 #train# step 9565, loss = 0.8811, cross_entropy loss = 0.8811, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:57.533637 #train# step 9566, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:20:59.123528 #train# step 9567, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:00.685568 #train# step 9568, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:02.248596 #train# step 9569, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:03.791758 #train# step 9570, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:05.325487 #train# step 9571, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:06.879201 #train# step 9572, loss = 0.8886, cross_entropy loss = 0.8886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:08.415003 #train# step 9573, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:09.943629 #train# step 9574, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:11.496845 #train# step 9575, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:13.044194 #train# step 9576, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:14.606017 #train# step 9577, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:16.171414 #train# step 9578, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:17.718430 #train# step 9579, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:19.265955 #train# step 9580, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:20.799369 #train# step 9581, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:22.348448 #train# step 9582, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:23.894283 #train# step 9583, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:25.403142 #train# step 9584, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:26.962843 #train# step 9585, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:28.518056 #train# step 9586, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:30.089420 #train# step 9587, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:31.640580 #train# step 9588, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:33.206267 #train# step 9589, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:34.790951 #train# step 9590, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:36.319396 #train# step 9591, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:37.890748 #train# step 9592, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:39.468187 #train# step 9593, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:40.994802 #train# step 9594, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:42.562164 #train# step 9595, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:44.117052 #train# step 9596, loss = 0.8891, cross_entropy loss = 0.8891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:45.651757 #train# step 9597, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:47.192751 #train# step 9598, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:48.717993 #train# step 9599, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:50.275842 #train# step 9600, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:51.796313 #train# step 9601, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:53.338091 #train# step 9602, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:54.890248 #train# step 9603, loss = 0.8897, cross_entropy loss = 0.8897, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:56.468357 #train# step 9604, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:58.012526 #train# step 9605, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:21:59.567358 #train# step 9606, loss = 0.8892, cross_entropy loss = 0.8892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:01.174500 #train# step 9607, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:02.701086 #train# step 9608, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:04.268412 #train# step 9609, loss = 0.8895, cross_entropy loss = 0.8895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:05.835444 #train# step 9610, loss = 0.8881, cross_entropy loss = 0.8881, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:07.402210 #train# step 9611, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:08.957061 #train# step 9612, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:10.498899 #train# step 9613, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:12.048341 #train# step 9614, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:13.624515 #train# step 9615, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:15.216678 #train# step 9616, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:16.794552 #train# step 9617, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:18.343776 #train# step 9618, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:19.903072 #train# step 9619, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:21.467321 #train# step 9620, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:23.023984 #train# step 9621, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:24.571375 #train# step 9622, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:26.107896 #train# step 9623, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:27.628982 #train# step 9624, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:29.196513 #train# step 9625, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:30.733657 #train# step 9626, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:32.249828 #train# step 9627, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:33.797598 #train# step 9628, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:35.357475 #train# step 9629, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:36.899932 #train# step 9630, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:38.469346 #train# step 9631, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:40.031153 #train# step 9632, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:41.578827 #train# step 9633, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:43.113689 #train# step 9634, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:44.633994 #train# step 9635, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:46.201948 #train# step 9636, loss = 0.8881, cross_entropy loss = 0.8881, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:47.762836 #train# step 9637, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:49.281585 #train# step 9638, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:50.842571 #train# step 9639, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:52.391932 #train# step 9640, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:53.979610 #train# step 9641, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:55.535737 #train# step 9642, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:57.079519 #train# step 9643, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:22:58.644881 #train# step 9644, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:00.197473 #train# step 9645, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:01.760142 #train# step 9646, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:03.346796 #train# step 9647, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:04.911150 #train# step 9648, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:06.440484 #train# step 9649, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:08.025905 #train# step 9650, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:09.583357 #train# step 9651, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:11.140329 #train# step 9652, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:12.714857 #train# step 9653, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:14.292392 #train# step 9654, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:15.843249 #train# step 9655, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:17.426175 #train# step 9656, loss = 0.8892, cross_entropy loss = 0.8892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:18.981811 #train# step 9657, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:20.550731 #train# step 9658, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:22.091638 #train# step 9659, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:23.671270 #train# step 9660, loss = 0.8807, cross_entropy loss = 0.8807, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:25.192391 #train# step 9661, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:26.737765 #train# step 9662, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:28.299273 #train# step 9663, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:29.860029 #train# step 9664, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:31.438960 #train# step 9665, loss = 0.8861, cross_entropy loss = 0.8861, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:32.975958 #train# step 9666, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:34.533043 #train# step 9667, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:36.075386 #train# step 9668, loss = 0.8875, cross_entropy loss = 0.8875, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:37.603397 #train# step 9669, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:39.160923 #train# step 9670, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:40.729524 #train# step 9671, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:42.313925 #train# step 9672, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:43.855039 #train# step 9673, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:45.392027 #train# step 9674, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:46.913975 #train# step 9675, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:48.452612 #train# step 9676, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:49.990216 #train# step 9677, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:51.531673 #train# step 9678, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:53.048512 #train# step 9679, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:54.624246 #train# step 9680, loss = 0.8884, cross_entropy loss = 0.8884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:56.162235 #train# step 9681, loss = 0.8913, cross_entropy loss = 0.8913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:57.715102 #train# step 9682, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:23:59.288300 #train# step 9683, loss = 0.8897, cross_entropy loss = 0.8897, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:00.806749 #train# step 9684, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:02.342607 #train# step 9685, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:03.895937 #train# step 9686, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:05.460540 #train# step 9687, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:07.021089 #train# step 9688, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:08.583989 #train# step 9689, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:10.110290 #train# step 9690, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:11.706469 #train# step 9691, loss = 0.8863, cross_entropy loss = 0.8863, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:13.248302 #train# step 9692, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:14.797542 #train# step 9693, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:16.344879 #train# step 9694, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:17.917989 #train# step 9695, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:19.456588 #train# step 9696, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:21.039059 #train# step 9697, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:22.619048 #train# step 9698, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:24.158374 #train# step 9699, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:25.731799 #train# step 9700, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:27.294643 #train# step 9701, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:28.826971 #train# step 9702, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:30.378088 #train# step 9703, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:31.941630 #train# step 9704, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:33.509411 #train# step 9705, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:35.044534 #train# step 9706, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:36.615338 #train# step 9707, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:38.183996 #train# step 9708, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:39.732313 #train# step 9709, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:41.301671 #train# step 9710, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:42.862272 #train# step 9711, loss = 0.8870, cross_entropy loss = 0.8870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:44.403982 #train# step 9712, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:45.966243 #train# step 9713, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:47.497660 #train# step 9714, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:49.044378 #train# step 9715, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:50.592862 #train# step 9716, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:52.157056 #train# step 9717, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:53.695759 #train# step 9718, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:55.231652 #train# step 9719, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:56.802120 #train# step 9720, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:58.314543 #train# step 9721, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:24:59.885284 #train# step 9722, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:01.459263 #train# step 9723, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:03.038241 #train# step 9724, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:04.571356 #train# step 9725, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:06.128994 #train# step 9726, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:07.700451 #train# step 9727, loss = 0.8888, cross_entropy loss = 0.8888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:09.237814 #train# step 9728, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:10.791883 #train# step 9729, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:12.357139 #train# step 9730, loss = 0.8911, cross_entropy loss = 0.8911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:13.936610 #train# step 9731, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:15.508636 #train# step 9732, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:17.078179 #train# step 9733, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:18.612415 #train# step 9734, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:20.159434 #train# step 9735, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:21.737478 #train# step 9736, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:23.307503 #train# step 9737, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:24.848344 #train# step 9738, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:26.395858 #train# step 9739, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:27.963789 #train# step 9740, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:29.533744 #train# step 9741, loss = 0.8881, cross_entropy loss = 0.8881, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:31.110205 #train# step 9742, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:32.663799 #train# step 9743, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:34.180219 #train# step 9744, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:35.722315 #train# step 9745, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:37.267130 #train# step 9746, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:38.809469 #train# step 9747, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:40.363818 #train# step 9748, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:41.900987 #train# step 9749, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:43.431712 #train# step 9750, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:44.984523 #train# step 9751, loss = 0.8863, cross_entropy loss = 0.8863, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:46.571588 #train# step 9752, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:48.142482 #train# step 9753, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:49.674037 #train# step 9754, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:51.197962 #train# step 9755, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:52.730960 #train# step 9756, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:54.266384 #train# step 9757, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:55.821854 #train# step 9758, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:57.380750 #train# step 9759, loss = 0.8785, cross_entropy loss = 0.8785, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:25:58.907133 #train# step 9760, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:00.463415 #train# step 9761, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:02.030427 #train# step 9762, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:03.604546 #train# step 9763, loss = 0.8871, cross_entropy loss = 0.8871, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:05.119654 #train# step 9764, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:06.682131 #train# step 9765, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:08.220438 #train# step 9766, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:09.768706 #train# step 9767, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:11.351411 #train# step 9768, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:12.897628 #train# step 9769, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:14.450527 #train# step 9770, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:15.998586 #train# step 9771, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:17.580689 #train# step 9772, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:19.156429 #train# step 9773, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:20.722732 #train# step 9774, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:22.291118 #train# step 9775, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:23.818853 #train# step 9776, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:25.347056 #train# step 9777, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:26.893284 #train# step 9778, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:28.456337 #train# step 9779, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:30.040754 #train# step 9780, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:31.602671 #train# step 9781, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:33.110691 #train# step 9782, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:34.663240 #train# step 9783, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:36.222905 #train# step 9784, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:37.786291 #train# step 9785, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:39.345648 #train# step 9786, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:40.917656 #train# step 9787, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:42.460652 #train# step 9788, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:44.003276 #train# step 9789, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:45.566299 #train# step 9790, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:47.136318 #train# step 9791, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:48.672363 #train# step 9792, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:50.205148 #train# step 9793, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:51.729806 #train# step 9794, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:53.266792 #train# step 9795, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:54.822445 #train# step 9796, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:56.378543 #train# step 9797, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:57.888665 #train# step 9798, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:26:59.446916 #train# step 9799, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:01.013083 #train# step 9800, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:02.543872 #train# step 9801, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:04.097090 #train# step 9802, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:05.682161 #train# step 9803, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:07.227678 #train# step 9804, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:08.806739 #train# step 9805, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:10.375085 #train# step 9806, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:11.941156 #train# step 9807, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:13.531686 #train# step 9808, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:15.083459 #train# step 9809, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:16.629903 #train# step 9810, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:18.220194 #train# step 9811, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:19.769166 #train# step 9812, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:21.310340 #train# step 9813, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:22.855789 #train# step 9814, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:24.410990 #train# step 9815, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:25.948910 #train# step 9816, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:27.487849 #train# step 9817, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:29.058320 #train# step 9818, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:30.614610 #train# step 9819, loss = 0.8865, cross_entropy loss = 0.8865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:32.140039 #train# step 9820, loss = 0.8832, cross_entropy loss = 0.8832, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:33.713683 #train# step 9821, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:35.247703 #train# step 9822, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:36.810362 #train# step 9823, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:38.351982 #train# step 9824, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:39.922896 #train# step 9825, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:41.462184 #train# step 9826, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:43.012133 #train# step 9827, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:44.604476 #train# step 9828, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:46.179613 #train# step 9829, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:47.713423 #train# step 9830, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:49.297769 #train# step 9831, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:50.855653 #train# step 9832, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:52.427135 #train# step 9833, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:53.947021 #train# step 9834, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:55.488932 #train# step 9835, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:57.046531 #train# step 9836, loss = 0.8887, cross_entropy loss = 0.8887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:27:58.600651 #train# step 9837, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:00.168158 #train# step 9838, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:01.731436 #train# step 9839, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:03.274510 #train# step 9840, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:04.853200 #train# step 9841, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:06.399424 #train# step 9842, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:07.960296 #train# step 9843, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:09.522816 #train# step 9844, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:11.075354 #train# step 9845, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:12.614557 #train# step 9846, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:14.181143 #train# step 9847, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:15.751922 #train# step 9848, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:17.294687 #train# step 9849, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:18.862774 #train# step 9850, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:20.430641 #train# step 9851, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:21.998344 #train# step 9852, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:23.558295 #train# step 9853, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:25.090940 #train# step 9854, loss = 0.8895, cross_entropy loss = 0.8895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:26.653400 #train# step 9855, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:28.163684 #train# step 9856, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:29.701926 #train# step 9857, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:31.218096 #train# step 9858, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:32.761357 #train# step 9859, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:34.305201 #train# step 9860, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:35.866555 #train# step 9861, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:37.421657 #train# step 9862, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:38.994816 #train# step 9863, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:40.554188 #train# step 9864, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:42.118779 #train# step 9865, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:43.667870 #train# step 9866, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:45.219735 #train# step 9867, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:46.791250 #train# step 9868, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:48.343183 #train# step 9869, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:49.867921 #train# step 9870, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:51.415324 #train# step 9871, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:52.960935 #train# step 9872, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:54.518690 #train# step 9873, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:56.068084 #train# step 9874, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:57.626647 #train# step 9875, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:28:59.167006 #train# step 9876, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:00.707037 #train# step 9877, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:02.255393 #train# step 9878, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:03.784426 #train# step 9879, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:05.338966 #train# step 9880, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:06.886681 #train# step 9881, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:08.430173 #train# step 9882, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:10.005589 #train# step 9883, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:11.558721 #train# step 9884, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:13.097495 #train# step 9885, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:14.640055 #train# step 9886, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:16.244053 #train# step 9887, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:17.810823 #train# step 9888, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:19.349394 #train# step 9889, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:20.906248 #train# step 9890, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:22.449794 #train# step 9891, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:23.985356 #train# step 9892, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:25.592018 #train# step 9893, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:27.150345 #train# step 9894, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:28.677892 #train# step 9895, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:30.221312 #train# step 9896, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:31.753733 #train# step 9897, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:33.311822 #train# step 9898, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:34.858949 #train# step 9899, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:36.403337 #train# step 9900, loss = 0.8814, cross_entropy loss = 0.8814, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:37.966581 #train# step 9901, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:39.536950 #train# step 9902, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:41.095456 #train# step 9903, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:42.642432 #train# step 9904, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:44.187634 #train# step 9905, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:45.746166 #train# step 9906, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:47.287514 #train# step 9907, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:48.870634 #train# step 9908, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:50.432770 #train# step 9909, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:51.988872 #train# step 9910, loss = 0.8829, cross_entropy loss = 0.8829, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:53.535045 #train# step 9911, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:55.085180 #train# step 9912, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:56.615054 #train# step 9913, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:58.182654 #train# step 9914, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:29:59.746122 #train# step 9915, loss = 0.8813, cross_entropy loss = 0.8813, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:01.332419 #train# step 9916, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:02.851587 #train# step 9917, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:04.383601 #train# step 9918, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:05.920713 #train# step 9919, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:07.503494 #train# step 9920, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:09.045337 #train# step 9921, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:10.639976 #train# step 9922, loss = 0.8844, cross_entropy loss = 0.8844, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:12.166371 #train# step 9923, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:13.733894 #train# step 9924, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:15.291679 #train# step 9925, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:16.846925 #train# step 9926, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:18.394789 #train# step 9927, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:19.961735 #train# step 9928, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:21.522713 #train# step 9929, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:23.050634 #train# step 9930, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:24.596806 #train# step 9931, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:26.134393 #train# step 9932, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:27.694864 #train# step 9933, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:29.199157 #train# step 9934, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:30.748625 #train# step 9935, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:32.305934 #train# step 9936, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:33.848280 #train# step 9937, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:35.402975 #train# step 9938, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:36.984731 #train# step 9939, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:38.547833 #train# step 9940, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:40.127792 #train# step 9941, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:41.657922 #train# step 9942, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:43.207294 #train# step 9943, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:44.744039 #train# step 9944, loss = 0.8853, cross_entropy loss = 0.8853, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:46.297068 #train# step 9945, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:47.805863 #train# step 9946, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:49.336567 #train# step 9947, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:50.920134 #train# step 9948, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:52.481609 #train# step 9949, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:54.015362 #train# step 9950, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:55.593223 #train# step 9951, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:57.137049 #train# step 9952, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:30:58.690942 #train# step 9953, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:00.245467 #train# step 9954, loss = 0.8763, cross_entropy loss = 0.8763, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:01.793896 #train# step 9955, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:03.350719 #train# step 9956, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:04.939761 #train# step 9957, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:06.517036 #train# step 9958, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:08.086108 #train# step 9959, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:09.648623 #train# step 9960, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:11.212915 #train# step 9961, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:12.774672 #train# step 9962, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:14.372850 #train# step 9963, loss = 0.8828, cross_entropy loss = 0.8828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:15.893136 #train# step 9964, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:17.457496 #train# step 9965, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:19.012103 #train# step 9966, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:20.568063 #train# step 9967, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:22.109616 #train# step 9968, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:23.658367 #train# step 9969, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:25.216903 #train# step 9970, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:26.757853 #train# step 9971, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:28.324456 #train# step 9972, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:29.875167 #train# step 9973, loss = 0.8913, cross_entropy loss = 0.8913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:31.424014 #train# step 9974, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:32.987184 #train# step 9975, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:34.514433 #train# step 9976, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:36.060798 #train# step 9977, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:37.590721 #train# step 9978, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:39.158096 #train# step 9979, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:40.728423 #train# step 9980, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:42.259722 #train# step 9981, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:43.811037 #train# step 9982, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:45.365574 #train# step 9983, loss = 0.8911, cross_entropy loss = 0.8911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:46.932227 #train# step 9984, loss = 0.8865, cross_entropy loss = 0.8865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:48.503006 #train# step 9985, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:50.057492 #train# step 9986, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:51.621273 #train# step 9987, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:53.163742 #train# step 9988, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:54.729607 #train# step 9989, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:56.240682 #train# step 9990, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:57.826866 #train# step 9991, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:31:59.353317 #train# step 9992, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:32:00.871326 #train# step 9993, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:32:02.447194 #train# step 9994, loss = 0.8876, cross_entropy loss = 0.8876, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:32:03.997251 #train# step 9995, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:32:05.519056 #train# step 9996, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:32:07.062221 #train# step 9997, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:32:08.604248 #train# step 9998, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:32:10.199531 #train# step 9999, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-21 05:32:11.753338 #train# step 10000, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
2021-01-21 05:32:11.753627 #traing# finish training
saving model to ./models/lr_5e-05_cqlambda_0.0_alpha_10.0_dataset_VeRi_hashbit_512.npy
model saved
{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 512,
 'save_dir': './models/',
 'val_batch_size': 100}
