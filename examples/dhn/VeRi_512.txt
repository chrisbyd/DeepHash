{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 512,
 'save_dir': './models/',
 'val_batch_size': 100}
initializing
launching session
loading img model from ../../architecture/pretrained_model/reference_pretrain.npy
['hash_layer', 'fc6', 'fc7', 'conv3', 'conv2', 'conv1', 'conv5', 'conv4']
img model loading finished
Initializing Dataset
Dataset already
2021-01-22 18:01:08.845720 #train# start training
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:26.343820 #train# step    1, loss = 2.0505, cross_entropy loss = 2.0505, 12.6 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:27.935358 #train# step    2, loss = 2.0193, cross_entropy loss = 2.0193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:29.484728 #train# step    3, loss = 1.9091, cross_entropy loss = 1.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:31.031623 #train# step    4, loss = 1.8000, cross_entropy loss = 1.8000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:32.600771 #train# step    5, loss = 1.6341, cross_entropy loss = 1.6341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:34.154503 #train# step    6, loss = 1.5183, cross_entropy loss = 1.5183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:35.693947 #train# step    7, loss = 1.3932, cross_entropy loss = 1.3932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:37.240556 #train# step    8, loss = 1.3034, cross_entropy loss = 1.3034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:38.796513 #train# step    9, loss = 1.2380, cross_entropy loss = 1.2380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:40.376467 #train# step   10, loss = 1.1926, cross_entropy loss = 1.1926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:41.903715 #train# step   11, loss = 1.1648, cross_entropy loss = 1.1648, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:43.453425 #train# step   12, loss = 1.1564, cross_entropy loss = 1.1564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:45.019742 #train# step   13, loss = 1.1273, cross_entropy loss = 1.1273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:46.585421 #train# step   14, loss = 1.1242, cross_entropy loss = 1.1242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:48.125309 #train# step   15, loss = 1.1358, cross_entropy loss = 1.1358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:49.694177 #train# step   16, loss = 1.1245, cross_entropy loss = 1.1245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:51.238373 #train# step   17, loss = 1.1196, cross_entropy loss = 1.1196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:52.784253 #train# step   18, loss = 1.1307, cross_entropy loss = 1.1307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:54.357493 #train# step   19, loss = 1.1530, cross_entropy loss = 1.1530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:55.918026 #train# step   20, loss = 1.1481, cross_entropy loss = 1.1481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:57.475186 #train# step   21, loss = 1.1686, cross_entropy loss = 1.1686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:01:59.033458 #train# step   22, loss = 1.1444, cross_entropy loss = 1.1444, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:00.593377 #train# step   23, loss = 1.1622, cross_entropy loss = 1.1622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:02.181501 #train# step   24, loss = 1.1814, cross_entropy loss = 1.1814, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:03.748663 #train# step   25, loss = 1.1585, cross_entropy loss = 1.1585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:05.316594 #train# step   26, loss = 1.1686, cross_entropy loss = 1.1686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:06.920899 #train# step   27, loss = 1.1481, cross_entropy loss = 1.1481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:08.447911 #train# step   28, loss = 1.1695, cross_entropy loss = 1.1695, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:10.000322 #train# step   29, loss = 1.1536, cross_entropy loss = 1.1536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:11.522457 #train# step   30, loss = 1.1443, cross_entropy loss = 1.1443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:13.080597 #train# step   31, loss = 1.1515, cross_entropy loss = 1.1515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:14.645840 #train# step   32, loss = 1.1326, cross_entropy loss = 1.1326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:16.174319 #train# step   33, loss = 1.1307, cross_entropy loss = 1.1307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:17.697198 #train# step   34, loss = 1.1384, cross_entropy loss = 1.1384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:19.255766 #train# step   35, loss = 1.1225, cross_entropy loss = 1.1225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:20.814507 #train# step   36, loss = 1.1286, cross_entropy loss = 1.1286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:22.357761 #train# step   37, loss = 1.1041, cross_entropy loss = 1.1041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:23.893011 #train# step   38, loss = 1.1108, cross_entropy loss = 1.1108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:25.409539 #train# step   39, loss = 1.1116, cross_entropy loss = 1.1116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:26.949680 #train# step   40, loss = 1.0951, cross_entropy loss = 1.0951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:28.489477 #train# step   41, loss = 1.1021, cross_entropy loss = 1.1021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:30.079706 #train# step   42, loss = 1.0999, cross_entropy loss = 1.0999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:31.675320 #train# step   43, loss = 1.0844, cross_entropy loss = 1.0844, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:33.251958 #train# step   44, loss = 1.0936, cross_entropy loss = 1.0936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:34.812087 #train# step   45, loss = 1.1093, cross_entropy loss = 1.1093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:36.356503 #train# step   46, loss = 1.0897, cross_entropy loss = 1.0897, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:37.893590 #train# step   47, loss = 1.1054, cross_entropy loss = 1.1054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:39.465146 #train# step   48, loss = 1.1023, cross_entropy loss = 1.1023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:41.034538 #train# step   49, loss = 1.0964, cross_entropy loss = 1.0964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:42.598845 #train# step   50, loss = 1.0848, cross_entropy loss = 1.0848, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:44.151026 #train# step   51, loss = 1.0989, cross_entropy loss = 1.0989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:45.709686 #train# step   52, loss = 1.1046, cross_entropy loss = 1.1046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:47.272852 #train# step   53, loss = 1.0998, cross_entropy loss = 1.0998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:48.822673 #train# step   54, loss = 1.0912, cross_entropy loss = 1.0912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:50.352082 #train# step   55, loss = 1.1016, cross_entropy loss = 1.1016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:51.901767 #train# step   56, loss = 1.1036, cross_entropy loss = 1.1036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:53.445551 #train# step   57, loss = 1.0858, cross_entropy loss = 1.0858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:55.009660 #train# step   58, loss = 1.0856, cross_entropy loss = 1.0856, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:56.577237 #train# step   59, loss = 1.0968, cross_entropy loss = 1.0968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:58.153593 #train# step   60, loss = 1.0903, cross_entropy loss = 1.0903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:02:59.706308 #train# step   61, loss = 1.0899, cross_entropy loss = 1.0899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:01.243622 #train# step   62, loss = 1.1027, cross_entropy loss = 1.1027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:02.797914 #train# step   63, loss = 1.0949, cross_entropy loss = 1.0949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:04.355166 #train# step   64, loss = 1.1125, cross_entropy loss = 1.1125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:05.896871 #train# step   65, loss = 1.0938, cross_entropy loss = 1.0938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:07.476436 #train# step   66, loss = 1.0807, cross_entropy loss = 1.0807, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:09.038934 #train# step   67, loss = 1.0895, cross_entropy loss = 1.0895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:10.630672 #train# step   68, loss = 1.0572, cross_entropy loss = 1.0572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:12.204367 #train# step   69, loss = 1.0899, cross_entropy loss = 1.0899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:13.738312 #train# step   70, loss = 1.0763, cross_entropy loss = 1.0763, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:15.294996 #train# step   71, loss = 1.0852, cross_entropy loss = 1.0852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:16.839062 #train# step   72, loss = 1.0892, cross_entropy loss = 1.0892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:18.407802 #train# step   73, loss = 1.1022, cross_entropy loss = 1.1022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:19.958646 #train# step   74, loss = 1.0931, cross_entropy loss = 1.0931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:21.516475 #train# step   75, loss = 1.0560, cross_entropy loss = 1.0560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:23.057320 #train# step   76, loss = 1.0864, cross_entropy loss = 1.0864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:24.601827 #train# step   77, loss = 1.1006, cross_entropy loss = 1.1006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:26.136742 #train# step   78, loss = 1.1039, cross_entropy loss = 1.1039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:27.691117 #train# step   79, loss = 1.0697, cross_entropy loss = 1.0697, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:29.245813 #train# step   80, loss = 1.0704, cross_entropy loss = 1.0704, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:30.816062 #train# step   81, loss = 1.0716, cross_entropy loss = 1.0716, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:32.365735 #train# step   82, loss = 1.0857, cross_entropy loss = 1.0857, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:33.896762 #train# step   83, loss = 1.0752, cross_entropy loss = 1.0752, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:35.408691 #train# step   84, loss = 1.0985, cross_entropy loss = 1.0985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:36.959578 #train# step   85, loss = 1.0911, cross_entropy loss = 1.0911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:38.536996 #train# step   86, loss = 1.0632, cross_entropy loss = 1.0632, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:40.106986 #train# step   87, loss = 1.0939, cross_entropy loss = 1.0939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:41.632287 #train# step   88, loss = 1.0424, cross_entropy loss = 1.0424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:43.210704 #train# step   89, loss = 1.0693, cross_entropy loss = 1.0693, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:44.785238 #train# step   90, loss = 1.0734, cross_entropy loss = 1.0734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:46.333658 #train# step   91, loss = 1.0789, cross_entropy loss = 1.0789, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:47.884018 #train# step   92, loss = 1.0724, cross_entropy loss = 1.0724, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:49.441590 #train# step   93, loss = 1.0638, cross_entropy loss = 1.0638, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:51.033277 #train# step   94, loss = 1.0793, cross_entropy loss = 1.0793, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:52.589747 #train# step   95, loss = 1.0777, cross_entropy loss = 1.0777, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:54.139904 #train# step   96, loss = 1.0662, cross_entropy loss = 1.0662, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:55.695264 #train# step   97, loss = 1.0739, cross_entropy loss = 1.0739, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:57.227356 #train# step   98, loss = 1.0606, cross_entropy loss = 1.0606, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:03:58.799556 #train# step   99, loss = 1.0507, cross_entropy loss = 1.0507, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:00.335633 #train# step  100, loss = 1.1069, cross_entropy loss = 1.1069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:01.922403 #train# step  101, loss = 1.0655, cross_entropy loss = 1.0655, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:03.473950 #train# step  102, loss = 1.0810, cross_entropy loss = 1.0810, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:05.035338 #train# step  103, loss = 1.0857, cross_entropy loss = 1.0857, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:06.601250 #train# step  104, loss = 1.0897, cross_entropy loss = 1.0897, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:08.155903 #train# step  105, loss = 1.0572, cross_entropy loss = 1.0572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:09.705321 #train# step  106, loss = 1.0828, cross_entropy loss = 1.0828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:11.285572 #train# step  107, loss = 1.0679, cross_entropy loss = 1.0679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:12.837983 #train# step  108, loss = 1.0480, cross_entropy loss = 1.0480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:14.389985 #train# step  109, loss = 1.0422, cross_entropy loss = 1.0422, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:15.944371 #train# step  110, loss = 1.0766, cross_entropy loss = 1.0766, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:17.496222 #train# step  111, loss = 1.0581, cross_entropy loss = 1.0581, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:19.051652 #train# step  112, loss = 1.0652, cross_entropy loss = 1.0652, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:20.595283 #train# step  113, loss = 1.0557, cross_entropy loss = 1.0557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:22.124766 #train# step  114, loss = 1.0610, cross_entropy loss = 1.0610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:23.684669 #train# step  115, loss = 1.0403, cross_entropy loss = 1.0403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:25.243180 #train# step  116, loss = 1.0621, cross_entropy loss = 1.0621, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:26.791591 #train# step  117, loss = 1.0767, cross_entropy loss = 1.0767, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:28.367034 #train# step  118, loss = 1.0642, cross_entropy loss = 1.0642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:29.915153 #train# step  119, loss = 1.0808, cross_entropy loss = 1.0808, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:31.451763 #train# step  120, loss = 1.0522, cross_entropy loss = 1.0522, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:33.020968 #train# step  121, loss = 1.0528, cross_entropy loss = 1.0528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:34.557764 #train# step  122, loss = 1.0571, cross_entropy loss = 1.0571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:36.154782 #train# step  123, loss = 1.0621, cross_entropy loss = 1.0621, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:37.712742 #train# step  124, loss = 1.0514, cross_entropy loss = 1.0514, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:39.257804 #train# step  125, loss = 1.0772, cross_entropy loss = 1.0772, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:40.821561 #train# step  126, loss = 1.0593, cross_entropy loss = 1.0593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:42.386560 #train# step  127, loss = 1.0707, cross_entropy loss = 1.0707, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:43.959317 #train# step  128, loss = 1.0706, cross_entropy loss = 1.0706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:45.505198 #train# step  129, loss = 1.0570, cross_entropy loss = 1.0570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:47.072356 #train# step  130, loss = 1.0608, cross_entropy loss = 1.0608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:48.648382 #train# step  131, loss = 1.0431, cross_entropy loss = 1.0431, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:50.198434 #train# step  132, loss = 1.0645, cross_entropy loss = 1.0645, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:51.790545 #train# step  133, loss = 1.0480, cross_entropy loss = 1.0480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:53.341461 #train# step  134, loss = 1.0538, cross_entropy loss = 1.0538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:54.877401 #train# step  135, loss = 1.0542, cross_entropy loss = 1.0542, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:56.431991 #train# step  136, loss = 1.0611, cross_entropy loss = 1.0611, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:57.977378 #train# step  137, loss = 1.0584, cross_entropy loss = 1.0584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:04:59.567023 #train# step  138, loss = 1.0498, cross_entropy loss = 1.0498, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:01.129829 #train# step  139, loss = 1.0617, cross_entropy loss = 1.0617, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:02.692210 #train# step  140, loss = 1.0333, cross_entropy loss = 1.0333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:04.258362 #train# step  141, loss = 1.0545, cross_entropy loss = 1.0545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:05.797333 #train# step  142, loss = 1.0524, cross_entropy loss = 1.0524, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:07.334174 #train# step  143, loss = 1.0470, cross_entropy loss = 1.0470, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:08.882092 #train# step  144, loss = 1.0636, cross_entropy loss = 1.0636, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:10.450131 #train# step  145, loss = 1.0598, cross_entropy loss = 1.0598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:12.004031 #train# step  146, loss = 1.0537, cross_entropy loss = 1.0537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:13.576783 #train# step  147, loss = 1.0594, cross_entropy loss = 1.0594, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:15.170954 #train# step  148, loss = 1.0473, cross_entropy loss = 1.0473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:16.761969 #train# step  149, loss = 1.0547, cross_entropy loss = 1.0547, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:18.331308 #train# step  150, loss = 1.0545, cross_entropy loss = 1.0545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:19.906126 #train# step  151, loss = 1.0340, cross_entropy loss = 1.0340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:21.490251 #train# step  152, loss = 1.0496, cross_entropy loss = 1.0496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:23.046544 #train# step  153, loss = 1.0357, cross_entropy loss = 1.0357, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:24.620505 #train# step  154, loss = 1.0686, cross_entropy loss = 1.0686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:26.197436 #train# step  155, loss = 1.0427, cross_entropy loss = 1.0427, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:27.725378 #train# step  156, loss = 1.0562, cross_entropy loss = 1.0562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:29.276398 #train# step  157, loss = 1.0481, cross_entropy loss = 1.0481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:30.814314 #train# step  158, loss = 1.0426, cross_entropy loss = 1.0426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:32.406803 #train# step  159, loss = 1.0726, cross_entropy loss = 1.0726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:33.936210 #train# step  160, loss = 1.0520, cross_entropy loss = 1.0520, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:35.501658 #train# step  161, loss = 1.0470, cross_entropy loss = 1.0470, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:37.064232 #train# step  162, loss = 1.0386, cross_entropy loss = 1.0386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:38.636230 #train# step  163, loss = 1.0557, cross_entropy loss = 1.0557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:40.206112 #train# step  164, loss = 1.0406, cross_entropy loss = 1.0406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:41.756228 #train# step  165, loss = 1.0529, cross_entropy loss = 1.0529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:43.289687 #train# step  166, loss = 1.0784, cross_entropy loss = 1.0784, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:44.877261 #train# step  167, loss = 1.0460, cross_entropy loss = 1.0460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:46.441008 #train# step  168, loss = 1.0323, cross_entropy loss = 1.0323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:47.966083 #train# step  169, loss = 1.0447, cross_entropy loss = 1.0447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:49.506643 #train# step  170, loss = 1.0415, cross_entropy loss = 1.0415, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:51.064871 #train# step  171, loss = 1.0341, cross_entropy loss = 1.0341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:52.632380 #train# step  172, loss = 1.0471, cross_entropy loss = 1.0471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:54.163269 #train# step  173, loss = 1.0561, cross_entropy loss = 1.0561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:55.697703 #train# step  174, loss = 1.0635, cross_entropy loss = 1.0635, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:57.239527 #train# step  175, loss = 1.0468, cross_entropy loss = 1.0468, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:05:58.821629 #train# step  176, loss = 1.0262, cross_entropy loss = 1.0262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:00.376382 #train# step  177, loss = 1.0284, cross_entropy loss = 1.0284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:01.927179 #train# step  178, loss = 1.0419, cross_entropy loss = 1.0419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:03.442153 #train# step  179, loss = 1.0360, cross_entropy loss = 1.0360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:05.001821 #train# step  180, loss = 1.0433, cross_entropy loss = 1.0433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:06.569669 #train# step  181, loss = 1.0267, cross_entropy loss = 1.0267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:08.126610 #train# step  182, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:09.672597 #train# step  183, loss = 1.0352, cross_entropy loss = 1.0352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:11.236752 #train# step  184, loss = 1.0438, cross_entropy loss = 1.0438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:12.807689 #train# step  185, loss = 1.0269, cross_entropy loss = 1.0269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:14.350249 #train# step  186, loss = 1.0490, cross_entropy loss = 1.0490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:15.887724 #train# step  187, loss = 1.0276, cross_entropy loss = 1.0276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:17.487276 #train# step  188, loss = 1.0254, cross_entropy loss = 1.0254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:19.019807 #train# step  189, loss = 1.0590, cross_entropy loss = 1.0590, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:20.621898 #train# step  190, loss = 1.0377, cross_entropy loss = 1.0377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:22.187163 #train# step  191, loss = 1.0328, cross_entropy loss = 1.0328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:23.725334 #train# step  192, loss = 1.0251, cross_entropy loss = 1.0251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:25.290180 #train# step  193, loss = 1.0391, cross_entropy loss = 1.0391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:26.860872 #train# step  194, loss = 1.0249, cross_entropy loss = 1.0249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:28.419641 #train# step  195, loss = 1.0275, cross_entropy loss = 1.0275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:29.975526 #train# step  196, loss = 1.0409, cross_entropy loss = 1.0409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:31.552990 #train# step  197, loss = 1.0328, cross_entropy loss = 1.0328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:33.072641 #train# step  198, loss = 1.0298, cross_entropy loss = 1.0298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:34.623523 #train# step  199, loss = 1.0154, cross_entropy loss = 1.0154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:36.182451 #train# step  200, loss = 1.0393, cross_entropy loss = 1.0393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:37.725228 #train# step  201, loss = 1.0262, cross_entropy loss = 1.0262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:39.305946 #train# step  202, loss = 1.0399, cross_entropy loss = 1.0399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:40.897880 #train# step  203, loss = 1.0429, cross_entropy loss = 1.0429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:42.429796 #train# step  204, loss = 1.0466, cross_entropy loss = 1.0466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:43.995999 #train# step  205, loss = 1.0627, cross_entropy loss = 1.0627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:45.575683 #train# step  206, loss = 1.0187, cross_entropy loss = 1.0187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:47.133019 #train# step  207, loss = 1.0293, cross_entropy loss = 1.0293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:48.697485 #train# step  208, loss = 1.0205, cross_entropy loss = 1.0205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:50.284600 #train# step  209, loss = 1.0439, cross_entropy loss = 1.0439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:51.861962 #train# step  210, loss = 1.0191, cross_entropy loss = 1.0191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:53.422600 #train# step  211, loss = 1.0182, cross_entropy loss = 1.0182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:54.986269 #train# step  212, loss = 1.0293, cross_entropy loss = 1.0293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:56.581396 #train# step  213, loss = 1.0466, cross_entropy loss = 1.0466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:58.142647 #train# step  214, loss = 1.0387, cross_entropy loss = 1.0387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:06:59.675461 #train# step  215, loss = 1.0336, cross_entropy loss = 1.0336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:01.227230 #train# step  216, loss = 1.0286, cross_entropy loss = 1.0286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:02.780556 #train# step  217, loss = 1.0478, cross_entropy loss = 1.0478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:04.339613 #train# step  218, loss = 1.0154, cross_entropy loss = 1.0154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:05.880077 #train# step  219, loss = 1.0331, cross_entropy loss = 1.0331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:07.431974 #train# step  220, loss = 1.0549, cross_entropy loss = 1.0549, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:08.990104 #train# step  221, loss = 1.0362, cross_entropy loss = 1.0362, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:10.545825 #train# step  222, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:12.116225 #train# step  223, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:13.696743 #train# step  224, loss = 1.0496, cross_entropy loss = 1.0496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:15.250695 #train# step  225, loss = 1.0251, cross_entropy loss = 1.0251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:16.795600 #train# step  226, loss = 1.0440, cross_entropy loss = 1.0440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:18.332873 #train# step  227, loss = 1.0298, cross_entropy loss = 1.0298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:19.890687 #train# step  228, loss = 1.0279, cross_entropy loss = 1.0279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:21.483097 #train# step  229, loss = 1.0290, cross_entropy loss = 1.0290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:23.037074 #train# step  230, loss = 1.0096, cross_entropy loss = 1.0096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:24.628528 #train# step  231, loss = 1.0099, cross_entropy loss = 1.0099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:26.160933 #train# step  232, loss = 1.0306, cross_entropy loss = 1.0306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:27.675383 #train# step  233, loss = 1.0248, cross_entropy loss = 1.0248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:29.222519 #train# step  234, loss = 1.0155, cross_entropy loss = 1.0155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:30.753002 #train# step  235, loss = 1.0320, cross_entropy loss = 1.0320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:32.322616 #train# step  236, loss = 1.0337, cross_entropy loss = 1.0337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:33.883198 #train# step  237, loss = 1.0288, cross_entropy loss = 1.0288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:35.427743 #train# step  238, loss = 1.0356, cross_entropy loss = 1.0356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:37.015626 #train# step  239, loss = 1.0205, cross_entropy loss = 1.0205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:38.568525 #train# step  240, loss = 1.0150, cross_entropy loss = 1.0150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:40.119677 #train# step  241, loss = 1.0330, cross_entropy loss = 1.0330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:41.664200 #train# step  242, loss = 1.0243, cross_entropy loss = 1.0243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:43.222855 #train# step  243, loss = 1.0143, cross_entropy loss = 1.0143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:44.778235 #train# step  244, loss = 1.0138, cross_entropy loss = 1.0138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:46.322663 #train# step  245, loss = 1.0164, cross_entropy loss = 1.0164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:47.861199 #train# step  246, loss = 1.0265, cross_entropy loss = 1.0265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:49.408852 #train# step  247, loss = 1.0230, cross_entropy loss = 1.0230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:50.963975 #train# step  248, loss = 1.0291, cross_entropy loss = 1.0291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:52.532152 #train# step  249, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:54.097981 #train# step  250, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:55.663491 #train# step  251, loss = 1.0107, cross_entropy loss = 1.0107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:57.209882 #train# step  252, loss = 1.0136, cross_entropy loss = 1.0136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:07:58.746238 #train# step  253, loss = 1.0266, cross_entropy loss = 1.0266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:00.310634 #train# step  254, loss = 1.0186, cross_entropy loss = 1.0186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:01.871197 #train# step  255, loss = 1.0018, cross_entropy loss = 1.0018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:03.437377 #train# step  256, loss = 1.0194, cross_entropy loss = 1.0194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:04.986092 #train# step  257, loss = 1.0244, cross_entropy loss = 1.0244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:06.542007 #train# step  258, loss = 1.0206, cross_entropy loss = 1.0206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:08.114849 #train# step  259, loss = 1.0216, cross_entropy loss = 1.0216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:09.683459 #train# step  260, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:11.257650 #train# step  261, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:12.786115 #train# step  262, loss = 1.0183, cross_entropy loss = 1.0183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:14.356461 #train# step  263, loss = 1.0351, cross_entropy loss = 1.0351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:15.922180 #train# step  264, loss = 1.0169, cross_entropy loss = 1.0169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:17.474023 #train# step  265, loss = 1.0072, cross_entropy loss = 1.0072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:19.040843 #train# step  266, loss = 1.0289, cross_entropy loss = 1.0289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:20.581012 #train# step  267, loss = 1.0203, cross_entropy loss = 1.0203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:22.129196 #train# step  268, loss = 1.0198, cross_entropy loss = 1.0198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:23.700922 #train# step  269, loss = 1.0151, cross_entropy loss = 1.0151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:25.280996 #train# step  270, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:26.875704 #train# step  271, loss = 1.0172, cross_entropy loss = 1.0172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:28.407700 #train# step  272, loss = 1.0121, cross_entropy loss = 1.0121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:29.968044 #train# step  273, loss = 1.0163, cross_entropy loss = 1.0163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:31.546246 #train# step  274, loss = 1.0227, cross_entropy loss = 1.0227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:33.088176 #train# step  275, loss = 1.0397, cross_entropy loss = 1.0397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:34.643679 #train# step  276, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:36.201413 #train# step  277, loss = 1.0183, cross_entropy loss = 1.0183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:37.784345 #train# step  278, loss = 1.0143, cross_entropy loss = 1.0143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:39.348380 #train# step  279, loss = 1.0066, cross_entropy loss = 1.0066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:40.914589 #train# step  280, loss = 1.0390, cross_entropy loss = 1.0390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:42.468351 #train# step  281, loss = 1.0127, cross_entropy loss = 1.0127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:44.019893 #train# step  282, loss = 1.0218, cross_entropy loss = 1.0218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:45.595141 #train# step  283, loss = 1.0100, cross_entropy loss = 1.0100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:47.193298 #train# step  284, loss = 1.0107, cross_entropy loss = 1.0107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:48.734043 #train# step  285, loss = 1.0315, cross_entropy loss = 1.0315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:50.282805 #train# step  286, loss = 1.0182, cross_entropy loss = 1.0182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:51.816800 #train# step  287, loss = 1.0172, cross_entropy loss = 1.0172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:53.371704 #train# step  288, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:54.891864 #train# step  289, loss = 1.0110, cross_entropy loss = 1.0110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:56.440324 #train# step  290, loss = 1.0390, cross_entropy loss = 1.0390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:57.992497 #train# step  291, loss = 1.0089, cross_entropy loss = 1.0089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:08:59.538077 #train# step  292, loss = 1.0048, cross_entropy loss = 1.0048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:01.063273 #train# step  293, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:02.641360 #train# step  294, loss = 1.0142, cross_entropy loss = 1.0142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:04.182139 #train# step  295, loss = 1.0224, cross_entropy loss = 1.0224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:05.755968 #train# step  296, loss = 1.0198, cross_entropy loss = 1.0198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:07.351179 #train# step  297, loss = 0.9914, cross_entropy loss = 0.9914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:08.915942 #train# step  298, loss = 1.0198, cross_entropy loss = 1.0198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:10.493790 #train# step  299, loss = 1.0193, cross_entropy loss = 1.0193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:12.061691 #train# step  300, loss = 1.0181, cross_entropy loss = 1.0181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:13.641949 #train# step  301, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:15.184536 #train# step  302, loss = 1.0217, cross_entropy loss = 1.0217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:16.731044 #train# step  303, loss = 1.0057, cross_entropy loss = 1.0057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:18.311808 #train# step  304, loss = 0.9962, cross_entropy loss = 0.9962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:19.901013 #train# step  305, loss = 1.0042, cross_entropy loss = 1.0042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:21.492936 #train# step  306, loss = 1.0218, cross_entropy loss = 1.0218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:23.069850 #train# step  307, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:24.621688 #train# step  308, loss = 1.0159, cross_entropy loss = 1.0159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:26.163404 #train# step  309, loss = 1.0307, cross_entropy loss = 1.0307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:27.705372 #train# step  310, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:29.268721 #train# step  311, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:30.817309 #train# step  312, loss = 1.0092, cross_entropy loss = 1.0092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:32.378520 #train# step  313, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:33.944814 #train# step  314, loss = 1.0118, cross_entropy loss = 1.0118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:35.482482 #train# step  315, loss = 1.0140, cross_entropy loss = 1.0140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:37.033259 #train# step  316, loss = 1.0183, cross_entropy loss = 1.0183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:38.601090 #train# step  317, loss = 1.0064, cross_entropy loss = 1.0064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:40.193952 #train# step  318, loss = 1.0103, cross_entropy loss = 1.0103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:41.740316 #train# step  319, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:43.263401 #train# step  320, loss = 1.0190, cross_entropy loss = 1.0190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:44.847267 #train# step  321, loss = 1.0009, cross_entropy loss = 1.0009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:46.411574 #train# step  322, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:47.985179 #train# step  323, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:49.517523 #train# step  324, loss = 1.0242, cross_entropy loss = 1.0242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:51.067600 #train# step  325, loss = 1.0133, cross_entropy loss = 1.0133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:52.634878 #train# step  326, loss = 1.0046, cross_entropy loss = 1.0046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:54.197008 #train# step  327, loss = 1.0194, cross_entropy loss = 1.0194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:55.790733 #train# step  328, loss = 1.0149, cross_entropy loss = 1.0149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:57.324617 #train# step  329, loss = 1.0297, cross_entropy loss = 1.0297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:09:58.852918 #train# step  330, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:00.421816 #train# step  331, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:01.945318 #train# step  332, loss = 1.0168, cross_entropy loss = 1.0168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:03.476838 #train# step  333, loss = 1.0390, cross_entropy loss = 1.0390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:05.046877 #train# step  334, loss = 1.0135, cross_entropy loss = 1.0135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:06.615520 #train# step  335, loss = 1.0030, cross_entropy loss = 1.0030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:08.148935 #train# step  336, loss = 0.9982, cross_entropy loss = 0.9982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:09.704843 #train# step  337, loss = 1.0290, cross_entropy loss = 1.0290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:11.291762 #train# step  338, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:12.813498 #train# step  339, loss = 1.0072, cross_entropy loss = 1.0072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:14.397344 #train# step  340, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:15.928492 #train# step  341, loss = 1.0187, cross_entropy loss = 1.0187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:17.485676 #train# step  342, loss = 1.0090, cross_entropy loss = 1.0090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:19.062255 #train# step  343, loss = 1.0128, cross_entropy loss = 1.0128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:20.624706 #train# step  344, loss = 1.0176, cross_entropy loss = 1.0176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:22.203893 #train# step  345, loss = 1.0011, cross_entropy loss = 1.0011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:23.740188 #train# step  346, loss = 0.9926, cross_entropy loss = 0.9926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:25.324516 #train# step  347, loss = 0.9883, cross_entropy loss = 0.9883, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:26.872640 #train# step  348, loss = 1.0131, cross_entropy loss = 1.0131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:28.448755 #train# step  349, loss = 1.0067, cross_entropy loss = 1.0067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:30.033705 #train# step  350, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:31.589036 #train# step  351, loss = 0.9966, cross_entropy loss = 0.9966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:33.139953 #train# step  352, loss = 1.0085, cross_entropy loss = 1.0085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:34.718646 #train# step  353, loss = 0.9968, cross_entropy loss = 0.9968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:36.305263 #train# step  354, loss = 1.0015, cross_entropy loss = 1.0015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:37.839839 #train# step  355, loss = 1.0083, cross_entropy loss = 1.0083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:39.389202 #train# step  356, loss = 0.9978, cross_entropy loss = 0.9978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:40.968719 #train# step  357, loss = 0.9969, cross_entropy loss = 0.9969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:42.539384 #train# step  358, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:44.074791 #train# step  359, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:45.595807 #train# step  360, loss = 1.0162, cross_entropy loss = 1.0162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:47.149172 #train# step  361, loss = 0.9955, cross_entropy loss = 0.9955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:48.747575 #train# step  362, loss = 1.0111, cross_entropy loss = 1.0111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:50.327180 #train# step  363, loss = 0.9977, cross_entropy loss = 0.9977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:51.894456 #train# step  364, loss = 1.0210, cross_entropy loss = 1.0210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:53.451625 #train# step  365, loss = 1.0199, cross_entropy loss = 1.0199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:55.006194 #train# step  366, loss = 1.0045, cross_entropy loss = 1.0045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:56.573183 #train# step  367, loss = 0.9958, cross_entropy loss = 0.9958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:58.108886 #train# step  368, loss = 1.0057, cross_entropy loss = 1.0057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:10:59.674868 #train# step  369, loss = 0.9962, cross_entropy loss = 0.9962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:01.255347 #train# step  370, loss = 1.0131, cross_entropy loss = 1.0131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:02.806522 #train# step  371, loss = 0.9936, cross_entropy loss = 0.9936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:04.359055 #train# step  372, loss = 0.9954, cross_entropy loss = 0.9954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:05.921288 #train# step  373, loss = 1.0067, cross_entropy loss = 1.0067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:07.466390 #train# step  374, loss = 1.0019, cross_entropy loss = 1.0019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:09.063690 #train# step  375, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:10.609689 #train# step  376, loss = 0.9988, cross_entropy loss = 0.9988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:12.171061 #train# step  377, loss = 1.0018, cross_entropy loss = 1.0018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:13.713315 #train# step  378, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:15.277155 #train# step  379, loss = 0.9820, cross_entropy loss = 0.9820, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:16.837894 #train# step  380, loss = 1.0014, cross_entropy loss = 1.0014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:18.359065 #train# step  381, loss = 1.0074, cross_entropy loss = 1.0074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:19.897376 #train# step  382, loss = 0.9984, cross_entropy loss = 0.9984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:21.493654 #train# step  383, loss = 1.0162, cross_entropy loss = 1.0162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:23.057722 #train# step  384, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:24.598594 #train# step  385, loss = 1.0084, cross_entropy loss = 1.0084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:26.187535 #train# step  386, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:27.746414 #train# step  387, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:29.301008 #train# step  388, loss = 0.9929, cross_entropy loss = 0.9929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:30.843782 #train# step  389, loss = 1.0144, cross_entropy loss = 1.0144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:32.432563 #train# step  390, loss = 0.9991, cross_entropy loss = 0.9991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:33.980188 #train# step  391, loss = 1.0063, cross_entropy loss = 1.0063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:35.542286 #train# step  392, loss = 1.0050, cross_entropy loss = 1.0050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:37.114677 #train# step  393, loss = 0.9841, cross_entropy loss = 0.9841, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:38.670366 #train# step  394, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:40.241158 #train# step  395, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:41.804858 #train# step  396, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:43.380847 #train# step  397, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:44.942354 #train# step  398, loss = 1.0051, cross_entropy loss = 1.0051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:46.502226 #train# step  399, loss = 0.9988, cross_entropy loss = 0.9988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:48.050980 #train# step  400, loss = 0.9934, cross_entropy loss = 0.9934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:49.620285 #train# step  401, loss = 0.9906, cross_entropy loss = 0.9906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:51.183456 #train# step  402, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:52.700998 #train# step  403, loss = 1.0092, cross_entropy loss = 1.0092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:54.255549 #train# step  404, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:55.823340 #train# step  405, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:57.392337 #train# step  406, loss = 1.0012, cross_entropy loss = 1.0012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:11:58.953382 #train# step  407, loss = 1.0209, cross_entropy loss = 1.0209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:00.530381 #train# step  408, loss = 0.9967, cross_entropy loss = 0.9967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:02.097967 #train# step  409, loss = 1.0039, cross_entropy loss = 1.0039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:03.625802 #train# step  410, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:05.153568 #train# step  411, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:06.673367 #train# step  412, loss = 1.0240, cross_entropy loss = 1.0240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:08.215137 #train# step  413, loss = 0.9964, cross_entropy loss = 0.9964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:09.757108 #train# step  414, loss = 1.0168, cross_entropy loss = 1.0168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:11.296388 #train# step  415, loss = 1.0136, cross_entropy loss = 1.0136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:12.884714 #train# step  416, loss = 0.9925, cross_entropy loss = 0.9925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:14.455805 #train# step  417, loss = 1.0049, cross_entropy loss = 1.0049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:16.064002 #train# step  418, loss = 0.9940, cross_entropy loss = 0.9940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:17.627482 #train# step  419, loss = 1.0029, cross_entropy loss = 1.0029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:19.200213 #train# step  420, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:20.771374 #train# step  421, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:22.313802 #train# step  422, loss = 0.9883, cross_entropy loss = 0.9883, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:23.864455 #train# step  423, loss = 1.0040, cross_entropy loss = 1.0040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:25.401850 #train# step  424, loss = 0.9972, cross_entropy loss = 0.9972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:26.941627 #train# step  425, loss = 0.9888, cross_entropy loss = 0.9888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:28.480909 #train# step  426, loss = 0.9987, cross_entropy loss = 0.9987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:30.063376 #train# step  427, loss = 0.9965, cross_entropy loss = 0.9965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:31.627447 #train# step  428, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:33.199953 #train# step  429, loss = 0.9874, cross_entropy loss = 0.9874, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:34.727563 #train# step  430, loss = 1.0042, cross_entropy loss = 1.0042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:36.265025 #train# step  431, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:37.814728 #train# step  432, loss = 0.9976, cross_entropy loss = 0.9976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:39.352667 #train# step  433, loss = 0.9980, cross_entropy loss = 0.9980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:40.922096 #train# step  434, loss = 1.0232, cross_entropy loss = 1.0232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:42.507878 #train# step  435, loss = 1.0034, cross_entropy loss = 1.0034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:44.085841 #train# step  436, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:45.673783 #train# step  437, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:47.242317 #train# step  438, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:48.781092 #train# step  439, loss = 0.9799, cross_entropy loss = 0.9799, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:50.323664 #train# step  440, loss = 1.0062, cross_entropy loss = 1.0062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:51.907405 #train# step  441, loss = 0.9942, cross_entropy loss = 0.9942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:53.440080 #train# step  442, loss = 0.9979, cross_entropy loss = 0.9979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:54.986886 #train# step  443, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:56.526403 #train# step  444, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:58.122171 #train# step  445, loss = 1.0036, cross_entropy loss = 1.0036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:12:59.674954 #train# step  446, loss = 1.0105, cross_entropy loss = 1.0105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:01.241328 #train# step  447, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:02.798063 #train# step  448, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:04.369417 #train# step  449, loss = 0.9980, cross_entropy loss = 0.9980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:05.913161 #train# step  450, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:07.473052 #train# step  451, loss = 0.9928, cross_entropy loss = 0.9928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:09.023561 #train# step  452, loss = 1.0044, cross_entropy loss = 1.0044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:10.590445 #train# step  453, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:12.166754 #train# step  454, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:13.707242 #train# step  455, loss = 0.9830, cross_entropy loss = 0.9830, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:15.274406 #train# step  456, loss = 0.9913, cross_entropy loss = 0.9913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:16.817648 #train# step  457, loss = 1.0063, cross_entropy loss = 1.0063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:18.368607 #train# step  458, loss = 1.0125, cross_entropy loss = 1.0125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:19.930709 #train# step  459, loss = 1.0116, cross_entropy loss = 1.0116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:21.510548 #train# step  460, loss = 0.9986, cross_entropy loss = 0.9986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:23.055153 #train# step  461, loss = 0.9935, cross_entropy loss = 0.9935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:24.612295 #train# step  462, loss = 0.9770, cross_entropy loss = 0.9770, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:26.166075 #train# step  463, loss = 0.9966, cross_entropy loss = 0.9966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:27.740291 #train# step  464, loss = 1.0091, cross_entropy loss = 1.0091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:29.315646 #train# step  465, loss = 0.9862, cross_entropy loss = 0.9862, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:30.893917 #train# step  466, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:32.457578 #train# step  467, loss = 0.9976, cross_entropy loss = 0.9976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:34.017986 #train# step  468, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:35.585695 #train# step  469, loss = 0.9909, cross_entropy loss = 0.9909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:37.130910 #train# step  470, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:38.684070 #train# step  471, loss = 1.0084, cross_entropy loss = 1.0084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:40.255166 #train# step  472, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:41.801029 #train# step  473, loss = 1.0071, cross_entropy loss = 1.0071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:43.380183 #train# step  474, loss = 0.9865, cross_entropy loss = 0.9865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:44.958444 #train# step  475, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:46.511338 #train# step  476, loss = 0.9790, cross_entropy loss = 0.9790, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:48.052949 #train# step  477, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:49.620842 #train# step  478, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:51.191223 #train# step  479, loss = 0.9877, cross_entropy loss = 0.9877, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:52.755434 #train# step  480, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:54.291866 #train# step  481, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:55.846750 #train# step  482, loss = 0.9911, cross_entropy loss = 0.9911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:57.398718 #train# step  483, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:13:58.943867 #train# step  484, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:00.489860 #train# step  485, loss = 0.9916, cross_entropy loss = 0.9916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:02.034222 #train# step  486, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:03.612151 #train# step  487, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:05.129301 #train# step  488, loss = 0.9908, cross_entropy loss = 0.9908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:06.703827 #train# step  489, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:08.274033 #train# step  490, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:09.814130 #train# step  491, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:11.386401 #train# step  492, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:12.921819 #train# step  493, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:14.473910 #train# step  494, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:16.023358 #train# step  495, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:17.581040 #train# step  496, loss = 0.9914, cross_entropy loss = 0.9914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:19.155751 #train# step  497, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:20.714856 #train# step  498, loss = 0.9911, cross_entropy loss = 0.9911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:22.277611 #train# step  499, loss = 1.0042, cross_entropy loss = 1.0042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:23.827003 #train# step  500, loss = 1.0072, cross_entropy loss = 1.0072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:25.400757 #train# step  501, loss = 0.9795, cross_entropy loss = 0.9795, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:26.982116 #train# step  502, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:28.576658 #train# step  503, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:30.127951 #train# step  504, loss = 0.9979, cross_entropy loss = 0.9979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:31.689097 #train# step  505, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:33.259250 #train# step  506, loss = 0.9822, cross_entropy loss = 0.9822, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:34.800950 #train# step  507, loss = 0.9996, cross_entropy loss = 0.9996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:36.374000 #train# step  508, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:37.951371 #train# step  509, loss = 0.9980, cross_entropy loss = 0.9980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:39.515025 #train# step  510, loss = 0.9845, cross_entropy loss = 0.9845, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:41.070495 #train# step  511, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:42.596550 #train# step  512, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:44.151852 #train# step  513, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:45.702407 #train# step  514, loss = 0.9834, cross_entropy loss = 0.9834, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:47.238906 #train# step  515, loss = 0.9994, cross_entropy loss = 0.9994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:48.821422 #train# step  516, loss = 1.0023, cross_entropy loss = 1.0023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:50.398545 #train# step  517, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:51.953238 #train# step  518, loss = 1.0043, cross_entropy loss = 1.0043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:53.512723 #train# step  519, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:55.045034 #train# step  520, loss = 0.9844, cross_entropy loss = 0.9844, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:56.606006 #train# step  521, loss = 1.0214, cross_entropy loss = 1.0214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:58.148320 #train# step  522, loss = 0.9959, cross_entropy loss = 0.9959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:14:59.725666 #train# step  523, loss = 0.9716, cross_entropy loss = 0.9716, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:01.290530 #train# step  524, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:02.847167 #train# step  525, loss = 1.0013, cross_entropy loss = 1.0013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:04.412552 #train# step  526, loss = 0.9970, cross_entropy loss = 0.9970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:05.969086 #train# step  527, loss = 1.0077, cross_entropy loss = 1.0077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:07.519330 #train# step  528, loss = 1.0054, cross_entropy loss = 1.0054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:09.079626 #train# step  529, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:10.654981 #train# step  530, loss = 0.9765, cross_entropy loss = 0.9765, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:12.181194 #train# step  531, loss = 0.9976, cross_entropy loss = 0.9976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:13.765328 #train# step  532, loss = 0.9873, cross_entropy loss = 0.9873, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:15.318374 #train# step  533, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:16.910565 #train# step  534, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:18.478017 #train# step  535, loss = 0.9963, cross_entropy loss = 0.9963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:20.009747 #train# step  536, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:21.545971 #train# step  537, loss = 0.9869, cross_entropy loss = 0.9869, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:23.088902 #train# step  538, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:24.641344 #train# step  539, loss = 0.9865, cross_entropy loss = 0.9865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:26.210938 #train# step  540, loss = 0.9882, cross_entropy loss = 0.9882, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:27.737361 #train# step  541, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:29.307160 #train# step  542, loss = 0.9833, cross_entropy loss = 0.9833, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:30.853408 #train# step  543, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:32.424868 #train# step  544, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:34.010542 #train# step  545, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:35.602989 #train# step  546, loss = 0.9880, cross_entropy loss = 0.9880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:37.153252 #train# step  547, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:38.727389 #train# step  548, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:40.315166 #train# step  549, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:41.882875 #train# step  550, loss = 0.9847, cross_entropy loss = 0.9847, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:43.434622 #train# step  551, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:45.024508 #train# step  552, loss = 0.9981, cross_entropy loss = 0.9981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:46.567812 #train# step  553, loss = 0.9795, cross_entropy loss = 0.9795, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:48.144684 #train# step  554, loss = 0.9819, cross_entropy loss = 0.9819, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:49.709147 #train# step  555, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:51.263472 #train# step  556, loss = 1.0065, cross_entropy loss = 1.0065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:52.783740 #train# step  557, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:54.378931 #train# step  558, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:55.976208 #train# step  559, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:57.535071 #train# step  560, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:15:59.059874 #train# step  561, loss = 0.9878, cross_entropy loss = 0.9878, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:00.625278 #train# step  562, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:02.156588 #train# step  563, loss = 0.9921, cross_entropy loss = 0.9921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:03.727628 #train# step  564, loss = 0.9910, cross_entropy loss = 0.9910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:05.283984 #train# step  565, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:06.846734 #train# step  566, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:08.412025 #train# step  567, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:09.956924 #train# step  568, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:11.520192 #train# step  569, loss = 0.9997, cross_entropy loss = 0.9997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:13.110606 #train# step  570, loss = 0.9736, cross_entropy loss = 0.9736, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:14.653648 #train# step  571, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:16.202022 #train# step  572, loss = 0.9737, cross_entropy loss = 0.9737, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:17.741253 #train# step  573, loss = 0.9920, cross_entropy loss = 0.9920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:19.334309 #train# step  574, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:20.884417 #train# step  575, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:22.435856 #train# step  576, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:23.996155 #train# step  577, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:25.540065 #train# step  578, loss = 0.9922, cross_entropy loss = 0.9922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:27.086443 #train# step  579, loss = 0.9951, cross_entropy loss = 0.9951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:28.640441 #train# step  580, loss = 0.9998, cross_entropy loss = 0.9998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:30.200383 #train# step  581, loss = 0.9836, cross_entropy loss = 0.9836, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:31.767815 #train# step  582, loss = 0.9905, cross_entropy loss = 0.9905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:33.311321 #train# step  583, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:34.870080 #train# step  584, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:36.431829 #train# step  585, loss = 0.9969, cross_entropy loss = 0.9969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:37.971055 #train# step  586, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:39.537526 #train# step  587, loss = 0.9871, cross_entropy loss = 0.9871, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:41.090835 #train# step  588, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:42.673460 #train# step  589, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:44.225799 #train# step  590, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:45.757416 #train# step  591, loss = 0.9988, cross_entropy loss = 0.9988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:47.282536 #train# step  592, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:48.884368 #train# step  593, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:50.401636 #train# step  594, loss = 0.9902, cross_entropy loss = 0.9902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:51.925937 #train# step  595, loss = 1.0007, cross_entropy loss = 1.0007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:53.504672 #train# step  596, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:55.053516 #train# step  597, loss = 1.0006, cross_entropy loss = 1.0006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:56.687915 #train# step  598, loss = 0.9660, cross_entropy loss = 0.9660, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:58.233865 #train# step  599, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:16:59.808566 #train# step  600, loss = 0.9917, cross_entropy loss = 0.9917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:01.381383 #train# step  601, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:02.973025 #train# step  602, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:04.558852 #train# step  603, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:06.117492 #train# step  604, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:07.691112 #train# step  605, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:09.236349 #train# step  606, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:10.801133 #train# step  607, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:12.367139 #train# step  608, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:13.916511 #train# step  609, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:15.507578 #train# step  610, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:17.074120 #train# step  611, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:18.637096 #train# step  612, loss = 0.9900, cross_entropy loss = 0.9900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:20.199474 #train# step  613, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:21.735492 #train# step  614, loss = 0.9824, cross_entropy loss = 0.9824, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:23.305634 #train# step  615, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:24.827106 #train# step  616, loss = 1.0072, cross_entropy loss = 1.0072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:26.381485 #train# step  617, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:27.960452 #train# step  618, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:29.549078 #train# step  619, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:31.141543 #train# step  620, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:32.712970 #train# step  621, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:34.303698 #train# step  622, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:35.830056 #train# step  623, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:37.408985 #train# step  624, loss = 0.9961, cross_entropy loss = 0.9961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:38.945567 #train# step  625, loss = 0.9950, cross_entropy loss = 0.9950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:40.507615 #train# step  626, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:42.048828 #train# step  627, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:43.594367 #train# step  628, loss = 1.0008, cross_entropy loss = 1.0008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:45.193708 #train# step  629, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:46.756957 #train# step  630, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:48.303785 #train# step  631, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:49.849816 #train# step  632, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:51.425542 #train# step  633, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:52.997102 #train# step  634, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:54.585804 #train# step  635, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:56.125160 #train# step  636, loss = 0.9985, cross_entropy loss = 0.9985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:57.672987 #train# step  637, loss = 0.9999, cross_entropy loss = 0.9999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:17:59.223960 #train# step  638, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:00.756873 #train# step  639, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:02.308366 #train# step  640, loss = 0.9843, cross_entropy loss = 0.9843, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:03.865905 #train# step  641, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:05.426200 #train# step  642, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:06.996169 #train# step  643, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:08.581536 #train# step  644, loss = 0.9772, cross_entropy loss = 0.9772, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:10.128525 #train# step  645, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:11.703148 #train# step  646, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:13.249009 #train# step  647, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:14.829333 #train# step  648, loss = 0.9888, cross_entropy loss = 0.9888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:16.394188 #train# step  649, loss = 0.9937, cross_entropy loss = 0.9937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:17.981641 #train# step  650, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:19.549043 #train# step  651, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:21.106903 #train# step  652, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:22.668985 #train# step  653, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:24.225070 #train# step  654, loss = 0.9941, cross_entropy loss = 0.9941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:25.745215 #train# step  655, loss = 0.9894, cross_entropy loss = 0.9894, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:27.284332 #train# step  656, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:28.840054 #train# step  657, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:30.418015 #train# step  658, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:31.960419 #train# step  659, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:33.533213 #train# step  660, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:35.074809 #train# step  661, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:36.604851 #train# step  662, loss = 0.9811, cross_entropy loss = 0.9811, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:38.156777 #train# step  663, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:39.726168 #train# step  664, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:41.291445 #train# step  665, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:42.840946 #train# step  666, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:44.403632 #train# step  667, loss = 0.9917, cross_entropy loss = 0.9917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:45.959737 #train# step  668, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:47.504679 #train# step  669, loss = 0.9853, cross_entropy loss = 0.9853, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:49.059563 #train# step  670, loss = 0.9863, cross_entropy loss = 0.9863, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:50.622066 #train# step  671, loss = 0.9992, cross_entropy loss = 0.9992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:52.149985 #train# step  672, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:53.743642 #train# step  673, loss = 0.9924, cross_entropy loss = 0.9924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:55.301343 #train# step  674, loss = 0.9810, cross_entropy loss = 0.9810, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:56.860213 #train# step  675, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:58.418877 #train# step  676, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:18:59.975739 #train# step  677, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:01.528633 #train# step  678, loss = 0.9738, cross_entropy loss = 0.9738, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:03.090181 #train# step  679, loss = 0.9901, cross_entropy loss = 0.9901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:04.637673 #train# step  680, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:06.211788 #train# step  681, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:07.768297 #train# step  682, loss = 0.9785, cross_entropy loss = 0.9785, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:09.321849 #train# step  683, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:10.903000 #train# step  684, loss = 0.9932, cross_entropy loss = 0.9932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:12.463788 #train# step  685, loss = 0.9875, cross_entropy loss = 0.9875, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:14.038323 #train# step  686, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:15.597827 #train# step  687, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:17.184425 #train# step  688, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:18.747344 #train# step  689, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:20.256178 #train# step  690, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:21.818746 #train# step  691, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:23.371749 #train# step  692, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:24.940293 #train# step  693, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:26.502390 #train# step  694, loss = 0.9912, cross_entropy loss = 0.9912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:28.063646 #train# step  695, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:29.660529 #train# step  696, loss = 0.9838, cross_entropy loss = 0.9838, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:31.225371 #train# step  697, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:32.761769 #train# step  698, loss = 0.9793, cross_entropy loss = 0.9793, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:34.306210 #train# step  699, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:35.878178 #train# step  700, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:37.432794 #train# step  701, loss = 0.9752, cross_entropy loss = 0.9752, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:38.972845 #train# step  702, loss = 0.9807, cross_entropy loss = 0.9807, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:40.531252 #train# step  703, loss = 0.9887, cross_entropy loss = 0.9887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:42.128410 #train# step  704, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:43.712480 #train# step  705, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:45.260941 #train# step  706, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:46.835872 #train# step  707, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:48.414206 #train# step  708, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:49.958109 #train# step  709, loss = 0.9858, cross_entropy loss = 0.9858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:51.524345 #train# step  710, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:53.078742 #train# step  711, loss = 0.9889, cross_entropy loss = 0.9889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:54.643479 #train# step  712, loss = 0.9827, cross_entropy loss = 0.9827, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:56.192445 #train# step  713, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:57.776049 #train# step  714, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:19:59.342010 #train# step  715, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:00.892209 #train# step  716, loss = 0.9903, cross_entropy loss = 0.9903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:02.461738 #train# step  717, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:03.991427 #train# step  718, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:05.522441 #train# step  719, loss = 0.9973, cross_entropy loss = 0.9973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:07.104687 #train# step  720, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:08.641934 #train# step  721, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:10.204356 #train# step  722, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:11.805131 #train# step  723, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:13.358358 #train# step  724, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:14.924287 #train# step  725, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:16.513636 #train# step  726, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:18.049120 #train# step  727, loss = 0.9824, cross_entropy loss = 0.9824, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:19.597961 #train# step  728, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:21.134187 #train# step  729, loss = 0.9876, cross_entropy loss = 0.9876, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:22.707228 #train# step  730, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:24.270806 #train# step  731, loss = 0.9956, cross_entropy loss = 0.9956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:25.842727 #train# step  732, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:27.422094 #train# step  733, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:29.007130 #train# step  734, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:30.591918 #train# step  735, loss = 0.9733, cross_entropy loss = 0.9733, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:32.159198 #train# step  736, loss = 0.9771, cross_entropy loss = 0.9771, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:33.711068 #train# step  737, loss = 0.9886, cross_entropy loss = 0.9886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:35.277158 #train# step  738, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:36.823559 #train# step  739, loss = 0.9896, cross_entropy loss = 0.9896, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:38.391332 #train# step  740, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:39.961686 #train# step  741, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:41.525329 #train# step  742, loss = 0.9952, cross_entropy loss = 0.9952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:43.074469 #train# step  743, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:44.587314 #train# step  744, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:46.135800 #train# step  745, loss = 0.9948, cross_entropy loss = 0.9948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:47.657419 #train# step  746, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:49.234924 #train# step  747, loss = 0.9814, cross_entropy loss = 0.9814, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:50.789047 #train# step  748, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:52.351292 #train# step  749, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:53.881469 #train# step  750, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:55.460901 #train# step  751, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:57.003896 #train# step  752, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:20:58.567700 #train# step  753, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:00.130893 #train# step  754, loss = 1.0062, cross_entropy loss = 1.0062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:01.706530 #train# step  755, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:03.270504 #train# step  756, loss = 0.9971, cross_entropy loss = 0.9971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:04.828034 #train# step  757, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:06.352474 #train# step  758, loss = 0.9904, cross_entropy loss = 0.9904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:07.916076 #train# step  759, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:09.492760 #train# step  760, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:11.058302 #train# step  761, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:12.608785 #train# step  762, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:14.174580 #train# step  763, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:15.717104 #train# step  764, loss = 0.9915, cross_entropy loss = 0.9915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:17.278044 #train# step  765, loss = 0.9812, cross_entropy loss = 0.9812, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:18.823947 #train# step  766, loss = 0.9789, cross_entropy loss = 0.9789, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:20.372681 #train# step  767, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:21.922134 #train# step  768, loss = 0.9795, cross_entropy loss = 0.9795, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:23.502271 #train# step  769, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:25.079316 #train# step  770, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:26.636429 #train# step  771, loss = 0.9859, cross_entropy loss = 0.9859, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:28.190589 #train# step  772, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:29.737291 #train# step  773, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:31.262948 #train# step  774, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:32.820550 #train# step  775, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:34.363612 #train# step  776, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:35.897732 #train# step  777, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:37.458837 #train# step  778, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:39.035465 #train# step  779, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:40.598452 #train# step  780, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:42.145638 #train# step  781, loss = 0.9949, cross_entropy loss = 0.9949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:43.714279 #train# step  782, loss = 0.9707, cross_entropy loss = 0.9707, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:45.259331 #train# step  783, loss = 0.9983, cross_entropy loss = 0.9983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:46.828915 #train# step  784, loss = 0.9763, cross_entropy loss = 0.9763, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:48.413170 #train# step  785, loss = 0.9667, cross_entropy loss = 0.9667, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:49.952480 #train# step  786, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:51.514635 #train# step  787, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:53.067874 #train# step  788, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:54.628515 #train# step  789, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:56.184876 #train# step  790, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:57.742199 #train# step  791, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:21:59.331443 #train# step  792, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:00.890904 #train# step  793, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:02.490402 #train# step  794, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:04.042242 #train# step  795, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:05.624915 #train# step  796, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:07.211743 #train# step  797, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:08.772617 #train# step  798, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:10.346913 #train# step  799, loss = 0.9854, cross_entropy loss = 0.9854, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:11.899913 #train# step  800, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:13.442283 #train# step  801, loss = 0.9892, cross_entropy loss = 0.9892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:15.011242 #train# step  802, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:16.575703 #train# step  803, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:18.153401 #train# step  804, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:19.691941 #train# step  805, loss = 0.9825, cross_entropy loss = 0.9825, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:21.284466 #train# step  806, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:22.816675 #train# step  807, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:24.394066 #train# step  808, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:25.950380 #train# step  809, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:27.543676 #train# step  810, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:29.121004 #train# step  811, loss = 0.9762, cross_entropy loss = 0.9762, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:30.659994 #train# step  812, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:32.223238 #train# step  813, loss = 0.9890, cross_entropy loss = 0.9890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:33.772296 #train# step  814, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:35.320605 #train# step  815, loss = 0.9947, cross_entropy loss = 0.9947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:36.869669 #train# step  816, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:38.402937 #train# step  817, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:39.939056 #train# step  818, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:41.504415 #train# step  819, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:43.074083 #train# step  820, loss = 1.0004, cross_entropy loss = 1.0004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:44.634232 #train# step  821, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:46.217374 #train# step  822, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:47.781129 #train# step  823, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:49.338397 #train# step  824, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:50.923195 #train# step  825, loss = 0.9705, cross_entropy loss = 0.9705, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:52.496707 #train# step  826, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:54.059899 #train# step  827, loss = 0.9774, cross_entropy loss = 0.9774, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:55.611992 #train# step  828, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:57.142115 #train# step  829, loss = 0.9818, cross_entropy loss = 0.9818, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:22:58.678651 #train# step  830, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:00.224307 #train# step  831, loss = 0.9938, cross_entropy loss = 0.9938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:01.770186 #train# step  832, loss = 0.9800, cross_entropy loss = 0.9800, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:03.337683 #train# step  833, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:04.903053 #train# step  834, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:06.457941 #train# step  835, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:07.996904 #train# step  836, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:09.565883 #train# step  837, loss = 0.9846, cross_entropy loss = 0.9846, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:11.116673 #train# step  838, loss = 0.9944, cross_entropy loss = 0.9944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:12.679015 #train# step  839, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:14.248355 #train# step  840, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:15.823374 #train# step  841, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:17.415766 #train# step  842, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:18.979102 #train# step  843, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:20.539668 #train# step  844, loss = 0.9869, cross_entropy loss = 0.9869, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:22.108455 #train# step  845, loss = 0.9775, cross_entropy loss = 0.9775, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:23.649399 #train# step  846, loss = 0.9732, cross_entropy loss = 0.9732, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:25.229387 #train# step  847, loss = 0.9868, cross_entropy loss = 0.9868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:26.786053 #train# step  848, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:28.355891 #train# step  849, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:29.925689 #train# step  850, loss = 0.9776, cross_entropy loss = 0.9776, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:31.520642 #train# step  851, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:33.097212 #train# step  852, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:34.627763 #train# step  853, loss = 0.9860, cross_entropy loss = 0.9860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:36.197202 #train# step  854, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:37.745600 #train# step  855, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:39.317495 #train# step  856, loss = 0.9703, cross_entropy loss = 0.9703, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:40.894190 #train# step  857, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:42.443599 #train# step  858, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:44.009399 #train# step  859, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:45.571274 #train# step  860, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:47.135615 #train# step  861, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:48.687131 #train# step  862, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:50.280542 #train# step  863, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:51.857042 #train# step  864, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:53.414224 #train# step  865, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:54.976797 #train# step  866, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:56.546044 #train# step  867, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:58.097751 #train# step  868, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:23:59.658381 #train# step  869, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:01.213574 #train# step  870, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:02.780373 #train# step  871, loss = 0.9842, cross_entropy loss = 0.9842, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:04.314666 #train# step  872, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:05.845896 #train# step  873, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:07.390282 #train# step  874, loss = 0.9890, cross_entropy loss = 0.9890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:08.936615 #train# step  875, loss = 0.9768, cross_entropy loss = 0.9768, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:10.494228 #train# step  876, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:12.029391 #train# step  877, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:13.584510 #train# step  878, loss = 0.9943, cross_entropy loss = 0.9943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:15.135621 #train# step  879, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:16.695312 #train# step  880, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:18.251206 #train# step  881, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:19.829018 #train# step  882, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:21.407157 #train# step  883, loss = 0.9855, cross_entropy loss = 0.9855, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:22.973036 #train# step  884, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:24.544713 #train# step  885, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:26.079271 #train# step  886, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:27.668033 #train# step  887, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:29.218881 #train# step  888, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:30.784390 #train# step  889, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:32.333535 #train# step  890, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:33.878466 #train# step  891, loss = 0.9839, cross_entropy loss = 0.9839, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:35.461625 #train# step  892, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:37.025513 #train# step  893, loss = 0.9874, cross_entropy loss = 0.9874, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:38.572743 #train# step  894, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:40.105533 #train# step  895, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:41.687035 #train# step  896, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:43.240338 #train# step  897, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:44.828506 #train# step  898, loss = 0.9857, cross_entropy loss = 0.9857, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:46.377906 #train# step  899, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:47.969890 #train# step  900, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:49.517007 #train# step  901, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:51.069312 #train# step  902, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:52.607364 #train# step  903, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:54.156985 #train# step  904, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:55.727033 #train# step  905, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:57.266056 #train# step  906, loss = 0.9791, cross_entropy loss = 0.9791, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:24:58.834413 #train# step  907, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:00.399916 #train# step  908, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:01.970139 #train# step  909, loss = 0.9953, cross_entropy loss = 0.9953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:03.540717 #train# step  910, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:05.098103 #train# step  911, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:06.667382 #train# step  912, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:08.222634 #train# step  913, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:09.804060 #train# step  914, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:11.376812 #train# step  915, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:12.945672 #train# step  916, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:14.533480 #train# step  917, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:16.095210 #train# step  918, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:17.666550 #train# step  919, loss = 0.9673, cross_entropy loss = 0.9673, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:19.222409 #train# step  920, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:20.782346 #train# step  921, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:22.325086 #train# step  922, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:23.875634 #train# step  923, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:25.448080 #train# step  924, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:27.038439 #train# step  925, loss = 0.9664, cross_entropy loss = 0.9664, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:28.610811 #train# step  926, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:30.180010 #train# step  927, loss = 0.9798, cross_entropy loss = 0.9798, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:31.744056 #train# step  928, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:33.293419 #train# step  929, loss = 0.9760, cross_entropy loss = 0.9760, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:34.852652 #train# step  930, loss = 0.9742, cross_entropy loss = 0.9742, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:36.476983 #train# step  931, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:38.032584 #train# step  932, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:39.557911 #train# step  933, loss = 0.9849, cross_entropy loss = 0.9849, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:41.090675 #train# step  934, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:42.661434 #train# step  935, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:44.232157 #train# step  936, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:45.741267 #train# step  937, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:47.283825 #train# step  938, loss = 0.9695, cross_entropy loss = 0.9695, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:48.833345 #train# step  939, loss = 0.9759, cross_entropy loss = 0.9759, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:50.364193 #train# step  940, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:51.946029 #train# step  941, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:53.488463 #train# step  942, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:55.069662 #train# step  943, loss = 0.9656, cross_entropy loss = 0.9656, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:56.611187 #train# step  944, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:58.207524 #train# step  945, loss = 0.9755, cross_entropy loss = 0.9755, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:25:59.775392 #train# step  946, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:01.360728 #train# step  947, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:02.942219 #train# step  948, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:04.483013 #train# step  949, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:06.079742 #train# step  950, loss = 0.9899, cross_entropy loss = 0.9899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:07.673243 #train# step  951, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:09.255122 #train# step  952, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:10.792073 #train# step  953, loss = 1.0025, cross_entropy loss = 1.0025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:12.341890 #train# step  954, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:13.904325 #train# step  955, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:15.443962 #train# step  956, loss = 0.9754, cross_entropy loss = 0.9754, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:17.023563 #train# step  957, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:18.578262 #train# step  958, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:20.178295 #train# step  959, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:21.701180 #train# step  960, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:23.273232 #train# step  961, loss = 0.9864, cross_entropy loss = 0.9864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:24.848323 #train# step  962, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:26.417915 #train# step  963, loss = 0.9757, cross_entropy loss = 0.9757, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:27.954485 #train# step  964, loss = 0.9831, cross_entropy loss = 0.9831, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:29.551680 #train# step  965, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:31.094741 #train# step  966, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:32.647789 #train# step  967, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:34.216501 #train# step  968, loss = 0.9697, cross_entropy loss = 0.9697, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:35.766707 #train# step  969, loss = 0.9761, cross_entropy loss = 0.9761, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:37.329932 #train# step  970, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:38.872796 #train# step  971, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:40.412484 #train# step  972, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:41.967925 #train# step  973, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:43.539368 #train# step  974, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:45.106927 #train# step  975, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:46.680303 #train# step  976, loss = 0.9828, cross_entropy loss = 0.9828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:48.234675 #train# step  977, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:49.762730 #train# step  978, loss = 0.9779, cross_entropy loss = 0.9779, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:51.300937 #train# step  979, loss = 0.9837, cross_entropy loss = 0.9837, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:52.835269 #train# step  980, loss = 0.9756, cross_entropy loss = 0.9756, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:54.389684 #train# step  981, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:55.961677 #train# step  982, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:57.523962 #train# step  983, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:26:59.090519 #train# step  984, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:00.669617 #train# step  985, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:02.210872 #train# step  986, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:03.743548 #train# step  987, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:05.289024 #train# step  988, loss = 0.9809, cross_entropy loss = 0.9809, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:06.871134 #train# step  989, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:08.404098 #train# step  990, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:09.960162 #train# step  991, loss = 0.9866, cross_entropy loss = 0.9866, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:11.497851 #train# step  992, loss = 0.9939, cross_entropy loss = 0.9939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:13.026335 #train# step  993, loss = 0.9773, cross_entropy loss = 0.9773, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:14.609663 #train# step  994, loss = 0.9852, cross_entropy loss = 0.9852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:16.158716 #train# step  995, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:17.717093 #train# step  996, loss = 0.9870, cross_entropy loss = 0.9870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:19.278394 #train# step  997, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:20.854498 #train# step  998, loss = 0.9856, cross_entropy loss = 0.9856, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:22.428976 #train# step  999, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:24.014932 #train# step 1000, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:25.551255 #train# step 1001, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:27.126561 #train# step 1002, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:28.692443 #train# step 1003, loss = 0.9766, cross_entropy loss = 0.9766, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:30.257915 #train# step 1004, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:31.839985 #train# step 1005, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:33.386544 #train# step 1006, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:34.969806 #train# step 1007, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:36.530335 #train# step 1008, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:38.051496 #train# step 1009, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:39.617517 #train# step 1010, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:41.145011 #train# step 1011, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:42.700252 #train# step 1012, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:44.297147 #train# step 1013, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:45.856763 #train# step 1014, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:47.408984 #train# step 1015, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:48.953583 #train# step 1016, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:50.510734 #train# step 1017, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:52.078602 #train# step 1018, loss = 0.9748, cross_entropy loss = 0.9748, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:53.640431 #train# step 1019, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:55.199913 #train# step 1020, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:56.760792 #train# step 1021, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:58.312473 #train# step 1022, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:27:59.871320 #train# step 1023, loss = 0.9806, cross_entropy loss = 0.9806, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:01.448333 #train# step 1024, loss = 0.9730, cross_entropy loss = 0.9730, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:03.054192 #train# step 1025, loss = 0.9714, cross_entropy loss = 0.9714, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:04.604496 #train# step 1026, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:06.161333 #train# step 1027, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:07.717536 #train# step 1028, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:09.271355 #train# step 1029, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:10.819146 #train# step 1030, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:12.393441 #train# step 1031, loss = 0.9696, cross_entropy loss = 0.9696, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:13.943275 #train# step 1032, loss = 0.9813, cross_entropy loss = 0.9813, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:15.505705 #train# step 1033, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:17.075588 #train# step 1034, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:18.597912 #train# step 1035, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:20.167246 #train# step 1036, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:21.708361 #train# step 1037, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:23.289083 #train# step 1038, loss = 0.9727, cross_entropy loss = 0.9727, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:24.850139 #train# step 1039, loss = 0.9769, cross_entropy loss = 0.9769, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:26.369648 #train# step 1040, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:27.958814 #train# step 1041, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:29.507011 #train# step 1042, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:31.086250 #train# step 1043, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:32.629795 #train# step 1044, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:34.197721 #train# step 1045, loss = 0.9787, cross_entropy loss = 0.9787, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:35.772040 #train# step 1046, loss = 0.9690, cross_entropy loss = 0.9690, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:37.351426 #train# step 1047, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:38.899229 #train# step 1048, loss = 0.9659, cross_entropy loss = 0.9659, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:40.471061 #train# step 1049, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:42.018600 #train# step 1050, loss = 0.9801, cross_entropy loss = 0.9801, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:43.559022 #train# step 1051, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:45.091536 #train# step 1052, loss = 0.9758, cross_entropy loss = 0.9758, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:46.657508 #train# step 1053, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:48.225462 #train# step 1054, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:49.795765 #train# step 1055, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:51.333458 #train# step 1056, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:52.890801 #train# step 1057, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:54.464923 #train# step 1058, loss = 0.9744, cross_entropy loss = 0.9744, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:56.051308 #train# step 1059, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:57.600654 #train# step 1060, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:28:59.156805 #train# step 1061, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:00.736760 #train# step 1062, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:02.287148 #train# step 1063, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:03.874242 #train# step 1064, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:05.459181 #train# step 1065, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:07.033451 #train# step 1066, loss = 0.9574, cross_entropy loss = 0.9574, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:08.553792 #train# step 1067, loss = 0.9775, cross_entropy loss = 0.9775, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:10.143815 #train# step 1068, loss = 0.9808, cross_entropy loss = 0.9808, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:11.709130 #train# step 1069, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:13.290480 #train# step 1070, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:14.835522 #train# step 1071, loss = 0.9884, cross_entropy loss = 0.9884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:16.375823 #train# step 1072, loss = 0.9865, cross_entropy loss = 0.9865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:17.925501 #train# step 1073, loss = 0.9676, cross_entropy loss = 0.9676, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:19.500073 #train# step 1074, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:21.098610 #train# step 1075, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:22.652408 #train# step 1076, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:24.183116 #train# step 1077, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:25.741644 #train# step 1078, loss = 0.9850, cross_entropy loss = 0.9850, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:27.276697 #train# step 1079, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:28.829937 #train# step 1080, loss = 0.9851, cross_entropy loss = 0.9851, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:30.401017 #train# step 1081, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:31.941624 #train# step 1082, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:33.489782 #train# step 1083, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:35.059935 #train# step 1084, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:36.617869 #train# step 1085, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:38.184083 #train# step 1086, loss = 0.9735, cross_entropy loss = 0.9735, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:39.747525 #train# step 1087, loss = 0.9739, cross_entropy loss = 0.9739, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:41.281144 #train# step 1088, loss = 0.9764, cross_entropy loss = 0.9764, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:42.850308 #train# step 1089, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:44.410656 #train# step 1090, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:45.969578 #train# step 1091, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:47.524014 #train# step 1092, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:49.087859 #train# step 1093, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:50.657358 #train# step 1094, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:52.231024 #train# step 1095, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:53.769332 #train# step 1096, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:55.370373 #train# step 1097, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:56.943773 #train# step 1098, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:29:58.504880 #train# step 1099, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:00.072845 #train# step 1100, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:01.612920 #train# step 1101, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:03.166837 #train# step 1102, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:04.723664 #train# step 1103, loss = 0.9665, cross_entropy loss = 0.9665, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:06.307385 #train# step 1104, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:07.870337 #train# step 1105, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:09.437323 #train# step 1106, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:11.004215 #train# step 1107, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:12.585362 #train# step 1108, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:14.169668 #train# step 1109, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:15.746765 #train# step 1110, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:17.289259 #train# step 1111, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:18.869188 #train# step 1112, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:20.439472 #train# step 1113, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:21.997439 #train# step 1114, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:23.560125 #train# step 1115, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:25.095385 #train# step 1116, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:26.677870 #train# step 1117, loss = 0.9685, cross_entropy loss = 0.9685, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:28.376101 #train# step 1118, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:29.912928 #train# step 1119, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:31.463520 #train# step 1120, loss = 0.9674, cross_entropy loss = 0.9674, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:33.027933 #train# step 1121, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:34.555972 #train# step 1122, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:36.122291 #train# step 1123, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:37.678321 #train# step 1124, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:39.217524 #train# step 1125, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:40.774384 #train# step 1126, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:42.361799 #train# step 1127, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:43.934274 #train# step 1128, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:45.492687 #train# step 1129, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:47.048950 #train# step 1130, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:48.609971 #train# step 1131, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:50.170321 #train# step 1132, loss = 0.9618, cross_entropy loss = 0.9618, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:51.745799 #train# step 1133, loss = 0.9823, cross_entropy loss = 0.9823, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:53.286818 #train# step 1134, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:54.874332 #train# step 1135, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:56.427700 #train# step 1136, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:57.990306 #train# step 1137, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:30:59.579344 #train# step 1138, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:01.126896 #train# step 1139, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:02.680304 #train# step 1140, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:04.233119 #train# step 1141, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:05.785170 #train# step 1142, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:07.367696 #train# step 1143, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:08.919370 #train# step 1144, loss = 0.9820, cross_entropy loss = 0.9820, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:10.479450 #train# step 1145, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:12.060247 #train# step 1146, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:13.621558 #train# step 1147, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:15.197644 #train# step 1148, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:16.780636 #train# step 1149, loss = 0.9821, cross_entropy loss = 0.9821, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:18.325146 #train# step 1150, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:19.912742 #train# step 1151, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:21.434524 #train# step 1152, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:22.993326 #train# step 1153, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:24.546750 #train# step 1154, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:26.088249 #train# step 1155, loss = 0.9740, cross_entropy loss = 0.9740, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:27.684677 #train# step 1156, loss = 0.9689, cross_entropy loss = 0.9689, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:29.269703 #train# step 1157, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:30.805262 #train# step 1158, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:32.362328 #train# step 1159, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:33.926316 #train# step 1160, loss = 0.9552, cross_entropy loss = 0.9552, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:35.465725 #train# step 1161, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:37.021119 #train# step 1162, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:38.589013 #train# step 1163, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:40.162912 #train# step 1164, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:41.724514 #train# step 1165, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:43.273279 #train# step 1166, loss = 0.9765, cross_entropy loss = 0.9765, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:44.826314 #train# step 1167, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:46.379742 #train# step 1168, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:47.928383 #train# step 1169, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:49.456578 #train# step 1170, loss = 0.9692, cross_entropy loss = 0.9692, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:51.054276 #train# step 1171, loss = 0.9643, cross_entropy loss = 0.9643, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:52.623279 #train# step 1172, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:54.176746 #train# step 1173, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:55.742968 #train# step 1174, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:57.279254 #train# step 1175, loss = 0.9783, cross_entropy loss = 0.9783, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:31:58.846450 #train# step 1176, loss = 0.9687, cross_entropy loss = 0.9687, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:00.412107 #train# step 1177, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:01.992898 #train# step 1178, loss = 0.9729, cross_entropy loss = 0.9729, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:03.586951 #train# step 1179, loss = 0.9632, cross_entropy loss = 0.9632, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:05.180511 #train# step 1180, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:06.722427 #train# step 1181, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:08.259577 #train# step 1182, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:09.864706 #train# step 1183, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:11.427681 #train# step 1184, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:12.982257 #train# step 1185, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:14.573896 #train# step 1186, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:16.122253 #train# step 1187, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:17.655854 #train# step 1188, loss = 0.9748, cross_entropy loss = 0.9748, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:19.182258 #train# step 1189, loss = 0.9767, cross_entropy loss = 0.9767, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:20.724095 #train# step 1190, loss = 0.9816, cross_entropy loss = 0.9816, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:22.289398 #train# step 1191, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:23.861737 #train# step 1192, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:25.410201 #train# step 1193, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:26.989976 #train# step 1194, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:28.537494 #train# step 1195, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:30.112935 #train# step 1196, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:31.705609 #train# step 1197, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:33.279489 #train# step 1198, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:34.847567 #train# step 1199, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:36.417527 #train# step 1200, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:38.007850 #train# step 1201, loss = 0.9750, cross_entropy loss = 0.9750, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:39.592440 #train# step 1202, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:41.153431 #train# step 1203, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:42.677623 #train# step 1204, loss = 0.9840, cross_entropy loss = 0.9840, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:44.222949 #train# step 1205, loss = 0.9835, cross_entropy loss = 0.9835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:45.777150 #train# step 1206, loss = 0.9715, cross_entropy loss = 0.9715, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:47.319718 #train# step 1207, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:48.875318 #train# step 1208, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:50.434809 #train# step 1209, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:52.018477 #train# step 1210, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:53.567860 #train# step 1211, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:55.118313 #train# step 1212, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:56.642481 #train# step 1213, loss = 0.9688, cross_entropy loss = 0.9688, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:58.226271 #train# step 1214, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:32:59.798277 #train# step 1215, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:01.368059 #train# step 1216, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:02.921235 #train# step 1217, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:04.508796 #train# step 1218, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:06.028793 #train# step 1219, loss = 0.9782, cross_entropy loss = 0.9782, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:07.600956 #train# step 1220, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:09.136024 #train# step 1221, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:10.683791 #train# step 1222, loss = 0.9749, cross_entropy loss = 0.9749, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:12.258201 #train# step 1223, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:13.816001 #train# step 1224, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:15.349850 #train# step 1225, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:16.952866 #train# step 1226, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:18.530226 #train# step 1227, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:20.095451 #train# step 1228, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:21.674372 #train# step 1229, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:23.247570 #train# step 1230, loss = 0.9640, cross_entropy loss = 0.9640, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:24.794005 #train# step 1231, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:26.306185 #train# step 1232, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:27.870372 #train# step 1233, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:29.429019 #train# step 1234, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:30.979162 #train# step 1235, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:32.542587 #train# step 1236, loss = 0.9829, cross_entropy loss = 0.9829, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:34.086044 #train# step 1237, loss = 0.9710, cross_entropy loss = 0.9710, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:35.627540 #train# step 1238, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:37.184936 #train# step 1239, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:38.758449 #train# step 1240, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:40.333710 #train# step 1241, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:41.904690 #train# step 1242, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:43.480535 #train# step 1243, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:45.023713 #train# step 1244, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:46.592064 #train# step 1245, loss = 0.9728, cross_entropy loss = 0.9728, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:48.128047 #train# step 1246, loss = 0.9636, cross_entropy loss = 0.9636, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:49.690876 #train# step 1247, loss = 0.9815, cross_entropy loss = 0.9815, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:51.283106 #train# step 1248, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:52.862693 #train# step 1249, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:54.424311 #train# step 1250, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:55.964321 #train# step 1251, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:57.517625 #train# step 1252, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:33:59.079035 #train# step 1253, loss = 0.9709, cross_entropy loss = 0.9709, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:00.669735 #train# step 1254, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:02.225719 #train# step 1255, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:03.747499 #train# step 1256, loss = 0.9698, cross_entropy loss = 0.9698, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:05.314326 #train# step 1257, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:06.884543 #train# step 1258, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:08.444171 #train# step 1259, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:10.004856 #train# step 1260, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:11.555583 #train# step 1261, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:13.106145 #train# step 1262, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:14.664607 #train# step 1263, loss = 0.9694, cross_entropy loss = 0.9694, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:16.250243 #train# step 1264, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:17.793371 #train# step 1265, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:19.366590 #train# step 1266, loss = 0.9606, cross_entropy loss = 0.9606, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:20.929420 #train# step 1267, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:22.467064 #train# step 1268, loss = 0.9731, cross_entropy loss = 0.9731, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:24.064630 #train# step 1269, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:25.625927 #train# step 1270, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:27.207795 #train# step 1271, loss = 0.9719, cross_entropy loss = 0.9719, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:28.746019 #train# step 1272, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:30.326233 #train# step 1273, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:31.865387 #train# step 1274, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:33.415175 #train# step 1275, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:34.976459 #train# step 1276, loss = 0.9726, cross_entropy loss = 0.9726, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:36.533119 #train# step 1277, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:38.088925 #train# step 1278, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:39.657121 #train# step 1279, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:41.190593 #train# step 1280, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:42.757599 #train# step 1281, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:44.354599 #train# step 1282, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:45.920527 #train# step 1283, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:47.479592 #train# step 1284, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:49.074354 #train# step 1285, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:50.653358 #train# step 1286, loss = 0.9780, cross_entropy loss = 0.9780, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:52.198569 #train# step 1287, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:53.764097 #train# step 1288, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:55.329490 #train# step 1289, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:56.899999 #train# step 1290, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:34:58.443570 #train# step 1291, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:00.019354 #train# step 1292, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:01.569918 #train# step 1293, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:03.107884 #train# step 1294, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:04.664665 #train# step 1295, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:06.257069 #train# step 1296, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:07.820698 #train# step 1297, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:09.369816 #train# step 1298, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:10.899684 #train# step 1299, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:12.459652 #train# step 1300, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:13.979274 #train# step 1301, loss = 0.9610, cross_entropy loss = 0.9610, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:15.556922 #train# step 1302, loss = 0.9697, cross_entropy loss = 0.9697, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:17.142811 #train# step 1303, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:18.680502 #train# step 1304, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:20.239764 #train# step 1305, loss = 0.9669, cross_entropy loss = 0.9669, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:21.798321 #train# step 1306, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:23.338257 #train# step 1307, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:24.893998 #train# step 1308, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:26.453369 #train# step 1309, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:28.013413 #train# step 1310, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:29.544444 #train# step 1311, loss = 0.9930, cross_entropy loss = 0.9930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:31.116844 #train# step 1312, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:32.678597 #train# step 1313, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:34.269243 #train# step 1314, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:35.878836 #train# step 1315, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:37.440611 #train# step 1316, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:38.987840 #train# step 1317, loss = 0.9590, cross_entropy loss = 0.9590, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:40.542767 #train# step 1318, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:42.126348 #train# step 1319, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:43.672057 #train# step 1320, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:45.213549 #train# step 1321, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:46.751685 #train# step 1322, loss = 0.9747, cross_entropy loss = 0.9747, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:48.348982 #train# step 1323, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:49.879567 #train# step 1324, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:51.419359 #train# step 1325, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:52.991048 #train# step 1326, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:54.534965 #train# step 1327, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:56.098479 #train# step 1328, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:57.641191 #train# step 1329, loss = 0.9626, cross_entropy loss = 0.9626, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:35:59.261094 #train# step 1330, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:00.833199 #train# step 1331, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:02.413493 #train# step 1332, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:03.966942 #train# step 1333, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:05.527202 #train# step 1334, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:07.070768 #train# step 1335, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:08.636781 #train# step 1336, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:10.192271 #train# step 1337, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:11.764372 #train# step 1338, loss = 0.9517, cross_entropy loss = 0.9517, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:13.361026 #train# step 1339, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:14.957464 #train# step 1340, loss = 0.9867, cross_entropy loss = 0.9867, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:16.502005 #train# step 1341, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:18.045308 #train# step 1342, loss = 0.9745, cross_entropy loss = 0.9745, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:19.601117 #train# step 1343, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:21.192398 #train# step 1344, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:22.735164 #train# step 1345, loss = 0.9805, cross_entropy loss = 0.9805, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:24.315084 #train# step 1346, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:25.900218 #train# step 1347, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:27.420431 #train# step 1348, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:29.008616 #train# step 1349, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:30.560042 #train# step 1350, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:32.117493 #train# step 1351, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:33.682274 #train# step 1352, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:35.222254 #train# step 1353, loss = 0.9717, cross_entropy loss = 0.9717, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:36.781766 #train# step 1354, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:38.357600 #train# step 1355, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:39.903395 #train# step 1356, loss = 0.9635, cross_entropy loss = 0.9635, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:41.466519 #train# step 1357, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:43.013848 #train# step 1358, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:44.572695 #train# step 1359, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:46.145418 #train# step 1360, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:47.713644 #train# step 1361, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:49.291851 #train# step 1362, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:50.832259 #train# step 1363, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:52.388045 #train# step 1364, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:53.952999 #train# step 1365, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:55.548456 #train# step 1366, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:57.118207 #train# step 1367, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:36:58.684896 #train# step 1368, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:00.234673 #train# step 1369, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:01.757106 #train# step 1370, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:03.353400 #train# step 1371, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:04.922557 #train# step 1372, loss = 0.9699, cross_entropy loss = 0.9699, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:06.505069 #train# step 1373, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:08.093011 #train# step 1374, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:09.682218 #train# step 1375, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:11.245062 #train# step 1376, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:12.797052 #train# step 1377, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:14.375229 #train# step 1378, loss = 0.9734, cross_entropy loss = 0.9734, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:15.954854 #train# step 1379, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:17.516864 #train# step 1380, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:19.045221 #train# step 1381, loss = 0.9647, cross_entropy loss = 0.9647, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:20.626590 #train# step 1382, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:22.176264 #train# step 1383, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:23.741536 #train# step 1384, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:25.278806 #train# step 1385, loss = 0.9673, cross_entropy loss = 0.9673, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:26.837378 #train# step 1386, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:28.417901 #train# step 1387, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:29.960049 #train# step 1388, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:31.487040 #train# step 1389, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:33.031414 #train# step 1390, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:34.589234 #train# step 1391, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:36.165030 #train# step 1392, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:37.704665 #train# step 1393, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:39.249091 #train# step 1394, loss = 0.9654, cross_entropy loss = 0.9654, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:40.822322 #train# step 1395, loss = 0.9630, cross_entropy loss = 0.9630, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:42.391480 #train# step 1396, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:43.949904 #train# step 1397, loss = 0.9784, cross_entropy loss = 0.9784, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:45.508602 #train# step 1398, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:47.035046 #train# step 1399, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:48.629354 #train# step 1400, loss = 0.9549, cross_entropy loss = 0.9549, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:50.169625 #train# step 1401, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:51.728363 #train# step 1402, loss = 0.9629, cross_entropy loss = 0.9629, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:53.244433 #train# step 1403, loss = 0.9662, cross_entropy loss = 0.9662, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:54.808112 #train# step 1404, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:56.374422 #train# step 1405, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:57.937014 #train# step 1406, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:37:59.518956 #train# step 1407, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:01.111413 #train# step 1408, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:02.679484 #train# step 1409, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:04.250254 #train# step 1410, loss = 0.9592, cross_entropy loss = 0.9592, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:05.801552 #train# step 1411, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:07.357316 #train# step 1412, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:08.903262 #train# step 1413, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:10.531785 #train# step 1414, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:12.100698 #train# step 1415, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:13.663067 #train# step 1416, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:15.218864 #train# step 1417, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:16.803292 #train# step 1418, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:18.336625 #train# step 1419, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:19.886204 #train# step 1420, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:21.437789 #train# step 1421, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:23.017680 #train# step 1422, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:24.591407 #train# step 1423, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:26.143995 #train# step 1424, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:27.708955 #train# step 1425, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:29.255775 #train# step 1426, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:30.830813 #train# step 1427, loss = 0.9627, cross_entropy loss = 0.9627, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:32.385392 #train# step 1428, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:33.980630 #train# step 1429, loss = 0.9533, cross_entropy loss = 0.9533, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:35.543014 #train# step 1430, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:37.084700 #train# step 1431, loss = 0.9602, cross_entropy loss = 0.9602, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:38.657851 #train# step 1432, loss = 0.9706, cross_entropy loss = 0.9706, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:40.242175 #train# step 1433, loss = 0.9670, cross_entropy loss = 0.9670, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:41.787297 #train# step 1434, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:43.350835 #train# step 1435, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:44.903305 #train# step 1436, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:46.446013 #train# step 1437, loss = 0.9742, cross_entropy loss = 0.9742, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:47.977286 #train# step 1438, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:49.502153 #train# step 1439, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:51.074913 #train# step 1440, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:52.636487 #train# step 1441, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:54.193713 #train# step 1442, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:55.734403 #train# step 1443, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:57.314925 #train# step 1444, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:38:58.859564 #train# step 1445, loss = 0.9612, cross_entropy loss = 0.9612, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:00.429192 #train# step 1446, loss = 0.9613, cross_entropy loss = 0.9613, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:01.982933 #train# step 1447, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:03.568366 #train# step 1448, loss = 0.9634, cross_entropy loss = 0.9634, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:05.128705 #train# step 1449, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:06.705464 #train# step 1450, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:08.262811 #train# step 1451, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:09.842958 #train# step 1452, loss = 0.9651, cross_entropy loss = 0.9651, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:11.447092 #train# step 1453, loss = 0.9702, cross_entropy loss = 0.9702, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:13.019154 #train# step 1454, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:14.578926 #train# step 1455, loss = 0.9686, cross_entropy loss = 0.9686, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:16.121523 #train# step 1456, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:17.690780 #train# step 1457, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:19.229219 #train# step 1458, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:20.785694 #train# step 1459, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:22.335831 #train# step 1460, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:23.901635 #train# step 1461, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:25.472355 #train# step 1462, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:27.028843 #train# step 1463, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:28.590409 #train# step 1464, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:30.154539 #train# step 1465, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:31.718800 #train# step 1466, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:33.292422 #train# step 1467, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:34.854475 #train# step 1468, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:36.398029 #train# step 1469, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:37.958661 #train# step 1470, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:39.507732 #train# step 1471, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:41.071208 #train# step 1472, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:42.661087 #train# step 1473, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:44.222945 #train# step 1474, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:45.765588 #train# step 1475, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:47.354585 #train# step 1476, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:48.919577 #train# step 1477, loss = 0.9693, cross_entropy loss = 0.9693, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:50.455348 #train# step 1478, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:52.002774 #train# step 1479, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:53.575848 #train# step 1480, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:55.122243 #train# step 1481, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:56.671222 #train# step 1482, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:58.204098 #train# step 1483, loss = 0.9657, cross_entropy loss = 0.9657, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:39:59.770911 #train# step 1484, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:01.339540 #train# step 1485, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:02.892448 #train# step 1486, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:04.474480 #train# step 1487, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:06.046954 #train# step 1488, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:07.583162 #train# step 1489, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:09.129266 #train# step 1490, loss = 0.9675, cross_entropy loss = 0.9675, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:10.706790 #train# step 1491, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:12.298094 #train# step 1492, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:13.863897 #train# step 1493, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:15.412290 #train# step 1494, loss = 0.9683, cross_entropy loss = 0.9683, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:16.982688 #train# step 1495, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:18.560380 #train# step 1496, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:20.128185 #train# step 1497, loss = 0.9660, cross_entropy loss = 0.9660, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:21.683485 #train# step 1498, loss = 0.9515, cross_entropy loss = 0.9515, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:23.246921 #train# step 1499, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:24.803714 #train# step 1500, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:26.347831 #train# step 1501, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:27.902960 #train# step 1502, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:29.492057 #train# step 1503, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:31.050257 #train# step 1504, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:32.618965 #train# step 1505, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:34.175105 #train# step 1506, loss = 0.9648, cross_entropy loss = 0.9648, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:35.734055 #train# step 1507, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:37.307702 #train# step 1508, loss = 0.9646, cross_entropy loss = 0.9646, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:38.854814 #train# step 1509, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:40.404525 #train# step 1510, loss = 0.9713, cross_entropy loss = 0.9713, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:41.955040 #train# step 1511, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:43.527211 #train# step 1512, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:45.100563 #train# step 1513, loss = 0.9679, cross_entropy loss = 0.9679, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:46.662191 #train# step 1514, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:48.240829 #train# step 1515, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:49.827576 #train# step 1516, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:51.400485 #train# step 1517, loss = 0.9704, cross_entropy loss = 0.9704, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:52.921407 #train# step 1518, loss = 0.9673, cross_entropy loss = 0.9673, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:54.482482 #train# step 1519, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:56.058417 #train# step 1520, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:57.607410 #train# step 1521, loss = 0.9794, cross_entropy loss = 0.9794, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:40:59.192395 #train# step 1522, loss = 0.9826, cross_entropy loss = 0.9826, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:00.765315 #train# step 1523, loss = 0.9601, cross_entropy loss = 0.9601, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:02.297509 #train# step 1524, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:03.849077 #train# step 1525, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:05.392752 #train# step 1526, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:06.949766 #train# step 1527, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:08.498635 #train# step 1528, loss = 0.9594, cross_entropy loss = 0.9594, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:10.052544 #train# step 1529, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:11.600831 #train# step 1530, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:13.145422 #train# step 1531, loss = 0.9712, cross_entropy loss = 0.9712, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:14.708276 #train# step 1532, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:16.280110 #train# step 1533, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:17.859637 #train# step 1534, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:19.419881 #train# step 1535, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:21.023033 #train# step 1536, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:22.626717 #train# step 1537, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:24.170749 #train# step 1538, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:25.753238 #train# step 1539, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:27.305930 #train# step 1540, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:28.824404 #train# step 1541, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:30.387882 #train# step 1542, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:31.978898 #train# step 1543, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:33.536988 #train# step 1544, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:35.105553 #train# step 1545, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:36.638889 #train# step 1546, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:38.188514 #train# step 1547, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:39.752603 #train# step 1548, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:41.319383 #train# step 1549, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:42.899018 #train# step 1550, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:44.471028 #train# step 1551, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:46.045316 #train# step 1552, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:47.609542 #train# step 1553, loss = 0.9638, cross_entropy loss = 0.9638, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:49.169146 #train# step 1554, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:50.695897 #train# step 1555, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:52.259628 #train# step 1556, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:53.822429 #train# step 1557, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:55.366785 #train# step 1558, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:56.954684 #train# step 1559, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:41:58.499765 #train# step 1560, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:00.048273 #train# step 1561, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:01.618140 #train# step 1562, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:03.167187 #train# step 1563, loss = 0.9682, cross_entropy loss = 0.9682, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:04.709841 #train# step 1564, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:06.283392 #train# step 1565, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:07.859427 #train# step 1566, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:09.409145 #train# step 1567, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:10.995580 #train# step 1568, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:12.562495 #train# step 1569, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:14.108313 #train# step 1570, loss = 0.9622, cross_entropy loss = 0.9622, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:15.718676 #train# step 1571, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:17.267825 #train# step 1572, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:18.809378 #train# step 1573, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:20.357741 #train# step 1574, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:21.918361 #train# step 1575, loss = 0.9743, cross_entropy loss = 0.9743, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:23.481229 #train# step 1576, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:25.043967 #train# step 1577, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:26.625519 #train# step 1578, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:28.219447 #train# step 1579, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:29.760912 #train# step 1580, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:31.321826 #train# step 1581, loss = 0.9631, cross_entropy loss = 0.9631, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:32.878204 #train# step 1582, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:34.450280 #train# step 1583, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:35.996278 #train# step 1584, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:37.540964 #train# step 1585, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:39.121611 #train# step 1586, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:40.660834 #train# step 1587, loss = 0.9804, cross_entropy loss = 0.9804, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:42.237656 #train# step 1588, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:43.808821 #train# step 1589, loss = 0.9792, cross_entropy loss = 0.9792, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:45.365336 #train# step 1590, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:46.926526 #train# step 1591, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:48.511083 #train# step 1592, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:50.086845 #train# step 1593, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:51.654082 #train# step 1594, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:53.194133 #train# step 1595, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:54.745928 #train# step 1596, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:56.299131 #train# step 1597, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:57.823412 #train# step 1598, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:42:59.379488 #train# step 1599, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:00.931808 #train# step 1600, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:02.460916 #train# step 1601, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:04.047143 #train# step 1602, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:05.596558 #train# step 1603, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:07.141775 #train# step 1604, loss = 0.9681, cross_entropy loss = 0.9681, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:08.679604 #train# step 1605, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:10.246942 #train# step 1606, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:11.816210 #train# step 1607, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:13.363999 #train# step 1608, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:14.901126 #train# step 1609, loss = 0.9671, cross_entropy loss = 0.9671, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:16.460787 #train# step 1610, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:18.049009 #train# step 1611, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:19.600963 #train# step 1612, loss = 0.9525, cross_entropy loss = 0.9525, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:21.165358 #train# step 1613, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:22.736470 #train# step 1614, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:24.327518 #train# step 1615, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:25.870117 #train# step 1616, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:27.465367 #train# step 1617, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:29.023857 #train# step 1618, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:30.578280 #train# step 1619, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:32.178257 #train# step 1620, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:33.722649 #train# step 1621, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:35.282910 #train# step 1622, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:36.882684 #train# step 1623, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:38.442694 #train# step 1624, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:40.022547 #train# step 1625, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:41.578307 #train# step 1626, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:43.131161 #train# step 1627, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:44.679483 #train# step 1628, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:46.224607 #train# step 1629, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:47.783940 #train# step 1630, loss = 0.9781, cross_entropy loss = 0.9781, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:49.334190 #train# step 1631, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:50.896645 #train# step 1632, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:52.449100 #train# step 1633, loss = 0.9609, cross_entropy loss = 0.9609, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:54.011508 #train# step 1634, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:55.565629 #train# step 1635, loss = 0.9723, cross_entropy loss = 0.9723, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:57.125070 #train# step 1636, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:43:58.701682 #train# step 1637, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:00.266298 #train# step 1638, loss = 0.9725, cross_entropy loss = 0.9725, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:01.841336 #train# step 1639, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:03.406040 #train# step 1640, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:04.951835 #train# step 1641, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:06.504164 #train# step 1642, loss = 0.9720, cross_entropy loss = 0.9720, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:08.067699 #train# step 1643, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:09.648321 #train# step 1644, loss = 0.9650, cross_entropy loss = 0.9650, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:11.231705 #train# step 1645, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:12.793221 #train# step 1646, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:14.388937 #train# step 1647, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:15.923958 #train# step 1648, loss = 0.9620, cross_entropy loss = 0.9620, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:17.512003 #train# step 1649, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:19.074240 #train# step 1650, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:20.638785 #train# step 1651, loss = 0.9701, cross_entropy loss = 0.9701, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:22.195125 #train# step 1652, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:23.745566 #train# step 1653, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:25.312656 #train# step 1654, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:26.903765 #train# step 1655, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:28.448920 #train# step 1656, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:30.008387 #train# step 1657, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:31.544228 #train# step 1658, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:33.125221 #train# step 1659, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:34.682884 #train# step 1660, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:36.246430 #train# step 1661, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:37.799819 #train# step 1662, loss = 0.9708, cross_entropy loss = 0.9708, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:39.393713 #train# step 1663, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:40.942917 #train# step 1664, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:42.498025 #train# step 1665, loss = 0.9588, cross_entropy loss = 0.9588, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:44.074873 #train# step 1666, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:45.681516 #train# step 1667, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:47.213960 #train# step 1668, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:48.779920 #train# step 1669, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:50.370599 #train# step 1670, loss = 0.9528, cross_entropy loss = 0.9528, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:51.932455 #train# step 1671, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:53.500732 #train# step 1672, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:55.087326 #train# step 1673, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:56.644534 #train# step 1674, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:58.210698 #train# step 1675, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:44:59.750687 #train# step 1676, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:01.299997 #train# step 1677, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:02.838859 #train# step 1678, loss = 0.9660, cross_entropy loss = 0.9660, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:04.399758 #train# step 1679, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:05.984117 #train# step 1680, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:07.542815 #train# step 1681, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:09.132554 #train# step 1682, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:10.696223 #train# step 1683, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:12.252008 #train# step 1684, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:13.798259 #train# step 1685, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:15.359871 #train# step 1686, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:16.900976 #train# step 1687, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:18.467539 #train# step 1688, loss = 0.9645, cross_entropy loss = 0.9645, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:20.008727 #train# step 1689, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:21.542799 #train# step 1690, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:23.078772 #train# step 1691, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:24.638733 #train# step 1692, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:26.211261 #train# step 1693, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:27.769765 #train# step 1694, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:29.324312 #train# step 1695, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:30.874396 #train# step 1696, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:32.447471 #train# step 1697, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:34.016792 #train# step 1698, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:35.567110 #train# step 1699, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:37.103605 #train# step 1700, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:38.643059 #train# step 1701, loss = 0.9554, cross_entropy loss = 0.9554, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:40.206443 #train# step 1702, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:41.763645 #train# step 1703, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:43.339072 #train# step 1704, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:44.929947 #train# step 1705, loss = 0.9619, cross_entropy loss = 0.9619, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:46.488429 #train# step 1706, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:48.045094 #train# step 1707, loss = 0.9596, cross_entropy loss = 0.9596, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:49.599792 #train# step 1708, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:51.164800 #train# step 1709, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:52.718562 #train# step 1710, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:54.277035 #train# step 1711, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:55.841277 #train# step 1712, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:57.406232 #train# step 1713, loss = 0.9668, cross_entropy loss = 0.9668, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:45:58.955216 #train# step 1714, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:00.517422 #train# step 1715, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:02.069190 #train# step 1716, loss = 0.9608, cross_entropy loss = 0.9608, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:03.600767 #train# step 1717, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:05.168033 #train# step 1718, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:06.761493 #train# step 1719, loss = 0.9547, cross_entropy loss = 0.9547, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:08.361755 #train# step 1720, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:09.928181 #train# step 1721, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:11.474431 #train# step 1722, loss = 0.9566, cross_entropy loss = 0.9566, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:13.057881 #train# step 1723, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:14.632029 #train# step 1724, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:16.194874 #train# step 1725, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:17.780447 #train# step 1726, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:19.352995 #train# step 1727, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:20.941756 #train# step 1728, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:22.498988 #train# step 1729, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:24.053997 #train# step 1730, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:25.618299 #train# step 1731, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:27.172508 #train# step 1732, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:28.748095 #train# step 1733, loss = 0.9677, cross_entropy loss = 0.9677, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:30.292859 #train# step 1734, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:31.862948 #train# step 1735, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:33.398976 #train# step 1736, loss = 0.9633, cross_entropy loss = 0.9633, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:34.964802 #train# step 1737, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:36.522186 #train# step 1738, loss = 0.9658, cross_entropy loss = 0.9658, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:38.058818 #train# step 1739, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:39.630754 #train# step 1740, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:41.223687 #train# step 1741, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:42.785517 #train# step 1742, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:44.356526 #train# step 1743, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:45.919143 #train# step 1744, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:47.475063 #train# step 1745, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:49.042170 #train# step 1746, loss = 0.9653, cross_entropy loss = 0.9653, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:50.627481 #train# step 1747, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:52.195702 #train# step 1748, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:53.752965 #train# step 1749, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:55.310313 #train# step 1750, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:56.891627 #train# step 1751, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:46:58.477469 #train# step 1752, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:00.032662 #train# step 1753, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:01.583616 #train# step 1754, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:03.131843 #train# step 1755, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:04.721143 #train# step 1756, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:06.283699 #train# step 1757, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:07.833706 #train# step 1758, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:09.392029 #train# step 1759, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:10.945346 #train# step 1760, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:12.482353 #train# step 1761, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:14.053333 #train# step 1762, loss = 0.9560, cross_entropy loss = 0.9560, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:15.614043 #train# step 1763, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:17.170413 #train# step 1764, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:18.740874 #train# step 1765, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:20.309197 #train# step 1766, loss = 0.9722, cross_entropy loss = 0.9722, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:21.883578 #train# step 1767, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:23.450805 #train# step 1768, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:25.026659 #train# step 1769, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:26.579885 #train# step 1770, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:28.124912 #train# step 1771, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:29.707130 #train# step 1772, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:31.251520 #train# step 1773, loss = 0.9589, cross_entropy loss = 0.9589, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:32.809502 #train# step 1774, loss = 0.9678, cross_entropy loss = 0.9678, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:34.374635 #train# step 1775, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:35.961959 #train# step 1776, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:37.510102 #train# step 1777, loss = 0.9641, cross_entropy loss = 0.9641, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:39.073168 #train# step 1778, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:40.618724 #train# step 1779, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:42.174868 #train# step 1780, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:43.745511 #train# step 1781, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:45.287343 #train# step 1782, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:46.841788 #train# step 1783, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:48.405155 #train# step 1784, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:49.962997 #train# step 1785, loss = 0.9753, cross_entropy loss = 0.9753, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:51.505993 #train# step 1786, loss = 0.9614, cross_entropy loss = 0.9614, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:53.062623 #train# step 1787, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:54.627932 #train# step 1788, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:56.173780 #train# step 1789, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:57.741050 #train# step 1790, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:47:59.275300 #train# step 1791, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:00.828403 #train# step 1792, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:02.400881 #train# step 1793, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:03.959853 #train# step 1794, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:05.536442 #train# step 1795, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:07.032010 #train# step 1796, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:08.607056 #train# step 1797, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:10.199462 #train# step 1798, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:11.812093 #train# step 1799, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:13.406383 #train# step 1800, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:14.975508 #train# step 1801, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:16.513248 #train# step 1802, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:18.051838 #train# step 1803, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:19.639070 #train# step 1804, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:21.190172 #train# step 1805, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:22.759552 #train# step 1806, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:24.322646 #train# step 1807, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:25.867323 #train# step 1808, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:27.454947 #train# step 1809, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:29.067689 #train# step 1810, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:30.611927 #train# step 1811, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:32.162627 #train# step 1812, loss = 0.9644, cross_entropy loss = 0.9644, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:33.696075 #train# step 1813, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:35.278902 #train# step 1814, loss = 0.9569, cross_entropy loss = 0.9569, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:36.821236 #train# step 1815, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:38.419644 #train# step 1816, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:39.962596 #train# step 1817, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:41.529752 #train# step 1818, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:43.103673 #train# step 1819, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:44.666490 #train# step 1820, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:46.239807 #train# step 1821, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:47.805698 #train# step 1822, loss = 0.9672, cross_entropy loss = 0.9672, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:49.334270 #train# step 1823, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:50.915378 #train# step 1824, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:52.492129 #train# step 1825, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:54.030338 #train# step 1826, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:55.603255 #train# step 1827, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:57.185484 #train# step 1828, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:48:58.759164 #train# step 1829, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:00.329576 #train# step 1830, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:01.873560 #train# step 1831, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:03.429704 #train# step 1832, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:04.991051 #train# step 1833, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:06.568528 #train# step 1834, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:08.138119 #train# step 1835, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:09.719478 #train# step 1836, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:11.282600 #train# step 1837, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:12.836086 #train# step 1838, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:14.428684 #train# step 1839, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:15.983887 #train# step 1840, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:17.540609 #train# step 1841, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:19.106362 #train# step 1842, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:20.656080 #train# step 1843, loss = 0.9451, cross_entropy loss = 0.9451, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:22.230623 #train# step 1844, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:23.796382 #train# step 1845, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:25.356442 #train# step 1846, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:26.912520 #train# step 1847, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:28.441489 #train# step 1848, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:29.990754 #train# step 1849, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:31.547577 #train# step 1850, loss = 0.9652, cross_entropy loss = 0.9652, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:33.112906 #train# step 1851, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:34.650636 #train# step 1852, loss = 0.9582, cross_entropy loss = 0.9582, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:36.188649 #train# step 1853, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:37.734379 #train# step 1854, loss = 0.9519, cross_entropy loss = 0.9519, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:39.272187 #train# step 1855, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:40.799321 #train# step 1856, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:42.368702 #train# step 1857, loss = 0.9518, cross_entropy loss = 0.9518, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:43.961108 #train# step 1858, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:45.530006 #train# step 1859, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:47.089200 #train# step 1860, loss = 0.9585, cross_entropy loss = 0.9585, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:48.655664 #train# step 1861, loss = 0.9514, cross_entropy loss = 0.9514, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:50.217234 #train# step 1862, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:51.805938 #train# step 1863, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:53.396072 #train# step 1864, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:54.970986 #train# step 1865, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:56.521341 #train# step 1866, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:58.084370 #train# step 1867, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:49:59.654889 #train# step 1868, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:01.227428 #train# step 1869, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:02.766905 #train# step 1870, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:04.327102 #train# step 1871, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:05.919573 #train# step 1872, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:07.465837 #train# step 1873, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:08.994882 #train# step 1874, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:10.556155 #train# step 1875, loss = 0.9663, cross_entropy loss = 0.9663, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:12.091277 #train# step 1876, loss = 0.9660, cross_entropy loss = 0.9660, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:13.685170 #train# step 1877, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:15.238806 #train# step 1878, loss = 0.9530, cross_entropy loss = 0.9530, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:16.815672 #train# step 1879, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:18.375318 #train# step 1880, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:19.911741 #train# step 1881, loss = 0.9691, cross_entropy loss = 0.9691, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:21.480014 #train# step 1882, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:23.032924 #train# step 1883, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:24.589100 #train# step 1884, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:26.165400 #train# step 1885, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:27.739621 #train# step 1886, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:29.305382 #train# step 1887, loss = 0.9637, cross_entropy loss = 0.9637, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:30.898732 #train# step 1888, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:32.440856 #train# step 1889, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:34.008298 #train# step 1890, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:35.567679 #train# step 1891, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:37.154697 #train# step 1892, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:38.726777 #train# step 1893, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:40.298088 #train# step 1894, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:41.844687 #train# step 1895, loss = 0.9541, cross_entropy loss = 0.9541, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:43.403251 #train# step 1896, loss = 0.9584, cross_entropy loss = 0.9584, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:44.986420 #train# step 1897, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:46.590284 #train# step 1898, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:48.142896 #train# step 1899, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:49.707594 #train# step 1900, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:51.270267 #train# step 1901, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:52.839774 #train# step 1902, loss = 0.9544, cross_entropy loss = 0.9544, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:54.387768 #train# step 1903, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:55.967205 #train# step 1904, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:57.559346 #train# step 1905, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:50:59.109210 #train# step 1906, loss = 0.9467, cross_entropy loss = 0.9467, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:00.660364 #train# step 1907, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:02.210099 #train# step 1908, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:03.764133 #train# step 1909, loss = 0.9578, cross_entropy loss = 0.9578, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:05.326217 #train# step 1910, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:06.908795 #train# step 1911, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:08.458044 #train# step 1912, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:10.037679 #train# step 1913, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:11.630152 #train# step 1914, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:13.179973 #train# step 1915, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:14.717339 #train# step 1916, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:16.247719 #train# step 1917, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:17.781515 #train# step 1918, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:19.360374 #train# step 1919, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:20.915129 #train# step 1920, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:22.452070 #train# step 1921, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:24.005670 #train# step 1922, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:25.537657 #train# step 1923, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:27.089661 #train# step 1924, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:28.672631 #train# step 1925, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:30.256407 #train# step 1926, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:31.827315 #train# step 1927, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:33.395628 #train# step 1928, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:34.942239 #train# step 1929, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:36.503783 #train# step 1930, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:38.043002 #train# step 1931, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:39.622248 #train# step 1932, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:41.174678 #train# step 1933, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:42.716719 #train# step 1934, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:44.309791 #train# step 1935, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:45.892650 #train# step 1936, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:47.466714 #train# step 1937, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:49.020573 #train# step 1938, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:50.560978 #train# step 1939, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:52.118027 #train# step 1940, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:53.660917 #train# step 1941, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:55.232881 #train# step 1942, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:56.782136 #train# step 1943, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:58.338847 #train# step 1944, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:51:59.862123 #train# step 1945, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:01.440761 #train# step 1946, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:02.990817 #train# step 1947, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:04.542427 #train# step 1948, loss = 0.9616, cross_entropy loss = 0.9616, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:06.084522 #train# step 1949, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:07.631275 #train# step 1950, loss = 0.9623, cross_entropy loss = 0.9623, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:09.189858 #train# step 1951, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:10.779110 #train# step 1952, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:12.366472 #train# step 1953, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:13.915650 #train# step 1954, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:15.480022 #train# step 1955, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:17.070489 #train# step 1956, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:18.618304 #train# step 1957, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:20.206142 #train# step 1958, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:21.749066 #train# step 1959, loss = 0.9600, cross_entropy loss = 0.9600, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:23.327406 #train# step 1960, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:24.879821 #train# step 1961, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:26.459101 #train# step 1962, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:28.005997 #train# step 1963, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:29.532017 #train# step 1964, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:31.095724 #train# step 1965, loss = 0.9473, cross_entropy loss = 0.9473, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:32.659569 #train# step 1966, loss = 0.9649, cross_entropy loss = 0.9649, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:34.221408 #train# step 1967, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:35.804421 #train# step 1968, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:37.357415 #train# step 1969, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:38.896449 #train# step 1970, loss = 0.9532, cross_entropy loss = 0.9532, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:40.500136 #train# step 1971, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:42.065784 #train# step 1972, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:43.660338 #train# step 1973, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:45.266886 #train# step 1974, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:46.826980 #train# step 1975, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:48.392042 #train# step 1976, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:49.939040 #train# step 1977, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:51.485889 #train# step 1978, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:53.051319 #train# step 1979, loss = 0.9611, cross_entropy loss = 0.9611, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:54.597276 #train# step 1980, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:56.196266 #train# step 1981, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:57.764739 #train# step 1982, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:52:59.305418 #train# step 1983, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:00.873992 #train# step 1984, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:02.445641 #train# step 1985, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:03.987611 #train# step 1986, loss = 0.9642, cross_entropy loss = 0.9642, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:05.533217 #train# step 1987, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:07.116265 #train# step 1988, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:08.665656 #train# step 1989, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:10.282716 #train# step 1990, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:11.827326 #train# step 1991, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:13.388450 #train# step 1992, loss = 0.9556, cross_entropy loss = 0.9556, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:14.935093 #train# step 1993, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:16.510834 #train# step 1994, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:18.091156 #train# step 1995, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:19.621785 #train# step 1996, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:21.180762 #train# step 1997, loss = 0.9571, cross_entropy loss = 0.9571, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:22.764737 #train# step 1998, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:24.316267 #train# step 1999, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:25.907676 #train# step 2000, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:27.458200 #train# step 2001, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:29.017042 #train# step 2002, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:30.568755 #train# step 2003, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:32.088234 #train# step 2004, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:33.677123 #train# step 2005, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:35.215145 #train# step 2006, loss = 0.9551, cross_entropy loss = 0.9551, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:36.766931 #train# step 2007, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:38.330181 #train# step 2008, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:39.935268 #train# step 2009, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:41.488051 #train# step 2010, loss = 0.9522, cross_entropy loss = 0.9522, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:43.054309 #train# step 2011, loss = 0.9607, cross_entropy loss = 0.9607, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:44.605974 #train# step 2012, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:46.197020 #train# step 2013, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:47.766690 #train# step 2014, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:49.344281 #train# step 2015, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:50.940386 #train# step 2016, loss = 0.9474, cross_entropy loss = 0.9474, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:52.467219 #train# step 2017, loss = 0.9591, cross_entropy loss = 0.9591, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:54.010377 #train# step 2018, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:55.571432 #train# step 2019, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:57.134186 #train# step 2020, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:53:58.713560 #train# step 2021, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:00.278248 #train# step 2022, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:01.846895 #train# step 2023, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:03.410347 #train# step 2024, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:04.983510 #train# step 2025, loss = 0.9586, cross_entropy loss = 0.9586, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:06.566645 #train# step 2026, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:08.100215 #train# step 2027, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:09.653388 #train# step 2028, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:11.248660 #train# step 2029, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:12.772489 #train# step 2030, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:14.331202 #train# step 2031, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:15.865991 #train# step 2032, loss = 0.9577, cross_entropy loss = 0.9577, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:17.434656 #train# step 2033, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:18.993655 #train# step 2034, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:20.559711 #train# step 2035, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:22.118305 #train# step 2036, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:23.668817 #train# step 2037, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:25.232656 #train# step 2038, loss = 0.9575, cross_entropy loss = 0.9575, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:26.805941 #train# step 2039, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:28.358292 #train# step 2040, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:29.911287 #train# step 2041, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:31.471407 #train# step 2042, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:33.040890 #train# step 2043, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:34.593332 #train# step 2044, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:36.154682 #train# step 2045, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:37.695233 #train# step 2046, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:39.241753 #train# step 2047, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:40.811630 #train# step 2048, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:42.383657 #train# step 2049, loss = 0.9655, cross_entropy loss = 0.9655, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:43.939397 #train# step 2050, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:45.504763 #train# step 2051, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:47.081668 #train# step 2052, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:48.647981 #train# step 2053, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:50.182375 #train# step 2054, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:51.769086 #train# step 2055, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:53.334438 #train# step 2056, loss = 0.9553, cross_entropy loss = 0.9553, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:54.897536 #train# step 2057, loss = 0.9711, cross_entropy loss = 0.9711, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:56.466989 #train# step 2058, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:58.032202 #train# step 2059, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:54:59.601988 #train# step 2060, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:01.155400 #train# step 2061, loss = 0.9666, cross_entropy loss = 0.9666, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:02.683777 #train# step 2062, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:04.269938 #train# step 2063, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:05.836859 #train# step 2064, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:07.359190 #train# step 2065, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:08.915231 #train# step 2066, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:10.578476 #train# step 2067, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:12.092884 #train# step 2068, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:13.636038 #train# step 2069, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:15.198269 #train# step 2070, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:16.761872 #train# step 2071, loss = 0.9597, cross_entropy loss = 0.9597, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:18.313650 #train# step 2072, loss = 0.9472, cross_entropy loss = 0.9472, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:19.859072 #train# step 2073, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:21.414851 #train# step 2074, loss = 0.9567, cross_entropy loss = 0.9567, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:23.010461 #train# step 2075, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:24.593150 #train# step 2076, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:26.151869 #train# step 2077, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:27.710620 #train# step 2078, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:29.279132 #train# step 2079, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:30.861937 #train# step 2080, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:32.401563 #train# step 2081, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:33.979191 #train# step 2082, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:35.517753 #train# step 2083, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:37.096672 #train# step 2084, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:38.641414 #train# step 2085, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:40.188802 #train# step 2086, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:41.730819 #train# step 2087, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:43.289530 #train# step 2088, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:44.826610 #train# step 2089, loss = 0.9563, cross_entropy loss = 0.9563, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:46.385135 #train# step 2090, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:47.954332 #train# step 2091, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:49.522263 #train# step 2092, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:51.064693 #train# step 2093, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:52.602714 #train# step 2094, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:54.159858 #train# step 2095, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:55.724352 #train# step 2096, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:57.309912 #train# step 2097, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:55:58.907764 #train# step 2098, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:00.464580 #train# step 2099, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:02.034703 #train# step 2100, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:03.620740 #train# step 2101, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:05.187710 #train# step 2102, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:06.762271 #train# step 2103, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:08.323068 #train# step 2104, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:09.874546 #train# step 2105, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:11.423807 #train# step 2106, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:12.970800 #train# step 2107, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:14.550753 #train# step 2108, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:16.152249 #train# step 2109, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:17.720191 #train# step 2110, loss = 0.9621, cross_entropy loss = 0.9621, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:19.255754 #train# step 2111, loss = 0.9494, cross_entropy loss = 0.9494, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:20.819911 #train# step 2112, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:22.357025 #train# step 2113, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:23.928308 #train# step 2114, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:25.490503 #train# step 2115, loss = 0.9579, cross_entropy loss = 0.9579, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:27.079935 #train# step 2116, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:28.668670 #train# step 2117, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:30.225767 #train# step 2118, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:31.773889 #train# step 2119, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:33.330441 #train# step 2120, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:34.900959 #train# step 2121, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:36.451756 #train# step 2122, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:38.052691 #train# step 2123, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:39.589496 #train# step 2124, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:41.128322 #train# step 2125, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:42.715560 #train# step 2126, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:44.252405 #train# step 2127, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:45.799125 #train# step 2128, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:47.363462 #train# step 2129, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:48.915240 #train# step 2130, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:50.493233 #train# step 2131, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:52.079208 #train# step 2132, loss = 0.9557, cross_entropy loss = 0.9557, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:53.660497 #train# step 2133, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:55.240092 #train# step 2134, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:56.839015 #train# step 2135, loss = 0.9598, cross_entropy loss = 0.9598, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:58.420825 #train# step 2136, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:56:59.976413 #train# step 2137, loss = 0.9558, cross_entropy loss = 0.9558, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:01.562451 #train# step 2138, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:03.124756 #train# step 2139, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:04.676874 #train# step 2140, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:06.216480 #train# step 2141, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:07.787495 #train# step 2142, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:09.304596 #train# step 2143, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:10.840395 #train# step 2144, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:12.442085 #train# step 2145, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:14.021950 #train# step 2146, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:15.581863 #train# step 2147, loss = 0.9555, cross_entropy loss = 0.9555, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:17.148073 #train# step 2148, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:18.710299 #train# step 2149, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:20.269103 #train# step 2150, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:21.831514 #train# step 2151, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:23.390472 #train# step 2152, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:24.917074 #train# step 2153, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:26.489234 #train# step 2154, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:28.082965 #train# step 2155, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:29.632770 #train# step 2156, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:31.183468 #train# step 2157, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:32.759496 #train# step 2158, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:34.298284 #train# step 2159, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:35.870585 #train# step 2160, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:37.408612 #train# step 2161, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:38.961419 #train# step 2162, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:40.551921 #train# step 2163, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:42.124331 #train# step 2164, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:43.690205 #train# step 2165, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:45.256431 #train# step 2166, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:46.818599 #train# step 2167, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:48.356751 #train# step 2168, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:49.896265 #train# step 2169, loss = 0.9593, cross_entropy loss = 0.9593, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:51.456032 #train# step 2170, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:53.008405 #train# step 2171, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:54.603433 #train# step 2172, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:56.188756 #train# step 2173, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:57.743776 #train# step 2174, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:57:59.337125 #train# step 2175, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:00.892819 #train# step 2176, loss = 0.9529, cross_entropy loss = 0.9529, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:02.444140 #train# step 2177, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:03.983238 #train# step 2178, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:05.557412 #train# step 2179, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:07.076766 #train# step 2180, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:08.602402 #train# step 2181, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:10.165489 #train# step 2182, loss = 0.9440, cross_entropy loss = 0.9440, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:11.749781 #train# step 2183, loss = 0.9513, cross_entropy loss = 0.9513, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:13.315994 #train# step 2184, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:14.878724 #train# step 2185, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:16.409528 #train# step 2186, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:17.973432 #train# step 2187, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:19.539936 #train# step 2188, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:21.079806 #train# step 2189, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:22.641234 #train# step 2190, loss = 0.9537, cross_entropy loss = 0.9537, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:24.210070 #train# step 2191, loss = 0.9506, cross_entropy loss = 0.9506, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:25.783311 #train# step 2192, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:27.324716 #train# step 2193, loss = 0.9581, cross_entropy loss = 0.9581, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:28.934656 #train# step 2194, loss = 0.9458, cross_entropy loss = 0.9458, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:30.470824 #train# step 2195, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:32.045136 #train# step 2196, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:33.640934 #train# step 2197, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:35.182173 #train# step 2198, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:36.768447 #train# step 2199, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:38.349202 #train# step 2200, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:39.948288 #train# step 2201, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:41.491236 #train# step 2202, loss = 0.9572, cross_entropy loss = 0.9572, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:43.053800 #train# step 2203, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:44.606723 #train# step 2204, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:46.149002 #train# step 2205, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:47.732148 #train# step 2206, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:49.258680 #train# step 2207, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:50.819654 #train# step 2208, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:52.391469 #train# step 2209, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:53.947269 #train# step 2210, loss = 0.9527, cross_entropy loss = 0.9527, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:55.529206 #train# step 2211, loss = 0.9431, cross_entropy loss = 0.9431, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:57.078409 #train# step 2212, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:58:58.620021 #train# step 2213, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:00.182064 #train# step 2214, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:01.748923 #train# step 2215, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:03.310704 #train# step 2216, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:04.894639 #train# step 2217, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:06.455059 #train# step 2218, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:08.025702 #train# step 2219, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:09.572871 #train# step 2220, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:11.149714 #train# step 2221, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:12.700870 #train# step 2222, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:14.264488 #train# step 2223, loss = 0.9603, cross_entropy loss = 0.9603, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:15.838575 #train# step 2224, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:17.420488 #train# step 2225, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:18.985622 #train# step 2226, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:20.547702 #train# step 2227, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:22.103803 #train# step 2228, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:23.679667 #train# step 2229, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:25.256684 #train# step 2230, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:26.795149 #train# step 2231, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:28.380840 #train# step 2232, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:29.959379 #train# step 2233, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:31.510640 #train# step 2234, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:33.076670 #train# step 2235, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:34.631850 #train# step 2236, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:36.198413 #train# step 2237, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:37.742668 #train# step 2238, loss = 0.9615, cross_entropy loss = 0.9615, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:39.289951 #train# step 2239, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:40.858966 #train# step 2240, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:42.415544 #train# step 2241, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:43.970441 #train# step 2242, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:45.508897 #train# step 2243, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:47.055642 #train# step 2244, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:48.633994 #train# step 2245, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:50.197548 #train# step 2246, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:51.747120 #train# step 2247, loss = 0.9604, cross_entropy loss = 0.9604, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:53.295803 #train# step 2248, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:54.873746 #train# step 2249, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:56.411804 #train# step 2250, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:58.007059 #train# step 2251, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 18:59:59.612711 #train# step 2252, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:01.205263 #train# step 2253, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:02.735116 #train# step 2254, loss = 0.9576, cross_entropy loss = 0.9576, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:04.289941 #train# step 2255, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:05.861556 #train# step 2256, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:07.434304 #train# step 2257, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:09.037205 #train# step 2258, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:10.586087 #train# step 2259, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:12.143208 #train# step 2260, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:13.710420 #train# step 2261, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:15.277207 #train# step 2262, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:16.804062 #train# step 2263, loss = 0.9520, cross_entropy loss = 0.9520, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:18.371112 #train# step 2264, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:19.916971 #train# step 2265, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:21.426948 #train# step 2266, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:22.963316 #train# step 2267, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:24.501500 #train# step 2268, loss = 0.9507, cross_entropy loss = 0.9507, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:26.075123 #train# step 2269, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:27.638284 #train# step 2270, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:29.185466 #train# step 2271, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:30.774454 #train# step 2272, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:32.329567 #train# step 2273, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:33.873010 #train# step 2274, loss = 0.9718, cross_entropy loss = 0.9718, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:35.456653 #train# step 2275, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:37.020813 #train# step 2276, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:38.588063 #train# step 2277, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:40.158709 #train# step 2278, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:41.710441 #train# step 2279, loss = 0.9500, cross_entropy loss = 0.9500, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:43.275737 #train# step 2280, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:44.857979 #train# step 2281, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:46.417359 #train# step 2282, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:47.972374 #train# step 2283, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:49.497676 #train# step 2284, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:51.070996 #train# step 2285, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:52.637681 #train# step 2286, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:54.190055 #train# step 2287, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:55.764381 #train# step 2288, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:57.321001 #train# step 2289, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:00:58.910329 #train# step 2290, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:00.473666 #train# step 2291, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:02.042761 #train# step 2292, loss = 0.9559, cross_entropy loss = 0.9559, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:03.600340 #train# step 2293, loss = 0.9624, cross_entropy loss = 0.9624, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:05.181885 #train# step 2294, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:06.734496 #train# step 2295, loss = 0.9639, cross_entropy loss = 0.9639, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:08.330561 #train# step 2296, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:09.884303 #train# step 2297, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:11.433642 #train# step 2298, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:12.975243 #train# step 2299, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:14.554591 #train# step 2300, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:16.117758 #train# step 2301, loss = 0.9570, cross_entropy loss = 0.9570, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:17.720856 #train# step 2302, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:19.294087 #train# step 2303, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:20.875923 #train# step 2304, loss = 0.9595, cross_entropy loss = 0.9595, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:22.437691 #train# step 2305, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:23.995647 #train# step 2306, loss = 0.9455, cross_entropy loss = 0.9455, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:25.607889 #train# step 2307, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:27.182238 #train# step 2308, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:28.767583 #train# step 2309, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:30.339991 #train# step 2310, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:31.891542 #train# step 2311, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:33.462315 #train# step 2312, loss = 0.9462, cross_entropy loss = 0.9462, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:35.009606 #train# step 2313, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:36.573039 #train# step 2314, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:38.128411 #train# step 2315, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:39.698262 #train# step 2316, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:41.246639 #train# step 2317, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:42.828116 #train# step 2318, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:44.432340 #train# step 2319, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:45.991355 #train# step 2320, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:47.555657 #train# step 2321, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:49.141713 #train# step 2322, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:50.697868 #train# step 2323, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:52.243179 #train# step 2324, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:53.818690 #train# step 2325, loss = 0.9357, cross_entropy loss = 0.9357, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:55.371165 #train# step 2326, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:56.943091 #train# step 2327, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:01:58.501060 #train# step 2328, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:00.094834 #train# step 2329, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:01.631135 #train# step 2330, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:03.190709 #train# step 2331, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:04.761865 #train# step 2332, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:06.343975 #train# step 2333, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:07.898654 #train# step 2334, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:09.460942 #train# step 2335, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:11.012512 #train# step 2336, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:12.568142 #train# step 2337, loss = 0.9568, cross_entropy loss = 0.9568, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:14.156522 #train# step 2338, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:15.690127 #train# step 2339, loss = 0.9449, cross_entropy loss = 0.9449, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:17.241846 #train# step 2340, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:18.800488 #train# step 2341, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:20.365536 #train# step 2342, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:21.915235 #train# step 2343, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:23.459996 #train# step 2344, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:24.995767 #train# step 2345, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:26.545964 #train# step 2346, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:28.111204 #train# step 2347, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:29.664205 #train# step 2348, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:31.221651 #train# step 2349, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:32.794202 #train# step 2350, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:34.364012 #train# step 2351, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:35.944498 #train# step 2352, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:37.508445 #train# step 2353, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:39.070699 #train# step 2354, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:40.611172 #train# step 2355, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:42.192776 #train# step 2356, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:43.760339 #train# step 2357, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:45.318592 #train# step 2358, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:46.851451 #train# step 2359, loss = 0.9580, cross_entropy loss = 0.9580, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:48.421165 #train# step 2360, loss = 0.9464, cross_entropy loss = 0.9464, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:49.970433 #train# step 2361, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:51.545514 #train# step 2362, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:53.085398 #train# step 2363, loss = 0.9562, cross_entropy loss = 0.9562, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:54.665117 #train# step 2364, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:56.227923 #train# step 2365, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:57.769841 #train# step 2366, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:02:59.322185 #train# step 2367, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:00.896592 #train# step 2368, loss = 0.9548, cross_entropy loss = 0.9548, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:02.471059 #train# step 2369, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:04.042288 #train# step 2370, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:05.609832 #train# step 2371, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:07.179122 #train# step 2372, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:08.757915 #train# step 2373, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:10.310256 #train# step 2374, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:11.847401 #train# step 2375, loss = 0.9680, cross_entropy loss = 0.9680, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:13.459603 #train# step 2376, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:15.023178 #train# step 2377, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:16.598544 #train# step 2378, loss = 0.9661, cross_entropy loss = 0.9661, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:18.184617 #train# step 2379, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:19.733759 #train# step 2380, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:21.267632 #train# step 2381, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:22.851277 #train# step 2382, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:24.379565 #train# step 2383, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:25.942300 #train# step 2384, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:27.499701 #train# step 2385, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:29.059993 #train# step 2386, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:30.629982 #train# step 2387, loss = 0.9463, cross_entropy loss = 0.9463, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:32.185400 #train# step 2388, loss = 0.9443, cross_entropy loss = 0.9443, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:33.742001 #train# step 2389, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:35.311205 #train# step 2390, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:36.863366 #train# step 2391, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:38.424488 #train# step 2392, loss = 0.9423, cross_entropy loss = 0.9423, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:39.987995 #train# step 2393, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:41.543599 #train# step 2394, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:43.098425 #train# step 2395, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:44.665734 #train# step 2396, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:46.267244 #train# step 2397, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:47.828742 #train# step 2398, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:49.395669 #train# step 2399, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:50.977715 #train# step 2400, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:52.534708 #train# step 2401, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:54.100098 #train# step 2402, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:55.670669 #train# step 2403, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:57.241741 #train# step 2404, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:03:58.812649 #train# step 2405, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:00.371157 #train# step 2406, loss = 0.9564, cross_entropy loss = 0.9564, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:01.947626 #train# step 2407, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:03.535380 #train# step 2408, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:05.089062 #train# step 2409, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:06.637999 #train# step 2410, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:08.228833 #train# step 2411, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:09.793302 #train# step 2412, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:11.337755 #train# step 2413, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:12.900377 #train# step 2414, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:14.463443 #train# step 2415, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:15.995924 #train# step 2416, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:17.546198 #train# step 2417, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:19.108847 #train# step 2418, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:20.662658 #train# step 2419, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:22.226559 #train# step 2420, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:23.792777 #train# step 2421, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:25.360211 #train# step 2422, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:26.924781 #train# step 2423, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:28.499821 #train# step 2424, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:30.082456 #train# step 2425, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:31.658922 #train# step 2426, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:33.234333 #train# step 2427, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:34.770455 #train# step 2428, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:36.337874 #train# step 2429, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:37.868794 #train# step 2430, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:39.444875 #train# step 2431, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:40.997423 #train# step 2432, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:42.553520 #train# step 2433, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:44.118092 #train# step 2434, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:45.711882 #train# step 2435, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:47.297870 #train# step 2436, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:48.844133 #train# step 2437, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:50.427066 #train# step 2438, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:51.974177 #train# step 2439, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:53.535312 #train# step 2440, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:55.094239 #train# step 2441, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:56.663657 #train# step 2442, loss = 0.9573, cross_entropy loss = 0.9573, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:58.191061 #train# step 2443, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:04:59.753355 #train# step 2444, loss = 0.9469, cross_entropy loss = 0.9469, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:01.334867 #train# step 2445, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:02.899693 #train# step 2446, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:04.450332 #train# step 2447, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:06.017416 #train# step 2448, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:07.586182 #train# step 2449, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:09.127445 #train# step 2450, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:10.690599 #train# step 2451, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:12.237682 #train# step 2452, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:13.783511 #train# step 2453, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:15.379906 #train# step 2454, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:16.958951 #train# step 2455, loss = 0.9482, cross_entropy loss = 0.9482, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:18.530483 #train# step 2456, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:20.115053 #train# step 2457, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:21.669032 #train# step 2458, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:23.221487 #train# step 2459, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:24.773677 #train# step 2460, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:26.383124 #train# step 2461, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:27.926548 #train# step 2462, loss = 0.9442, cross_entropy loss = 0.9442, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:29.471337 #train# step 2463, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:31.023533 #train# step 2464, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:32.599591 #train# step 2465, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:34.140736 #train# step 2466, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:35.694616 #train# step 2467, loss = 0.9605, cross_entropy loss = 0.9605, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:37.267732 #train# step 2468, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:38.824359 #train# step 2469, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:40.356563 #train# step 2470, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:41.932715 #train# step 2471, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:43.545616 #train# step 2472, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:45.139891 #train# step 2473, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:46.727781 #train# step 2474, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:48.302161 #train# step 2475, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:49.865082 #train# step 2476, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:51.417936 #train# step 2477, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:52.987277 #train# step 2478, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:54.535799 #train# step 2479, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:56.128929 #train# step 2480, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:57.688289 #train# step 2481, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:05:59.259431 #train# step 2482, loss = 0.9495, cross_entropy loss = 0.9495, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:00.821468 #train# step 2483, loss = 0.9490, cross_entropy loss = 0.9490, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:02.367253 #train# step 2484, loss = 0.9435, cross_entropy loss = 0.9435, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:03.934987 #train# step 2485, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:05.478401 #train# step 2486, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:07.034100 #train# step 2487, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:08.582843 #train# step 2488, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:10.118007 #train# step 2489, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:11.668484 #train# step 2490, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:13.214614 #train# step 2491, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:14.805325 #train# step 2492, loss = 0.9565, cross_entropy loss = 0.9565, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:16.361545 #train# step 2493, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:17.935028 #train# step 2494, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:19.513561 #train# step 2495, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:21.075450 #train# step 2496, loss = 0.9484, cross_entropy loss = 0.9484, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:22.632048 #train# step 2497, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:24.178146 #train# step 2498, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:25.757463 #train# step 2499, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:27.314082 #train# step 2500, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:28.844336 #train# step 2501, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:30.416731 #train# step 2502, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:31.980775 #train# step 2503, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:33.535254 #train# step 2504, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:35.092480 #train# step 2505, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:36.675716 #train# step 2506, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:38.258325 #train# step 2507, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:39.839099 #train# step 2508, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:41.384305 #train# step 2509, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:42.951154 #train# step 2510, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:44.509315 #train# step 2511, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:46.064824 #train# step 2512, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:47.670916 #train# step 2513, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:49.218995 #train# step 2514, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:50.796855 #train# step 2515, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:52.370791 #train# step 2516, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:53.896400 #train# step 2517, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:55.444833 #train# step 2518, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:57.023471 #train# step 2519, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:06:58.605610 #train# step 2520, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:00.163805 #train# step 2521, loss = 0.9531, cross_entropy loss = 0.9531, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:01.742528 #train# step 2522, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:03.312515 #train# step 2523, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:04.864065 #train# step 2524, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:06.439249 #train# step 2525, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:08.002635 #train# step 2526, loss = 0.9504, cross_entropy loss = 0.9504, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:09.605555 #train# step 2527, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:11.164115 #train# step 2528, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:12.703720 #train# step 2529, loss = 0.9433, cross_entropy loss = 0.9433, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:14.241391 #train# step 2530, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:15.821111 #train# step 2531, loss = 0.9395, cross_entropy loss = 0.9395, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:17.373874 #train# step 2532, loss = 0.9354, cross_entropy loss = 0.9354, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:18.950716 #train# step 2533, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:20.523326 #train# step 2534, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:22.070247 #train# step 2535, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:23.597970 #train# step 2536, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:25.152171 #train# step 2537, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:26.718448 #train# step 2538, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:28.322672 #train# step 2539, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:29.874397 #train# step 2540, loss = 0.9538, cross_entropy loss = 0.9538, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:31.415235 #train# step 2541, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:32.963984 #train# step 2542, loss = 0.9460, cross_entropy loss = 0.9460, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:34.547653 #train# step 2543, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:36.112012 #train# step 2544, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:37.696697 #train# step 2545, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:39.269015 #train# step 2546, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:40.825555 #train# step 2547, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:42.380822 #train# step 2548, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:43.932396 #train# step 2549, loss = 0.9625, cross_entropy loss = 0.9625, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:45.498854 #train# step 2550, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:47.081014 #train# step 2551, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:48.669462 #train# step 2552, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:50.221132 #train# step 2553, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:51.772445 #train# step 2554, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:53.356842 #train# step 2555, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:54.909090 #train# step 2556, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:56.465829 #train# step 2557, loss = 0.9540, cross_entropy loss = 0.9540, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:58.040533 #train# step 2558, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:07:59.593314 #train# step 2559, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:01.180628 #train# step 2560, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:02.722614 #train# step 2561, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:04.288956 #train# step 2562, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:05.867146 #train# step 2563, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:07.425713 #train# step 2564, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:08.981332 #train# step 2565, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:10.532477 #train# step 2566, loss = 0.9508, cross_entropy loss = 0.9508, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:12.093841 #train# step 2567, loss = 0.9545, cross_entropy loss = 0.9545, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:13.683413 #train# step 2568, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:15.258041 #train# step 2569, loss = 0.9628, cross_entropy loss = 0.9628, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:16.841617 #train# step 2570, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:18.377858 #train# step 2571, loss = 0.9502, cross_entropy loss = 0.9502, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:19.900231 #train# step 2572, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:21.449466 #train# step 2573, loss = 0.9486, cross_entropy loss = 0.9486, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:23.020210 #train# step 2574, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:24.577489 #train# step 2575, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:26.122950 #train# step 2576, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:27.692117 #train# step 2577, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:29.265682 #train# step 2578, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:30.811465 #train# step 2579, loss = 0.9475, cross_entropy loss = 0.9475, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:32.375819 #train# step 2580, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:33.908427 #train# step 2581, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:35.453689 #train# step 2582, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:37.013510 #train# step 2583, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:38.573584 #train# step 2584, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:40.145419 #train# step 2585, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:41.711491 #train# step 2586, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:43.266056 #train# step 2587, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:44.793941 #train# step 2588, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:46.367978 #train# step 2589, loss = 0.9497, cross_entropy loss = 0.9497, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:47.909724 #train# step 2590, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:49.511538 #train# step 2591, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:51.070961 #train# step 2592, loss = 0.9477, cross_entropy loss = 0.9477, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:52.605443 #train# step 2593, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:54.185460 #train# step 2594, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:55.783328 #train# step 2595, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:57.356994 #train# step 2596, loss = 0.9480, cross_entropy loss = 0.9480, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:08:58.880316 #train# step 2597, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:00.433155 #train# step 2598, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:02.030686 #train# step 2599, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:03.577445 #train# step 2600, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:05.163103 #train# step 2601, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:06.758893 #train# step 2602, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:08.307117 #train# step 2603, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:09.904570 #train# step 2604, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:11.457238 #train# step 2605, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:13.017814 #train# step 2606, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:14.576485 #train# step 2607, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:16.159808 #train# step 2608, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:17.732027 #train# step 2609, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:19.284975 #train# step 2610, loss = 0.9512, cross_entropy loss = 0.9512, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:20.846128 #train# step 2611, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:22.399240 #train# step 2612, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:23.972548 #train# step 2613, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:25.521806 #train# step 2614, loss = 0.9459, cross_entropy loss = 0.9459, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:27.086069 #train# step 2615, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:28.652186 #train# step 2616, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:30.192090 #train# step 2617, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:31.767942 #train# step 2618, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:33.329258 #train# step 2619, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:34.885994 #train# step 2620, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:36.433809 #train# step 2621, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:38.000582 #train# step 2622, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:39.562334 #train# step 2623, loss = 0.9505, cross_entropy loss = 0.9505, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:41.144929 #train# step 2624, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:42.716550 #train# step 2625, loss = 0.9583, cross_entropy loss = 0.9583, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:44.270606 #train# step 2626, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:45.822495 #train# step 2627, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:47.393979 #train# step 2628, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:48.970676 #train# step 2629, loss = 0.9448, cross_entropy loss = 0.9448, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:50.534429 #train# step 2630, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:52.095798 #train# step 2631, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:53.628974 #train# step 2632, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:55.217366 #train# step 2633, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:56.775869 #train# step 2634, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:58.319065 #train# step 2635, loss = 0.9599, cross_entropy loss = 0.9599, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:09:59.905065 #train# step 2636, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:01.479728 #train# step 2637, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:03.072463 #train# step 2638, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:04.617294 #train# step 2639, loss = 0.9534, cross_entropy loss = 0.9534, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:06.184874 #train# step 2640, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:07.731834 #train# step 2641, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:09.308680 #train# step 2642, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:10.875562 #train# step 2643, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:12.434938 #train# step 2644, loss = 0.9461, cross_entropy loss = 0.9461, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:13.989182 #train# step 2645, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:15.527333 #train# step 2646, loss = 0.9493, cross_entropy loss = 0.9493, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:17.092240 #train# step 2647, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:18.678202 #train# step 2648, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:20.262112 #train# step 2649, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:21.820776 #train# step 2650, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:23.366023 #train# step 2651, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:24.916295 #train# step 2652, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:26.449136 #train# step 2653, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:27.978398 #train# step 2654, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:29.540231 #train# step 2655, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:31.117126 #train# step 2656, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:32.690891 #train# step 2657, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:34.260238 #train# step 2658, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:35.836905 #train# step 2659, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:37.389936 #train# step 2660, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:38.951473 #train# step 2661, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:40.544782 #train# step 2662, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:42.107832 #train# step 2663, loss = 0.9546, cross_entropy loss = 0.9546, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:43.672446 #train# step 2664, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:45.218521 #train# step 2665, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:46.787290 #train# step 2666, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:48.358318 #train# step 2667, loss = 0.9450, cross_entropy loss = 0.9450, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:49.919769 #train# step 2668, loss = 0.9364, cross_entropy loss = 0.9364, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:51.479244 #train# step 2669, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:53.025845 #train# step 2670, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:54.590756 #train# step 2671, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:56.149348 #train# step 2672, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:57.721819 #train# step 2673, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:10:59.315959 #train# step 2674, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:00.896597 #train# step 2675, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:02.467030 #train# step 2676, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:04.035737 #train# step 2677, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:05.584052 #train# step 2678, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:07.132082 #train# step 2679, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:08.682672 #train# step 2680, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:10.291024 #train# step 2681, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:11.850494 #train# step 2682, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:13.421790 #train# step 2683, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:15.001771 #train# step 2684, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:16.537544 #train# step 2685, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:18.098927 #train# step 2686, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:19.668532 #train# step 2687, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:21.200638 #train# step 2688, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:22.784594 #train# step 2689, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:24.332818 #train# step 2690, loss = 0.9587, cross_entropy loss = 0.9587, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:25.908654 #train# step 2691, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:27.484186 #train# step 2692, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:29.027686 #train# step 2693, loss = 0.9444, cross_entropy loss = 0.9444, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:30.596593 #train# step 2694, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:32.142498 #train# step 2695, loss = 0.9536, cross_entropy loss = 0.9536, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:33.694570 #train# step 2696, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:35.274395 #train# step 2697, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:36.846866 #train# step 2698, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:38.434509 #train# step 2699, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:40.054455 #train# step 2700, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:41.630469 #train# step 2701, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:43.200573 #train# step 2702, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:44.745647 #train# step 2703, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:46.303421 #train# step 2704, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:47.872494 #train# step 2705, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:49.407415 #train# step 2706, loss = 0.9491, cross_entropy loss = 0.9491, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:50.956869 #train# step 2707, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:52.495947 #train# step 2708, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:54.043363 #train# step 2709, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:55.589512 #train# step 2710, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:57.140097 #train# step 2711, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:11:58.678831 #train# step 2712, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:00.221624 #train# step 2713, loss = 0.9510, cross_entropy loss = 0.9510, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:01.775831 #train# step 2714, loss = 0.9542, cross_entropy loss = 0.9542, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:03.335445 #train# step 2715, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:04.901566 #train# step 2716, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:06.473594 #train# step 2717, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:08.048083 #train# step 2718, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:09.585294 #train# step 2719, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:11.195345 #train# step 2720, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:12.756339 #train# step 2721, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:14.338028 #train# step 2722, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:15.902231 #train# step 2723, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:17.444801 #train# step 2724, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:19.015213 #train# step 2725, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:20.570099 #train# step 2726, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:22.142149 #train# step 2727, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:23.700819 #train# step 2728, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:25.260983 #train# step 2729, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:26.819398 #train# step 2730, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:28.381850 #train# step 2731, loss = 0.9516, cross_entropy loss = 0.9516, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:29.914399 #train# step 2732, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:31.474385 #train# step 2733, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:33.045600 #train# step 2734, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:34.595583 #train# step 2735, loss = 0.9415, cross_entropy loss = 0.9415, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:36.163569 #train# step 2736, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:37.703665 #train# step 2737, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:39.280023 #train# step 2738, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:40.841148 #train# step 2739, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:42.415376 #train# step 2740, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:43.960796 #train# step 2741, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:45.501987 #train# step 2742, loss = 0.9511, cross_entropy loss = 0.9511, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:47.073451 #train# step 2743, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:48.609774 #train# step 2744, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:50.180704 #train# step 2745, loss = 0.9446, cross_entropy loss = 0.9446, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:51.758771 #train# step 2746, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:53.313850 #train# step 2747, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:54.912568 #train# step 2748, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:56.451485 #train# step 2749, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:58.046840 #train# step 2750, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:12:59.607481 #train# step 2751, loss = 0.9410, cross_entropy loss = 0.9410, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:01.156933 #train# step 2752, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:02.737939 #train# step 2753, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:04.310858 #train# step 2754, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:05.885035 #train# step 2755, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:07.437620 #train# step 2756, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:09.018954 #train# step 2757, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:10.589274 #train# step 2758, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:12.186888 #train# step 2759, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:13.742447 #train# step 2760, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:15.297224 #train# step 2761, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:16.821562 #train# step 2762, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:18.395757 #train# step 2763, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:19.958811 #train# step 2764, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:21.521552 #train# step 2765, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:23.065918 #train# step 2766, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:24.621812 #train# step 2767, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:26.200465 #train# step 2768, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:27.799472 #train# step 2769, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:29.368578 #train# step 2770, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:30.918000 #train# step 2771, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:32.468723 #train# step 2772, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:34.030699 #train# step 2773, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:35.622411 #train# step 2774, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:37.211694 #train# step 2775, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:38.779777 #train# step 2776, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:40.368169 #train# step 2777, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:41.914837 #train# step 2778, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:43.465773 #train# step 2779, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:45.016829 #train# step 2780, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:46.573008 #train# step 2781, loss = 0.9526, cross_entropy loss = 0.9526, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:48.114520 #train# step 2782, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:49.690789 #train# step 2783, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:51.226183 #train# step 2784, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:52.808210 #train# step 2785, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:54.389005 #train# step 2786, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:55.948698 #train# step 2787, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:57.509265 #train# step 2788, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:13:59.064724 #train# step 2789, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:00.647771 #train# step 2790, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:02.183363 #train# step 2791, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:03.739419 #train# step 2792, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:05.286443 #train# step 2793, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:06.857560 #train# step 2794, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:08.413953 #train# step 2795, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:09.987025 #train# step 2796, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:11.535692 #train# step 2797, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:13.095537 #train# step 2798, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:14.665326 #train# step 2799, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:16.239807 #train# step 2800, loss = 0.9489, cross_entropy loss = 0.9489, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:17.805595 #train# step 2801, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:19.379150 #train# step 2802, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:20.955870 #train# step 2803, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:22.544604 #train# step 2804, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:24.109945 #train# step 2805, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:25.687527 #train# step 2806, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:27.220065 #train# step 2807, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:28.779105 #train# step 2808, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:30.350051 #train# step 2809, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:31.881813 #train# step 2810, loss = 0.9381, cross_entropy loss = 0.9381, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:33.516608 #train# step 2811, loss = 0.9391, cross_entropy loss = 0.9391, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:35.081529 #train# step 2812, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:36.683581 #train# step 2813, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:38.296272 #train# step 2814, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:39.866779 #train# step 2815, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:41.457866 #train# step 2816, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:43.030686 #train# step 2817, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:44.586315 #train# step 2818, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:46.170565 #train# step 2819, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:47.756294 #train# step 2820, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:49.324595 #train# step 2821, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:50.879522 #train# step 2822, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:52.503836 #train# step 2823, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:54.116108 #train# step 2824, loss = 0.9275, cross_entropy loss = 0.9275, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:55.783115 #train# step 2825, loss = 0.9419, cross_entropy loss = 0.9419, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:57.388001 #train# step 2826, loss = 0.9492, cross_entropy loss = 0.9492, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:14:58.984500 #train# step 2827, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:00.551783 #train# step 2828, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:02.129501 #train# step 2829, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:03.705725 #train# step 2830, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:05.279927 #train# step 2831, loss = 0.9496, cross_entropy loss = 0.9496, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:06.866527 #train# step 2832, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:08.452418 #train# step 2833, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:10.012349 #train# step 2834, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:11.590715 #train# step 2835, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:13.212673 #train# step 2836, loss = 0.9286, cross_entropy loss = 0.9286, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:14.769604 #train# step 2837, loss = 0.9428, cross_entropy loss = 0.9428, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:16.341977 #train# step 2838, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:17.923153 #train# step 2839, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:19.499509 #train# step 2840, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:21.078233 #train# step 2841, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:22.637754 #train# step 2842, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:24.201134 #train# step 2843, loss = 0.9487, cross_entropy loss = 0.9487, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:25.774698 #train# step 2844, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:27.354016 #train# step 2845, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:28.947243 #train# step 2846, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:30.540914 #train# step 2847, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:32.141400 #train# step 2848, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:33.730623 #train# step 2849, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:35.340558 #train# step 2850, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:36.927607 #train# step 2851, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:38.532369 #train# step 2852, loss = 0.9335, cross_entropy loss = 0.9335, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:40.099555 #train# step 2853, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:41.687745 #train# step 2854, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:43.283775 #train# step 2855, loss = 0.9417, cross_entropy loss = 0.9417, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:44.884945 #train# step 2856, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:46.463050 #train# step 2857, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:48.051625 #train# step 2858, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:49.630302 #train# step 2859, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:51.194807 #train# step 2860, loss = 0.9499, cross_entropy loss = 0.9499, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:52.786234 #train# step 2861, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:54.355165 #train# step 2862, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:55.923004 #train# step 2863, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:57.523629 #train# step 2864, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:15:59.119698 #train# step 2865, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:00.685202 #train# step 2866, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:02.290700 #train# step 2867, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:03.874328 #train# step 2868, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:05.452903 #train# step 2869, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:07.023447 #train# step 2870, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:08.584442 #train# step 2871, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:10.215478 #train# step 2872, loss = 0.9314, cross_entropy loss = 0.9314, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:11.855728 #train# step 2873, loss = 0.9435, cross_entropy loss = 0.9435, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:13.470031 #train# step 2874, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:15.061177 #train# step 2875, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:16.644016 #train# step 2876, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:18.227029 #train# step 2877, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:19.814910 #train# step 2878, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:21.402149 #train# step 2879, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:22.982014 #train# step 2880, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:24.603425 #train# step 2881, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:26.174968 #train# step 2882, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:27.805806 #train# step 2883, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:29.392076 #train# step 2884, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:30.946709 #train# step 2885, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:32.547638 #train# step 2886, loss = 0.9413, cross_entropy loss = 0.9413, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:34.114405 #train# step 2887, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:35.655649 #train# step 2888, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:37.256415 #train# step 2889, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:38.822111 #train# step 2890, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:40.427166 #train# step 2891, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:41.998676 #train# step 2892, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:43.583024 #train# step 2893, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:45.181332 #train# step 2894, loss = 0.9521, cross_entropy loss = 0.9521, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:46.772504 #train# step 2895, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:48.343774 #train# step 2896, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:49.936516 #train# step 2897, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:51.504498 #train# step 2898, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:53.066838 #train# step 2899, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:54.637914 #train# step 2900, loss = 0.9427, cross_entropy loss = 0.9427, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:56.248537 #train# step 2901, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:57.823981 #train# step 2902, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:16:59.428518 #train# step 2903, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:01.026595 #train# step 2904, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:02.631577 #train# step 2905, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:04.209554 #train# step 2906, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:05.774368 #train# step 2907, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:07.363542 #train# step 2908, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:08.946709 #train# step 2909, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:10.527189 #train# step 2910, loss = 0.9479, cross_entropy loss = 0.9479, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:12.103423 #train# step 2911, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:13.675762 #train# step 2912, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:15.231538 #train# step 2913, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:16.787971 #train# step 2914, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:18.382476 #train# step 2915, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:19.947310 #train# step 2916, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:21.559786 #train# step 2917, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:23.119014 #train# step 2918, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:24.704994 #train# step 2919, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:26.276944 #train# step 2920, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:27.856262 #train# step 2921, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:29.432926 #train# step 2922, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:31.000161 #train# step 2923, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:32.606237 #train# step 2924, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:34.195793 #train# step 2925, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:35.815505 #train# step 2926, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:37.378484 #train# step 2927, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:38.959800 #train# step 2928, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:40.564489 #train# step 2929, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:42.118481 #train# step 2930, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:43.673663 #train# step 2931, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:45.220215 #train# step 2932, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:46.839365 #train# step 2933, loss = 0.9266, cross_entropy loss = 0.9266, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:48.466471 #train# step 2934, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:50.082090 #train# step 2935, loss = 0.9454, cross_entropy loss = 0.9454, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:51.699216 #train# step 2936, loss = 0.9178, cross_entropy loss = 0.9178, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:53.295810 #train# step 2937, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:54.897366 #train# step 2938, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:56.507333 #train# step 2939, loss = 0.9335, cross_entropy loss = 0.9335, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:58.096173 #train# step 2940, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:17:59.688837 #train# step 2941, loss = 0.9419, cross_entropy loss = 0.9419, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:01.250800 #train# step 2942, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:02.867002 #train# step 2943, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:04.442112 #train# step 2944, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:06.023188 #train# step 2945, loss = 0.9359, cross_entropy loss = 0.9359, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:07.634319 #train# step 2946, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:09.225437 #train# step 2947, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:10.794146 #train# step 2948, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:12.320028 #train# step 2949, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:13.870638 #train# step 2950, loss = 0.9456, cross_entropy loss = 0.9456, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:15.473473 #train# step 2951, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:17.108684 #train# step 2952, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:18.736261 #train# step 2953, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:20.317501 #train# step 2954, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:21.901242 #train# step 2955, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:23.529267 #train# step 2956, loss = 0.9519, cross_entropy loss = 0.9519, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:25.188892 #train# step 2957, loss = 0.9260, cross_entropy loss = 0.9260, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:26.875511 #train# step 2958, loss = 0.9314, cross_entropy loss = 0.9314, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:28.496095 #train# step 2959, loss = 0.9431, cross_entropy loss = 0.9431, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:30.102712 #train# step 2960, loss = 0.9252, cross_entropy loss = 0.9252, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:31.745907 #train# step 2961, loss = 0.9452, cross_entropy loss = 0.9452, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:33.358961 #train# step 2962, loss = 0.9488, cross_entropy loss = 0.9488, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:34.929225 #train# step 2963, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:36.551620 #train# step 2964, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:38.109921 #train# step 2965, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:39.697744 #train# step 2966, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:41.275408 #train# step 2967, loss = 0.9441, cross_entropy loss = 0.9441, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:42.863058 #train# step 2968, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:44.463934 #train# step 2969, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:46.087919 #train# step 2970, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:47.661477 #train# step 2971, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:49.250907 #train# step 2972, loss = 0.9268, cross_entropy loss = 0.9268, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:50.827506 #train# step 2973, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:52.405633 #train# step 2974, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:53.973185 #train# step 2975, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:55.561564 #train# step 2976, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:57.127206 #train# step 2977, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:18:58.687677 #train# step 2978, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:00.242948 #train# step 2979, loss = 0.9523, cross_entropy loss = 0.9523, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:01.811439 #train# step 2980, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:03.412988 #train# step 2981, loss = 0.9377, cross_entropy loss = 0.9377, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:05.028108 #train# step 2982, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:06.626699 #train# step 2983, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:08.214438 #train# step 2984, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:09.840517 #train# step 2985, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:11.442338 #train# step 2986, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:13.015737 #train# step 2987, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:14.592648 #train# step 2988, loss = 0.9436, cross_entropy loss = 0.9436, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:16.140460 #train# step 2989, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:17.729208 #train# step 2990, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:19.302777 #train# step 2991, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:20.900283 #train# step 2992, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:22.489005 #train# step 2993, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:24.080051 #train# step 2994, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:25.630634 #train# step 2995, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:27.181481 #train# step 2996, loss = 0.9550, cross_entropy loss = 0.9550, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:28.768807 #train# step 2997, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:30.350822 #train# step 2998, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:31.929611 #train# step 2999, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:33.504484 #train# step 3000, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:35.081135 #train# step 3001, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:36.705954 #train# step 3002, loss = 0.9203, cross_entropy loss = 0.9203, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:38.290443 #train# step 3003, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:39.880277 #train# step 3004, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:41.477114 #train# step 3005, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:43.059892 #train# step 3006, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:44.633888 #train# step 3007, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:46.219142 #train# step 3008, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:47.825849 #train# step 3009, loss = 0.9503, cross_entropy loss = 0.9503, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:49.426411 #train# step 3010, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:51.028850 #train# step 3011, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:52.593460 #train# step 3012, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:54.159833 #train# step 3013, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:55.735767 #train# step 3014, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:57.342963 #train# step 3015, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:19:58.911571 #train# step 3016, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:00.514393 #train# step 3017, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:02.094032 #train# step 3018, loss = 0.9389, cross_entropy loss = 0.9389, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:03.701500 #train# step 3019, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:05.259825 #train# step 3020, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:06.824732 #train# step 3021, loss = 0.9438, cross_entropy loss = 0.9438, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:08.397542 #train# step 3022, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:09.979516 #train# step 3023, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:11.546774 #train# step 3024, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:13.132078 #train# step 3025, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:14.735701 #train# step 3026, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:16.303792 #train# step 3027, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:17.899643 #train# step 3028, loss = 0.9561, cross_entropy loss = 0.9561, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:19.465296 #train# step 3029, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:20.984061 #train# step 3030, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:22.563954 #train# step 3031, loss = 0.9374, cross_entropy loss = 0.9374, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:24.143716 #train# step 3032, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:25.723816 #train# step 3033, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:27.280705 #train# step 3034, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:28.873327 #train# step 3035, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:30.455849 #train# step 3036, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:32.030760 #train# step 3037, loss = 0.9339, cross_entropy loss = 0.9339, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:33.632181 #train# step 3038, loss = 0.9409, cross_entropy loss = 0.9409, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:35.204574 #train# step 3039, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:36.795537 #train# step 3040, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:38.389415 #train# step 3041, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:39.964197 #train# step 3042, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:41.566792 #train# step 3043, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:43.131203 #train# step 3044, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:44.734051 #train# step 3045, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:46.281708 #train# step 3046, loss = 0.9535, cross_entropy loss = 0.9535, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:47.875021 #train# step 3047, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:49.450505 #train# step 3048, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:51.064127 #train# step 3049, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:52.640153 #train# step 3050, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:54.221037 #train# step 3051, loss = 0.9498, cross_entropy loss = 0.9498, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:55.817660 #train# step 3052, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:57.404710 #train# step 3053, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:20:58.953604 #train# step 3054, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:00.532154 #train# step 3055, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:02.100080 #train# step 3056, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:03.662405 #train# step 3057, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:05.230166 #train# step 3058, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:06.807676 #train# step 3059, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:08.408839 #train# step 3060, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:09.977605 #train# step 3061, loss = 0.9367, cross_entropy loss = 0.9367, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:11.562294 #train# step 3062, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:13.119568 #train# step 3063, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:14.684105 #train# step 3064, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:16.233129 #train# step 3065, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:17.795185 #train# step 3066, loss = 0.9390, cross_entropy loss = 0.9390, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:19.367183 #train# step 3067, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:20.933457 #train# step 3068, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:22.495918 #train# step 3069, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:24.096033 #train# step 3070, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:25.685276 #train# step 3071, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:27.299924 #train# step 3072, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:28.893195 #train# step 3073, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:30.507450 #train# step 3074, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:32.066349 #train# step 3075, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:33.643418 #train# step 3076, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:35.207164 #train# step 3077, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:36.797573 #train# step 3078, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:38.372464 #train# step 3079, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:39.968497 #train# step 3080, loss = 0.9392, cross_entropy loss = 0.9392, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:41.538307 #train# step 3081, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:43.089638 #train# step 3082, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:44.659986 #train# step 3083, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:46.243796 #train# step 3084, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:47.845000 #train# step 3085, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:49.458742 #train# step 3086, loss = 0.9478, cross_entropy loss = 0.9478, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:51.018822 #train# step 3087, loss = 0.9439, cross_entropy loss = 0.9439, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:52.611559 #train# step 3088, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:54.208975 #train# step 3089, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:55.824850 #train# step 3090, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:57.399048 #train# step 3091, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:21:58.996437 #train# step 3092, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:00.607692 #train# step 3093, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:02.188723 #train# step 3094, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:03.753010 #train# step 3095, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:05.346118 #train# step 3096, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:06.935470 #train# step 3097, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:08.511115 #train# step 3098, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:10.070888 #train# step 3099, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:11.673487 #train# step 3100, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:13.290374 #train# step 3101, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:14.861089 #train# step 3102, loss = 0.9408, cross_entropy loss = 0.9408, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:16.456803 #train# step 3103, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:18.006346 #train# step 3104, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:19.568149 #train# step 3105, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:21.140168 #train# step 3106, loss = 0.9412, cross_entropy loss = 0.9412, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:22.740429 #train# step 3107, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:24.308884 #train# step 3108, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:25.876336 #train# step 3109, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:27.449744 #train# step 3110, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:29.033495 #train# step 3111, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:30.621281 #train# step 3112, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:32.173163 #train# step 3113, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:33.743944 #train# step 3114, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:35.316844 #train# step 3115, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:36.888295 #train# step 3116, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:38.451021 #train# step 3117, loss = 0.9543, cross_entropy loss = 0.9543, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:40.042361 #train# step 3118, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:41.643168 #train# step 3119, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:43.186546 #train# step 3120, loss = 0.9483, cross_entropy loss = 0.9483, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:44.744347 #train# step 3121, loss = 0.9414, cross_entropy loss = 0.9414, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:46.318324 #train# step 3122, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:47.902055 #train# step 3123, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:49.475454 #train# step 3124, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:51.042145 #train# step 3125, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:52.592640 #train# step 3126, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:54.199518 #train# step 3127, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:55.769049 #train# step 3128, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:57.355962 #train# step 3129, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:22:58.930487 #train# step 3130, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:00.499594 #train# step 3131, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:02.085560 #train# step 3132, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:03.680428 #train# step 3133, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:05.237440 #train# step 3134, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:06.801506 #train# step 3135, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:08.385639 #train# step 3136, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:09.973658 #train# step 3137, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:11.595019 #train# step 3138, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:13.193476 #train# step 3139, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:14.791678 #train# step 3140, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:16.349398 #train# step 3141, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:17.930703 #train# step 3142, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:19.510579 #train# step 3143, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:21.099906 #train# step 3144, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:22.663926 #train# step 3145, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:24.260511 #train# step 3146, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:25.837899 #train# step 3147, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:27.447459 #train# step 3148, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:29.009199 #train# step 3149, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:30.590856 #train# step 3150, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:32.179888 #train# step 3151, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:33.777335 #train# step 3152, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:35.365824 #train# step 3153, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:36.946096 #train# step 3154, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:38.518721 #train# step 3155, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:40.083943 #train# step 3156, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:41.638125 #train# step 3157, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:43.223651 #train# step 3158, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:44.791944 #train# step 3159, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:46.354551 #train# step 3160, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:47.938003 #train# step 3161, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:49.544291 #train# step 3162, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:51.131860 #train# step 3163, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:52.725590 #train# step 3164, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:54.298136 #train# step 3165, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:55.876095 #train# step 3166, loss = 0.9457, cross_entropy loss = 0.9457, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:57.450677 #train# step 3167, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:23:59.005708 #train# step 3168, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:00.561751 #train# step 3169, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:02.098504 #train# step 3170, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:03.679311 #train# step 3171, loss = 0.9372, cross_entropy loss = 0.9372, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:05.286773 #train# step 3172, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:06.884170 #train# step 3173, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:08.464977 #train# step 3174, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:10.054578 #train# step 3175, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:11.632888 #train# step 3176, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:13.236107 #train# step 3177, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:14.865790 #train# step 3178, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:16.428813 #train# step 3179, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:17.979549 #train# step 3180, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:19.567940 #train# step 3181, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:21.158075 #train# step 3182, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:22.742544 #train# step 3183, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:24.311982 #train# step 3184, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:25.893242 #train# step 3185, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:27.476834 #train# step 3186, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:29.029775 #train# step 3187, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:30.626149 #train# step 3188, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:32.192153 #train# step 3189, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:33.751518 #train# step 3190, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:35.341694 #train# step 3191, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:36.904633 #train# step 3192, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:38.473996 #train# step 3193, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:40.032541 #train# step 3194, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:41.593070 #train# step 3195, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:43.168438 #train# step 3196, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:44.765171 #train# step 3197, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:46.358630 #train# step 3198, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:47.899577 #train# step 3199, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:49.477120 #train# step 3200, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:51.049067 #train# step 3201, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:52.594134 #train# step 3202, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:54.181494 #train# step 3203, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:55.803207 #train# step 3204, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:57.363931 #train# step 3205, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:24:58.934449 #train# step 3206, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:00.510355 #train# step 3207, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:02.085253 #train# step 3208, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:03.699878 #train# step 3209, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:05.289687 #train# step 3210, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:06.882909 #train# step 3211, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:08.461819 #train# step 3212, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:10.040998 #train# step 3213, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:11.598870 #train# step 3214, loss = 0.9501, cross_entropy loss = 0.9501, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:13.199036 #train# step 3215, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:14.807622 #train# step 3216, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:16.383883 #train# step 3217, loss = 0.9418, cross_entropy loss = 0.9418, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:17.960919 #train# step 3218, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:19.533685 #train# step 3219, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:21.098211 #train# step 3220, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:22.680923 #train# step 3221, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:24.230650 #train# step 3222, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:25.815767 #train# step 3223, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:27.347902 #train# step 3224, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:28.921683 #train# step 3225, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:30.496582 #train# step 3226, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:32.074018 #train# step 3227, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:33.643669 #train# step 3228, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:35.218672 #train# step 3229, loss = 0.9509, cross_entropy loss = 0.9509, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:36.795424 #train# step 3230, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:38.365530 #train# step 3231, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:39.962331 #train# step 3232, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:41.539881 #train# step 3233, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:43.111900 #train# step 3234, loss = 0.9353, cross_entropy loss = 0.9353, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:44.705904 #train# step 3235, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:46.277816 #train# step 3236, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:47.846676 #train# step 3237, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:49.424837 #train# step 3238, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:51.002202 #train# step 3239, loss = 0.9453, cross_entropy loss = 0.9453, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:52.597516 #train# step 3240, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:54.171735 #train# step 3241, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:55.771232 #train# step 3242, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:57.343768 #train# step 3243, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:25:58.972058 #train# step 3244, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:00.576834 #train# step 3245, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:02.165689 #train# step 3246, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:03.749779 #train# step 3247, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:05.308382 #train# step 3248, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:06.879505 #train# step 3249, loss = 0.9397, cross_entropy loss = 0.9397, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:08.446399 #train# step 3250, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:10.019455 #train# step 3251, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:11.624060 #train# step 3252, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:13.196807 #train# step 3253, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:14.765507 #train# step 3254, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:16.341449 #train# step 3255, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:17.902869 #train# step 3256, loss = 0.9452, cross_entropy loss = 0.9452, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:19.466962 #train# step 3257, loss = 0.9524, cross_entropy loss = 0.9524, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:21.042715 #train# step 3258, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:22.606105 #train# step 3259, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:24.167976 #train# step 3260, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:25.741638 #train# step 3261, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:27.339754 #train# step 3262, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:28.887536 #train# step 3263, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:30.453715 #train# step 3264, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:32.036229 #train# step 3265, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:33.605330 #train# step 3266, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:35.164843 #train# step 3267, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:36.739159 #train# step 3268, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:38.306300 #train# step 3269, loss = 0.9465, cross_entropy loss = 0.9465, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:39.895940 #train# step 3270, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:41.476764 #train# step 3271, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:43.034076 #train# step 3272, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:44.620744 #train# step 3273, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:46.185833 #train# step 3274, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:47.738815 #train# step 3275, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:49.336979 #train# step 3276, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:50.922432 #train# step 3277, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:52.519940 #train# step 3278, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:54.069187 #train# step 3279, loss = 0.9379, cross_entropy loss = 0.9379, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:55.634787 #train# step 3280, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:57.203180 #train# step 3281, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:26:58.804260 #train# step 3282, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:00.375749 #train# step 3283, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:01.937056 #train# step 3284, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:03.538635 #train# step 3285, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:05.141422 #train# step 3286, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:06.692324 #train# step 3287, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:08.270006 #train# step 3288, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:09.879549 #train# step 3289, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:11.439922 #train# step 3290, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:13.000768 #train# step 3291, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:14.605350 #train# step 3292, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:16.195373 #train# step 3293, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:17.751373 #train# step 3294, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:19.340944 #train# step 3295, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:20.933336 #train# step 3296, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:22.484649 #train# step 3297, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:24.050534 #train# step 3298, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:25.631584 #train# step 3299, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:27.202752 #train# step 3300, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:28.750085 #train# step 3301, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:30.342334 #train# step 3302, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:31.898056 #train# step 3303, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:33.468965 #train# step 3304, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:35.036550 #train# step 3305, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:36.625225 #train# step 3306, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:38.214874 #train# step 3307, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:39.765984 #train# step 3308, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:41.334064 #train# step 3309, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:42.927849 #train# step 3310, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:44.520024 #train# step 3311, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:46.118171 #train# step 3312, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:47.719999 #train# step 3313, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:49.315467 #train# step 3314, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:50.916096 #train# step 3315, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:52.488665 #train# step 3316, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:54.059281 #train# step 3317, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:55.609304 #train# step 3318, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:57.209572 #train# step 3319, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:27:58.786363 #train# step 3320, loss = 0.9348, cross_entropy loss = 0.9348, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:00.381009 #train# step 3321, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:01.973792 #train# step 3322, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:03.543845 #train# step 3323, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:05.112480 #train# step 3324, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:06.669779 #train# step 3325, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:08.259030 #train# step 3326, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:09.826891 #train# step 3327, loss = 0.9384, cross_entropy loss = 0.9384, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:11.400136 #train# step 3328, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:12.974727 #train# step 3329, loss = 0.9476, cross_entropy loss = 0.9476, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:14.562517 #train# step 3330, loss = 0.9411, cross_entropy loss = 0.9411, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:16.118060 #train# step 3331, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:17.685436 #train# step 3332, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:19.240231 #train# step 3333, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:20.815553 #train# step 3334, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:22.393810 #train# step 3335, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:23.981218 #train# step 3336, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:25.574341 #train# step 3337, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:27.173622 #train# step 3338, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:28.735050 #train# step 3339, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:30.313239 #train# step 3340, loss = 0.9337, cross_entropy loss = 0.9337, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:31.911351 #train# step 3341, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:33.511501 #train# step 3342, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:35.074261 #train# step 3343, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:36.645934 #train# step 3344, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:38.234000 #train# step 3345, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:39.827411 #train# step 3346, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:41.419379 #train# step 3347, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:42.991733 #train# step 3348, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:44.565158 #train# step 3349, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:46.112248 #train# step 3350, loss = 0.9437, cross_entropy loss = 0.9437, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:47.692977 #train# step 3351, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:49.281791 #train# step 3352, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:50.859183 #train# step 3353, loss = 0.9385, cross_entropy loss = 0.9385, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:52.456883 #train# step 3354, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:54.043677 #train# step 3355, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:55.600684 #train# step 3356, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:57.133476 #train# step 3357, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:28:58.694702 #train# step 3358, loss = 0.9468, cross_entropy loss = 0.9468, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:00.305394 #train# step 3359, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:01.890125 #train# step 3360, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:03.466063 #train# step 3361, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:05.042793 #train# step 3362, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:06.633062 #train# step 3363, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:08.173167 #train# step 3364, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:09.753008 #train# step 3365, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:11.341458 #train# step 3366, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:12.925837 #train# step 3367, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:14.490906 #train# step 3368, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:16.054043 #train# step 3369, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:17.672707 #train# step 3370, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:19.238459 #train# step 3371, loss = 0.9432, cross_entropy loss = 0.9432, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:20.798907 #train# step 3372, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:22.365409 #train# step 3373, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:23.955793 #train# step 3374, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:25.512585 #train# step 3375, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:27.085638 #train# step 3376, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:28.648758 #train# step 3377, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:30.249095 #train# step 3378, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:31.831815 #train# step 3379, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:33.419579 #train# step 3380, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:35.015345 #train# step 3381, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:36.582659 #train# step 3382, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:38.155414 #train# step 3383, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:39.755039 #train# step 3384, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:41.334235 #train# step 3385, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:42.910984 #train# step 3386, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:44.476447 #train# step 3387, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:46.046894 #train# step 3388, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:47.639932 #train# step 3389, loss = 0.9404, cross_entropy loss = 0.9404, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:49.231629 #train# step 3390, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:50.827455 #train# step 3391, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:52.395808 #train# step 3392, loss = 0.9281, cross_entropy loss = 0.9281, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:53.965535 #train# step 3393, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:55.542110 #train# step 3394, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:57.107700 #train# step 3395, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:29:58.697786 #train# step 3396, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:00.287399 #train# step 3397, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:01.879203 #train# step 3398, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:03.447122 #train# step 3399, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:05.008864 #train# step 3400, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:06.635714 #train# step 3401, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:08.214086 #train# step 3402, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:09.749707 #train# step 3403, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:11.352567 #train# step 3404, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:12.959635 #train# step 3405, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:14.534766 #train# step 3406, loss = 0.9471, cross_entropy loss = 0.9471, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:16.154204 #train# step 3407, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:17.712132 #train# step 3408, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:19.280502 #train# step 3409, loss = 0.9466, cross_entropy loss = 0.9466, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:20.893189 #train# step 3410, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:22.432094 #train# step 3411, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:24.005193 #train# step 3412, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:25.602318 #train# step 3413, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:27.165048 #train# step 3414, loss = 0.9351, cross_entropy loss = 0.9351, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:28.733347 #train# step 3415, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:30.323120 #train# step 3416, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:31.868614 #train# step 3417, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:33.417073 #train# step 3418, loss = 0.9424, cross_entropy loss = 0.9424, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:34.970644 #train# step 3419, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:36.520329 #train# step 3420, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:38.138120 #train# step 3421, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:39.770597 #train# step 3422, loss = 0.9270, cross_entropy loss = 0.9270, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:41.342022 #train# step 3423, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:42.922090 #train# step 3424, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:44.471414 #train# step 3425, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:46.049657 #train# step 3426, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:47.617874 #train# step 3427, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:49.209587 #train# step 3428, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:50.807717 #train# step 3429, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:52.372490 #train# step 3430, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:54.001795 #train# step 3431, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:55.572024 #train# step 3432, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:57.163141 #train# step 3433, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:30:58.741786 #train# step 3434, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:00.345776 #train# step 3435, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:01.923150 #train# step 3436, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:03.508390 #train# step 3437, loss = 0.9332, cross_entropy loss = 0.9332, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:05.097874 #train# step 3438, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:06.688045 #train# step 3439, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:08.268905 #train# step 3440, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:09.821594 #train# step 3441, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:11.380037 #train# step 3442, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:12.971863 #train# step 3443, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:14.521308 #train# step 3444, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:16.113406 #train# step 3445, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:17.658420 #train# step 3446, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:19.221617 #train# step 3447, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:20.822531 #train# step 3448, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:22.384628 #train# step 3449, loss = 0.9305, cross_entropy loss = 0.9305, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:23.972332 #train# step 3450, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:25.551972 #train# step 3451, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:27.117231 #train# step 3452, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:28.701946 #train# step 3453, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:30.267538 #train# step 3454, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:31.833967 #train# step 3455, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:33.403122 #train# step 3456, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:34.957136 #train# step 3457, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:36.515600 #train# step 3458, loss = 0.9419, cross_entropy loss = 0.9419, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:38.090315 #train# step 3459, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:39.680686 #train# step 3460, loss = 0.9391, cross_entropy loss = 0.9391, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:41.300998 #train# step 3461, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:42.887124 #train# step 3462, loss = 0.9376, cross_entropy loss = 0.9376, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:44.483778 #train# step 3463, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:46.082836 #train# step 3464, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:47.619155 #train# step 3465, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:49.217038 #train# step 3466, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:50.782905 #train# step 3467, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:52.341582 #train# step 3468, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:53.956600 #train# step 3469, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:55.540623 #train# step 3470, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:57.143256 #train# step 3471, loss = 0.9420, cross_entropy loss = 0.9420, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:31:58.741615 #train# step 3472, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:00.313434 #train# step 3473, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:01.915163 #train# step 3474, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:03.483248 #train# step 3475, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:05.086316 #train# step 3476, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:06.641900 #train# step 3477, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:08.210815 #train# step 3478, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:09.773407 #train# step 3479, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:11.347031 #train# step 3480, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:12.926336 #train# step 3481, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:14.506633 #train# step 3482, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:16.072863 #train# step 3483, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:17.643360 #train# step 3484, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:19.225755 #train# step 3485, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:20.817057 #train# step 3486, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:22.400929 #train# step 3487, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:23.977880 #train# step 3488, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:25.553163 #train# step 3489, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:27.112141 #train# step 3490, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:28.659966 #train# step 3491, loss = 0.9341, cross_entropy loss = 0.9341, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:30.258403 #train# step 3492, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:31.840358 #train# step 3493, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:33.418534 #train# step 3494, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:35.013054 #train# step 3495, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:36.577517 #train# step 3496, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:38.154423 #train# step 3497, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:39.755949 #train# step 3498, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:41.330208 #train# step 3499, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:42.899018 #train# step 3500, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:44.454570 #train# step 3501, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:46.031372 #train# step 3502, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:47.628616 #train# step 3503, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:49.178105 #train# step 3504, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:50.751994 #train# step 3505, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:52.343311 #train# step 3506, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:53.918180 #train# step 3507, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:55.496772 #train# step 3508, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:57.100521 #train# step 3509, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:32:58.695647 #train# step 3510, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:00.265070 #train# step 3511, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:01.857771 #train# step 3512, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:03.437386 #train# step 3513, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:04.999235 #train# step 3514, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:06.585659 #train# step 3515, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:08.150095 #train# step 3516, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:09.749174 #train# step 3517, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:11.344226 #train# step 3518, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:12.920434 #train# step 3519, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:14.477530 #train# step 3520, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:16.057550 #train# step 3521, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:17.626872 #train# step 3522, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:19.192261 #train# step 3523, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:20.798118 #train# step 3524, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:22.400226 #train# step 3525, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:23.993746 #train# step 3526, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:25.548139 #train# step 3527, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:27.145862 #train# step 3528, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:28.712696 #train# step 3529, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:30.301970 #train# step 3530, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:31.895569 #train# step 3531, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:33.441768 #train# step 3532, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:34.979614 #train# step 3533, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:36.575662 #train# step 3534, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:38.137343 #train# step 3535, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:39.705715 #train# step 3536, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:41.304914 #train# step 3537, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:42.893289 #train# step 3538, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:44.490803 #train# step 3539, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:46.047863 #train# step 3540, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:47.661319 #train# step 3541, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:49.237099 #train# step 3542, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:50.814318 #train# step 3543, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:52.403050 #train# step 3544, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:53.988831 #train# step 3545, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:55.545530 #train# step 3546, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:57.126843 #train# step 3547, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:33:58.731621 #train# step 3548, loss = 0.9403, cross_entropy loss = 0.9403, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:00.304477 #train# step 3549, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:01.907004 #train# step 3550, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:03.466660 #train# step 3551, loss = 0.9426, cross_entropy loss = 0.9426, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:05.016574 #train# step 3552, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:06.572666 #train# step 3553, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:08.179173 #train# step 3554, loss = 0.9333, cross_entropy loss = 0.9333, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:09.762188 #train# step 3555, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:11.362484 #train# step 3556, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:12.943022 #train# step 3557, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:14.535805 #train# step 3558, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:16.110201 #train# step 3559, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:17.663476 #train# step 3560, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:19.246555 #train# step 3561, loss = 0.9485, cross_entropy loss = 0.9485, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:20.831852 #train# step 3562, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:22.394474 #train# step 3563, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:23.980287 #train# step 3564, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:25.542875 #train# step 3565, loss = 0.9362, cross_entropy loss = 0.9362, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:27.097267 #train# step 3566, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:28.675255 #train# step 3567, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:30.261833 #train# step 3568, loss = 0.9393, cross_entropy loss = 0.9393, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:31.864681 #train# step 3569, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:33.451279 #train# step 3570, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:35.052320 #train# step 3571, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:36.647070 #train# step 3572, loss = 0.9430, cross_entropy loss = 0.9430, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:38.261279 #train# step 3573, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:39.846453 #train# step 3574, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:41.436860 #train# step 3575, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:42.995793 #train# step 3576, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:44.566391 #train# step 3577, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:46.144649 #train# step 3578, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:47.740618 #train# step 3579, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:49.319053 #train# step 3580, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:50.915325 #train# step 3581, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:52.472005 #train# step 3582, loss = 0.9356, cross_entropy loss = 0.9356, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:54.057759 #train# step 3583, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:55.647168 #train# step 3584, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:57.227054 #train# step 3585, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:34:58.789414 #train# step 3586, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:00.348187 #train# step 3587, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:01.909849 #train# step 3588, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:03.480617 #train# step 3589, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:05.058100 #train# step 3590, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:06.694700 #train# step 3591, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:08.289622 #train# step 3592, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:09.904478 #train# step 3593, loss = 0.9445, cross_entropy loss = 0.9445, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:11.471671 #train# step 3594, loss = 0.9329, cross_entropy loss = 0.9329, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:13.095117 #train# step 3595, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:14.677169 #train# step 3596, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:16.259141 #train# step 3597, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:17.845342 #train# step 3598, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:19.410219 #train# step 3599, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:21.009325 #train# step 3600, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:22.597248 #train# step 3601, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:24.159019 #train# step 3602, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:25.722501 #train# step 3603, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:27.287197 #train# step 3604, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:28.885044 #train# step 3605, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:30.452563 #train# step 3606, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:32.023790 #train# step 3607, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:33.575349 #train# step 3608, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:35.130473 #train# step 3609, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:36.682008 #train# step 3610, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:38.239826 #train# step 3611, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:39.820020 #train# step 3612, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:41.367861 #train# step 3613, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:42.934474 #train# step 3614, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:44.517719 #train# step 3615, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:46.091906 #train# step 3616, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:47.668782 #train# step 3617, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:49.271782 #train# step 3618, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:50.845988 #train# step 3619, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:52.415499 #train# step 3620, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:54.023446 #train# step 3621, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:55.633896 #train# step 3622, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:57.206616 #train# step 3623, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:35:58.754426 #train# step 3624, loss = 0.9342, cross_entropy loss = 0.9342, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:00.339602 #train# step 3625, loss = 0.9368, cross_entropy loss = 0.9368, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:01.939092 #train# step 3626, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:03.517033 #train# step 3627, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:05.119933 #train# step 3628, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:06.675846 #train# step 3629, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:08.247232 #train# step 3630, loss = 0.9365, cross_entropy loss = 0.9365, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:09.831038 #train# step 3631, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:11.410186 #train# step 3632, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:12.968298 #train# step 3633, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:14.541504 #train# step 3634, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:16.120726 #train# step 3635, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:17.673061 #train# step 3636, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:19.278015 #train# step 3637, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:20.883220 #train# step 3638, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:22.471230 #train# step 3639, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:24.050229 #train# step 3640, loss = 0.9326, cross_entropy loss = 0.9326, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:25.670416 #train# step 3641, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:27.245115 #train# step 3642, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:28.807419 #train# step 3643, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:30.389301 #train# step 3644, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:31.965512 #train# step 3645, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:33.520246 #train# step 3646, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:35.092317 #train# step 3647, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:36.670120 #train# step 3648, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:38.271400 #train# step 3649, loss = 0.9370, cross_entropy loss = 0.9370, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:39.847188 #train# step 3650, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:41.399385 #train# step 3651, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:42.975701 #train# step 3652, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:44.549159 #train# step 3653, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:46.158732 #train# step 3654, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:47.735480 #train# step 3655, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:49.310527 #train# step 3656, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:50.889885 #train# step 3657, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:52.457131 #train# step 3658, loss = 0.9358, cross_entropy loss = 0.9358, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:54.016792 #train# step 3659, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:55.615907 #train# step 3660, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:57.204933 #train# step 3661, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:36:58.779784 #train# step 3662, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:00.390251 #train# step 3663, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:01.944317 #train# step 3664, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:03.511569 #train# step 3665, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:05.071440 #train# step 3666, loss = 0.9407, cross_entropy loss = 0.9407, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:06.642176 #train# step 3667, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:08.260796 #train# step 3668, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:09.831039 #train# step 3669, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:11.411465 #train# step 3670, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:13.026690 #train# step 3671, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:14.590266 #train# step 3672, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:16.137705 #train# step 3673, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:17.718788 #train# step 3674, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:19.289229 #train# step 3675, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:20.881881 #train# step 3676, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:22.433962 #train# step 3677, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:24.030004 #train# step 3678, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:25.609563 #train# step 3679, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:27.185647 #train# step 3680, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:28.789674 #train# step 3681, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:30.361344 #train# step 3682, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:31.959055 #train# step 3683, loss = 0.9429, cross_entropy loss = 0.9429, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:33.522982 #train# step 3684, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:35.096490 #train# step 3685, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:36.661102 #train# step 3686, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:38.243989 #train# step 3687, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:39.824467 #train# step 3688, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:41.385384 #train# step 3689, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:42.993256 #train# step 3690, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:44.573688 #train# step 3691, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:46.126652 #train# step 3692, loss = 0.9314, cross_entropy loss = 0.9314, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:47.682546 #train# step 3693, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:49.247989 #train# step 3694, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:50.830474 #train# step 3695, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:52.432854 #train# step 3696, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:54.001206 #train# step 3697, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:55.607767 #train# step 3698, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:57.206617 #train# step 3699, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:37:58.775279 #train# step 3700, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:00.321746 #train# step 3701, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:01.876306 #train# step 3702, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:03.440917 #train# step 3703, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:05.073382 #train# step 3704, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:06.623802 #train# step 3705, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:08.183777 #train# step 3706, loss = 0.9317, cross_entropy loss = 0.9317, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:09.747059 #train# step 3707, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:11.330291 #train# step 3708, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:12.917795 #train# step 3709, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:14.492296 #train# step 3710, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:16.063764 #train# step 3711, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:17.637266 #train# step 3712, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:19.223883 #train# step 3713, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:20.796285 #train# step 3714, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:22.394668 #train# step 3715, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:23.963661 #train# step 3716, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:25.502854 #train# step 3717, loss = 0.9422, cross_entropy loss = 0.9422, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:27.091146 #train# step 3718, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:28.681317 #train# step 3719, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:30.245700 #train# step 3720, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:31.827874 #train# step 3721, loss = 0.9330, cross_entropy loss = 0.9330, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:33.440730 #train# step 3722, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:35.026899 #train# step 3723, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:36.609273 #train# step 3724, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:38.181883 #train# step 3725, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:39.758485 #train# step 3726, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:41.339298 #train# step 3727, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:42.890133 #train# step 3728, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:44.449708 #train# step 3729, loss = 0.9388, cross_entropy loss = 0.9388, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:46.044830 #train# step 3730, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:47.645147 #train# step 3731, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:49.250531 #train# step 3732, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:50.795142 #train# step 3733, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:52.372503 #train# step 3734, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:53.941536 #train# step 3735, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:55.507653 #train# step 3736, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:57.114776 #train# step 3737, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:38:58.715224 #train# step 3738, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:00.333992 #train# step 3739, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:01.924593 #train# step 3740, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:03.477177 #train# step 3741, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:05.078344 #train# step 3742, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:06.687175 #train# step 3743, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:08.241099 #train# step 3744, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:09.854092 #train# step 3745, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:11.422656 #train# step 3746, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:13.023327 #train# step 3747, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:14.598606 #train# step 3748, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:16.164879 #train# step 3749, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:17.719699 #train# step 3750, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:19.305564 #train# step 3751, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:20.899311 #train# step 3752, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:22.467921 #train# step 3753, loss = 0.9301, cross_entropy loss = 0.9301, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:24.055968 #train# step 3754, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:25.634966 #train# step 3755, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:27.231589 #train# step 3756, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:28.805890 #train# step 3757, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:30.386322 #train# step 3758, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:31.941669 #train# step 3759, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:33.509042 #train# step 3760, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:35.047455 #train# step 3761, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:36.670081 #train# step 3762, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:38.257983 #train# step 3763, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:39.814107 #train# step 3764, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:41.439321 #train# step 3765, loss = 0.9126, cross_entropy loss = 0.9126, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:43.035171 #train# step 3766, loss = 0.9351, cross_entropy loss = 0.9351, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:44.617578 #train# step 3767, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:46.201729 #train# step 3768, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:47.875291 #train# step 3769, loss = 0.9133, cross_entropy loss = 0.9133, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:49.516514 #train# step 3770, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:51.134351 #train# step 3771, loss = 0.9311, cross_entropy loss = 0.9311, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:52.717518 #train# step 3772, loss = 0.9321, cross_entropy loss = 0.9321, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:54.319123 #train# step 3773, loss = 0.9275, cross_entropy loss = 0.9275, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:55.884835 #train# step 3774, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:57.566620 #train# step 3775, loss = 0.9255, cross_entropy loss = 0.9255, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:39:59.259446 #train# step 3776, loss = 0.9258, cross_entropy loss = 0.9258, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:00.948776 #train# step 3777, loss = 0.9043, cross_entropy loss = 0.9043, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:02.592735 #train# step 3778, loss = 0.9130, cross_entropy loss = 0.9130, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:04.242089 #train# step 3779, loss = 0.9295, cross_entropy loss = 0.9295, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:05.871257 #train# step 3780, loss = 0.9223, cross_entropy loss = 0.9223, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:07.510066 #train# step 3781, loss = 0.9345, cross_entropy loss = 0.9345, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:09.096143 #train# step 3782, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:10.695530 #train# step 3783, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:12.290655 #train# step 3784, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:13.830785 #train# step 3785, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:15.382474 #train# step 3786, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:16.979703 #train# step 3787, loss = 0.9338, cross_entropy loss = 0.9338, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:18.553238 #train# step 3788, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:20.133801 #train# step 3789, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:21.714070 #train# step 3790, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:23.280255 #train# step 3791, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:24.840949 #train# step 3792, loss = 0.9539, cross_entropy loss = 0.9539, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:26.393256 #train# step 3793, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:27.998098 #train# step 3794, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:29.567945 #train# step 3795, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:31.131382 #train# step 3796, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:32.741553 #train# step 3797, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:34.315294 #train# step 3798, loss = 0.9344, cross_entropy loss = 0.9344, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:35.930598 #train# step 3799, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:37.483087 #train# step 3800, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:39.062466 #train# step 3801, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:40.640950 #train# step 3802, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:42.211995 #train# step 3803, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:43.793890 #train# step 3804, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:45.340679 #train# step 3805, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:46.922221 #train# step 3806, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:48.481414 #train# step 3807, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:50.050789 #train# step 3808, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:51.609952 #train# step 3809, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:53.166970 #train# step 3810, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:54.737830 #train# step 3811, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:56.305947 #train# step 3812, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:57.889851 #train# step 3813, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:40:59.490210 #train# step 3814, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:01.038693 #train# step 3815, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:02.589418 #train# step 3816, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:04.157241 #train# step 3817, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:05.712966 #train# step 3818, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:07.289313 #train# step 3819, loss = 0.9421, cross_entropy loss = 0.9421, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:08.853304 #train# step 3820, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:10.429689 #train# step 3821, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:12.025446 #train# step 3822, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:13.603875 #train# step 3823, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:15.163948 #train# step 3824, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:16.772400 #train# step 3825, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:18.376159 #train# step 3826, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:19.958388 #train# step 3827, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:21.528894 #train# step 3828, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:23.108341 #train# step 3829, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:24.721745 #train# step 3830, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:26.290531 #train# step 3831, loss = 0.9350, cross_entropy loss = 0.9350, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:27.873530 #train# step 3832, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:29.460570 #train# step 3833, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:31.023517 #train# step 3834, loss = 0.9319, cross_entropy loss = 0.9319, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:32.579327 #train# step 3835, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:34.174401 #train# step 3836, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:35.780033 #train# step 3837, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:37.371412 #train# step 3838, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:39.004787 #train# step 3839, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:40.574535 #train# step 3840, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:42.140173 #train# step 3841, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:43.747303 #train# step 3842, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:45.313826 #train# step 3843, loss = 0.9262, cross_entropy loss = 0.9262, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:46.897567 #train# step 3844, loss = 0.9396, cross_entropy loss = 0.9396, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:48.519245 #train# step 3845, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:50.087889 #train# step 3846, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:51.684019 #train# step 3847, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:53.261879 #train# step 3848, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:54.813434 #train# step 3849, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:56.381376 #train# step 3850, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:57.975579 #train# step 3851, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:41:59.543944 #train# step 3852, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:01.108575 #train# step 3853, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:02.723814 #train# step 3854, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:04.328571 #train# step 3855, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:05.932077 #train# step 3856, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:07.517475 #train# step 3857, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:09.101665 #train# step 3858, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:10.673434 #train# step 3859, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:12.259459 #train# step 3860, loss = 0.9371, cross_entropy loss = 0.9371, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:13.854289 #train# step 3861, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:15.440614 #train# step 3862, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:17.011942 #train# step 3863, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:18.587666 #train# step 3864, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:20.167315 #train# step 3865, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:21.763252 #train# step 3866, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:23.337291 #train# step 3867, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:24.897311 #train# step 3868, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:26.478397 #train# step 3869, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:28.077752 #train# step 3870, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:29.652125 #train# step 3871, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:31.244020 #train# step 3872, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:32.810459 #train# step 3873, loss = 0.9236, cross_entropy loss = 0.9236, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:34.386257 #train# step 3874, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:35.982791 #train# step 3875, loss = 0.9383, cross_entropy loss = 0.9383, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:37.555676 #train# step 3876, loss = 0.9399, cross_entropy loss = 0.9399, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:39.126669 #train# step 3877, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:40.684928 #train# step 3878, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:42.288696 #train# step 3879, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:43.824786 #train# step 3880, loss = 0.9315, cross_entropy loss = 0.9315, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:45.377168 #train# step 3881, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:46.947809 #train# step 3882, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:48.535310 #train# step 3883, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:50.102798 #train# step 3884, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:51.690353 #train# step 3885, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:53.259139 #train# step 3886, loss = 0.9375, cross_entropy loss = 0.9375, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:54.833858 #train# step 3887, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:56.383902 #train# step 3888, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:57.964508 #train# step 3889, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:42:59.540216 #train# step 3890, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:01.146353 #train# step 3891, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:02.775950 #train# step 3892, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:04.366615 #train# step 3893, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:05.916576 #train# step 3894, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:07.463780 #train# step 3895, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:09.048863 #train# step 3896, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:10.665194 #train# step 3897, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:12.209917 #train# step 3898, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:13.782629 #train# step 3899, loss = 0.9387, cross_entropy loss = 0.9387, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:15.387910 #train# step 3900, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:16.981532 #train# step 3901, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:18.550699 #train# step 3902, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:20.129174 #train# step 3903, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:21.699549 #train# step 3904, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:23.270150 #train# step 3905, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:24.838505 #train# step 3906, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:26.414843 #train# step 3907, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:27.984155 #train# step 3908, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:29.585325 #train# step 3909, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:31.175379 #train# step 3910, loss = 0.9313, cross_entropy loss = 0.9313, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:32.754854 #train# step 3911, loss = 0.9318, cross_entropy loss = 0.9318, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:34.339951 #train# step 3912, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:35.894879 #train# step 3913, loss = 0.9331, cross_entropy loss = 0.9331, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:37.473796 #train# step 3914, loss = 0.9324, cross_entropy loss = 0.9324, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:39.034434 #train# step 3915, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:40.638868 #train# step 3916, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:42.233241 #train# step 3917, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:43.820495 #train# step 3918, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:45.401897 #train# step 3919, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:46.989877 #train# step 3920, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:48.593502 #train# step 3921, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:50.185053 #train# step 3922, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:51.765936 #train# step 3923, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:53.331063 #train# step 3924, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:54.896871 #train# step 3925, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:56.434560 #train# step 3926, loss = 0.9398, cross_entropy loss = 0.9398, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:58.027736 #train# step 3927, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:43:59.604800 #train# step 3928, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:01.183364 #train# step 3929, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:02.747488 #train# step 3930, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:04.300832 #train# step 3931, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:05.870919 #train# step 3932, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:07.465452 #train# step 3933, loss = 0.9447, cross_entropy loss = 0.9447, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:09.052386 #train# step 3934, loss = 0.9382, cross_entropy loss = 0.9382, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:10.627325 #train# step 3935, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:12.212342 #train# step 3936, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:13.787495 #train# step 3937, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:15.338078 #train# step 3938, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:16.917254 #train# step 3939, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:18.495208 #train# step 3940, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:20.101956 #train# step 3941, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:21.659648 #train# step 3942, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:23.254976 #train# step 3943, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:24.815045 #train# step 3944, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:26.360560 #train# step 3945, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:27.951323 #train# step 3946, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:29.543521 #train# step 3947, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:31.144788 #train# step 3948, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:32.737951 #train# step 3949, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:34.296170 #train# step 3950, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:35.898510 #train# step 3951, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:37.437375 #train# step 3952, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:38.991893 #train# step 3953, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:40.570012 #train# step 3954, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:42.152988 #train# step 3955, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:43.755785 #train# step 3956, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:45.301931 #train# step 3957, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:46.852132 #train# step 3958, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:48.410989 #train# step 3959, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:49.997948 #train# step 3960, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:51.563016 #train# step 3961, loss = 0.9401, cross_entropy loss = 0.9401, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:53.166150 #train# step 3962, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:54.732416 #train# step 3963, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:56.336077 #train# step 3964, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:57.919580 #train# step 3965, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:44:59.494940 #train# step 3966, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:01.073947 #train# step 3967, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:02.704918 #train# step 3968, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:04.270081 #train# step 3969, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:05.879033 #train# step 3970, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:07.440247 #train# step 3971, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:08.985158 #train# step 3972, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:10.607671 #train# step 3973, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:12.154456 #train# step 3974, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:13.755775 #train# step 3975, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:15.351694 #train# step 3976, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:16.910780 #train# step 3977, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:18.462099 #train# step 3978, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:20.043868 #train# step 3979, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:21.639373 #train# step 3980, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:23.234377 #train# step 3981, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:24.822461 #train# step 3982, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:26.388632 #train# step 3983, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:27.976826 #train# step 3984, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:29.539768 #train# step 3985, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:31.117238 #train# step 3986, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:32.686589 #train# step 3987, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:34.271531 #train# step 3988, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:35.866593 #train# step 3989, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:37.429824 #train# step 3990, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:38.994905 #train# step 3991, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:40.600882 #train# step 3992, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:42.175748 #train# step 3993, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:43.767259 #train# step 3994, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:45.347263 #train# step 3995, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:46.899274 #train# step 3996, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:48.475894 #train# step 3997, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:50.048114 #train# step 3998, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:51.631343 #train# step 3999, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:53.208064 #train# step 4000, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:54.790780 #train# step 4001, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:56.373914 #train# step 4002, loss = 0.9359, cross_entropy loss = 0.9359, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:57.970293 #train# step 4003, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:45:59.550217 #train# step 4004, loss = 0.9312, cross_entropy loss = 0.9312, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:01.127382 #train# step 4005, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:02.702809 #train# step 4006, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:04.237239 #train# step 4007, loss = 0.9481, cross_entropy loss = 0.9481, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:05.833560 #train# step 4008, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:07.411982 #train# step 4009, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:08.996236 #train# step 4010, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:10.598120 #train# step 4011, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:12.199612 #train# step 4012, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:13.780990 #train# step 4013, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:15.354412 #train# step 4014, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:16.924103 #train# step 4015, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:18.514403 #train# step 4016, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:20.068050 #train# step 4017, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:21.656097 #train# step 4018, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:23.223347 #train# step 4019, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:24.817867 #train# step 4020, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:26.405076 #train# step 4021, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:27.989576 #train# step 4022, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:29.576252 #train# step 4023, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:31.150706 #train# step 4024, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:32.734778 #train# step 4025, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:34.326626 #train# step 4026, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:35.901741 #train# step 4027, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:37.450488 #train# step 4028, loss = 0.9434, cross_entropy loss = 0.9434, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:39.060518 #train# step 4029, loss = 0.9323, cross_entropy loss = 0.9323, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:40.661843 #train# step 4030, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:42.219808 #train# step 4031, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:43.793225 #train# step 4032, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:45.373803 #train# step 4033, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:46.939379 #train# step 4034, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:48.516193 #train# step 4035, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:50.090467 #train# step 4036, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:51.665184 #train# step 4037, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:53.213933 #train# step 4038, loss = 0.9310, cross_entropy loss = 0.9310, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:54.767349 #train# step 4039, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:56.364108 #train# step 4040, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:57.949439 #train# step 4041, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:46:59.515798 #train# step 4042, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:01.072691 #train# step 4043, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:02.653553 #train# step 4044, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:04.240478 #train# step 4045, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:05.814524 #train# step 4046, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:07.375441 #train# step 4047, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:08.975198 #train# step 4048, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:10.554882 #train# step 4049, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:12.131549 #train# step 4050, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:13.700159 #train# step 4051, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:15.288292 #train# step 4052, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:16.866214 #train# step 4053, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:18.445721 #train# step 4054, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:20.038441 #train# step 4055, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:21.605538 #train# step 4056, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:23.171314 #train# step 4057, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:24.721935 #train# step 4058, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:26.323512 #train# step 4059, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:27.912780 #train# step 4060, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:29.490996 #train# step 4061, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:31.059575 #train# step 4062, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:32.633796 #train# step 4063, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:34.231150 #train# step 4064, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:35.843779 #train# step 4065, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:37.428978 #train# step 4066, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:39.006586 #train# step 4067, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:40.609271 #train# step 4068, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:42.209984 #train# step 4069, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:43.774643 #train# step 4070, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:45.339018 #train# step 4071, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:46.931495 #train# step 4072, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:48.491875 #train# step 4073, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:50.089716 #train# step 4074, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:51.665883 #train# step 4075, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:53.229714 #train# step 4076, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:54.815777 #train# step 4077, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:56.398343 #train# step 4078, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:57.975933 #train# step 4079, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:47:59.560529 #train# step 4080, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:01.112474 #train# step 4081, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:02.665943 #train# step 4082, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:04.269491 #train# step 4083, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:05.845137 #train# step 4084, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:07.411067 #train# step 4085, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:08.990877 #train# step 4086, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:10.565769 #train# step 4087, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:12.146219 #train# step 4088, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:13.748608 #train# step 4089, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:15.317638 #train# step 4090, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:16.898983 #train# step 4091, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:18.487365 #train# step 4092, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:20.052291 #train# step 4093, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:21.669318 #train# step 4094, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:23.254750 #train# step 4095, loss = 0.9425, cross_entropy loss = 0.9425, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:24.835141 #train# step 4096, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:26.418761 #train# step 4097, loss = 0.9307, cross_entropy loss = 0.9307, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:28.023853 #train# step 4098, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:29.604354 #train# step 4099, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:31.194942 #train# step 4100, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:32.773629 #train# step 4101, loss = 0.9380, cross_entropy loss = 0.9380, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:34.340366 #train# step 4102, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:35.960391 #train# step 4103, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:37.529223 #train# step 4104, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:39.087993 #train# step 4105, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:40.656538 #train# step 4106, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:42.214228 #train# step 4107, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:43.781080 #train# step 4108, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:45.373112 #train# step 4109, loss = 0.9306, cross_entropy loss = 0.9306, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:46.953667 #train# step 4110, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:48.548722 #train# step 4111, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:50.144356 #train# step 4112, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:51.751129 #train# step 4113, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:53.323628 #train# step 4114, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:54.916490 #train# step 4115, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:56.514910 #train# step 4116, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:58.060931 #train# step 4117, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:48:59.636464 #train# step 4118, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:01.171175 #train# step 4119, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:02.748226 #train# step 4120, loss = 0.9276, cross_entropy loss = 0.9276, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:04.352222 #train# step 4121, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:05.930269 #train# step 4122, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:07.509408 #train# step 4123, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:09.070473 #train# step 4124, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:10.655571 #train# step 4125, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:12.247909 #train# step 4126, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:13.834112 #train# step 4127, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:15.437707 #train# step 4128, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:17.031682 #train# step 4129, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:18.606053 #train# step 4130, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:20.201881 #train# step 4131, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:21.775844 #train# step 4132, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:23.301749 #train# step 4133, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:24.853593 #train# step 4134, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:26.405477 #train# step 4135, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:27.988307 #train# step 4136, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:29.585737 #train# step 4137, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:31.155486 #train# step 4138, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:32.751169 #train# step 4139, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:34.332244 #train# step 4140, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:35.963147 #train# step 4141, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:37.560909 #train# step 4142, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:39.145797 #train# step 4143, loss = 0.9363, cross_entropy loss = 0.9363, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:40.690866 #train# step 4144, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:42.261936 #train# step 4145, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:43.821222 #train# step 4146, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:45.384519 #train# step 4147, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:46.954936 #train# step 4148, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:48.555773 #train# step 4149, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:50.127917 #train# step 4150, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:51.704868 #train# step 4151, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:53.264154 #train# step 4152, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:54.882615 #train# step 4153, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:56.472853 #train# step 4154, loss = 0.9352, cross_entropy loss = 0.9352, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:58.057384 #train# step 4155, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:49:59.632488 #train# step 4156, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:01.215162 #train# step 4157, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:02.833836 #train# step 4158, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:04.392716 #train# step 4159, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:05.971271 #train# step 4160, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:07.539741 #train# step 4161, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:09.115428 #train# step 4162, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:10.672040 #train# step 4163, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:12.266290 #train# step 4164, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:13.872736 #train# step 4165, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:15.458596 #train# step 4166, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:17.012779 #train# step 4167, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:18.621684 #train# step 4168, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:20.178879 #train# step 4169, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:21.745040 #train# step 4170, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:23.297043 #train# step 4171, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:24.893750 #train# step 4172, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:26.499957 #train# step 4173, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:28.058596 #train# step 4174, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:29.614008 #train# step 4175, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:31.157731 #train# step 4176, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:32.703598 #train# step 4177, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:34.254244 #train# step 4178, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:35.856888 #train# step 4179, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:37.427498 #train# step 4180, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:39.028634 #train# step 4181, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:40.640769 #train# step 4182, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:42.225278 #train# step 4183, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:43.803708 #train# step 4184, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:45.394007 #train# step 4185, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:46.963271 #train# step 4186, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:48.536829 #train# step 4187, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:50.114275 #train# step 4188, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:51.704065 #train# step 4189, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:53.308280 #train# step 4190, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:54.903005 #train# step 4191, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:56.487379 #train# step 4192, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:58.047357 #train# step 4193, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:50:59.665693 #train# step 4194, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:01.260441 #train# step 4195, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:02.830362 #train# step 4196, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:04.426960 #train# step 4197, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:06.011184 #train# step 4198, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:07.568412 #train# step 4199, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:09.154289 #train# step 4200, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:10.704297 #train# step 4201, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:12.269980 #train# step 4202, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:13.828705 #train# step 4203, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:15.389262 #train# step 4204, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:16.978099 #train# step 4205, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:18.520855 #train# step 4206, loss = 0.9327, cross_entropy loss = 0.9327, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:20.129536 #train# step 4207, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:21.675215 #train# step 4208, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:23.236348 #train# step 4209, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:24.830677 #train# step 4210, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:26.406621 #train# step 4211, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:27.978488 #train# step 4212, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:29.574354 #train# step 4213, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:31.129192 #train# step 4214, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:32.716833 #train# step 4215, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:34.303835 #train# step 4216, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:35.872793 #train# step 4217, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:37.456565 #train# step 4218, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:39.037519 #train# step 4219, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:40.605819 #train# step 4220, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:42.191465 #train# step 4221, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:43.753728 #train# step 4222, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:45.360045 #train# step 4223, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:46.963957 #train# step 4224, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:48.571114 #train# step 4225, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:50.145360 #train# step 4226, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:51.722530 #train# step 4227, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:53.317095 #train# step 4228, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:54.879276 #train# step 4229, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:56.450675 #train# step 4230, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:58.013700 #train# step 4231, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:51:59.594267 #train# step 4232, loss = 0.9268, cross_entropy loss = 0.9268, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:01.195856 #train# step 4233, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:02.762395 #train# step 4234, loss = 0.9328, cross_entropy loss = 0.9328, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:04.337160 #train# step 4235, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:05.924864 #train# step 4236, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:07.532677 #train# step 4237, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:09.082426 #train# step 4238, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:10.646997 #train# step 4239, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:12.220582 #train# step 4240, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:13.824077 #train# step 4241, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:15.411285 #train# step 4242, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:16.972485 #train# step 4243, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:18.528166 #train# step 4244, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:20.134214 #train# step 4245, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:21.708944 #train# step 4246, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:23.284406 #train# step 4247, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:24.898717 #train# step 4248, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:26.503743 #train# step 4249, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:28.063752 #train# step 4250, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:29.641646 #train# step 4251, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:31.220723 #train# step 4252, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:32.784195 #train# step 4253, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:34.383499 #train# step 4254, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:35.992308 #train# step 4255, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:37.581696 #train# step 4256, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:39.147213 #train# step 4257, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:40.734658 #train# step 4258, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:42.314276 #train# step 4259, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:43.876957 #train# step 4260, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:45.424314 #train# step 4261, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:47.002046 #train# step 4262, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:48.567346 #train# step 4263, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:50.128725 #train# step 4264, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:51.716526 #train# step 4265, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:53.328634 #train# step 4266, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:54.923994 #train# step 4267, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:56.497542 #train# step 4268, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:58.080422 #train# step 4269, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:52:59.650781 #train# step 4270, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:01.192064 #train# step 4271, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:02.761590 #train# step 4272, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:04.355707 #train# step 4273, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:05.928023 #train# step 4274, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:07.518539 #train# step 4275, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:09.115430 #train# step 4276, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:10.678554 #train# step 4277, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:12.258413 #train# step 4278, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:13.815274 #train# step 4279, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:15.384791 #train# step 4280, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:16.950396 #train# step 4281, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:18.550666 #train# step 4282, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:20.141488 #train# step 4283, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:21.742656 #train# step 4284, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:23.306145 #train# step 4285, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:24.893780 #train# step 4286, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:26.447399 #train# step 4287, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:28.017072 #train# step 4288, loss = 0.9416, cross_entropy loss = 0.9416, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:29.587834 #train# step 4289, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:31.191736 #train# step 4290, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:32.762258 #train# step 4291, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:34.333451 #train# step 4292, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:35.903248 #train# step 4293, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:37.485841 #train# step 4294, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:39.073697 #train# step 4295, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:40.634799 #train# step 4296, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:42.188046 #train# step 4297, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:43.786041 #train# step 4298, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:45.394048 #train# step 4299, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:46.979012 #train# step 4300, loss = 0.9386, cross_entropy loss = 0.9386, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:48.561387 #train# step 4301, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:50.124832 #train# step 4302, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:51.703619 #train# step 4303, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:53.253217 #train# step 4304, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:54.831257 #train# step 4305, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:56.428287 #train# step 4306, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:58.001985 #train# step 4307, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:53:59.577761 #train# step 4308, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:01.186764 #train# step 4309, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:02.758861 #train# step 4310, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:04.338879 #train# step 4311, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:05.898323 #train# step 4312, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:07.500732 #train# step 4313, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:09.064736 #train# step 4314, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:10.630513 #train# step 4315, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:12.212845 #train# step 4316, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:13.817774 #train# step 4317, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:15.418050 #train# step 4318, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:17.020361 #train# step 4319, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:18.582633 #train# step 4320, loss = 0.9279, cross_entropy loss = 0.9279, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:20.166848 #train# step 4321, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:21.754538 #train# step 4322, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:23.333723 #train# step 4323, loss = 0.9346, cross_entropy loss = 0.9346, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:24.896589 #train# step 4324, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:26.481877 #train# step 4325, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:28.066363 #train# step 4326, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:29.655427 #train# step 4327, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:31.238217 #train# step 4328, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:32.818610 #train# step 4329, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:34.394772 #train# step 4330, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:35.986766 #train# step 4331, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:37.540671 #train# step 4332, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:39.130648 #train# step 4333, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:40.704829 #train# step 4334, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:42.258296 #train# step 4335, loss = 0.9361, cross_entropy loss = 0.9361, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:43.866552 #train# step 4336, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:45.453819 #train# step 4337, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:47.046913 #train# step 4338, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:48.638456 #train# step 4339, loss = 0.9284, cross_entropy loss = 0.9284, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:50.209171 #train# step 4340, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:51.794957 #train# step 4341, loss = 0.9308, cross_entropy loss = 0.9308, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:53.381084 #train# step 4342, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:54.957957 #train# step 4343, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:56.539616 #train# step 4344, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:58.092916 #train# step 4345, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:54:59.681480 #train# step 4346, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:01.265763 #train# step 4347, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:02.807611 #train# step 4348, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:04.373548 #train# step 4349, loss = 0.9311, cross_entropy loss = 0.9311, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:05.975720 #train# step 4350, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:07.564772 #train# step 4351, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:09.169361 #train# step 4352, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:10.769222 #train# step 4353, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:12.338857 #train# step 4354, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:13.888793 #train# step 4355, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:15.457456 #train# step 4356, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:17.017740 #train# step 4357, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:18.572974 #train# step 4358, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:20.162718 #train# step 4359, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:21.755569 #train# step 4360, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:23.324921 #train# step 4361, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:24.926140 #train# step 4362, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:26.524657 #train# step 4363, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:28.134934 #train# step 4364, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:29.726014 #train# step 4365, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:31.293743 #train# step 4366, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:32.850012 #train# step 4367, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:34.435994 #train# step 4368, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:36.034962 #train# step 4369, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:37.580324 #train# step 4370, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:39.147021 #train# step 4371, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:40.747672 #train# step 4372, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:42.332182 #train# step 4373, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:43.888114 #train# step 4374, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:45.490813 #train# step 4375, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:47.046120 #train# step 4376, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:48.615205 #train# step 4377, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:50.194734 #train# step 4378, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:51.760121 #train# step 4379, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:53.368179 #train# step 4380, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:54.916060 #train# step 4381, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:56.499196 #train# step 4382, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:58.068360 #train# step 4383, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:55:59.644022 #train# step 4384, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:01.217053 #train# step 4385, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:02.776115 #train# step 4386, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:04.359607 #train# step 4387, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:05.935049 #train# step 4388, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:07.558097 #train# step 4389, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:09.171623 #train# step 4390, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:10.759484 #train# step 4391, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:12.345426 #train# step 4392, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:13.908748 #train# step 4393, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:15.511570 #train# step 4394, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:17.092512 #train# step 4395, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:18.665496 #train# step 4396, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:20.259657 #train# step 4397, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:21.817659 #train# step 4398, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:23.390039 #train# step 4399, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:24.965676 #train# step 4400, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:26.545076 #train# step 4401, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:28.110071 #train# step 4402, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:29.703994 #train# step 4403, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:31.288516 #train# step 4404, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:32.886860 #train# step 4405, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:34.473814 #train# step 4406, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:36.024853 #train# step 4407, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:37.638038 #train# step 4408, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:39.227295 #train# step 4409, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:40.786535 #train# step 4410, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:42.376173 #train# step 4411, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:43.952363 #train# step 4412, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:45.515961 #train# step 4413, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:47.091620 #train# step 4414, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:48.657902 #train# step 4415, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:50.238602 #train# step 4416, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:51.824969 #train# step 4417, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:53.414369 #train# step 4418, loss = 0.9269, cross_entropy loss = 0.9269, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:54.992087 #train# step 4419, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:56.563849 #train# step 4420, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:58.126936 #train# step 4421, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:56:59.713639 #train# step 4422, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:01.315139 #train# step 4423, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:02.896570 #train# step 4424, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:04.454151 #train# step 4425, loss = 0.9278, cross_entropy loss = 0.9278, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:06.037926 #train# step 4426, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:07.594706 #train# step 4427, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:09.181528 #train# step 4428, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:10.716456 #train# step 4429, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:12.285866 #train# step 4430, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:13.894235 #train# step 4431, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:15.480323 #train# step 4432, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:17.065364 #train# step 4433, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:18.649897 #train# step 4434, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:20.202317 #train# step 4435, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:21.793217 #train# step 4436, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:23.381931 #train# step 4437, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:24.945069 #train# step 4438, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:26.553289 #train# step 4439, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:28.166209 #train# step 4440, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:29.781322 #train# step 4441, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:31.370857 #train# step 4442, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:32.921451 #train# step 4443, loss = 0.9347, cross_entropy loss = 0.9347, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:34.450492 #train# step 4444, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:36.003973 #train# step 4445, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:37.586274 #train# step 4446, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:39.157947 #train# step 4447, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:40.720109 #train# step 4448, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:42.303224 #train# step 4449, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:43.904448 #train# step 4450, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:45.518006 #train# step 4451, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:47.085094 #train# step 4452, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:48.662872 #train# step 4453, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:50.215344 #train# step 4454, loss = 0.9300, cross_entropy loss = 0.9300, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:51.817154 #train# step 4455, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:53.403465 #train# step 4456, loss = 0.9378, cross_entropy loss = 0.9378, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:55.010984 #train# step 4457, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:56.582272 #train# step 4458, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:58.122517 #train# step 4459, loss = 0.9402, cross_entropy loss = 0.9402, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:57:59.720415 #train# step 4460, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:01.319566 #train# step 4461, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:02.873826 #train# step 4462, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:04.444943 #train# step 4463, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:06.054917 #train# step 4464, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:07.654311 #train# step 4465, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:09.246585 #train# step 4466, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:10.833417 #train# step 4467, loss = 0.9355, cross_entropy loss = 0.9355, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:12.392561 #train# step 4468, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:13.968006 #train# step 4469, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:15.544170 #train# step 4470, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:17.118319 #train# step 4471, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:18.706706 #train# step 4472, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:20.293711 #train# step 4473, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:21.860022 #train# step 4474, loss = 0.9373, cross_entropy loss = 0.9373, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:23.485691 #train# step 4475, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:25.061818 #train# step 4476, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:26.647420 #train# step 4477, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:28.208170 #train# step 4478, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:29.786559 #train# step 4479, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:31.388249 #train# step 4480, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:32.967772 #train# step 4481, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:34.568704 #train# step 4482, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:36.163720 #train# step 4483, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:37.740652 #train# step 4484, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:39.328016 #train# step 4485, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:40.879299 #train# step 4486, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:42.470429 #train# step 4487, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:44.038530 #train# step 4488, loss = 0.9233, cross_entropy loss = 0.9233, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:45.583314 #train# step 4489, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:47.124008 #train# step 4490, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:48.688487 #train# step 4491, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:50.272028 #train# step 4492, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:51.853931 #train# step 4493, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:53.450710 #train# step 4494, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:55.035143 #train# step 4495, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:56.600516 #train# step 4496, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:58.159239 #train# step 4497, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:58:59.737496 #train# step 4498, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:01.302938 #train# step 4499, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:02.908339 #train# step 4500, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:04.476953 #train# step 4501, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:06.052718 #train# step 4502, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:07.632829 #train# step 4503, loss = 0.9299, cross_entropy loss = 0.9299, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:09.238556 #train# step 4504, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:10.814753 #train# step 4505, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:12.399872 #train# step 4506, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:13.980769 #train# step 4507, loss = 0.9257, cross_entropy loss = 0.9257, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:15.510897 #train# step 4508, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:17.128022 #train# step 4509, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:18.690964 #train# step 4510, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:20.287317 #train# step 4511, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:21.845519 #train# step 4512, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:23.417316 #train# step 4513, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:24.997997 #train# step 4514, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:26.533080 #train# step 4515, loss = 0.9239, cross_entropy loss = 0.9239, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:28.107284 #train# step 4516, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:29.712549 #train# step 4517, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:31.275107 #train# step 4518, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:32.852901 #train# step 4519, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:34.437294 #train# step 4520, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:36.027612 #train# step 4521, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:37.615899 #train# step 4522, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:39.189458 #train# step 4523, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:40.765198 #train# step 4524, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:42.340720 #train# step 4525, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:43.939623 #train# step 4526, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:45.519270 #train# step 4527, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:47.100421 #train# step 4528, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:48.708522 #train# step 4529, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:50.284722 #train# step 4530, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:51.870166 #train# step 4531, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:53.426506 #train# step 4532, loss = 0.9322, cross_entropy loss = 0.9322, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:55 #train# step 4533, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:56.558828 #train# step 4534, loss = 0.9343, cross_entropy loss = 0.9343, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:58.109261 #train# step 4535, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 19:59:59.675519 #train# step 4536, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:01.274698 #train# step 4537, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:02.844469 #train# step 4538, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:04.454669 #train# step 4539, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:06.007277 #train# step 4540, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:07.598972 #train# step 4541, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:09.184423 #train# step 4542, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:10.762637 #train# step 4543, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:12.374278 #train# step 4544, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:13.960602 #train# step 4545, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:15.560336 #train# step 4546, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:17.160272 #train# step 4547, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:18.768491 #train# step 4548, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:20.349024 #train# step 4549, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:21.921491 #train# step 4550, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:23.482274 #train# step 4551, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:25.046909 #train# step 4552, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:26.643272 #train# step 4553, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:28.209053 #train# step 4554, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:29.769996 #train# step 4555, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:31.337748 #train# step 4556, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:32.923414 #train# step 4557, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:34.480042 #train# step 4558, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:36.061142 #train# step 4559, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:37.651149 #train# step 4560, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:39.214060 #train# step 4561, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:40.812280 #train# step 4562, loss = 0.9286, cross_entropy loss = 0.9286, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:42.395750 #train# step 4563, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:44.004359 #train# step 4564, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:45.547622 #train# step 4565, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:47.172904 #train# step 4566, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:48.763369 #train# step 4567, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:50.340086 #train# step 4568, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:51.924544 #train# step 4569, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:53.518477 #train# step 4570, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:55.131518 #train# step 4571, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:56.677088 #train# step 4572, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:58.255875 #train# step 4573, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:00:59.826469 #train# step 4574, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:01.416486 #train# step 4575, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:02.992199 #train# step 4576, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:04.573815 #train# step 4577, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:06.157671 #train# step 4578, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:07.724404 #train# step 4579, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:09.275713 #train# step 4580, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:10.863055 #train# step 4581, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:12.447218 #train# step 4582, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:14.033079 #train# step 4583, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:15.629462 #train# step 4584, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:17.193478 #train# step 4585, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:18.748800 #train# step 4586, loss = 0.9285, cross_entropy loss = 0.9285, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:20.328951 #train# step 4587, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:21.922944 #train# step 4588, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:23.509867 #train# step 4589, loss = 0.9303, cross_entropy loss = 0.9303, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:25.084327 #train# step 4590, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:26.655986 #train# step 4591, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:28.247419 #train# step 4592, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:29.814834 #train# step 4593, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:31.391520 #train# step 4594, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:32.936372 #train# step 4595, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:34.519231 #train# step 4596, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:36.081405 #train# step 4597, loss = 0.9302, cross_entropy loss = 0.9302, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:37.661859 #train# step 4598, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:39.234939 #train# step 4599, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:40.809473 #train# step 4600, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:42.359223 #train# step 4601, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:43.941475 #train# step 4602, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:45.543744 #train# step 4603, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:47.143558 #train# step 4604, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:48.716909 #train# step 4605, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:50.312635 #train# step 4606, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:51.934608 #train# step 4607, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:53.560061 #train# step 4608, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:55.124248 #train# step 4609, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:56.679103 #train# step 4610, loss = 0.9320, cross_entropy loss = 0.9320, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:58.294683 #train# step 4611, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:01:59.900345 #train# step 4612, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:01.464007 #train# step 4613, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:03.017450 #train# step 4614, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:04.591600 #train# step 4615, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:06.149714 #train# step 4616, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:07.703643 #train# step 4617, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:09.286741 #train# step 4618, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:10.875559 #train# step 4619, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:12.476034 #train# step 4620, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:14.058485 #train# step 4621, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:15.592625 #train# step 4622, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:17.154343 #train# step 4623, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:18.684182 #train# step 4624, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:20.293144 #train# step 4625, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:21.880265 #train# step 4626, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:23.449596 #train# step 4627, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:25.010875 #train# step 4628, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:26.609104 #train# step 4629, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:28.159772 #train# step 4630, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:29.679725 #train# step 4631, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:31.265796 #train# step 4632, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:32.829914 #train# step 4633, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:34.378006 #train# step 4634, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:35.980549 #train# step 4635, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:37.545776 #train# step 4636, loss = 0.9360, cross_entropy loss = 0.9360, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:39.146486 #train# step 4637, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:40.706464 #train# step 4638, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:42.286171 #train# step 4639, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:43.888110 #train# step 4640, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:45.462832 #train# step 4641, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:47.073941 #train# step 4642, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:48.677124 #train# step 4643, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:50.269256 #train# step 4644, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:51.857734 #train# step 4645, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:53.451377 #train# step 4646, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:55.015316 #train# step 4647, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:56.612363 #train# step 4648, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:58.202163 #train# step 4649, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:02:59.820988 #train# step 4650, loss = 0.9254, cross_entropy loss = 0.9254, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:01.425363 #train# step 4651, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:02.990596 #train# step 4652, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:04.576648 #train# step 4653, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:06.146116 #train# step 4654, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:07.730200 #train# step 4655, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:09.320578 #train# step 4656, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:10.916654 #train# step 4657, loss = 0.9369, cross_entropy loss = 0.9369, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:12.501580 #train# step 4658, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:14.076024 #train# step 4659, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:15.669747 #train# step 4660, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:17.237816 #train# step 4661, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:18.827910 #train# step 4662, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:20.407808 #train# step 4663, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:21.990908 #train# step 4664, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:23.572194 #train# step 4665, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:25.168943 #train# step 4666, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:26.753463 #train# step 4667, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:28.331787 #train# step 4668, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:29.930384 #train# step 4669, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:31.497984 #train# step 4670, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:33.070155 #train# step 4671, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:34.672653 #train# step 4672, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:36.230029 #train# step 4673, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:37.784429 #train# step 4674, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:39.352157 #train# step 4675, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:40.946071 #train# step 4676, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:42.544178 #train# step 4677, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:44.137089 #train# step 4678, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:45.727391 #train# step 4679, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:47.313854 #train# step 4680, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:48.876998 #train# step 4681, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:50.433434 #train# step 4682, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:52.013171 #train# step 4683, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:53.586789 #train# step 4684, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:55.151341 #train# step 4685, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:56.724948 #train# step 4686, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:58.323371 #train# step 4687, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:03:59.874517 #train# step 4688, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:01.443661 #train# step 4689, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:03.007981 #train# step 4690, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:04.634607 #train# step 4691, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:06.231872 #train# step 4692, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:07.814703 #train# step 4693, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:09.383680 #train# step 4694, loss = 0.9394, cross_entropy loss = 0.9394, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:10.957043 #train# step 4695, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:12.561755 #train# step 4696, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:14.133190 #train# step 4697, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:15.690838 #train# step 4698, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:17.255012 #train# step 4699, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:18.817779 #train# step 4700, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:20.388031 #train# step 4701, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:21.982046 #train# step 4702, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:23.566222 #train# step 4703, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:25.139223 #train# step 4704, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:26.730051 #train# step 4705, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:28.311962 #train# step 4706, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:29.871045 #train# step 4707, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:31.451996 #train# step 4708, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:33.058537 #train# step 4709, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:34.678129 #train# step 4710, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:36.281232 #train# step 4711, loss = 0.9283, cross_entropy loss = 0.9283, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:37.919427 #train# step 4712, loss = 0.9176, cross_entropy loss = 0.9176, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:39.537450 #train# step 4713, loss = 0.9186, cross_entropy loss = 0.9186, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:41.196902 #train# step 4714, loss = 0.9138, cross_entropy loss = 0.9138, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:42.872920 #train# step 4715, loss = 0.9202, cross_entropy loss = 0.9202, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:44.535461 #train# step 4716, loss = 0.9302, cross_entropy loss = 0.9302, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:46.283673 #train# step 4717, loss = 0.9051, cross_entropy loss = 0.9051, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:47.971886 #train# step 4718, loss = 0.9180, cross_entropy loss = 0.9180, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:49.646415 #train# step 4719, loss = 0.9097, cross_entropy loss = 0.9097, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:51.276909 #train# step 4720, loss = 0.9107, cross_entropy loss = 0.9107, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:52.963719 #train# step 4721, loss = 0.9014, cross_entropy loss = 0.9014, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:54.644980 #train# step 4722, loss = 0.9189, cross_entropy loss = 0.9189, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:56.330279 #train# step 4723, loss = 0.9128, cross_entropy loss = 0.9128, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:58.010728 #train# step 4724, loss = 0.9014, cross_entropy loss = 0.9014, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:04:59.651192 #train# step 4725, loss = 0.9036, cross_entropy loss = 0.9036, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:01.361660 #train# step 4726, loss = 0.9197, cross_entropy loss = 0.9197, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:03.019536 #train# step 4727, loss = 0.9109, cross_entropy loss = 0.9109, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:04.690639 #train# step 4728, loss = 0.9209, cross_entropy loss = 0.9209, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:06.348345 #train# step 4729, loss = 0.9275, cross_entropy loss = 0.9275, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:07.946859 #train# step 4730, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:09.542299 #train# step 4731, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:11.134785 #train# step 4732, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:12.727801 #train# step 4733, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:14.282186 #train# step 4734, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:15.858734 #train# step 4735, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:17.415599 #train# step 4736, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:19.021731 #train# step 4737, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:20.622578 #train# step 4738, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:22.216132 #train# step 4739, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:23.811959 #train# step 4740, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:25.432186 #train# step 4741, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:26.989197 #train# step 4742, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:28.541097 #train# step 4743, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:30.126790 #train# step 4744, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:31.754217 #train# step 4745, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:33.337227 #train# step 4746, loss = 0.9267, cross_entropy loss = 0.9267, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:34.917535 #train# step 4747, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:36.534572 #train# step 4748, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:38.091473 #train# step 4749, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:39.672836 #train# step 4750, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:41.245771 #train# step 4751, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:42.852438 #train# step 4752, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:44.428815 #train# step 4753, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:45.996683 #train# step 4754, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:47.565029 #train# step 4755, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:49.147244 #train# step 4756, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:50.708888 #train# step 4757, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:52.292392 #train# step 4758, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:53.886336 #train# step 4759, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:55.450621 #train# step 4760, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:57.031435 #train# step 4761, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:05:58.633493 #train# step 4762, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:00.193780 #train# step 4763, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:01.774766 #train# step 4764, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:03.366015 #train# step 4765, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:04.975835 #train# step 4766, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:06.589969 #train# step 4767, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:08.182234 #train# step 4768, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:09.778620 #train# step 4769, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:11.379795 #train# step 4770, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:12.987340 #train# step 4771, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:14.547768 #train# step 4772, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:16.101285 #train# step 4773, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:17.685954 #train# step 4774, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:19.293235 #train# step 4775, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:20.847013 #train# step 4776, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:22.424644 #train# step 4777, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:23.999481 #train# step 4778, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:25.567811 #train# step 4779, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:27.148708 #train# step 4780, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:28.712430 #train# step 4781, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:30.294945 #train# step 4782, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:31.909580 #train# step 4783, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:33.504128 #train# step 4784, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:35.102456 #train# step 4785, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:36.678968 #train# step 4786, loss = 0.9271, cross_entropy loss = 0.9271, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:38.294815 #train# step 4787, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:39.896102 #train# step 4788, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:41.478240 #train# step 4789, loss = 0.9291, cross_entropy loss = 0.9291, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:43.071890 #train# step 4790, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:44.662253 #train# step 4791, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:46.244513 #train# step 4792, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:47.792306 #train# step 4793, loss = 0.9366, cross_entropy loss = 0.9366, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:49.386368 #train# step 4794, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:50.942758 #train# step 4795, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:52.521192 #train# step 4796, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:54.080195 #train# step 4797, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:55.684055 #train# step 4798, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:57.285266 #train# step 4799, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:06:58.893451 #train# step 4800, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:00.472285 #train# step 4801, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:02.067745 #train# step 4802, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:03.645198 #train# step 4803, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:05.244524 #train# step 4804, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:06.842499 #train# step 4805, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:08.405755 #train# step 4806, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:10.017056 #train# step 4807, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:11.608663 #train# step 4808, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:13.188521 #train# step 4809, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:14.764063 #train# step 4810, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:16.398594 #train# step 4811, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:17.984582 #train# step 4812, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:19.555195 #train# step 4813, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:21.115966 #train# step 4814, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:22.695149 #train# step 4815, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:24.251606 #train# step 4816, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:25.834021 #train# step 4817, loss = 0.9316, cross_entropy loss = 0.9316, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:27.413961 #train# step 4818, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:28.990958 #train# step 4819, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:30.566731 #train# step 4820, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:32.170264 #train# step 4821, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:33.748601 #train# step 4822, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:35.340675 #train# step 4823, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:36.905119 #train# step 4824, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:38.488100 #train# step 4825, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:40.064545 #train# step 4826, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:41.667137 #train# step 4827, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:43.269316 #train# step 4828, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:44.843033 #train# step 4829, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:46.407523 #train# step 4830, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:47.978743 #train# step 4831, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:49.548965 #train# step 4832, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:51.108877 #train# step 4833, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:52.685882 #train# step 4834, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:54.265301 #train# step 4835, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:55.823687 #train# step 4836, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:57.418215 #train# step 4837, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:07:58.998531 #train# step 4838, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:00.601509 #train# step 4839, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:02.210610 #train# step 4840, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:03.801725 #train# step 4841, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:05.365412 #train# step 4842, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:06.955047 #train# step 4843, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:08.521008 #train# step 4844, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:10.087521 #train# step 4845, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:11.671097 #train# step 4846, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:13.274956 #train# step 4847, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:14.867907 #train# step 4848, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:16.458182 #train# step 4849, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:18.020048 #train# step 4850, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:19.627475 #train# step 4851, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:21.238498 #train# step 4852, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:22.796843 #train# step 4853, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:24.376885 #train# step 4854, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:25.959235 #train# step 4855, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:27.526432 #train# step 4856, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:29.112527 #train# step 4857, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:30.687404 #train# step 4858, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:32.263238 #train# step 4859, loss = 0.9400, cross_entropy loss = 0.9400, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:33.843478 #train# step 4860, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:35.390256 #train# step 4861, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:36.988674 #train# step 4862, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:38.572596 #train# step 4863, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:40.190088 #train# step 4864, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:41.785555 #train# step 4865, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:43.374166 #train# step 4866, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:44.943662 #train# step 4867, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:46.517303 #train# step 4868, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:48.096483 #train# step 4869, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:49.688410 #train# step 4870, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:51.237997 #train# step 4871, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:52.814963 #train# step 4872, loss = 0.9349, cross_entropy loss = 0.9349, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:54.399457 #train# step 4873, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:55.967849 #train# step 4874, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:57.583313 #train# step 4875, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:08:59.188785 #train# step 4876, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:00.775822 #train# step 4877, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:02.366541 #train# step 4878, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:03.948299 #train# step 4879, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:05.540448 #train# step 4880, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:07.125665 #train# step 4881, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:08.704927 #train# step 4882, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:10.297962 #train# step 4883, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:11.871945 #train# step 4884, loss = 0.9335, cross_entropy loss = 0.9335, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:13.472308 #train# step 4885, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:15.052106 #train# step 4886, loss = 0.9304, cross_entropy loss = 0.9304, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:16.646526 #train# step 4887, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:18.229340 #train# step 4888, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:19.793320 #train# step 4889, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:21.380679 #train# step 4890, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:22.997670 #train# step 4891, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:24.590327 #train# step 4892, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:26.159468 #train# step 4893, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:27.756512 #train# step 4894, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:29.361145 #train# step 4895, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:30.939769 #train# step 4896, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:32.528421 #train# step 4897, loss = 0.9289, cross_entropy loss = 0.9289, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:34.106827 #train# step 4898, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:35.693417 #train# step 4899, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:37.303278 #train# step 4900, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:38.861711 #train# step 4901, loss = 0.9406, cross_entropy loss = 0.9406, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:40.454487 #train# step 4902, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:42.031410 #train# step 4903, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:43.620825 #train# step 4904, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:45.251408 #train# step 4905, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:46.845656 #train# step 4906, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:48.416789 #train# step 4907, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:49.979493 #train# step 4908, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:51.576882 #train# step 4909, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:53.124622 #train# step 4910, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:54.694022 #train# step 4911, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:56.263754 #train# step 4912, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:57.835778 #train# step 4913, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:09:59.394892 #train# step 4914, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:00.960947 #train# step 4915, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:02.543187 #train# step 4916, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:04.095625 #train# step 4917, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:05.690630 #train# step 4918, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:07.274242 #train# step 4919, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:08.889191 #train# step 4920, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:10.455296 #train# step 4921, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:12.016242 #train# step 4922, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:13.629240 #train# step 4923, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:15.204793 #train# step 4924, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:16.773481 #train# step 4925, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:18.354656 #train# step 4926, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:19.932801 #train# step 4927, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:21.505048 #train# step 4928, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:23.062878 #train# step 4929, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:24.641767 #train# step 4930, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:26.220199 #train# step 4931, loss = 0.9293, cross_entropy loss = 0.9293, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:27.822698 #train# step 4932, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:29.407208 #train# step 4933, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:30.983816 #train# step 4934, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:32.568842 #train# step 4935, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:34.120700 #train# step 4936, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:35.710258 #train# step 4937, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:37.282156 #train# step 4938, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:38.876482 #train# step 4939, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:40.474989 #train# step 4940, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:42.054444 #train# step 4941, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:43.637467 #train# step 4942, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:45.204288 #train# step 4943, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:46.784083 #train# step 4944, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:48.350856 #train# step 4945, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:49.959252 #train# step 4946, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:51.549061 #train# step 4947, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:53.147805 #train# step 4948, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:54.685468 #train# step 4949, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:56.280102 #train# step 4950, loss = 0.9277, cross_entropy loss = 0.9277, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:57.880318 #train# step 4951, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:10:59.449433 #train# step 4952, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:01.060296 #train# step 4953, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:02.665986 #train# step 4954, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:04.219513 #train# step 4955, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:05.788916 #train# step 4956, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:07.386382 #train# step 4957, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:08.969562 #train# step 4958, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:10.618028 #train# step 4959, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:12.192512 #train# step 4960, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:13.718619 #train# step 4961, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:15.316575 #train# step 4962, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:16.874385 #train# step 4963, loss = 0.9261, cross_entropy loss = 0.9261, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:18.473159 #train# step 4964, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:20.063888 #train# step 4965, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:21.646872 #train# step 4966, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:23.255934 #train# step 4967, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:24.858013 #train# step 4968, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:26.465500 #train# step 4969, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:28.024696 #train# step 4970, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:29.597282 #train# step 4971, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:31.173351 #train# step 4972, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:32.752920 #train# step 4973, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:34.347291 #train# step 4974, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:35.936919 #train# step 4975, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:37.535417 #train# step 4976, loss = 0.9297, cross_entropy loss = 0.9297, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:39.098024 #train# step 4977, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:40.696799 #train# step 4978, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:42.282256 #train# step 4979, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:43.873940 #train# step 4980, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:45.475534 #train# step 4981, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:47.057089 #train# step 4982, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:48.649640 #train# step 4983, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:50.218139 #train# step 4984, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:51.805822 #train# step 4985, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:53.382075 #train# step 4986, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:54.949043 #train# step 4987, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:56.496946 #train# step 4988, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:58.078426 #train# step 4989, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:11:59.688559 #train# step 4990, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:01.286445 #train# step 4991, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:02.870411 #train# step 4992, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:04.487303 #train# step 4993, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:06.027825 #train# step 4994, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:07.603908 #train# step 4995, loss = 0.9259, cross_entropy loss = 0.9259, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:09.190046 #train# step 4996, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:10.767778 #train# step 4997, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:12.377011 #train# step 4998, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:13.929225 #train# step 4999, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:15.528917 #train# step 5000, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:17.122733 #train# step 5001, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:18.708952 #train# step 5002, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:20.278679 #train# step 5003, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:21.860594 #train# step 5004, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:23.453703 #train# step 5005, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:25.036071 #train# step 5006, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:26.634902 #train# step 5007, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:28.185082 #train# step 5008, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:29.770142 #train# step 5009, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:31.349412 #train# step 5010, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:32.939274 #train# step 5011, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:34.539203 #train# step 5012, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:36.125083 #train# step 5013, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:37.715410 #train# step 5014, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:39.306274 #train# step 5015, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:40.883130 #train# step 5016, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:42.471942 #train# step 5017, loss = 0.8895, cross_entropy loss = 0.8895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:44.039781 #train# step 5018, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:45.635456 #train# step 5019, loss = 0.9340, cross_entropy loss = 0.9340, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:47.180210 #train# step 5020, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:48.765201 #train# step 5021, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:50.349011 #train# step 5022, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:51.943499 #train# step 5023, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:53.504568 #train# step 5024, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:55.118829 #train# step 5025, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:56.750124 #train# step 5026, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:58.341341 #train# step 5027, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:12:59.918398 #train# step 5028, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:01.491655 #train# step 5029, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:03.082131 #train# step 5030, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:04.662767 #train# step 5031, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:06.233178 #train# step 5032, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:07.791628 #train# step 5033, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:09.407361 #train# step 5034, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:10.992404 #train# step 5035, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:12.599500 #train# step 5036, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:14.170084 #train# step 5037, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:15.705819 #train# step 5038, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:17.275300 #train# step 5039, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:18.898697 #train# step 5040, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:20.469262 #train# step 5041, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:22.042380 #train# step 5042, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:23.633263 #train# step 5043, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:25.234472 #train# step 5044, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:26.857114 #train# step 5045, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:28.423887 #train# step 5046, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:30.002238 #train# step 5047, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:31.580914 #train# step 5048, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:33.202953 #train# step 5049, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:34.785553 #train# step 5050, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:36.354825 #train# step 5051, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:37.926390 #train# step 5052, loss = 0.9405, cross_entropy loss = 0.9405, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:39.517595 #train# step 5053, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:41.105635 #train# step 5054, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:42.694104 #train# step 5055, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:44.279355 #train# step 5056, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:45.870355 #train# step 5057, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:47.472984 #train# step 5058, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:49.042428 #train# step 5059, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:50.621866 #train# step 5060, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:52.204108 #train# step 5061, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:53.800679 #train# step 5062, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:55.375882 #train# step 5063, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:56.942929 #train# step 5064, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:13:58.499739 #train# step 5065, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:00.125702 #train# step 5066, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:01.711367 #train# step 5067, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:03.284005 #train# step 5068, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:04.833117 #train# step 5069, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:06.424615 #train# step 5070, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:08.023682 #train# step 5071, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:09.578798 #train# step 5072, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:11.168424 #train# step 5073, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:12.725822 #train# step 5074, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:14.317462 #train# step 5075, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:15.873563 #train# step 5076, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:17.457552 #train# step 5077, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:19.039577 #train# step 5078, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:20.647723 #train# step 5079, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:22.220505 #train# step 5080, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:23.809090 #train# step 5081, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:25.380019 #train# step 5082, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:26.977792 #train# step 5083, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:28.569707 #train# step 5084, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:30.170789 #train# step 5085, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:31.744911 #train# step 5086, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:33.353538 #train# step 5087, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:34.904223 #train# step 5088, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:36.480233 #train# step 5089, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:38.033553 #train# step 5090, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:39.619674 #train# step 5091, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:41.204011 #train# step 5092, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:42.766857 #train# step 5093, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:44.370987 #train# step 5094, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:45.963685 #train# step 5095, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:47.506981 #train# step 5096, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:49.073391 #train# step 5097, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:50.674568 #train# step 5098, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:52.252470 #train# step 5099, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:53.858596 #train# step 5100, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:55.465795 #train# step 5101, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:57.045534 #train# step 5102, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:14:58.649421 #train# step 5103, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:00.234760 #train# step 5104, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:01.854293 #train# step 5105, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:03.428174 #train# step 5106, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:04.998252 #train# step 5107, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:06.598540 #train# step 5108, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:08.175330 #train# step 5109, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:09.772924 #train# step 5110, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:11.339198 #train# step 5111, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:12.926335 #train# step 5112, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:14.496458 #train# step 5113, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:16.081579 #train# step 5114, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:17.613514 #train# step 5115, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:19.188580 #train# step 5116, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:20.776550 #train# step 5117, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:22.385796 #train# step 5118, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:23.961050 #train# step 5119, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:25.529868 #train# step 5120, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:27.114088 #train# step 5121, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:28.708250 #train# step 5122, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:30.267235 #train# step 5123, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:31.850823 #train# step 5124, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:33.451431 #train# step 5125, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:35.037486 #train# step 5126, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:36.610306 #train# step 5127, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:38.202775 #train# step 5128, loss = 0.9295, cross_entropy loss = 0.9295, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:39.775461 #train# step 5129, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:41.371614 #train# step 5130, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:42.933824 #train# step 5131, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:44.492694 #train# step 5132, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:46.101967 #train# step 5133, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:47.702015 #train# step 5134, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:49.287234 #train# step 5135, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:50.902531 #train# step 5136, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:52.487880 #train# step 5137, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:54.069336 #train# step 5138, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:55.658701 #train# step 5139, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:57.236402 #train# step 5140, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:15:58.786270 #train# step 5141, loss = 0.9275, cross_entropy loss = 0.9275, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:00.335554 #train# step 5142, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:01.915277 #train# step 5143, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:03.527098 #train# step 5144, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:05.098730 #train# step 5145, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:06.674889 #train# step 5146, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:08.273805 #train# step 5147, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:09.827299 #train# step 5148, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:11.393261 #train# step 5149, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:12.937051 #train# step 5150, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:14.516277 #train# step 5151, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:16.133965 #train# step 5152, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:17.716311 #train# step 5153, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:19.295427 #train# step 5154, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:20.844094 #train# step 5155, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:22.423524 #train# step 5156, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:24.008832 #train# step 5157, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:25.626767 #train# step 5158, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:27.217633 #train# step 5159, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:28.820057 #train# step 5160, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:30.403457 #train# step 5161, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:31.955909 #train# step 5162, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:33.536807 #train# step 5163, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:35.114510 #train# step 5164, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:36.720947 #train# step 5165, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:38.307942 #train# step 5166, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:39.876381 #train# step 5167, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:41.448922 #train# step 5168, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:43.036448 #train# step 5169, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:44.611581 #train# step 5170, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:46.159425 #train# step 5171, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:47.736992 #train# step 5172, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:49.333831 #train# step 5173, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:50.910066 #train# step 5174, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:52.486608 #train# step 5175, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:54.069203 #train# step 5176, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:55.652862 #train# step 5177, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:57.220524 #train# step 5178, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:16:58.827290 #train# step 5179, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:00.408795 #train# step 5180, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:02.008662 #train# step 5181, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:03.606911 #train# step 5182, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:05.214887 #train# step 5183, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:06.771565 #train# step 5184, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:08.364729 #train# step 5185, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:09.957186 #train# step 5186, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:11.521191 #train# step 5187, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:13.107531 #train# step 5188, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:14.667744 #train# step 5189, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:16.264197 #train# step 5190, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:17.827200 #train# step 5191, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:19.418118 #train# step 5192, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:20.989300 #train# step 5193, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:22.576994 #train# step 5194, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:24.162235 #train# step 5195, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:25.748008 #train# step 5196, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:27.316397 #train# step 5197, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:28.914528 #train# step 5198, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:30.495766 #train# step 5199, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:32.103242 #train# step 5200, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:33.687554 #train# step 5201, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:35.261970 #train# step 5202, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:36.840223 #train# step 5203, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:38.418511 #train# step 5204, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:40.004842 #train# step 5205, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:41.593060 #train# step 5206, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:43.195323 #train# step 5207, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:44.790168 #train# step 5208, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:46.369717 #train# step 5209, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:47.941655 #train# step 5210, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:49.552101 #train# step 5211, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:51.113180 #train# step 5212, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:52.720584 #train# step 5213, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:54.284605 #train# step 5214, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:55.854369 #train# step 5215, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:57.407138 #train# step 5216, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:17:59.012576 #train# step 5217, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:00.615503 #train# step 5218, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:02.208292 #train# step 5219, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:03.794463 #train# step 5220, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:05.357391 #train# step 5221, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:06.918696 #train# step 5222, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:08.542417 #train# step 5223, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:10.134531 #train# step 5224, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:11.723763 #train# step 5225, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:13.300739 #train# step 5226, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:14.914454 #train# step 5227, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:16.524883 #train# step 5228, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:18.125059 #train# step 5229, loss = 0.9051, cross_entropy loss = 0.9051, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:19.761735 #train# step 5230, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:21.372341 #train# step 5231, loss = 0.9184, cross_entropy loss = 0.9184, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:22.922015 #train# step 5232, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:24.542690 #train# step 5233, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:26.132981 #train# step 5234, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:27.717928 #train# step 5235, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:29.352731 #train# step 5236, loss = 0.9243, cross_entropy loss = 0.9243, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:30.914234 #train# step 5237, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:32.512486 #train# step 5238, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:34.081676 #train# step 5239, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:35.698491 #train# step 5240, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:37.267672 #train# step 5241, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:38.870688 #train# step 5242, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:40.458108 #train# step 5243, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:42.083696 #train# step 5244, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:43.664173 #train# step 5245, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:45.252480 #train# step 5246, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:46.878009 #train# step 5247, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:48.462802 #train# step 5248, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:50.074183 #train# step 5249, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:51.647298 #train# step 5250, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:53.208497 #train# step 5251, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:54.756805 #train# step 5252, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:56.339885 #train# step 5253, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:57.913355 #train# step 5254, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:18:59.542824 #train# step 5255, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:01.106492 #train# step 5256, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:02.669657 #train# step 5257, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:04.216098 #train# step 5258, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:05.767235 #train# step 5259, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:07.357183 #train# step 5260, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:08.950768 #train# step 5261, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:10.545366 #train# step 5262, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:12.149002 #train# step 5263, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:13.750095 #train# step 5264, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:15.363385 #train# step 5265, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:16.938535 #train# step 5266, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:18.536467 #train# step 5267, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:20.146285 #train# step 5268, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:21.748821 #train# step 5269, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:23.365273 #train# step 5270, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:24.959144 #train# step 5271, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:26.535446 #train# step 5272, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:28.138497 #train# step 5273, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:29.713068 #train# step 5274, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:31.275681 #train# step 5275, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:32.852218 #train# step 5276, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:34.426792 #train# step 5277, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:36.029844 #train# step 5278, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:37.589755 #train# step 5279, loss = 0.9165, cross_entropy loss = 0.9165, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:39.245891 #train# step 5280, loss = 0.9051, cross_entropy loss = 0.9051, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:40.846182 #train# step 5281, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:42.472013 #train# step 5282, loss = 0.9096, cross_entropy loss = 0.9096, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:44.066236 #train# step 5283, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:45.672904 #train# step 5284, loss = 0.9334, cross_entropy loss = 0.9334, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:47.259964 #train# step 5285, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:48.797341 #train# step 5286, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:50.358037 #train# step 5287, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:51.923835 #train# step 5288, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:53.564474 #train# step 5289, loss = 0.9109, cross_entropy loss = 0.9109, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:55.149673 #train# step 5290, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:56.752134 #train# step 5291, loss = 0.9183, cross_entropy loss = 0.9183, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:58.323131 #train# step 5292, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:19:59.904439 #train# step 5293, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:01.516557 #train# step 5294, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:03.085074 #train# step 5295, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:04.684143 #train# step 5296, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:06.276416 #train# step 5297, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:07.862258 #train# step 5298, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:09.445613 #train# step 5299, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:11.054708 #train# step 5300, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:12.684961 #train# step 5301, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:14.301283 #train# step 5302, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:15.912359 #train# step 5303, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:17.477244 #train# step 5304, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:19.057600 #train# step 5305, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:20.616345 #train# step 5306, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:22.203265 #train# step 5307, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:23.772178 #train# step 5308, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:25.353649 #train# step 5309, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:26.924278 #train# step 5310, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:28.512928 #train# step 5311, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:30.145048 #train# step 5312, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:31.731806 #train# step 5313, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:33.326935 #train# step 5314, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:34.921400 #train# step 5315, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:36.521949 #train# step 5316, loss = 0.9224, cross_entropy loss = 0.9224, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:38.140152 #train# step 5317, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:39.696281 #train# step 5318, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:41.282416 #train# step 5319, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:42.853387 #train# step 5320, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:44.424970 #train# step 5321, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:46.032228 #train# step 5322, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:47.615290 #train# step 5323, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:49.203840 #train# step 5324, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:50.779158 #train# step 5325, loss = 0.9241, cross_entropy loss = 0.9241, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:52.351811 #train# step 5326, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:53.925256 #train# step 5327, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:55.536711 #train# step 5328, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:57.095382 #train# step 5329, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:20:58.671143 #train# step 5330, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:00.291765 #train# step 5331, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:01.871893 #train# step 5332, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:03.484558 #train# step 5333, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:05.078143 #train# step 5334, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:06.665586 #train# step 5335, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:08.268529 #train# step 5336, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:09.879053 #train# step 5337, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:11.455786 #train# step 5338, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:13.042568 #train# step 5339, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:14.593410 #train# step 5340, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:16.165477 #train# step 5341, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:17.750296 #train# step 5342, loss = 0.9266, cross_entropy loss = 0.9266, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:19.358159 #train# step 5343, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:20.948975 #train# step 5344, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:22.548269 #train# step 5345, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:24.108812 #train# step 5346, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:25.691968 #train# step 5347, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:27.284685 #train# step 5348, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:28.885352 #train# step 5349, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:30.487533 #train# step 5350, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:32.048871 #train# step 5351, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:33.635064 #train# step 5352, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:35.204764 #train# step 5353, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:36.792976 #train# step 5354, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:38.389683 #train# step 5355, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:39.943627 #train# step 5356, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:41.548786 #train# step 5357, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:43.173764 #train# step 5358, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:44.770774 #train# step 5359, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:46.347263 #train# step 5360, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:47.948488 #train# step 5361, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:49.507605 #train# step 5362, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:51.097471 #train# step 5363, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:52.702748 #train# step 5364, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:54.278550 #train# step 5365, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:55.873155 #train# step 5366, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:57.459055 #train# step 5367, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:21:59.058944 #train# step 5368, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:00.633666 #train# step 5369, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:02.217686 #train# step 5370, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:03.797825 #train# step 5371, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:05.414947 #train# step 5372, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:06.987382 #train# step 5373, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:08.573687 #train# step 5374, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:10.128130 #train# step 5375, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:11.704846 #train# step 5376, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:13.297772 #train# step 5377, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:14.867564 #train# step 5378, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:16.450584 #train# step 5379, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:18.012575 #train# step 5380, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:19.592091 #train# step 5381, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:21.180483 #train# step 5382, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:22.765556 #train# step 5383, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:24.356703 #train# step 5384, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:25.914447 #train# step 5385, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:27.507452 #train# step 5386, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:29.091805 #train# step 5387, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:30.659828 #train# step 5388, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:32.257879 #train# step 5389, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:33.815603 #train# step 5390, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:35.411534 #train# step 5391, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:37.032477 #train# step 5392, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:38.611560 #train# step 5393, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:40.196409 #train# step 5394, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:41.808693 #train# step 5395, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:43.388484 #train# step 5396, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:44.999965 #train# step 5397, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:46.587119 #train# step 5398, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:48.177761 #train# step 5399, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:49.778142 #train# step 5400, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:51.354792 #train# step 5401, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:52.948729 #train# step 5402, loss = 0.9280, cross_entropy loss = 0.9280, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:54.552104 #train# step 5403, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:56.128099 #train# step 5404, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:57.666770 #train# step 5405, loss = 0.9274, cross_entropy loss = 0.9274, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:22:59.304056 #train# step 5406, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:00.874511 #train# step 5407, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:02.438691 #train# step 5408, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:04.015364 #train# step 5409, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:05.641091 #train# step 5410, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:07.224276 #train# step 5411, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:08.802289 #train# step 5412, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:10.397288 #train# step 5413, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:11.971337 #train# step 5414, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:13.557227 #train# step 5415, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:15.163422 #train# step 5416, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:16.735724 #train# step 5417, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:18.326351 #train# step 5418, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:19.873970 #train# step 5419, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:21.469907 #train# step 5420, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:23.124582 #train# step 5421, loss = 0.9071, cross_entropy loss = 0.9071, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:24.708299 #train# step 5422, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:26.304746 #train# step 5423, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:27.871008 #train# step 5424, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:29.446851 #train# step 5425, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:31.078414 #train# step 5426, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:32.726065 #train# step 5427, loss = 0.8926, cross_entropy loss = 0.8926, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:34.294368 #train# step 5428, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:35.906387 #train# step 5429, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:37.485729 #train# step 5430, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:39.105215 #train# step 5431, loss = 0.9011, cross_entropy loss = 0.9011, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:40.719413 #train# step 5432, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:42.320379 #train# step 5433, loss = 0.9076, cross_entropy loss = 0.9076, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:43.911652 #train# step 5434, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:45.543572 #train# step 5435, loss = 0.8971, cross_entropy loss = 0.8971, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:47.141826 #train# step 5436, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:48.741983 #train# step 5437, loss = 0.9108, cross_entropy loss = 0.9108, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:50.314007 #train# step 5438, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:51.892083 #train# step 5439, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:53.504364 #train# step 5440, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:55.124413 #train# step 5441, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:56.675766 #train# step 5442, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:58.279411 #train# step 5443, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:23:59.841305 #train# step 5444, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:01.441562 #train# step 5445, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:03.048000 #train# step 5446, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:04.603139 #train# step 5447, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:06.188180 #train# step 5448, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:07.766536 #train# step 5449, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:09.363737 #train# step 5450, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:10.953890 #train# step 5451, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:12.525107 #train# step 5452, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:14.109118 #train# step 5453, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:15.675952 #train# step 5454, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:17.254083 #train# step 5455, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:18.838371 #train# step 5456, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:20.442423 #train# step 5457, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:22.007800 #train# step 5458, loss = 0.9245, cross_entropy loss = 0.9245, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:23.614222 #train# step 5459, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:25.205015 #train# step 5460, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:26.782400 #train# step 5461, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:28.349073 #train# step 5462, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:29.950253 #train# step 5463, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:31.510273 #train# step 5464, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:33.101300 #train# step 5465, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:34.680323 #train# step 5466, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:36.271460 #train# step 5467, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:37.850298 #train# step 5468, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:39.439582 #train# step 5469, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:40.989208 #train# step 5470, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:42.620634 #train# step 5471, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:44.201659 #train# step 5472, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:45.757844 #train# step 5473, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:47.344648 #train# step 5474, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:48.943044 #train# step 5475, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:50.536620 #train# step 5476, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:52.139831 #train# step 5477, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:53.711523 #train# step 5478, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:55.342606 #train# step 5479, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:56.916390 #train# step 5480, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:24:58.508579 #train# step 5481, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:00.062063 #train# step 5482, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:01.640319 #train# step 5483, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:03.223487 #train# step 5484, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:04.822371 #train# step 5485, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:06.401240 #train# step 5486, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:08.012771 #train# step 5487, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:09.599060 #train# step 5488, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:11.165686 #train# step 5489, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:12.758946 #train# step 5490, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:14.388633 #train# step 5491, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:16.010054 #train# step 5492, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:17.597379 #train# step 5493, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:19.181060 #train# step 5494, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:20.765169 #train# step 5495, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:22.369006 #train# step 5496, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:23.926395 #train# step 5497, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:25.528596 #train# step 5498, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:27.091730 #train# step 5499, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:28.642117 #train# step 5500, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:30.218015 #train# step 5501, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:31.826976 #train# step 5502, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:33.432263 #train# step 5503, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:35.010107 #train# step 5504, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:36.608659 #train# step 5505, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:38.175527 #train# step 5506, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:39.771524 #train# step 5507, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:41.358978 #train# step 5508, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:42.960486 #train# step 5509, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:44.516429 #train# step 5510, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:46.115376 #train# step 5511, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:47.729112 #train# step 5512, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:49.360322 #train# step 5513, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:50.952597 #train# step 5514, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:52.511654 #train# step 5515, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:54.142753 #train# step 5516, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:55.721935 #train# step 5517, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:57.309839 #train# step 5518, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:25:58.888611 #train# step 5519, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:00.489897 #train# step 5520, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:02.049666 #train# step 5521, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:03.615682 #train# step 5522, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:05.198426 #train# step 5523, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:06.784274 #train# step 5524, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:08.403577 #train# step 5525, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:09.957529 #train# step 5526, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:11.534439 #train# step 5527, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:13.124878 #train# step 5528, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:14.720689 #train# step 5529, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:16.320861 #train# step 5530, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:17.884213 #train# step 5531, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:19.461977 #train# step 5532, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:21.028922 #train# step 5533, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:22.619677 #train# step 5534, loss = 0.9270, cross_entropy loss = 0.9270, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:24.212185 #train# step 5535, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:25.808902 #train# step 5536, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:27.401525 #train# step 5537, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:28.964556 #train# step 5538, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:30.548366 #train# step 5539, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:32.134418 #train# step 5540, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:33.734164 #train# step 5541, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:35.316109 #train# step 5542, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:36.904737 #train# step 5543, loss = 0.9251, cross_entropy loss = 0.9251, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:38.504123 #train# step 5544, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:40.112094 #train# step 5545, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:41.710986 #train# step 5546, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:43.295211 #train# step 5547, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:44.877584 #train# step 5548, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:46.456830 #train# step 5549, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:48.064511 #train# step 5550, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:49.659679 #train# step 5551, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:51.221829 #train# step 5552, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:52.832499 #train# step 5553, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:54.447261 #train# step 5554, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:56.033346 #train# step 5555, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:57.599526 #train# step 5556, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:26:59.181022 #train# step 5557, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:00.758827 #train# step 5558, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:02.358289 #train# step 5559, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:03.897530 #train# step 5560, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:05.454183 #train# step 5561, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:07.048130 #train# step 5562, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:08.630971 #train# step 5563, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:10.215271 #train# step 5564, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:11.779169 #train# step 5565, loss = 0.9296, cross_entropy loss = 0.9296, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:13.413532 #train# step 5566, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:15.009161 #train# step 5567, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:16.617496 #train# step 5568, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:18.170100 #train# step 5569, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:19.757415 #train# step 5570, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:21.325874 #train# step 5571, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:22.914150 #train# step 5572, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:24.502809 #train# step 5573, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:26.119117 #train# step 5574, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:27.708977 #train# step 5575, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:29.268398 #train# step 5576, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:30.875704 #train# step 5577, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:32.454614 #train# step 5578, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:34.047391 #train# step 5579, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:35.637508 #train# step 5580, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:37.210153 #train# step 5581, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:38.787978 #train# step 5582, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:40.365855 #train# step 5583, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:41.920123 #train# step 5584, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:43.506723 #train# step 5585, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:45.090277 #train# step 5586, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:46.672638 #train# step 5587, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:48.251580 #train# step 5588, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:49.840731 #train# step 5589, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:51.435335 #train# step 5590, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:53.031771 #train# step 5591, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:54.607370 #train# step 5592, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:56.181887 #train# step 5593, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:57.768771 #train# step 5594, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:27:59.362316 #train# step 5595, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:00.915089 #train# step 5596, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:02.511352 #train# step 5597, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:04.119368 #train# step 5598, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:05.701666 #train# step 5599, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:07.266679 #train# step 5600, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:08.857686 #train# step 5601, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:10.421560 #train# step 5602, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:12.019461 #train# step 5603, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:13.620196 #train# step 5604, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:15.225052 #train# step 5605, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:16.833902 #train# step 5606, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:18.447468 #train# step 5607, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:20.041269 #train# step 5608, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:21.626025 #train# step 5609, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:23.221691 #train# step 5610, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:24.777204 #train# step 5611, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:26.334355 #train# step 5612, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:27.921201 #train# step 5613, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:29.465913 #train# step 5614, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:31.055827 #train# step 5615, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:32.614332 #train# step 5616, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:34.221970 #train# step 5617, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:35.773977 #train# step 5618, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:37.373082 #train# step 5619, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:38.952231 #train# step 5620, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:40.546798 #train# step 5621, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:42.120711 #train# step 5622, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:43.705547 #train# step 5623, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:45.301612 #train# step 5624, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:46.915310 #train# step 5625, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:48.509407 #train# step 5626, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:50.060859 #train# step 5627, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:51.668377 #train# step 5628, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:53.261537 #train# step 5629, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:54.876839 #train# step 5630, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:56.462484 #train# step 5631, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:58.049524 #train# step 5632, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:28:59.637567 #train# step 5633, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:01.213239 #train# step 5634, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:02.794430 #train# step 5635, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:04.351053 #train# step 5636, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:05.951253 #train# step 5637, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:07.548095 #train# step 5638, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:09.144430 #train# step 5639, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:10.705809 #train# step 5640, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:12.272503 #train# step 5641, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:13.852426 #train# step 5642, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:15.427733 #train# step 5643, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:17.008375 #train# step 5644, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:18.614591 #train# step 5645, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:20.205530 #train# step 5646, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:21.792531 #train# step 5647, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:23.392618 #train# step 5648, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:24.963239 #train# step 5649, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:26.537317 #train# step 5650, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:28.105383 #train# step 5651, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:29.692338 #train# step 5652, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:31.294632 #train# step 5653, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:32.887677 #train# step 5654, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:34.459767 #train# step 5655, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:36.022630 #train# step 5656, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:37.631544 #train# step 5657, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:39.208155 #train# step 5658, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:40.770697 #train# step 5659, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:42.357872 #train# step 5660, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:43.914183 #train# step 5661, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:45.528161 #train# step 5662, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:47.117484 #train# step 5663, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:48.688446 #train# step 5664, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:50.291184 #train# step 5665, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:51.853477 #train# step 5666, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:53.425471 #train# step 5667, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:55.018512 #train# step 5668, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:56.596940 #train# step 5669, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:58.187974 #train# step 5670, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:29:59.791324 #train# step 5671, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:01.377736 #train# step 5672, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:02.963622 #train# step 5673, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:04.565542 #train# step 5674, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:06.132983 #train# step 5675, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:07.712802 #train# step 5676, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:09.286541 #train# step 5677, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:10.891525 #train# step 5678, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:12.468449 #train# step 5679, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:14.079876 #train# step 5680, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:15.677830 #train# step 5681, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:17.281476 #train# step 5682, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:18.852915 #train# step 5683, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:20.469726 #train# step 5684, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:22.064770 #train# step 5685, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:23.649356 #train# step 5686, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:25.230658 #train# step 5687, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:26.841556 #train# step 5688, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:28.398077 #train# step 5689, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:30.007177 #train# step 5690, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:31.602669 #train# step 5691, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:33.195671 #train# step 5692, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:34.763254 #train# step 5693, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:36.370538 #train# step 5694, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:37.928007 #train# step 5695, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:39.499764 #train# step 5696, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:41.068137 #train# step 5697, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:42.655665 #train# step 5698, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:44.249709 #train# step 5699, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:45.824544 #train# step 5700, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:47.400716 #train# step 5701, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:48.984601 #train# step 5702, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:50.586433 #train# step 5703, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:52.178290 #train# step 5704, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:53.770488 #train# step 5705, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:55.372706 #train# step 5706, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:56.961032 #train# step 5707, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:30:58.566417 #train# step 5708, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:00.125238 #train# step 5709, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:01.732877 #train# step 5710, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:03.299580 #train# step 5711, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:04.879649 #train# step 5712, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:06.471509 #train# step 5713, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:08.077907 #train# step 5714, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:09.628012 #train# step 5715, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:11.197362 #train# step 5716, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:12.750363 #train# step 5717, loss = 0.9192, cross_entropy loss = 0.9192, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:14.337139 #train# step 5718, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:15.939045 #train# step 5719, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:17.530334 #train# step 5720, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:19.118923 #train# step 5721, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:20.680584 #train# step 5722, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:22.307767 #train# step 5723, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:23.923311 #train# step 5724, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:25.518170 #train# step 5725, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:27.127671 #train# step 5726, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:28.727214 #train# step 5727, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:30.296087 #train# step 5728, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:31.897093 #train# step 5729, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:33.478319 #train# step 5730, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:35.065961 #train# step 5731, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:36.604397 #train# step 5732, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:38.168064 #train# step 5733, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:39.775851 #train# step 5734, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:41.380236 #train# step 5735, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:42.952230 #train# step 5736, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:44.514669 #train# step 5737, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:46.113429 #train# step 5738, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:47.703535 #train# step 5739, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:49.287264 #train# step 5740, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:50.890727 #train# step 5741, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:52.469629 #train# step 5742, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:54.056770 #train# step 5743, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:55.649173 #train# step 5744, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:57.215240 #train# step 5745, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:31:58.809854 #train# step 5746, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:00.403037 #train# step 5747, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:01.975591 #train# step 5748, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:03.569762 #train# step 5749, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:05.154153 #train# step 5750, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:06.778753 #train# step 5751, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:08.366561 #train# step 5752, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:09.966265 #train# step 5753, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:11.536927 #train# step 5754, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:13.127297 #train# step 5755, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:14.703673 #train# step 5756, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:16.303050 #train# step 5757, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:17.884069 #train# step 5758, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:19.429405 #train# step 5759, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:20.962929 #train# step 5760, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:22.554325 #train# step 5761, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:24.159813 #train# step 5762, loss = 0.9218, cross_entropy loss = 0.9218, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:25.738843 #train# step 5763, loss = 0.9221, cross_entropy loss = 0.9221, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:27.343176 #train# step 5764, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:28.921943 #train# step 5765, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:30.499959 #train# step 5766, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:32.105089 #train# step 5767, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:33.687134 #train# step 5768, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:35.268001 #train# step 5769, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:36.876567 #train# step 5770, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:38.463081 #train# step 5771, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:40.050350 #train# step 5772, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:41.636475 #train# step 5773, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:43.224105 #train# step 5774, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:44.833405 #train# step 5775, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:46.400535 #train# step 5776, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:47.976995 #train# step 5777, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:49.564432 #train# step 5778, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:51.123786 #train# step 5779, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:52.710682 #train# step 5780, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:54.289907 #train# step 5781, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:55.867177 #train# step 5782, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:57.444534 #train# step 5783, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:32:59.022378 #train# step 5784, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:00.623550 #train# step 5785, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:02.230287 #train# step 5786, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:03.826376 #train# step 5787, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:05.406099 #train# step 5788, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:07.021119 #train# step 5789, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:08.621446 #train# step 5790, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:10.250722 #train# step 5791, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:11.838695 #train# step 5792, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:13.438079 #train# step 5793, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:15.057360 #train# step 5794, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:16.640147 #train# step 5795, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:18.207096 #train# step 5796, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:19.770291 #train# step 5797, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:21.326634 #train# step 5798, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:22.921038 #train# step 5799, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:24.507475 #train# step 5800, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:26.088472 #train# step 5801, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:27.663164 #train# step 5802, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:29.274300 #train# step 5803, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:30.833775 #train# step 5804, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:32.396119 #train# step 5805, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:33.975418 #train# step 5806, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:35.548850 #train# step 5807, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:37.135729 #train# step 5808, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:38.722838 #train# step 5809, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:40.293076 #train# step 5810, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:41.907266 #train# step 5811, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:43.487907 #train# step 5812, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:45.054415 #train# step 5813, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:46.618631 #train# step 5814, loss = 0.9210, cross_entropy loss = 0.9210, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:48.193544 #train# step 5815, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:49.807238 #train# step 5816, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:51.410110 #train# step 5817, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:53.006273 #train# step 5818, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:54.614628 #train# step 5819, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:56.177022 #train# step 5820, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:57.778880 #train# step 5821, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:33:59.320105 #train# step 5822, loss = 0.9265, cross_entropy loss = 0.9265, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:00.920973 #train# step 5823, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:02.488805 #train# step 5824, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:04.094743 #train# step 5825, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:05.641973 #train# step 5826, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:07.248686 #train# step 5827, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:08.841784 #train# step 5828, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:10.430463 #train# step 5829, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:12.025692 #train# step 5830, loss = 0.9208, cross_entropy loss = 0.9208, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:13.594625 #train# step 5831, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:15.176139 #train# step 5832, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:16.750386 #train# step 5833, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:18.311871 #train# step 5834, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:19.893446 #train# step 5835, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:21.490657 #train# step 5836, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:23.062362 #train# step 5837, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:24.634844 #train# step 5838, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:26.219676 #train# step 5839, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:27.793724 #train# step 5840, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:29.367380 #train# step 5841, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:30.929841 #train# step 5842, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:32.508846 #train# step 5843, loss = 0.9246, cross_entropy loss = 0.9246, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:34.071522 #train# step 5844, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:35.663659 #train# step 5845, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:37.258077 #train# step 5846, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:38.843850 #train# step 5847, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:40.444557 #train# step 5848, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:42.016213 #train# step 5849, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:43.613719 #train# step 5850, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:45.179191 #train# step 5851, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:46.777740 #train# step 5852, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:48.419724 #train# step 5853, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:50.002209 #train# step 5854, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:51.590197 #train# step 5855, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:53.154950 #train# step 5856, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:54.761114 #train# step 5857, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:56.365909 #train# step 5858, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:57.949637 #train# step 5859, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:34:59.546743 #train# step 5860, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:01.123403 #train# step 5861, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:02.722617 #train# step 5862, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:04.328866 #train# step 5863, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:05.907947 #train# step 5864, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:07.486760 #train# step 5865, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:09.077512 #train# step 5866, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:10.648570 #train# step 5867, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:12.218585 #train# step 5868, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:13.807559 #train# step 5869, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:15.399120 #train# step 5870, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:16.976215 #train# step 5871, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:18.564317 #train# step 5872, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:20.183668 #train# step 5873, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:21.735996 #train# step 5874, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:23.317784 #train# step 5875, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:24.889295 #train# step 5876, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:26.482713 #train# step 5877, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:28.081807 #train# step 5878, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:29.666447 #train# step 5879, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:31.251568 #train# step 5880, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:32.815551 #train# step 5881, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:34.401711 #train# step 5882, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:35.998542 #train# step 5883, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:37.549211 #train# step 5884, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:39.149550 #train# step 5885, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:40.733826 #train# step 5886, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:42.315823 #train# step 5887, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:43.907577 #train# step 5888, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:45.479293 #train# step 5889, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:47.103406 #train# step 5890, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:48.710093 #train# step 5891, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:50.292699 #train# step 5892, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:51.841745 #train# step 5893, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:53.432543 #train# step 5894, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:55.008142 #train# step 5895, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:56.590253 #train# step 5896, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:58.155184 #train# step 5897, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:35:59.719319 #train# step 5898, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:01.292636 #train# step 5899, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:02.883107 #train# step 5900, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:04.460674 #train# step 5901, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:06.042432 #train# step 5902, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:07.643581 #train# step 5903, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:09.248603 #train# step 5904, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:10.859656 #train# step 5905, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:12.444834 #train# step 5906, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:14.024639 #train# step 5907, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:15.611129 #train# step 5908, loss = 0.9235, cross_entropy loss = 0.9235, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:17.196800 #train# step 5909, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:18.784046 #train# step 5910, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:20.368069 #train# step 5911, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:21.967230 #train# step 5912, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:23.563464 #train# step 5913, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:25.152344 #train# step 5914, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:26.763157 #train# step 5915, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:28.331850 #train# step 5916, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:29.949173 #train# step 5917, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:31.534726 #train# step 5918, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:33.119059 #train# step 5919, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:34.700796 #train# step 5920, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:36.301353 #train# step 5921, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:37.856288 #train# step 5922, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:39.445178 #train# step 5923, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:41.033337 #train# step 5924, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:42.619528 #train# step 5925, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:44.222391 #train# step 5926, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:45.808415 #train# step 5927, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:47.422364 #train# step 5928, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:49.007186 #train# step 5929, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:50.592639 #train# step 5930, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:52.133399 #train# step 5931, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:53.743065 #train# step 5932, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:55.312512 #train# step 5933, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:56.921765 #train# step 5934, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:36:58.493985 #train# step 5935, loss = 0.9325, cross_entropy loss = 0.9325, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:00.050835 #train# step 5936, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:01.657383 #train# step 5937, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:03.248140 #train# step 5938, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:04.813390 #train# step 5939, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:06.401306 #train# step 5940, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:07.985990 #train# step 5941, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:09.556490 #train# step 5942, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:11.104190 #train# step 5943, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:12.702398 #train# step 5944, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:14.294614 #train# step 5945, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:15.879791 #train# step 5946, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:17.477846 #train# step 5947, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:19.062099 #train# step 5948, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:20.670250 #train# step 5949, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:22.253285 #train# step 5950, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:23.850550 #train# step 5951, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:25.408720 #train# step 5952, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:27.006340 #train# step 5953, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:28.570774 #train# step 5954, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:30.160462 #train# step 5955, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:31.723705 #train# step 5956, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:33.306120 #train# step 5957, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:34.873674 #train# step 5958, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:36.451100 #train# step 5959, loss = 0.9230, cross_entropy loss = 0.9230, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:38.024207 #train# step 5960, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:39.626045 #train# step 5961, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:41.223348 #train# step 5962, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:42.822448 #train# step 5963, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:44.379342 #train# step 5964, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:46.003057 #train# step 5965, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:47.599626 #train# step 5966, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:49.157609 #train# step 5967, loss = 0.9294, cross_entropy loss = 0.9294, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:50.744698 #train# step 5968, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:52.333319 #train# step 5969, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:53.932790 #train# step 5970, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:55.505654 #train# step 5971, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:57.090442 #train# step 5972, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:37:58.688313 #train# step 5973, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:00.274959 #train# step 5974, loss = 0.9204, cross_entropy loss = 0.9204, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:01.861357 #train# step 5975, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:03.438008 #train# step 5976, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:04.995504 #train# step 5977, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:06.575823 #train# step 5978, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:08.140767 #train# step 5979, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:09.738354 #train# step 5980, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:11.295264 #train# step 5981, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:12.895047 #train# step 5982, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:14.512539 #train# step 5983, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:16.119042 #train# step 5984, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:17.692651 #train# step 5985, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:19.273630 #train# step 5986, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:20.859992 #train# step 5987, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:22.464349 #train# step 5988, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:24.053663 #train# step 5989, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:25.626513 #train# step 5990, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:27.239748 #train# step 5991, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:28.796421 #train# step 5992, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:30.364071 #train# step 5993, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:31.978979 #train# step 5994, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:33.557598 #train# step 5995, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:35.150769 #train# step 5996, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:36.743365 #train# step 5997, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:38.341355 #train# step 5998, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:39.944697 #train# step 5999, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:41.558683 #train# step 6000, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:43.132787 #train# step 6001, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:44.720077 #train# step 6002, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:46.307807 #train# step 6003, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:47.871673 #train# step 6004, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:49.427639 #train# step 6005, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:51.016014 #train# step 6006, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:52.584852 #train# step 6007, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:54.155430 #train# step 6008, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:55.727402 #train# step 6009, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:57.314769 #train# step 6010, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:38:58.897035 #train# step 6011, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:00.460322 #train# step 6012, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:02.032448 #train# step 6013, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:03.618774 #train# step 6014, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:05.179737 #train# step 6015, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:06.765857 #train# step 6016, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:08.362877 #train# step 6017, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:09.931594 #train# step 6018, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:11.538840 #train# step 6019, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:13.136435 #train# step 6020, loss = 0.9258, cross_entropy loss = 0.9258, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:14.699610 #train# step 6021, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:16.284980 #train# step 6022, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:17.888085 #train# step 6023, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:19.483898 #train# step 6024, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:21.071062 #train# step 6025, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:22.625986 #train# step 6026, loss = 0.9217, cross_entropy loss = 0.9217, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:24.204037 #train# step 6027, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:25.812666 #train# step 6028, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:27.404426 #train# step 6029, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:29.001295 #train# step 6030, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:30.603587 #train# step 6031, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:32.214831 #train# step 6032, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:33.754051 #train# step 6033, loss = 0.9248, cross_entropy loss = 0.9248, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:35.349390 #train# step 6034, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:36.918200 #train# step 6035, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:38.501615 #train# step 6036, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:40.094647 #train# step 6037, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:41.646235 #train# step 6038, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:43.247140 #train# step 6039, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:44.845802 #train# step 6040, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:46.426848 #train# step 6041, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:48.002455 #train# step 6042, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:49.598233 #train# step 6043, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:51.175581 #train# step 6044, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:52.756934 #train# step 6045, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:54.343144 #train# step 6046, loss = 0.9225, cross_entropy loss = 0.9225, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:55.938753 #train# step 6047, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:57.516911 #train# step 6048, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:39:59.107207 #train# step 6049, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:00.719263 #train# step 6050, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:02.293520 #train# step 6051, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:03.859939 #train# step 6052, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:05.419855 #train# step 6053, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:07.018771 #train# step 6054, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:08.577625 #train# step 6055, loss = 0.9273, cross_entropy loss = 0.9273, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:10.168920 #train# step 6056, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:11.736059 #train# step 6057, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:13.320322 #train# step 6058, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:14.918137 #train# step 6059, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:16.501458 #train# step 6060, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:18.101455 #train# step 6061, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:19.701529 #train# step 6062, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:21.305705 #train# step 6063, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:22.907994 #train# step 6064, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:24.484705 #train# step 6065, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:26.083239 #train# step 6066, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:27.670826 #train# step 6067, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:29.227661 #train# step 6068, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:30.797216 #train# step 6069, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:32.391316 #train# step 6070, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:33.966113 #train# step 6071, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:35.523757 #train# step 6072, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:37.135135 #train# step 6073, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:38.710537 #train# step 6074, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:40.275480 #train# step 6075, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:41.885864 #train# step 6076, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:43.437942 #train# step 6077, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:45.051702 #train# step 6078, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:46.647636 #train# step 6079, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:48.239257 #train# step 6080, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:49.831955 #train# step 6081, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:51.456922 #train# step 6082, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:53.052312 #train# step 6083, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:54.631380 #train# step 6084, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:56.217104 #train# step 6085, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:57.790894 #train# step 6086, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:40:59.391162 #train# step 6087, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:00.969388 #train# step 6088, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:02.533817 #train# step 6089, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:04.096516 #train# step 6090, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:05.672468 #train# step 6091, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:07.250423 #train# step 6092, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:08.881972 #train# step 6093, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:10.442614 #train# step 6094, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:12.052936 #train# step 6095, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:13.660114 #train# step 6096, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:15.245520 #train# step 6097, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:16.823765 #train# step 6098, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:18.419854 #train# step 6099, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:19.991394 #train# step 6100, loss = 0.9263, cross_entropy loss = 0.9263, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:21.574309 #train# step 6101, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:23.180493 #train# step 6102, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:24.739886 #train# step 6103, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:26.291638 #train# step 6104, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:27.849217 #train# step 6105, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:29.415325 #train# step 6106, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:30.976326 #train# step 6107, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:32.586980 #train# step 6108, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:34.168541 #train# step 6109, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:35.726199 #train# step 6110, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:37.322073 #train# step 6111, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:38.901128 #train# step 6112, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:40.450897 #train# step 6113, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:42.013148 #train# step 6114, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:43.554530 #train# step 6115, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:45.179606 #train# step 6116, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:46.785628 #train# step 6117, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:48.366155 #train# step 6118, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:49.951560 #train# step 6119, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:51.543401 #train# step 6120, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:53.139190 #train# step 6121, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:54.723120 #train# step 6122, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:56.316681 #train# step 6123, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:57.932517 #train# step 6124, loss = 0.9215, cross_entropy loss = 0.9215, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:41:59.520422 #train# step 6125, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:01.089162 #train# step 6126, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:02.665856 #train# step 6127, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:04.226225 #train# step 6128, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:05.792474 #train# step 6129, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:07.355679 #train# step 6130, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:08.905469 #train# step 6131, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:10.504362 #train# step 6132, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:12.081897 #train# step 6133, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:13.682247 #train# step 6134, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:15.250561 #train# step 6135, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:16.850803 #train# step 6136, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:18.411844 #train# step 6137, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:19.976622 #train# step 6138, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:21.573553 #train# step 6139, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:23.162310 #train# step 6140, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:24.756237 #train# step 6141, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:26.346437 #train# step 6142, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:27.935379 #train# step 6143, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:29.523309 #train# step 6144, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:31.109785 #train# step 6145, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:32.698259 #train# step 6146, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:34.297310 #train# step 6147, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:35.872603 #train# step 6148, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:37.482224 #train# step 6149, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:39.044734 #train# step 6150, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:40.651254 #train# step 6151, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:42.230129 #train# step 6152, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:43.853078 #train# step 6153, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:45.461895 #train# step 6154, loss = 0.9288, cross_entropy loss = 0.9288, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:47.045653 #train# step 6155, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:48.635896 #train# step 6156, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:50.228767 #train# step 6157, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:51.826928 #train# step 6158, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:53.444255 #train# step 6159, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:55.038434 #train# step 6160, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:56.614822 #train# step 6161, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:58.212024 #train# step 6162, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:42:59.781269 #train# step 6163, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:01.364301 #train# step 6164, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:02.953034 #train# step 6165, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:04.533754 #train# step 6166, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:06.121435 #train# step 6167, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:07.710502 #train# step 6168, loss = 0.8887, cross_entropy loss = 0.8887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:09.317022 #train# step 6169, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:10.896882 #train# step 6170, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:12.463801 #train# step 6171, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:14.045214 #train# step 6172, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:15.650974 #train# step 6173, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:17.234368 #train# step 6174, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:18.833125 #train# step 6175, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:20.410482 #train# step 6176, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:21.982120 #train# step 6177, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:23.555128 #train# step 6178, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:25.101705 #train# step 6179, loss = 0.9250, cross_entropy loss = 0.9250, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:26.676280 #train# step 6180, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:28.233652 #train# step 6181, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:29.824615 #train# step 6182, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:31.398748 #train# step 6183, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:32.962631 #train# step 6184, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:34.545030 #train# step 6185, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:36.149737 #train# step 6186, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:37.712046 #train# step 6187, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:39.294119 #train# step 6188, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:40.902649 #train# step 6189, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:42.508238 #train# step 6190, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:44.102660 #train# step 6191, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:45.659536 #train# step 6192, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:47.238992 #train# step 6193, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:48.810388 #train# step 6194, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:50.418258 #train# step 6195, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:51.996380 #train# step 6196, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:53.565414 #train# step 6197, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:55.148737 #train# step 6198, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:56.719189 #train# step 6199, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:58.305606 #train# step 6200, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:43:59.895010 #train# step 6201, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:01.501546 #train# step 6202, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:03.080986 #train# step 6203, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:04.727103 #train# step 6204, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:06.315435 #train# step 6205, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:07.868109 #train# step 6206, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:09.443620 #train# step 6207, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:11.034725 #train# step 6208, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:12.606952 #train# step 6209, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:14.166560 #train# step 6210, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:15.751117 #train# step 6211, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:17.321875 #train# step 6212, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:18.868143 #train# step 6213, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:20.457136 #train# step 6214, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:22.023261 #train# step 6215, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:23.610914 #train# step 6216, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:25.221690 #train# step 6217, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:26.814681 #train# step 6218, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:28.437677 #train# step 6219, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:30.015426 #train# step 6220, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:31.563307 #train# step 6221, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:33.149041 #train# step 6222, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:34.727312 #train# step 6223, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:36.309830 #train# step 6224, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:37.882922 #train# step 6225, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:39.467137 #train# step 6226, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:41.055503 #train# step 6227, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:42.640538 #train# step 6228, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:44.220604 #train# step 6229, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:45.806019 #train# step 6230, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:47.419459 #train# step 6231, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:49.006756 #train# step 6232, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:50.590095 #train# step 6233, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:52.199525 #train# step 6234, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:53.761423 #train# step 6235, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:55.372549 #train# step 6236, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:56.982437 #train# step 6237, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:44:58.566188 #train# step 6238, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:00.131994 #train# step 6239, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:01.717157 #train# step 6240, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:03.295301 #train# step 6241, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:04.879255 #train# step 6242, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:06.471295 #train# step 6243, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:08.052077 #train# step 6244, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:09.660717 #train# step 6245, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:11.248310 #train# step 6246, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:12.845262 #train# step 6247, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:14.420836 #train# step 6248, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:16.003241 #train# step 6249, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:17.604603 #train# step 6250, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:19.196316 #train# step 6251, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:20.785407 #train# step 6252, loss = 0.9287, cross_entropy loss = 0.9287, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:22.341153 #train# step 6253, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:23.959194 #train# step 6254, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:25.555650 #train# step 6255, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:27.102495 #train# step 6256, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:28.667756 #train# step 6257, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:30.262925 #train# step 6258, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:31.833758 #train# step 6259, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:33.397859 #train# step 6260, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:34.979424 #train# step 6261, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:36.569931 #train# step 6262, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:38.160259 #train# step 6263, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:39.713292 #train# step 6264, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:41.317455 #train# step 6265, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:42.904252 #train# step 6266, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:44.495175 #train# step 6267, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:46.084334 #train# step 6268, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:47.661433 #train# step 6269, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:49.255495 #train# step 6270, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:50.883230 #train# step 6271, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:52.468141 #train# step 6272, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:54.048793 #train# step 6273, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:55.615116 #train# step 6274, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:57.205441 #train# step 6275, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:45:58.810597 #train# step 6276, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:00.371690 #train# step 6277, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:01.945665 #train# step 6278, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:03.548994 #train# step 6279, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:05.116658 #train# step 6280, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:06.681738 #train# step 6281, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:08.298862 #train# step 6282, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:09.872529 #train# step 6283, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:11.440085 #train# step 6284, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:13.035766 #train# step 6285, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:14.610284 #train# step 6286, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:16.177844 #train# step 6287, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:17.789599 #train# step 6288, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:19.402017 #train# step 6289, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:21.002412 #train# step 6290, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:22.632517 #train# step 6291, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:24.183776 #train# step 6292, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:25.763390 #train# step 6293, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:27.345107 #train# step 6294, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:28.933600 #train# step 6295, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:30.544841 #train# step 6296, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:32.152217 #train# step 6297, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:33.732907 #train# step 6298, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:35.299702 #train# step 6299, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:36.875846 #train# step 6300, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:38.448129 #train# step 6301, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:40.008360 #train# step 6302, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:41.590977 #train# step 6303, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:43.191420 #train# step 6304, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:44.747934 #train# step 6305, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:46.335304 #train# step 6306, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:47.917204 #train# step 6307, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:49.518256 #train# step 6308, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:51.099056 #train# step 6309, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:52.707820 #train# step 6310, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:54.278163 #train# step 6311, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:55.859380 #train# step 6312, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:57.470248 #train# step 6313, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:46:59.071682 #train# step 6314, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:00.641775 #train# step 6315, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:02.234046 #train# step 6316, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:03.772913 #train# step 6317, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:05.369754 #train# step 6318, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:06.981706 #train# step 6319, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:08.545303 #train# step 6320, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:10.160891 #train# step 6321, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:11.716853 #train# step 6322, loss = 0.9253, cross_entropy loss = 0.9253, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:13.327042 #train# step 6323, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:14.920287 #train# step 6324, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:16.529544 #train# step 6325, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:18.092412 #train# step 6326, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:19.646565 #train# step 6327, loss = 0.9231, cross_entropy loss = 0.9231, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:21.208603 #train# step 6328, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:22.813938 #train# step 6329, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:24.413818 #train# step 6330, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:25.990646 #train# step 6331, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:27.562785 #train# step 6332, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:29.148722 #train# step 6333, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:30.712599 #train# step 6334, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:32.305924 #train# step 6335, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:33.914070 #train# step 6336, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:35.550854 #train# step 6337, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:37.141172 #train# step 6338, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:38.748468 #train# step 6339, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:40.308317 #train# step 6340, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:41.881003 #train# step 6341, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:43.458941 #train# step 6342, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:45.066087 #train# step 6343, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:46.675994 #train# step 6344, loss = 0.8902, cross_entropy loss = 0.8902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:48.237323 #train# step 6345, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:49.831269 #train# step 6346, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:51.438011 #train# step 6347, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:53.031217 #train# step 6348, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:54.639488 #train# step 6349, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:56.201346 #train# step 6350, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:57.806083 #train# step 6351, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:47:59.394710 #train# step 6352, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:00.968344 #train# step 6353, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:02.581779 #train# step 6354, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:04.147438 #train# step 6355, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:05.728620 #train# step 6356, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:07.296509 #train# step 6357, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:08.862757 #train# step 6358, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:10.450200 #train# step 6359, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:12.018240 #train# step 6360, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:13.597660 #train# step 6361, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:15.196532 #train# step 6362, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:16.752736 #train# step 6363, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:18.324699 #train# step 6364, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:19.917094 #train# step 6365, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:21.515352 #train# step 6366, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:23.107547 #train# step 6367, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:24.709506 #train# step 6368, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:26.309146 #train# step 6369, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:27.884743 #train# step 6370, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:29.498927 #train# step 6371, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:31.096542 #train# step 6372, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:32.674145 #train# step 6373, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:34.295344 #train# step 6374, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:35.873159 #train# step 6375, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:37.483324 #train# step 6376, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:39.067749 #train# step 6377, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:40.680566 #train# step 6378, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:42.261877 #train# step 6379, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:43.844097 #train# step 6380, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:45.418818 #train# step 6381, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:47.031378 #train# step 6382, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:48.594450 #train# step 6383, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:50.152604 #train# step 6384, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:51.731532 #train# step 6385, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:53.350925 #train# step 6386, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:54.926177 #train# step 6387, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:56.507027 #train# step 6388, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:58.082648 #train# step 6389, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:48:59.673529 #train# step 6390, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:01.232359 #train# step 6391, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:02.804783 #train# step 6392, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:04.403840 #train# step 6393, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:06.004625 #train# step 6394, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:07.585574 #train# step 6395, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:09.167850 #train# step 6396, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:10.772043 #train# step 6397, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:12.364609 #train# step 6398, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:13.950456 #train# step 6399, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:15.558849 #train# step 6400, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:17.138860 #train# step 6401, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:18.738678 #train# step 6402, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:20.360702 #train# step 6403, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:21.953771 #train# step 6404, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:23.518163 #train# step 6405, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:25.091381 #train# step 6406, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:26.665018 #train# step 6407, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:28.255505 #train# step 6408, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:29.825127 #train# step 6409, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:31.411277 #train# step 6410, loss = 0.9298, cross_entropy loss = 0.9298, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:32.971004 #train# step 6411, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:34.552106 #train# step 6412, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:36.137781 #train# step 6413, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:37.723668 #train# step 6414, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:39.283753 #train# step 6415, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:40.836919 #train# step 6416, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:42.437446 #train# step 6417, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:44.023343 #train# step 6418, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:45.616055 #train# step 6419, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:47.202770 #train# step 6420, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:48.774348 #train# step 6421, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:50.382268 #train# step 6422, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:51.929898 #train# step 6423, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:53.539347 #train# step 6424, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:55.124400 #train# step 6425, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:56.720614 #train# step 6426, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:58.308822 #train# step 6427, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:49:59.884726 #train# step 6428, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:01.506968 #train# step 6429, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:03.113203 #train# step 6430, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:04.704203 #train# step 6431, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:06.266946 #train# step 6432, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:07.840687 #train# step 6433, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:09.404298 #train# step 6434, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:11.011342 #train# step 6435, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:12.589352 #train# step 6436, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:14.149408 #train# step 6437, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:15.739144 #train# step 6438, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:17.331114 #train# step 6439, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:18.932240 #train# step 6440, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:20.501105 #train# step 6441, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:22.130920 #train# step 6442, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:23.684564 #train# step 6443, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:25.287230 #train# step 6444, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:26.869336 #train# step 6445, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:28.480067 #train# step 6446, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:30.041679 #train# step 6447, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:31.617652 #train# step 6448, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:33.175241 #train# step 6449, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:34.730380 #train# step 6450, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:36.321235 #train# step 6451, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:37.894982 #train# step 6452, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:39.486646 #train# step 6453, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:41.082518 #train# step 6454, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:42.667594 #train# step 6455, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:44.286733 #train# step 6456, loss = 0.8869, cross_entropy loss = 0.8869, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:45.875556 #train# step 6457, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:47.467936 #train# step 6458, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:49.043854 #train# step 6459, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:50.622746 #train# step 6460, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:52.184860 #train# step 6461, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:53.766435 #train# step 6462, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:55.359615 #train# step 6463, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:56.963864 #train# step 6464, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:50:58.526307 #train# step 6465, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:00.080738 #train# step 6466, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:01.664706 #train# step 6467, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:03.239461 #train# step 6468, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:04.834884 #train# step 6469, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:06.391283 #train# step 6470, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:07.960960 #train# step 6471, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:09.542930 #train# step 6472, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:11.162360 #train# step 6473, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:12.729011 #train# step 6474, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:14.335119 #train# step 6475, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:15.966558 #train# step 6476, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:17.583110 #train# step 6477, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:19.138961 #train# step 6478, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:20.725013 #train# step 6479, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:22.319379 #train# step 6480, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:23.865404 #train# step 6481, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:25.477746 #train# step 6482, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:27.061934 #train# step 6483, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:28.652242 #train# step 6484, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:30.220224 #train# step 6485, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:31.779057 #train# step 6486, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:33.379677 #train# step 6487, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:34.958816 #train# step 6488, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:36.576063 #train# step 6489, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:38.148861 #train# step 6490, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:39.726794 #train# step 6491, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:41.326278 #train# step 6492, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:42.909754 #train# step 6493, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:44.527711 #train# step 6494, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:46.108279 #train# step 6495, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:47.673579 #train# step 6496, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:49.268647 #train# step 6497, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:50.861710 #train# step 6498, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:52.452363 #train# step 6499, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:54.074103 #train# step 6500, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:55.645406 #train# step 6501, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:57.249976 #train# step 6502, loss = 0.9209, cross_entropy loss = 0.9209, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:51:58.859752 #train# step 6503, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:00.474458 #train# step 6504, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:02.071409 #train# step 6505, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:03.658741 #train# step 6506, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:05.239531 #train# step 6507, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:06.835543 #train# step 6508, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:08.395656 #train# step 6509, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:09.985606 #train# step 6510, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:11.573135 #train# step 6511, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:13.137509 #train# step 6512, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:14.709490 #train# step 6513, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:16.289788 #train# step 6514, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:17.860138 #train# step 6515, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:19.459528 #train# step 6516, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:21.056240 #train# step 6517, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:22.606378 #train# step 6518, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:24.192361 #train# step 6519, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:25.776052 #train# step 6520, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:27.398870 #train# step 6521, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:28.994315 #train# step 6522, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:30.596000 #train# step 6523, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:32.194018 #train# step 6524, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:33.830687 #train# step 6525, loss = 0.9194, cross_entropy loss = 0.9194, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:35.389356 #train# step 6526, loss = 0.9282, cross_entropy loss = 0.9282, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:36.938280 #train# step 6527, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:38.498750 #train# step 6528, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:40.133225 #train# step 6529, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:41.677177 #train# step 6530, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:43.266878 #train# step 6531, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:44.842130 #train# step 6532, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:46.436026 #train# step 6533, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:48.046814 #train# step 6534, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:49.596825 #train# step 6535, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:51.217443 #train# step 6536, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:52.802675 #train# step 6537, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:54.394544 #train# step 6538, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:55.966774 #train# step 6539, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:57.531824 #train# step 6540, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:52:59.129871 #train# step 6541, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:00.705836 #train# step 6542, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:02.281796 #train# step 6543, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:03.876245 #train# step 6544, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:05.480132 #train# step 6545, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:07.053302 #train# step 6546, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:08.655540 #train# step 6547, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:10.257457 #train# step 6548, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:11.861282 #train# step 6549, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:13.470424 #train# step 6550, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:15.043378 #train# step 6551, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:16.593131 #train# step 6552, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:18.194651 #train# step 6553, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:19.830699 #train# step 6554, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:21.412880 #train# step 6555, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:22.992187 #train# step 6556, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:24.639322 #train# step 6557, loss = 0.9168, cross_entropy loss = 0.9168, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:26.239667 #train# step 6558, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:27.848367 #train# step 6559, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:29.517023 #train# step 6560, loss = 0.9070, cross_entropy loss = 0.9070, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:31.094829 #train# step 6561, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:32.684859 #train# step 6562, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:34.282712 #train# step 6563, loss = 0.9148, cross_entropy loss = 0.9148, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:35.869049 #train# step 6564, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:37.440325 #train# step 6565, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:39.031809 #train# step 6566, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:40.627062 #train# step 6567, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:42.189808 #train# step 6568, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:43.789831 #train# step 6569, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:45.388871 #train# step 6570, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:46.993027 #train# step 6571, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:48.573758 #train# step 6572, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:50.163507 #train# step 6573, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:51.733853 #train# step 6574, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:53.335994 #train# step 6575, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:54.941475 #train# step 6576, loss = 0.9195, cross_entropy loss = 0.9195, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:56.536291 #train# step 6577, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:58.118540 #train# step 6578, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:53:59.694868 #train# step 6579, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:01.251289 #train# step 6580, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:02.830153 #train# step 6581, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:04.419444 #train# step 6582, loss = 0.9290, cross_entropy loss = 0.9290, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:05.989058 #train# step 6583, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:07.582827 #train# step 6584, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:09.170183 #train# step 6585, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:10.762307 #train# step 6586, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:12.348182 #train# step 6587, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:13.941070 #train# step 6588, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:15.561369 #train# step 6589, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:17.186824 #train# step 6590, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:18.787901 #train# step 6591, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:20.400146 #train# step 6592, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:21.990366 #train# step 6593, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:23.617775 #train# step 6594, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:25.178854 #train# step 6595, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:26.756792 #train# step 6596, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:28.338777 #train# step 6597, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:29.936182 #train# step 6598, loss = 0.9272, cross_entropy loss = 0.9272, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:31.538790 #train# step 6599, loss = 0.8879, cross_entropy loss = 0.8879, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:33.138743 #train# step 6600, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:34.730039 #train# step 6601, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:36.325165 #train# step 6602, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:37.911835 #train# step 6603, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:39.512338 #train# step 6604, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:41.095870 #train# step 6605, loss = 0.9244, cross_entropy loss = 0.9244, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:42.734393 #train# step 6606, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:44.325144 #train# step 6607, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:45.893284 #train# step 6608, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:47.510814 #train# step 6609, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:49.140335 #train# step 6610, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:50.692556 #train# step 6611, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:52.290751 #train# step 6612, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:53.859565 #train# step 6613, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:55.454398 #train# step 6614, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:57.133195 #train# step 6615, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:54:58.734833 #train# step 6616, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:00.312904 #train# step 6617, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:01.914069 #train# step 6618, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:03.504097 #train# step 6619, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:05.087254 #train# step 6620, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:06.695884 #train# step 6621, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:08.293821 #train# step 6622, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:09.897609 #train# step 6623, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:11.496685 #train# step 6624, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:13.090367 #train# step 6625, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:14.729333 #train# step 6626, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:16.337094 #train# step 6627, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:17.905398 #train# step 6628, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:19.481030 #train# step 6629, loss = 0.9222, cross_entropy loss = 0.9222, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:21.089890 #train# step 6630, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:22.673706 #train# step 6631, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:24.252207 #train# step 6632, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:25.869623 #train# step 6633, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:27.475391 #train# step 6634, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:29.064869 #train# step 6635, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:30.680058 #train# step 6636, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:32.247283 #train# step 6637, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:33.811640 #train# step 6638, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:35.425356 #train# step 6639, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:37.043465 #train# step 6640, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:38.665460 #train# step 6641, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:40.262569 #train# step 6642, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:41.860609 #train# step 6643, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:43.452194 #train# step 6644, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:45.031221 #train# step 6645, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:46.620036 #train# step 6646, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:48.211879 #train# step 6647, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:49.815972 #train# step 6648, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:51.399912 #train# step 6649, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:52.984760 #train# step 6650, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:54.591687 #train# step 6651, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:56.226532 #train# step 6652, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:57.806404 #train# step 6653, loss = 0.9068, cross_entropy loss = 0.9068, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:55:59.399438 #train# step 6654, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:00.973459 #train# step 6655, loss = 0.9145, cross_entropy loss = 0.9145, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:02.555509 #train# step 6656, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:04.125282 #train# step 6657, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:05.711625 #train# step 6658, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:07.333071 #train# step 6659, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:08.901654 #train# step 6660, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:10.484195 #train# step 6661, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:12.076474 #train# step 6662, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:13.651564 #train# step 6663, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:15.241756 #train# step 6664, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:16.848133 #train# step 6665, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:18.441114 #train# step 6666, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:20.025412 #train# step 6667, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:21.613014 #train# step 6668, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:23.217220 #train# step 6669, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:24.836929 #train# step 6670, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:26.418701 #train# step 6671, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:28.017711 #train# step 6672, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:29.622255 #train# step 6673, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:31.184667 #train# step 6674, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:32.775555 #train# step 6675, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:34.363970 #train# step 6676, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:35.999679 #train# step 6677, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:37.589747 #train# step 6678, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:39.195527 #train# step 6679, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:40.769971 #train# step 6680, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:42.376902 #train# step 6681, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:43.984525 #train# step 6682, loss = 0.9148, cross_entropy loss = 0.9148, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:45.548813 #train# step 6683, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:47.171612 #train# step 6684, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:48.782706 #train# step 6685, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:50.398459 #train# step 6686, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:52.004857 #train# step 6687, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:53.562769 #train# step 6688, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:55.209247 #train# step 6689, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:56.793701 #train# step 6690, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:58.401037 #train# step 6691, loss = 0.8893, cross_entropy loss = 0.8893, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:56:59.996414 #train# step 6692, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:01.574323 #train# step 6693, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:03.153665 #train# step 6694, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:04.747385 #train# step 6695, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:06.322953 #train# step 6696, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:07.897134 #train# step 6697, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:09.490790 #train# step 6698, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:11.083512 #train# step 6699, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:12.680855 #train# step 6700, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:14.307825 #train# step 6701, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:15.934718 #train# step 6702, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:17.502931 #train# step 6703, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:19.113778 #train# step 6704, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:20.662899 #train# step 6705, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:22.280290 #train# step 6706, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:23.889031 #train# step 6707, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:25.480126 #train# step 6708, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:27.094562 #train# step 6709, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:28.667144 #train# step 6710, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:30.255764 #train# step 6711, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:31.865826 #train# step 6712, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:33.424999 #train# step 6713, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:35.043100 #train# step 6714, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:36.638510 #train# step 6715, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:38.206848 #train# step 6716, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:39.793879 #train# step 6717, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:41.398955 #train# step 6718, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:42.996599 #train# step 6719, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:44.579048 #train# step 6720, loss = 0.9240, cross_entropy loss = 0.9240, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:46.131681 #train# step 6721, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:47.739612 #train# step 6722, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:49.347669 #train# step 6723, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:50.956188 #train# step 6724, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:52.555705 #train# step 6725, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:54.156121 #train# step 6726, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:55.756175 #train# step 6727, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:57.350385 #train# step 6728, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:57:58.977289 #train# step 6729, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:00.580879 #train# step 6730, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:02.157439 #train# step 6731, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:03.742767 #train# step 6732, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:05.323864 #train# step 6733, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:06.888586 #train# step 6734, loss = 0.9219, cross_entropy loss = 0.9219, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:08.507289 #train# step 6735, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:10.107747 #train# step 6736, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:11.688731 #train# step 6737, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:13.305614 #train# step 6738, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:14.881064 #train# step 6739, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:16.468709 #train# step 6740, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:18.090398 #train# step 6741, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:19.658227 #train# step 6742, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:21.224939 #train# step 6743, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:22.863839 #train# step 6744, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:24.411746 #train# step 6745, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:26.014380 #train# step 6746, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:27.631721 #train# step 6747, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:29.224778 #train# step 6748, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:30.807981 #train# step 6749, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:32.393886 #train# step 6750, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:33.989531 #train# step 6751, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:35.571192 #train# step 6752, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:37.189494 #train# step 6753, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:38.804587 #train# step 6754, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:40.398092 #train# step 6755, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:41.988262 #train# step 6756, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:43.598055 #train# step 6757, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:45.184424 #train# step 6758, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:46.772477 #train# step 6759, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:48.373960 #train# step 6760, loss = 0.9101, cross_entropy loss = 0.9101, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:49.958728 #train# step 6761, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:51.508984 #train# step 6762, loss = 0.9227, cross_entropy loss = 0.9227, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:53.073618 #train# step 6763, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:54.669775 #train# step 6764, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:56.271571 #train# step 6765, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:57.876720 #train# step 6766, loss = 0.8881, cross_entropy loss = 0.8881, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:58:59.478121 #train# step 6767, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:01.068613 #train# step 6768, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:02.658535 #train# step 6769, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:04.284439 #train# step 6770, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:05.881983 #train# step 6771, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:07.425013 #train# step 6772, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:09.007494 #train# step 6773, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:10.597194 #train# step 6774, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:12.210060 #train# step 6775, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:13.798326 #train# step 6776, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:15.408811 #train# step 6777, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:17.015669 #train# step 6778, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:18.621978 #train# step 6779, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:20.238083 #train# step 6780, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:21.856128 #train# step 6781, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:23.442010 #train# step 6782, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:25.018811 #train# step 6783, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:26.590342 #train# step 6784, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:28.158440 #train# step 6785, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:29.746389 #train# step 6786, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:31.378182 #train# step 6787, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:32.963135 #train# step 6788, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:34.574021 #train# step 6789, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:36.172963 #train# step 6790, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:37.767884 #train# step 6791, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:39.364762 #train# step 6792, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:40.949449 #train# step 6793, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:42.563301 #train# step 6794, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:44.158429 #train# step 6795, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:45.821316 #train# step 6796, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:47.425588 #train# step 6797, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:49.001654 #train# step 6798, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:50.617399 #train# step 6799, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:52.200415 #train# step 6800, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:53.796069 #train# step 6801, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:55.372611 #train# step 6802, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:56.955579 #train# step 6803, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 20:59:58.549353 #train# step 6804, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:00.148444 #train# step 6805, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:01.734402 #train# step 6806, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:03.308462 #train# step 6807, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:04.891433 #train# step 6808, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:06.463357 #train# step 6809, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:08.046070 #train# step 6810, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:09.642084 #train# step 6811, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:11.226669 #train# step 6812, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:12.828549 #train# step 6813, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:14.416272 #train# step 6814, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:16.017307 #train# step 6815, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:17.616262 #train# step 6816, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:19.228823 #train# step 6817, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:20.816460 #train# step 6818, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:22.413067 #train# step 6819, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:24.002467 #train# step 6820, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:25.600969 #train# step 6821, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:27.231042 #train# step 6822, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:28.780876 #train# step 6823, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:30.350276 #train# step 6824, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:31.952967 #train# step 6825, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:33.512182 #train# step 6826, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:35.099882 #train# step 6827, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:36.685326 #train# step 6828, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:38.261652 #train# step 6829, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:39.857421 #train# step 6830, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:41.444748 #train# step 6831, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:43.003391 #train# step 6832, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:44.587262 #train# step 6833, loss = 0.9242, cross_entropy loss = 0.9242, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:46.235898 #train# step 6834, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:47.865579 #train# step 6835, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:49.460753 #train# step 6836, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:51.050473 #train# step 6837, loss = 0.9309, cross_entropy loss = 0.9309, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:52.677293 #train# step 6838, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:54.235165 #train# step 6839, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:55.817734 #train# step 6840, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:57.412404 #train# step 6841, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:00:59.024702 #train# step 6842, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:00.639596 #train# step 6843, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:02.235555 #train# step 6844, loss = 0.8859, cross_entropy loss = 0.8859, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:03.826527 #train# step 6845, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:05.422939 #train# step 6846, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:07.034590 #train# step 6847, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:08.620406 #train# step 6848, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:10.202138 #train# step 6849, loss = 0.8961, cross_entropy loss = 0.8961, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:11.790808 #train# step 6850, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:13.400849 #train# step 6851, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:14.989819 #train# step 6852, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:16.578663 #train# step 6853, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:18.195700 #train# step 6854, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:19.782636 #train# step 6855, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:21.362560 #train# step 6856, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:22.985880 #train# step 6857, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:24.578977 #train# step 6858, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:26.203350 #train# step 6859, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:27.812346 #train# step 6860, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:29.396311 #train# step 6861, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:30.992167 #train# step 6862, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:32.583805 #train# step 6863, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:34.191477 #train# step 6864, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:35.795474 #train# step 6865, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:37.393676 #train# step 6866, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:38.985130 #train# step 6867, loss = 0.9205, cross_entropy loss = 0.9205, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:40.582772 #train# step 6868, loss = 0.9179, cross_entropy loss = 0.9179, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:42.162470 #train# step 6869, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:43.760458 #train# step 6870, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:45.366440 #train# step 6871, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:46.979897 #train# step 6872, loss = 0.9214, cross_entropy loss = 0.9214, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:48.579296 #train# step 6873, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:50.167327 #train# step 6874, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:51.755314 #train# step 6875, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:53.370789 #train# step 6876, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:54.940156 #train# step 6877, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:56.532496 #train# step 6878, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:58.157951 #train# step 6879, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:01:59.744037 #train# step 6880, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:01.316297 #train# step 6881, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:02.934778 #train# step 6882, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:04.548230 #train# step 6883, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:06.086859 #train# step 6884, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:07.703941 #train# step 6885, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:09.296503 #train# step 6886, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:10.886178 #train# step 6887, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:12.470152 #train# step 6888, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:14.059463 #train# step 6889, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:15.644727 #train# step 6890, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:17.248449 #train# step 6891, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:18.836619 #train# step 6892, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:20.433594 #train# step 6893, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:22.011242 #train# step 6894, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:23.590670 #train# step 6895, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:25.208268 #train# step 6896, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:26.773690 #train# step 6897, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:28.396513 #train# step 6898, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:29.991031 #train# step 6899, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:31.579402 #train# step 6900, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:33.138863 #train# step 6901, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:34.728530 #train# step 6902, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:36.331785 #train# step 6903, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:37.918026 #train# step 6904, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:39.510208 #train# step 6905, loss = 0.9046, cross_entropy loss = 0.9046, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:41.101317 #train# step 6906, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:42.690911 #train# step 6907, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:44.326952 #train# step 6908, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:45.911608 #train# step 6909, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:47.515556 #train# step 6910, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:49.126952 #train# step 6911, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:50.721760 #train# step 6912, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:52.319520 #train# step 6913, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:53.903519 #train# step 6914, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:55.518026 #train# step 6915, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:57.117279 #train# step 6916, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:02:58.702323 #train# step 6917, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:00.279328 #train# step 6918, loss = 0.8981, cross_entropy loss = 0.8981, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:01.866664 #train# step 6919, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:03.440852 #train# step 6920, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:05.036818 #train# step 6921, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:06.629239 #train# step 6922, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:08.238839 #train# step 6923, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:09.823086 #train# step 6924, loss = 0.9255, cross_entropy loss = 0.9255, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:11.444059 #train# step 6925, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:13.049951 #train# step 6926, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:14.621547 #train# step 6927, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:16.213889 #train# step 6928, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:17.787852 #train# step 6929, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:19.391701 #train# step 6930, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:20.967457 #train# step 6931, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:22.576148 #train# step 6932, loss = 0.9161, cross_entropy loss = 0.9161, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:24.178665 #train# step 6933, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:25.813959 #train# step 6934, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:27.427421 #train# step 6935, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:29.007157 #train# step 6936, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:30.592149 #train# step 6937, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:32.252573 #train# step 6938, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:33.861254 #train# step 6939, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:35.472751 #train# step 6940, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:37.053613 #train# step 6941, loss = 0.9238, cross_entropy loss = 0.9238, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:38.641214 #train# step 6942, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:40.224193 #train# step 6943, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:41.831627 #train# step 6944, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:43.404040 #train# step 6945, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:44.987384 #train# step 6946, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:46.563998 #train# step 6947, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:48.155954 #train# step 6948, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:49.748132 #train# step 6949, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:51.326600 #train# step 6950, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:52.901526 #train# step 6951, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:54.529265 #train# step 6952, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:56.124243 #train# step 6953, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:57.708366 #train# step 6954, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:03:59.347595 #train# step 6955, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:00.950221 #train# step 6956, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:02.585436 #train# step 6957, loss = 0.9101, cross_entropy loss = 0.9101, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:04.169098 #train# step 6958, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:05.741881 #train# step 6959, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:07.376338 #train# step 6960, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:08.994762 #train# step 6961, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:10.589051 #train# step 6962, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:12.180792 #train# step 6963, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:13.792335 #train# step 6964, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:15.378182 #train# step 6965, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:16.987889 #train# step 6966, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:18.569620 #train# step 6967, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:20.182871 #train# step 6968, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:21.763823 #train# step 6969, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:23.342156 #train# step 6970, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:24.916174 #train# step 6971, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:26.489899 #train# step 6972, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:28.084723 #train# step 6973, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:29.656872 #train# step 6974, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:31.230089 #train# step 6975, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:32.801944 #train# step 6976, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:34.415344 #train# step 6977, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:36.030160 #train# step 6978, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:37.597016 #train# step 6979, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:39.239145 #train# step 6980, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:40.828326 #train# step 6981, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:42.393994 #train# step 6982, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:43.999032 #train# step 6983, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:45.584507 #train# step 6984, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:47.179211 #train# step 6985, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:48.760042 #train# step 6986, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:50.348375 #train# step 6987, loss = 0.9024, cross_entropy loss = 0.9024, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:51.974665 #train# step 6988, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:53.572066 #train# step 6989, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:55.154167 #train# step 6990, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:56.745240 #train# step 6991, loss = 0.9058, cross_entropy loss = 0.9058, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:58.382792 #train# step 6992, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:04:59.972175 #train# step 6993, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:01.535762 #train# step 6994, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:03.115065 #train# step 6995, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:04.697693 #train# step 6996, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:06.317360 #train# step 6997, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:07.899609 #train# step 6998, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:09.526807 #train# step 6999, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:11.106572 #train# step 7000, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:12.702500 #train# step 7001, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:14.280720 #train# step 7002, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:15.898802 #train# step 7003, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:17.501546 #train# step 7004, loss = 0.8890, cross_entropy loss = 0.8890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:19.107515 #train# step 7005, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:20.646926 #train# step 7006, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:22.234903 #train# step 7007, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:23.834996 #train# step 7008, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:25.405467 #train# step 7009, loss = 0.9181, cross_entropy loss = 0.9181, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:26.985698 #train# step 7010, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:28.571516 #train# step 7011, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:30.163402 #train# step 7012, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:31.788153 #train# step 7013, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:33.365202 #train# step 7014, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:34.919944 #train# step 7015, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:36.508869 #train# step 7016, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:38.117177 #train# step 7017, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:39.729670 #train# step 7018, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:41.300296 #train# step 7019, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:42.869947 #train# step 7020, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:44.451814 #train# step 7021, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:46.037572 #train# step 7022, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:47.657796 #train# step 7023, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:49.251047 #train# step 7024, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:50.855435 #train# step 7025, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:52.482818 #train# step 7026, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:54.058558 #train# step 7027, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:55.676503 #train# step 7028, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:57.286575 #train# step 7029, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:05:58.881102 #train# step 7030, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:00.488387 #train# step 7031, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:02.093013 #train# step 7032, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:03.740324 #train# step 7033, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:05.377786 #train# step 7034, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:06.929981 #train# step 7035, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:08.539273 #train# step 7036, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:10.148222 #train# step 7037, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:11.747165 #train# step 7038, loss = 0.9054, cross_entropy loss = 0.9054, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:13.339232 #train# step 7039, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:14.968008 #train# step 7040, loss = 0.8953, cross_entropy loss = 0.8953, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:16.541954 #train# step 7041, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:18.148130 #train# step 7042, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:19.735241 #train# step 7043, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:21.320496 #train# step 7044, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:22.936237 #train# step 7045, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:24.519183 #train# step 7046, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:26.110801 #train# step 7047, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:27.663904 #train# step 7048, loss = 0.9249, cross_entropy loss = 0.9249, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:29.258831 #train# step 7049, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:30.806455 #train# step 7050, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:32.423365 #train# step 7051, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:34.049267 #train# step 7052, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:35.645083 #train# step 7053, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:37.251361 #train# step 7054, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:38.832346 #train# step 7055, loss = 0.9229, cross_entropy loss = 0.9229, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:40.420819 #train# step 7056, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:42.013523 #train# step 7057, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:43.605474 #train# step 7058, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:45.229966 #train# step 7059, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:46.819962 #train# step 7060, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:48.419184 #train# step 7061, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:49.996118 #train# step 7062, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:51.585015 #train# step 7063, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:53.201020 #train# step 7064, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:54.806991 #train# step 7065, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:56.399746 #train# step 7066, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:58.011789 #train# step 7067, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:06:59.605475 #train# step 7068, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:01.185291 #train# step 7069, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:02.765593 #train# step 7070, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:04.357437 #train# step 7071, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:05.928885 #train# step 7072, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:07.516017 #train# step 7073, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:09.099846 #train# step 7074, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:10.697362 #train# step 7075, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:12.290023 #train# step 7076, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:13.914356 #train# step 7077, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:15.490607 #train# step 7078, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:17.093501 #train# step 7079, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:18.675911 #train# step 7080, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:20.276928 #train# step 7081, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:21.869016 #train# step 7082, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:23.476120 #train# step 7083, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:25.064968 #train# step 7084, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:26.651296 #train# step 7085, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:28.287735 #train# step 7086, loss = 0.9082, cross_entropy loss = 0.9082, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:29.869224 #train# step 7087, loss = 0.9070, cross_entropy loss = 0.9070, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:31.490931 #train# step 7088, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:33.061149 #train# step 7089, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:34.639694 #train# step 7090, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:36.242926 #train# step 7091, loss = 0.9184, cross_entropy loss = 0.9184, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:37.845710 #train# step 7092, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:39.444917 #train# step 7093, loss = 0.9065, cross_entropy loss = 0.9065, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:41.056239 #train# step 7094, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:42.679053 #train# step 7095, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:44.262171 #train# step 7096, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:45.840694 #train# step 7097, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:47.443599 #train# step 7098, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:49.029166 #train# step 7099, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:50.628063 #train# step 7100, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:52.212991 #train# step 7101, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:53.821271 #train# step 7102, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:55.424325 #train# step 7103, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:56.975454 #train# step 7104, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:07:58.556366 #train# step 7105, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:00.147119 #train# step 7106, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:01.741694 #train# step 7107, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:03.366470 #train# step 7108, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:04.979565 #train# step 7109, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:06.588314 #train# step 7110, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:08.196126 #train# step 7111, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:09.792239 #train# step 7112, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:11.393600 #train# step 7113, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:12.974004 #train# step 7114, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:14.544155 #train# step 7115, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:16.149046 #train# step 7116, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:17.764105 #train# step 7117, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:19.332032 #train# step 7118, loss = 0.9336, cross_entropy loss = 0.9336, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:20.953996 #train# step 7119, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:22.569075 #train# step 7120, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:24.162840 #train# step 7121, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:25.749620 #train# step 7122, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:27.350864 #train# step 7123, loss = 0.9199, cross_entropy loss = 0.9199, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:28.933042 #train# step 7124, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:30.481766 #train# step 7125, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:32.083688 #train# step 7126, loss = 0.8899, cross_entropy loss = 0.8899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:33.678143 #train# step 7127, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:35.247299 #train# step 7128, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:36.856728 #train# step 7129, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:38.445763 #train# step 7130, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:40.064055 #train# step 7131, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:41.643041 #train# step 7132, loss = 0.9292, cross_entropy loss = 0.9292, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:43.249132 #train# step 7133, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:44.841324 #train# step 7134, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:46.434598 #train# step 7135, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:48.070654 #train# step 7136, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:49.641127 #train# step 7137, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:51.245089 #train# step 7138, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:52.860111 #train# step 7139, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:54.436298 #train# step 7140, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:56.011820 #train# step 7141, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:57.617872 #train# step 7142, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:08:59.206987 #train# step 7143, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:00.805156 #train# step 7144, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:02.392340 #train# step 7145, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:04.001828 #train# step 7146, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:05.577915 #train# step 7147, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:07.164067 #train# step 7148, loss = 0.9201, cross_entropy loss = 0.9201, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:08.740528 #train# step 7149, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:10.336382 #train# step 7150, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:11.925473 #train# step 7151, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:13.503409 #train# step 7152, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:15.140143 #train# step 7153, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:16.773958 #train# step 7154, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:18.355460 #train# step 7155, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:19.935729 #train# step 7156, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:21.534222 #train# step 7157, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:23.121762 #train# step 7158, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:24.704756 #train# step 7159, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:26.299675 #train# step 7160, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:27.865285 #train# step 7161, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:29.488056 #train# step 7162, loss = 0.9060, cross_entropy loss = 0.9060, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:31.068289 #train# step 7163, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:32.701711 #train# step 7164, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:34.299073 #train# step 7165, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:35.883395 #train# step 7166, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:37.462032 #train# step 7167, loss = 0.9067, cross_entropy loss = 0.9067, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:39.069369 #train# step 7168, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:40.650109 #train# step 7169, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:42.209282 #train# step 7170, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:43.822128 #train# step 7171, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:45.391623 #train# step 7172, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:46.953704 #train# step 7173, loss = 0.9247, cross_entropy loss = 0.9247, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:48.517043 #train# step 7174, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:50.108509 #train# step 7175, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:51.716815 #train# step 7176, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:53.305346 #train# step 7177, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:54.912302 #train# step 7178, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:56.502156 #train# step 7179, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:58.098835 #train# step 7180, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:09:59.733449 #train# step 7181, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:01.321314 #train# step 7182, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:02.919064 #train# step 7183, loss = 0.9128, cross_entropy loss = 0.9128, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:04.551949 #train# step 7184, loss = 0.8883, cross_entropy loss = 0.8883, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:06.149028 #train# step 7185, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:07.751359 #train# step 7186, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:09.345372 #train# step 7187, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:10.978564 #train# step 7188, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:12.598480 #train# step 7189, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:14.213358 #train# step 7190, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:15.805187 #train# step 7191, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:17.363432 #train# step 7192, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:18.964572 #train# step 7193, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:20.580051 #train# step 7194, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:22.186429 #train# step 7195, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:23.771515 #train# step 7196, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:25.357992 #train# step 7197, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:26.948922 #train# step 7198, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:28.570792 #train# step 7199, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:30.162222 #train# step 7200, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:31.761035 #train# step 7201, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:33.356518 #train# step 7202, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:34.934879 #train# step 7203, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:36.568743 #train# step 7204, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:38.154222 #train# step 7205, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:39.754581 #train# step 7206, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:41.357337 #train# step 7207, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:42.962157 #train# step 7208, loss = 0.9173, cross_entropy loss = 0.9173, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:44.528454 #train# step 7209, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:46.134754 #train# step 7210, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:47.739305 #train# step 7211, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:49.339897 #train# step 7212, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:50.965447 #train# step 7213, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:52.526476 #train# step 7214, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:54.104735 #train# step 7215, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:55.719631 #train# step 7216, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:57.322958 #train# step 7217, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:10:58.954446 #train# step 7218, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:00.541848 #train# step 7219, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:02.146427 #train# step 7220, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:03.721962 #train# step 7221, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:05.289597 #train# step 7222, loss = 0.9213, cross_entropy loss = 0.9213, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:06.853129 #train# step 7223, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:08.448875 #train# step 7224, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:10.061983 #train# step 7225, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:11.639087 #train# step 7226, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:13.208212 #train# step 7227, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:14.776510 #train# step 7228, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:16.387976 #train# step 7229, loss = 0.9100, cross_entropy loss = 0.9100, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:18.002799 #train# step 7230, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:19.582209 #train# step 7231, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:21.134325 #train# step 7232, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:22.725075 #train# step 7233, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:24.333125 #train# step 7234, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:25.969317 #train# step 7235, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:27.583960 #train# step 7236, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:29.200593 #train# step 7237, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:30.795596 #train# step 7238, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:32.380483 #train# step 7239, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:33.958257 #train# step 7240, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:35.542242 #train# step 7241, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:37.142781 #train# step 7242, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:38.725142 #train# step 7243, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:40.348800 #train# step 7244, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:41.961904 #train# step 7245, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:43.558751 #train# step 7246, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:45.151978 #train# step 7247, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:46.743944 #train# step 7248, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:48.301479 #train# step 7249, loss = 0.9252, cross_entropy loss = 0.9252, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:49.856212 #train# step 7250, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:51.452671 #train# step 7251, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:53.065664 #train# step 7252, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:54.670222 #train# step 7253, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:56.277467 #train# step 7254, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:57.900346 #train# step 7255, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:11:59.477179 #train# step 7256, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:01.064680 #train# step 7257, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:02.692724 #train# step 7258, loss = 0.8870, cross_entropy loss = 0.8870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:04.263927 #train# step 7259, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:05.863021 #train# step 7260, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:07.479550 #train# step 7261, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:09.079120 #train# step 7262, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:10.686371 #train# step 7263, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:12.266561 #train# step 7264, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:13.839095 #train# step 7265, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:15.427584 #train# step 7266, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:17.008444 #train# step 7267, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:18.619808 #train# step 7268, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:20.207322 #train# step 7269, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:21.788747 #train# step 7270, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:23.429267 #train# step 7271, loss = 0.9196, cross_entropy loss = 0.9196, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:25.024164 #train# step 7272, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:26.611532 #train# step 7273, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:28.178018 #train# step 7274, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:29.786108 #train# step 7275, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:31.359158 #train# step 7276, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:32.960737 #train# step 7277, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:34.565978 #train# step 7278, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:36.156542 #train# step 7279, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:37.735028 #train# step 7280, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:39.313758 #train# step 7281, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:40.929809 #train# step 7282, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:42.551101 #train# step 7283, loss = 0.9080, cross_entropy loss = 0.9080, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:44.133621 #train# step 7284, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:45.746505 #train# step 7285, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:47.319995 #train# step 7286, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:48.929062 #train# step 7287, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:50.524700 #train# step 7288, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:52.137711 #train# step 7289, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:53.708672 #train# step 7290, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:55.338667 #train# step 7291, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:56.944839 #train# step 7292, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:12:58.524857 #train# step 7293, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:00.111230 #train# step 7294, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:01.699917 #train# step 7295, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:03.261275 #train# step 7296, loss = 0.9224, cross_entropy loss = 0.9224, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:04.869135 #train# step 7297, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:06.467066 #train# step 7298, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:08.039642 #train# step 7299, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:09.639949 #train# step 7300, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:11.272531 #train# step 7301, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:12.865553 #train# step 7302, loss = 0.8858, cross_entropy loss = 0.8858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:14.469736 #train# step 7303, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:16.080249 #train# step 7304, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:17.652139 #train# step 7305, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:19.231520 #train# step 7306, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:20.837725 #train# step 7307, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:22.450598 #train# step 7308, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:24.057331 #train# step 7309, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:25.662944 #train# step 7310, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:27.233710 #train# step 7311, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:28.876165 #train# step 7312, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:30.502578 #train# step 7313, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:32.096264 #train# step 7314, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:33.690728 #train# step 7315, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:35.274120 #train# step 7316, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:36.880693 #train# step 7317, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:38.466171 #train# step 7318, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:40.088391 #train# step 7319, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:41.664003 #train# step 7320, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:43.233328 #train# step 7321, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:44.826708 #train# step 7322, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:46.430931 #train# step 7323, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:48.013211 #train# step 7324, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:49.585131 #train# step 7325, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:51.180803 #train# step 7326, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:52.739204 #train# step 7327, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:54.319029 #train# step 7328, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:55.927177 #train# step 7329, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:57.521306 #train# step 7330, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:13:59.100416 #train# step 7331, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:00.679415 #train# step 7332, loss = 0.9010, cross_entropy loss = 0.9010, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:02.264416 #train# step 7333, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:03.850666 #train# step 7334, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:05.442025 #train# step 7335, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:07.097547 #train# step 7336, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:08.669634 #train# step 7337, loss = 0.9182, cross_entropy loss = 0.9182, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:10.248628 #train# step 7338, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:11.852712 #train# step 7339, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:13.436388 #train# step 7340, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:15.027373 #train# step 7341, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:16.619776 #train# step 7342, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:18.207684 #train# step 7343, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:19.800420 #train# step 7344, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:21.379333 #train# step 7345, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:22.970509 #train# step 7346, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:24.551575 #train# step 7347, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:26.159279 #train# step 7348, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:27.770770 #train# step 7349, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:29.367915 #train# step 7350, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:30.948445 #train# step 7351, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:32.530587 #train# step 7352, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:34.139547 #train# step 7353, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:35.733546 #train# step 7354, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:37.326989 #train# step 7355, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:38.915693 #train# step 7356, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:40.472867 #train# step 7357, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:42.077372 #train# step 7358, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:43.654745 #train# step 7359, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:45.236291 #train# step 7360, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:46.851521 #train# step 7361, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:48.449095 #train# step 7362, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:50.082451 #train# step 7363, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:51.661020 #train# step 7364, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:53.249570 #train# step 7365, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:54.814372 #train# step 7366, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:56.418600 #train# step 7367, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:58.018457 #train# step 7368, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:14:59.617634 #train# step 7369, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:01.202273 #train# step 7370, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:02.790827 #train# step 7371, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:04.400548 #train# step 7372, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:05.987970 #train# step 7373, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:07.575042 #train# step 7374, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:09.178105 #train# step 7375, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:10.763357 #train# step 7376, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:12.355412 #train# step 7377, loss = 0.9177, cross_entropy loss = 0.9177, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:13.948704 #train# step 7378, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:15.569808 #train# step 7379, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:17.147093 #train# step 7380, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:18.724688 #train# step 7381, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:20.279315 #train# step 7382, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:21.894257 #train# step 7383, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:23.489000 #train# step 7384, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:25.112694 #train# step 7385, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:26.706840 #train# step 7386, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:28.272263 #train# step 7387, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:29.863968 #train# step 7388, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:31.455884 #train# step 7389, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:33.034610 #train# step 7390, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:34.635845 #train# step 7391, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:36.242124 #train# step 7392, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:37.852663 #train# step 7393, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:39.506151 #train# step 7394, loss = 0.8848, cross_entropy loss = 0.8848, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:41.124699 #train# step 7395, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:42.720282 #train# step 7396, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:44.302053 #train# step 7397, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:45.869161 #train# step 7398, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:47.475691 #train# step 7399, loss = 0.8857, cross_entropy loss = 0.8857, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:49.068285 #train# step 7400, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:50.672925 #train# step 7401, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:52.263411 #train# step 7402, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:53.893088 #train# step 7403, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:55.476725 #train# step 7404, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:57.068309 #train# step 7405, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:15:58.666839 #train# step 7406, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:00.215841 #train# step 7407, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:01.812882 #train# step 7408, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:03.392464 #train# step 7409, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:04.987169 #train# step 7410, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:06.590246 #train# step 7411, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:08.172426 #train# step 7412, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:09.804501 #train# step 7413, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:11.396584 #train# step 7414, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:12.991505 #train# step 7415, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:14.586230 #train# step 7416, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:16.180582 #train# step 7417, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:17.805032 #train# step 7418, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:19.421075 #train# step 7419, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:21.012706 #train# step 7420, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:22.592072 #train# step 7421, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:24.176192 #train# step 7422, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:25.787116 #train# step 7423, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:27.357039 #train# step 7424, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:28.973577 #train# step 7425, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:30.563265 #train# step 7426, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:32.150726 #train# step 7427, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:33.735984 #train# step 7428, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:35.328654 #train# step 7429, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:36.962551 #train# step 7430, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:38.531562 #train# step 7431, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:40.105479 #train# step 7432, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:41.708227 #train# step 7433, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:43.286536 #train# step 7434, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:44.855356 #train# step 7435, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:46.463227 #train# step 7436, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:48.060215 #train# step 7437, loss = 0.9164, cross_entropy loss = 0.9164, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:49.659719 #train# step 7438, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:51.230110 #train# step 7439, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:52.860396 #train# step 7440, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:54.501700 #train# step 7441, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:56.116311 #train# step 7442, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:57.713301 #train# step 7443, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:16:59.297808 #train# step 7444, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:00.875035 #train# step 7445, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:02.516766 #train# step 7446, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:04.154400 #train# step 7447, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:05.740715 #train# step 7448, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:07.320717 #train# step 7449, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:08.903783 #train# step 7450, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:10.528274 #train# step 7451, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:12.109236 #train# step 7452, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:13.723585 #train# step 7453, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:15.313887 #train# step 7454, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:16.915349 #train# step 7455, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:18.527319 #train# step 7456, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:20.131358 #train# step 7457, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:21.744587 #train# step 7458, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:23.340524 #train# step 7459, loss = 0.9186, cross_entropy loss = 0.9186, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:24.922547 #train# step 7460, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:26.502257 #train# step 7461, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:28.102591 #train# step 7462, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:29.684064 #train# step 7463, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:31.293985 #train# step 7464, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:32.874145 #train# step 7465, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:34.469515 #train# step 7466, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:36.061256 #train# step 7467, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:37.638838 #train# step 7468, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:39.216640 #train# step 7469, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:40.816231 #train# step 7470, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:42.393537 #train# step 7471, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:43.995970 #train# step 7472, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:45.547411 #train# step 7473, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:47.123210 #train# step 7474, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:48.710180 #train# step 7475, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:50.316567 #train# step 7476, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:51.936777 #train# step 7477, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:53.490043 #train# step 7478, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:55.089646 #train# step 7479, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:56.670789 #train# step 7480, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:58.281430 #train# step 7481, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:17:59.863478 #train# step 7482, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:01.458207 #train# step 7483, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:03.081753 #train# step 7484, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:04.649538 #train# step 7485, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:06.241445 #train# step 7486, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:07.838536 #train# step 7487, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:09.452821 #train# step 7488, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:11.030888 #train# step 7489, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:12.607848 #train# step 7490, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:14.209277 #train# step 7491, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:15.780401 #train# step 7492, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:17.414422 #train# step 7493, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:18.997574 #train# step 7494, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:20.591893 #train# step 7495, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:22.186031 #train# step 7496, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:23.776826 #train# step 7497, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:25.402782 #train# step 7498, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:26.993423 #train# step 7499, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:28.555837 #train# step 7500, loss = 0.9188, cross_entropy loss = 0.9188, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:30.153191 #train# step 7501, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:31.732487 #train# step 7502, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:33.344594 #train# step 7503, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:34.973291 #train# step 7504, loss = 0.8913, cross_entropy loss = 0.8913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:36.557616 #train# step 7505, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:38.147885 #train# step 7506, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:39.751821 #train# step 7507, loss = 0.9206, cross_entropy loss = 0.9206, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:41.368056 #train# step 7508, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:42.980299 #train# step 7509, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:44.591565 #train# step 7510, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:46.183689 #train# step 7511, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:47.757894 #train# step 7512, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:49.336432 #train# step 7513, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:50.916116 #train# step 7514, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:52.526381 #train# step 7515, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:54.120981 #train# step 7516, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:55.701850 #train# step 7517, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:57.307879 #train# step 7518, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:18:58.909257 #train# step 7519, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:00.504021 #train# step 7520, loss = 0.8836, cross_entropy loss = 0.8836, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:02.107648 #train# step 7521, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:03.719407 #train# step 7522, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:05.310235 #train# step 7523, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:06.902764 #train# step 7524, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:08.508183 #train# step 7525, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:10.106206 #train# step 7526, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:11.686378 #train# step 7527, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:13.260187 #train# step 7528, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:14.836941 #train# step 7529, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:16.426673 #train# step 7530, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:18.058024 #train# step 7531, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:19.646506 #train# step 7532, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:21.246332 #train# step 7533, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:22.831754 #train# step 7534, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:24.426592 #train# step 7535, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:26.003106 #train# step 7536, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:27.589716 #train# step 7537, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:29.156714 #train# step 7538, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:30.737998 #train# step 7539, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:32.357106 #train# step 7540, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:33.968824 #train# step 7541, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:35.590518 #train# step 7542, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:37.185077 #train# step 7543, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:38.768790 #train# step 7544, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:40.384528 #train# step 7545, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:41.991715 #train# step 7546, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:43.582996 #train# step 7547, loss = 0.9264, cross_entropy loss = 0.9264, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:45.169144 #train# step 7548, loss = 0.8876, cross_entropy loss = 0.8876, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:46.767582 #train# step 7549, loss = 0.9156, cross_entropy loss = 0.9156, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:48.354777 #train# step 7550, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:49.945177 #train# step 7551, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:51.531059 #train# step 7552, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:53.153920 #train# step 7553, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:54.756210 #train# step 7554, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:56.352513 #train# step 7555, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:57.940942 #train# step 7556, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:19:59.494204 #train# step 7557, loss = 0.9197, cross_entropy loss = 0.9197, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:01.103199 #train# step 7558, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:02.720693 #train# step 7559, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:04.323962 #train# step 7560, loss = 0.9172, cross_entropy loss = 0.9172, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:05.909809 #train# step 7561, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:07.488394 #train# step 7562, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:09.075355 #train# step 7563, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:10.672902 #train# step 7564, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:12.237023 #train# step 7565, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:13.831413 #train# step 7566, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:15.413374 #train# step 7567, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:17.034240 #train# step 7568, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:18.631926 #train# step 7569, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:20.232265 #train# step 7570, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:21.827892 #train# step 7571, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:23.433646 #train# step 7572, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:25.014855 #train# step 7573, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:26.613288 #train# step 7574, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:28.185460 #train# step 7575, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:29.787700 #train# step 7576, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:31.409055 #train# step 7577, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:33.006920 #train# step 7578, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:34.590020 #train# step 7579, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:36.183906 #train# step 7580, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:37.778225 #train# step 7581, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:39.369101 #train# step 7582, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:41.010319 #train# step 7583, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:42.619782 #train# step 7584, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:44.212608 #train# step 7585, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:45.806461 #train# step 7586, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:47.402413 #train# step 7587, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:48.989107 #train# step 7588, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:50.576290 #train# step 7589, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:52.194216 #train# step 7590, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:53.780336 #train# step 7591, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:55.388809 #train# step 7592, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:56.956337 #train# step 7593, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:20:58.588904 #train# step 7594, loss = 0.9102, cross_entropy loss = 0.9102, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:00.175072 #train# step 7595, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:01.759006 #train# step 7596, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:03.359313 #train# step 7597, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:04.929579 #train# step 7598, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:06.506274 #train# step 7599, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:08.093293 #train# step 7600, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:09.655612 #train# step 7601, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:11.231467 #train# step 7602, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:12.816678 #train# step 7603, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:14.424158 #train# step 7604, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:16.015736 #train# step 7605, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:17.616605 #train# step 7606, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:19.242072 #train# step 7607, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:20.859859 #train# step 7608, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:22.420266 #train# step 7609, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:23.991979 #train# step 7610, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:25.572586 #train# step 7611, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:27.166390 #train# step 7612, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:28.786412 #train# step 7613, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:30.385771 #train# step 7614, loss = 0.9152, cross_entropy loss = 0.9152, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:31.962188 #train# step 7615, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:33.592976 #train# step 7616, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:35.172532 #train# step 7617, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:36.803095 #train# step 7618, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:38.398128 #train# step 7619, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:40.021678 #train# step 7620, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:41.637425 #train# step 7621, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:43.215928 #train# step 7622, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:44.813171 #train# step 7623, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:46.394297 #train# step 7624, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:47.993332 #train# step 7625, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:49.576811 #train# step 7626, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:51.186936 #train# step 7627, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:52.805813 #train# step 7628, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:54.426023 #train# step 7629, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:56.067644 #train# step 7630, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:57.623042 #train# step 7631, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:21:59.213379 #train# step 7632, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:00.779534 #train# step 7633, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:02.377057 #train# step 7634, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:03.969528 #train# step 7635, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:05.570412 #train# step 7636, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:07.163417 #train# step 7637, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:08.749958 #train# step 7638, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:10.312481 #train# step 7639, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:11.893917 #train# step 7640, loss = 0.9189, cross_entropy loss = 0.9189, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:13.484346 #train# step 7641, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:15.095304 #train# step 7642, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:16.715613 #train# step 7643, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:18.340207 #train# step 7644, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:19.936244 #train# step 7645, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:21.518728 #train# step 7646, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:23.128299 #train# step 7647, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:24.728939 #train# step 7648, loss = 0.9013, cross_entropy loss = 0.9013, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:26.312208 #train# step 7649, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:27.901097 #train# step 7650, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:29.480117 #train# step 7651, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:31.060331 #train# step 7652, loss = 0.9125, cross_entropy loss = 0.9125, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:32.641488 #train# step 7653, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:34.251013 #train# step 7654, loss = 0.8985, cross_entropy loss = 0.8985, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:35.837908 #train# step 7655, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:37.393656 #train# step 7656, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:38.979115 #train# step 7657, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:40.590238 #train# step 7658, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:42.176601 #train# step 7659, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:43.751435 #train# step 7660, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:45.332388 #train# step 7661, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:46.911504 #train# step 7662, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:48.496444 #train# step 7663, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:50.063478 #train# step 7664, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:51.643828 #train# step 7665, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:53.246801 #train# step 7666, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:54.877981 #train# step 7667, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:56.495313 #train# step 7668, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:58.060283 #train# step 7669, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:22:59.639643 #train# step 7670, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:01.228379 #train# step 7671, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:02.821974 #train# step 7672, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:04.415870 #train# step 7673, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:05.992222 #train# step 7674, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:07.574033 #train# step 7675, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:09.173883 #train# step 7676, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:10.776169 #train# step 7677, loss = 0.8904, cross_entropy loss = 0.8904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:12.362221 #train# step 7678, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:13.985633 #train# step 7679, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:15.542433 #train# step 7680, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:17.147146 #train# step 7681, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:18.746000 #train# step 7682, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:20.343988 #train# step 7683, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:21.919783 #train# step 7684, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:23.532099 #train# step 7685, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:25.149001 #train# step 7686, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:26.763914 #train# step 7687, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:28.351770 #train# step 7688, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:29.919730 #train# step 7689, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:31.509984 #train# step 7690, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:33.118964 #train# step 7691, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:34.716002 #train# step 7692, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:36.320834 #train# step 7693, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:37.906831 #train# step 7694, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:39.494567 #train# step 7695, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:41.089165 #train# step 7696, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:42.701204 #train# step 7697, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:44.241396 #train# step 7698, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:45.838571 #train# step 7699, loss = 0.8831, cross_entropy loss = 0.8831, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:47.461397 #train# step 7700, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:49.091816 #train# step 7701, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:50.694734 #train# step 7702, loss = 0.8868, cross_entropy loss = 0.8868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:52.289514 #train# step 7703, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:53.890711 #train# step 7704, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:55.498997 #train# step 7705, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:57.098894 #train# step 7706, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:23:58.687787 #train# step 7707, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:00.280933 #train# step 7708, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:01.914711 #train# step 7709, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:03.494053 #train# step 7710, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:05.087545 #train# step 7711, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:06.682886 #train# step 7712, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:08.280062 #train# step 7713, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:09.868077 #train# step 7714, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:11.460764 #train# step 7715, loss = 0.9223, cross_entropy loss = 0.9223, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:13.055916 #train# step 7716, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:14.638169 #train# step 7717, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:16.246380 #train# step 7718, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:17.863485 #train# step 7719, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:19.445368 #train# step 7720, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:21.024415 #train# step 7721, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:22.579269 #train# step 7722, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:24.171916 #train# step 7723, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:25.756310 #train# step 7724, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:27.350307 #train# step 7725, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:28.926195 #train# step 7726, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:30.507991 #train# step 7727, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:32.071498 #train# step 7728, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:33.671256 #train# step 7729, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:35.280027 #train# step 7730, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:36.863881 #train# step 7731, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:38.470013 #train# step 7732, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:40.073061 #train# step 7733, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:41.699903 #train# step 7734, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:43.294531 #train# step 7735, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:44.911093 #train# step 7736, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:46.497290 #train# step 7737, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:48.073868 #train# step 7738, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:49.682736 #train# step 7739, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:51.274090 #train# step 7740, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:52.876245 #train# step 7741, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:54.473338 #train# step 7742, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:56.087504 #train# step 7743, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:57.712918 #train# step 7744, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:24:59.276022 #train# step 7745, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:00.888323 #train# step 7746, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:02.485404 #train# step 7747, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:04.085400 #train# step 7748, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:05.703878 #train# step 7749, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:07.320517 #train# step 7750, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:08.886258 #train# step 7751, loss = 0.9185, cross_entropy loss = 0.9185, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:10.464867 #train# step 7752, loss = 0.9183, cross_entropy loss = 0.9183, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:12.060903 #train# step 7753, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:13.636366 #train# step 7754, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:15.243013 #train# step 7755, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:16.857965 #train# step 7756, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:18.468697 #train# step 7757, loss = 0.8820, cross_entropy loss = 0.8820, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:20.080870 #train# step 7758, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:21.715690 #train# step 7759, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:23.300462 #train# step 7760, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:24.889438 #train# step 7761, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:26.469997 #train# step 7762, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:28.078005 #train# step 7763, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:29.681646 #train# step 7764, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:31.311207 #train# step 7765, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:32.906819 #train# step 7766, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:34.500801 #train# step 7767, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:36.066346 #train# step 7768, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:37.627300 #train# step 7769, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:39.221800 #train# step 7770, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:40.872604 #train# step 7771, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:42.457849 #train# step 7772, loss = 0.9006, cross_entropy loss = 0.9006, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:44.042337 #train# step 7773, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:45.624615 #train# step 7774, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:47.206280 #train# step 7775, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:48.780741 #train# step 7776, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:50.359881 #train# step 7777, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:51.940926 #train# step 7778, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:53.577704 #train# step 7779, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:55.171090 #train# step 7780, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:56.760697 #train# step 7781, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:58.369663 #train# step 7782, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:25:59.953523 #train# step 7783, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:01.567093 #train# step 7784, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:03.175068 #train# step 7785, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:04.783455 #train# step 7786, loss = 0.8904, cross_entropy loss = 0.8904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:06.372450 #train# step 7787, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:07.959815 #train# step 7788, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:09.569720 #train# step 7789, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:11.163966 #train# step 7790, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:12.775818 #train# step 7791, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:14.350059 #train# step 7792, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:15.955047 #train# step 7793, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:17.541155 #train# step 7794, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:19.133232 #train# step 7795, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:20.745086 #train# step 7796, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:22.310566 #train# step 7797, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:23.894769 #train# step 7798, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:25.491949 #train# step 7799, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:27.085502 #train# step 7800, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:28.669415 #train# step 7801, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:30.237461 #train# step 7802, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:31.820367 #train# step 7803, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:33.392388 #train# step 7804, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:35.027894 #train# step 7805, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:36.591469 #train# step 7806, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:38.178201 #train# step 7807, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:39.774886 #train# step 7808, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:41.367760 #train# step 7809, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:42.935949 #train# step 7810, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:44.533418 #train# step 7811, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:46.145833 #train# step 7812, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:47.735235 #train# step 7813, loss = 0.9226, cross_entropy loss = 0.9226, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:49.307288 #train# step 7814, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:50.904485 #train# step 7815, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:52.525351 #train# step 7816, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:54.110554 #train# step 7817, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:55.739664 #train# step 7818, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:57.326776 #train# step 7819, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:26:58.922720 #train# step 7820, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:00.503796 #train# step 7821, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:02.111627 #train# step 7822, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:03.718942 #train# step 7823, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:05.312488 #train# step 7824, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:06.891700 #train# step 7825, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:08.480119 #train# step 7826, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:10.059710 #train# step 7827, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:11.644265 #train# step 7828, loss = 0.8863, cross_entropy loss = 0.8863, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:13.256962 #train# step 7829, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:14.839802 #train# step 7830, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:16.452785 #train# step 7831, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:18.048453 #train# step 7832, loss = 0.9136, cross_entropy loss = 0.9136, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:19.653201 #train# step 7833, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:21.214302 #train# step 7834, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:22.801091 #train# step 7835, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:24.371242 #train# step 7836, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:25.960779 #train# step 7837, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:27.587307 #train# step 7838, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:29.160086 #train# step 7839, loss = 0.9203, cross_entropy loss = 0.9203, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:30.761996 #train# step 7840, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:32.326077 #train# step 7841, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:33.898965 #train# step 7842, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:35.502582 #train# step 7843, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:37.101467 #train# step 7844, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:38.714294 #train# step 7845, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:40.325909 #train# step 7846, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:41.925247 #train# step 7847, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:43.552353 #train# step 7848, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:45.168495 #train# step 7849, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:46.786824 #train# step 7850, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:48.379399 #train# step 7851, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:49.979062 #train# step 7852, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:51.572857 #train# step 7853, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:53.136409 #train# step 7854, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:54.728369 #train# step 7855, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:56.294172 #train# step 7856, loss = 0.9194, cross_entropy loss = 0.9194, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:57.874212 #train# step 7857, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:27:59.466261 #train# step 7858, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:01.051062 #train# step 7859, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:02.646444 #train# step 7860, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:04.204714 #train# step 7861, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:05.807086 #train# step 7862, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:07.384710 #train# step 7863, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:08.992753 #train# step 7864, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:10.599136 #train# step 7865, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:12.176486 #train# step 7866, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:13.778763 #train# step 7867, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:15.363228 #train# step 7868, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:16.959734 #train# step 7869, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:18.554264 #train# step 7870, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:20.179681 #train# step 7871, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:21.794112 #train# step 7872, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:23.410524 #train# step 7873, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:25.011140 #train# step 7874, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:26.634644 #train# step 7875, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:28.251126 #train# step 7876, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:29.826362 #train# step 7877, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:31.393270 #train# step 7878, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:32.989851 #train# step 7879, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:34.609149 #train# step 7880, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:36.210544 #train# step 7881, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:37.811466 #train# step 7882, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:39.402499 #train# step 7883, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:40.978841 #train# step 7884, loss = 0.9212, cross_entropy loss = 0.9212, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:42.596901 #train# step 7885, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:44.201659 #train# step 7886, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:45.798430 #train# step 7887, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:47.390575 #train# step 7888, loss = 0.8877, cross_entropy loss = 0.8877, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:48.983313 #train# step 7889, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:50.560915 #train# step 7890, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:52.182699 #train# step 7891, loss = 0.8945, cross_entropy loss = 0.8945, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:53.797334 #train# step 7892, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:55.366825 #train# step 7893, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:56.971445 #train# step 7894, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:28:58.583715 #train# step 7895, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:00.164789 #train# step 7896, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:01.742131 #train# step 7897, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:03.367063 #train# step 7898, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:04.935093 #train# step 7899, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:06.519600 #train# step 7900, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:08.119987 #train# step 7901, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:09.728085 #train# step 7902, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:11.320207 #train# step 7903, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:12.921346 #train# step 7904, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:14.505688 #train# step 7905, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:16.100469 #train# step 7906, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:17.672655 #train# step 7907, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:19.289026 #train# step 7908, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:20.877106 #train# step 7909, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:22.507594 #train# step 7910, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:24.100785 #train# step 7911, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:25.702268 #train# step 7912, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:27.322475 #train# step 7913, loss = 0.9137, cross_entropy loss = 0.9137, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:28.943191 #train# step 7914, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:30.532926 #train# step 7915, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:32.102043 #train# step 7916, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:33.690378 #train# step 7917, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:35.279929 #train# step 7918, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:36.879341 #train# step 7919, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:38.472824 #train# step 7920, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:40.118342 #train# step 7921, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:41.720501 #train# step 7922, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:43.310453 #train# step 7923, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:44.890583 #train# step 7924, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:46.488409 #train# step 7925, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:48.078240 #train# step 7926, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:49.663172 #train# step 7927, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:51.216998 #train# step 7928, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:52.798038 #train# step 7929, loss = 0.9139, cross_entropy loss = 0.9139, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:54.384915 #train# step 7930, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:55.976274 #train# step 7931, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:57.596799 #train# step 7932, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:29:59.191987 #train# step 7933, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:00.821521 #train# step 7934, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:02.423081 #train# step 7935, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:04.018509 #train# step 7936, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:05.578783 #train# step 7937, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:07.151072 #train# step 7938, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:08.714333 #train# step 7939, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:10.296779 #train# step 7940, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:11.920138 #train# step 7941, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:13.513867 #train# step 7942, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:15.101092 #train# step 7943, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:16.697954 #train# step 7944, loss = 0.9193, cross_entropy loss = 0.9193, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:18.292965 #train# step 7945, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:19.897086 #train# step 7946, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:21.484390 #train# step 7947, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:23.073732 #train# step 7948, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:24.661053 #train# step 7949, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:26.253921 #train# step 7950, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:27.851259 #train# step 7951, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:29.465105 #train# step 7952, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:31.062024 #train# step 7953, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:32.679304 #train# step 7954, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:34.248035 #train# step 7955, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:35.826873 #train# step 7956, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:37.403112 #train# step 7957, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:39.045793 #train# step 7958, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:40.638220 #train# step 7959, loss = 0.8886, cross_entropy loss = 0.8886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:42.207477 #train# step 7960, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:43.766432 #train# step 7961, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:45.370377 #train# step 7962, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:46.967883 #train# step 7963, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:48.560075 #train# step 7964, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:50.148654 #train# step 7965, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:51.763973 #train# step 7966, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:53.351503 #train# step 7967, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:54.952040 #train# step 7968, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:56.542755 #train# step 7969, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:58.141993 #train# step 7970, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:30:59.721997 #train# step 7971, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:01.341226 #train# step 7972, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:02.949451 #train# step 7973, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:04.538027 #train# step 7974, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:06.121989 #train# step 7975, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:07.701320 #train# step 7976, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:09.296530 #train# step 7977, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:10.872332 #train# step 7978, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:12.476235 #train# step 7979, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:14.087764 #train# step 7980, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:15.725029 #train# step 7981, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:17.321313 #train# step 7982, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:18.912469 #train# step 7983, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:20.521391 #train# step 7984, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:22.122776 #train# step 7985, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:23.714577 #train# step 7986, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:25.250592 #train# step 7987, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:26.841210 #train# step 7988, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:28.442277 #train# step 7989, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:30.050047 #train# step 7990, loss = 0.8904, cross_entropy loss = 0.8904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:31.634648 #train# step 7991, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:33.210969 #train# step 7992, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:34.812608 #train# step 7993, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:36.393565 #train# step 7994, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:37.979446 #train# step 7995, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:39.568571 #train# step 7996, loss = 0.8856, cross_entropy loss = 0.8856, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:41.161273 #train# step 7997, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:42.754423 #train# step 7998, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:44.365130 #train# step 7999, loss = 0.8935, cross_entropy loss = 0.8935, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:45.976697 #train# step 8000, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:47.620652 #train# step 8001, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:49.193006 #train# step 8002, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:50.760928 #train# step 8003, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:52.322675 #train# step 8004, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:53.905075 #train# step 8005, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:55.509601 #train# step 8006, loss = 0.8869, cross_entropy loss = 0.8869, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:57.107599 #train# step 8007, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:31:58.739010 #train# step 8008, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:00.338510 #train# step 8009, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:01.934506 #train# step 8010, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:03.537156 #train# step 8011, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:05.134507 #train# step 8012, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:06.753718 #train# step 8013, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:08.373378 #train# step 8014, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:09.967669 #train# step 8015, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:11.618055 #train# step 8016, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:13.205345 #train# step 8017, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:14.825262 #train# step 8018, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:16.428183 #train# step 8019, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:18.029759 #train# step 8020, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:19.613867 #train# step 8021, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:21.213585 #train# step 8022, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:22.808139 #train# step 8023, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:24.376839 #train# step 8024, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:25.964302 #train# step 8025, loss = 0.9106, cross_entropy loss = 0.9106, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:27.545310 #train# step 8026, loss = 0.9135, cross_entropy loss = 0.9135, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:29.126241 #train# step 8027, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:30.727194 #train# step 8028, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:32.313539 #train# step 8029, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:33.899145 #train# step 8030, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:35.472011 #train# step 8031, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:37.055238 #train# step 8032, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:38.636708 #train# step 8033, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:40.221587 #train# step 8034, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:41.807534 #train# step 8035, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:43.398582 #train# step 8036, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:44.980086 #train# step 8037, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:46.593277 #train# step 8038, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:48.167359 #train# step 8039, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:49.760638 #train# step 8040, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:51.340860 #train# step 8041, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:52.934697 #train# step 8042, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:54.555908 #train# step 8043, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:56.113425 #train# step 8044, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:57.692315 #train# step 8045, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:32:59.289789 #train# step 8046, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:00.876067 #train# step 8047, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:02.473739 #train# step 8048, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:04.071319 #train# step 8049, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:05.661204 #train# step 8050, loss = 0.9234, cross_entropy loss = 0.9234, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:07.271922 #train# step 8051, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:08.843280 #train# step 8052, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:10.470330 #train# step 8053, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:12.039727 #train# step 8054, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:13.644375 #train# step 8055, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:15.260921 #train# step 8056, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:16.842436 #train# step 8057, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:18.424609 #train# step 8058, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:20.026694 #train# step 8059, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:21.600648 #train# step 8060, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:23.193482 #train# step 8061, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:24.771128 #train# step 8062, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:26.350957 #train# step 8063, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:27.951725 #train# step 8064, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:29.527772 #train# step 8065, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:31.124587 #train# step 8066, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:32.720397 #train# step 8067, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:34.325526 #train# step 8068, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:35.931299 #train# step 8069, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:37.525257 #train# step 8070, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:39.111040 #train# step 8071, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:40.684695 #train# step 8072, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:42.295275 #train# step 8073, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:43.926306 #train# step 8074, loss = 0.8911, cross_entropy loss = 0.8911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:45.515652 #train# step 8075, loss = 0.9110, cross_entropy loss = 0.9110, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:47.116541 #train# step 8076, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:48.711142 #train# step 8077, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:50.316001 #train# step 8078, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:51.907798 #train# step 8079, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:53.529551 #train# step 8080, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:55.141699 #train# step 8081, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:56.740507 #train# step 8082, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:58.322942 #train# step 8083, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:33:59.949139 #train# step 8084, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:01.551008 #train# step 8085, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:03.163808 #train# step 8086, loss = 0.8836, cross_entropy loss = 0.8836, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:04.761306 #train# step 8087, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:06.347172 #train# step 8088, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:07.899990 #train# step 8089, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:09.521270 #train# step 8090, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:11.099468 #train# step 8091, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:12.690647 #train# step 8092, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:14.289657 #train# step 8093, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:15.919507 #train# step 8094, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:17.513268 #train# step 8095, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:19.090623 #train# step 8096, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:20.663989 #train# step 8097, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:22.247631 #train# step 8098, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:23.829761 #train# step 8099, loss = 0.9127, cross_entropy loss = 0.9127, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:25.440217 #train# step 8100, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:27.023005 #train# step 8101, loss = 0.9153, cross_entropy loss = 0.9153, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:28.626220 #train# step 8102, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:30.234852 #train# step 8103, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:31.851216 #train# step 8104, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:33.464819 #train# step 8105, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:35.052004 #train# step 8106, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:36.638620 #train# step 8107, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:38.225155 #train# step 8108, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:39.818619 #train# step 8109, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:41.413949 #train# step 8110, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:43.012688 #train# step 8111, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:44.575482 #train# step 8112, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:46.184662 #train# step 8113, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:47.783171 #train# step 8114, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:49.402060 #train# step 8115, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:50.986871 #train# step 8116, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:52.580559 #train# step 8117, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:54.176512 #train# step 8118, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:55.769456 #train# step 8119, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:57.370123 #train# step 8120, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:34:58.940763 #train# step 8121, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:00.542355 #train# step 8122, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:02.121740 #train# step 8123, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:03.695415 #train# step 8124, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:05.314218 #train# step 8125, loss = 0.8991, cross_entropy loss = 0.8991, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:06.912128 #train# step 8126, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:08.501955 #train# step 8127, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:10.061604 #train# step 8128, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:11.651113 #train# step 8129, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:13.267803 #train# step 8130, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:14.865397 #train# step 8131, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:16.441984 #train# step 8132, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:18.005641 #train# step 8133, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:19.587298 #train# step 8134, loss = 0.8899, cross_entropy loss = 0.8899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:21.169302 #train# step 8135, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:22.773386 #train# step 8136, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:24.372282 #train# step 8137, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:25.973186 #train# step 8138, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:27.568635 #train# step 8139, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:29.148362 #train# step 8140, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:30.736030 #train# step 8141, loss = 0.8887, cross_entropy loss = 0.8887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:32.297098 #train# step 8142, loss = 0.9174, cross_entropy loss = 0.9174, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:33.900586 #train# step 8143, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:35.508735 #train# step 8144, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:37.089068 #train# step 8145, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:38.706302 #train# step 8146, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:40.336881 #train# step 8147, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:41.932528 #train# step 8148, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:43.532262 #train# step 8149, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:45.143989 #train# step 8150, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:46.757592 #train# step 8151, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:48.342251 #train# step 8152, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:49.919181 #train# step 8153, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:51.532611 #train# step 8154, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:53.143166 #train# step 8155, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:54.749573 #train# step 8156, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:56.330152 #train# step 8157, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:57.916541 #train# step 8158, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:35:59.475928 #train# step 8159, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:01.067068 #train# step 8160, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:02.686816 #train# step 8161, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:04.316073 #train# step 8162, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:05.940848 #train# step 8163, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:07.536950 #train# step 8164, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:09.137331 #train# step 8165, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:10.736115 #train# step 8166, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:12.339592 #train# step 8167, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:13.939358 #train# step 8168, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:15.522721 #train# step 8169, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:17.118663 #train# step 8170, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:18.703781 #train# step 8171, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:20.287593 #train# step 8172, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:21.904504 #train# step 8173, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:23.492228 #train# step 8174, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:25.071765 #train# step 8175, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:26.632954 #train# step 8176, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:28.265220 #train# step 8177, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:29.837871 #train# step 8178, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:31.460410 #train# step 8179, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:33.040680 #train# step 8180, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:34.641025 #train# step 8181, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:36.261122 #train# step 8182, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:37.859687 #train# step 8183, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:39.476337 #train# step 8184, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:41.065906 #train# step 8185, loss = 0.9264, cross_entropy loss = 0.9264, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:42.631480 #train# step 8186, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:44.258018 #train# step 8187, loss = 0.9182, cross_entropy loss = 0.9182, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:45.824289 #train# step 8188, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:47.409283 #train# step 8189, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:49.000259 #train# step 8190, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:50.610836 #train# step 8191, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:52.209420 #train# step 8192, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:53.808534 #train# step 8193, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:55.399883 #train# step 8194, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:57.021261 #train# step 8195, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:36:58.656456 #train# step 8196, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:00.232951 #train# step 8197, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:01.809547 #train# step 8198, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:03.433980 #train# step 8199, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:05.021770 #train# step 8200, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:06.632451 #train# step 8201, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:08.254108 #train# step 8202, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:09.854988 #train# step 8203, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:11.437698 #train# step 8204, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:13.030007 #train# step 8205, loss = 0.8878, cross_entropy loss = 0.8878, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:14.610946 #train# step 8206, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:16.232024 #train# step 8207, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:17.810762 #train# step 8208, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:19.384702 #train# step 8209, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:20.969098 #train# step 8210, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:22.570911 #train# step 8211, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:24.175792 #train# step 8212, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:25.758899 #train# step 8213, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:27.328856 #train# step 8214, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:28.930660 #train# step 8215, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:30.532538 #train# step 8216, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:32.124294 #train# step 8217, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:33.716251 #train# step 8218, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:35.299114 #train# step 8219, loss = 0.9152, cross_entropy loss = 0.9152, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:36.877432 #train# step 8220, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:38.456090 #train# step 8221, loss = 0.8911, cross_entropy loss = 0.8911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:40.044777 #train# step 8222, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:41.613396 #train# step 8223, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:43.207426 #train# step 8224, loss = 0.8813, cross_entropy loss = 0.8813, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:44.809197 #train# step 8225, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:46.400696 #train# step 8226, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:47.996506 #train# step 8227, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:49.578757 #train# step 8228, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:51.186916 #train# step 8229, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:52.758601 #train# step 8230, loss = 0.9200, cross_entropy loss = 0.9200, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:54.348368 #train# step 8231, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:55.950286 #train# step 8232, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:57.536788 #train# step 8233, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:37:59.125173 #train# step 8234, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:00.697218 #train# step 8235, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:02.274584 #train# step 8236, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:03.880428 #train# step 8237, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:05.499933 #train# step 8238, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:07.096264 #train# step 8239, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:08.691151 #train# step 8240, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:10.267503 #train# step 8241, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:11.860388 #train# step 8242, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:13.452403 #train# step 8243, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:15.066386 #train# step 8244, loss = 0.8996, cross_entropy loss = 0.8996, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:16.673430 #train# step 8245, loss = 0.8866, cross_entropy loss = 0.8866, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:18.271241 #train# step 8246, loss = 0.9001, cross_entropy loss = 0.9001, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:19.876607 #train# step 8247, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:21.490647 #train# step 8248, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:23.074353 #train# step 8249, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:24.662121 #train# step 8250, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:26.280645 #train# step 8251, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:27.870380 #train# step 8252, loss = 0.9155, cross_entropy loss = 0.9155, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:29.450622 #train# step 8253, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:31.000968 #train# step 8254, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:32.595133 #train# step 8255, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:34.196493 #train# step 8256, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:35.823318 #train# step 8257, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:37.411715 #train# step 8258, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:38.985495 #train# step 8259, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:40.611040 #train# step 8260, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:42.222533 #train# step 8261, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:43.827102 #train# step 8262, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:45.411122 #train# step 8263, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:46.990941 #train# step 8264, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:48.564986 #train# step 8265, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:50.181982 #train# step 8266, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:51.800351 #train# step 8267, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:53.358393 #train# step 8268, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:54.958829 #train# step 8269, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:56.584406 #train# step 8270, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:58.169554 #train# step 8271, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:38:59.783273 #train# step 8272, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:01.375234 #train# step 8273, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:02.936283 #train# step 8274, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:04.563996 #train# step 8275, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:06.176860 #train# step 8276, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:07.785598 #train# step 8277, loss = 0.8841, cross_entropy loss = 0.8841, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:09.395814 #train# step 8278, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:10.999831 #train# step 8279, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:12.638288 #train# step 8280, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:14.249505 #train# step 8281, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:15.809592 #train# step 8282, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:17.422767 #train# step 8283, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:19.034019 #train# step 8284, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:20.616421 #train# step 8285, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:22.220781 #train# step 8286, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:23.804389 #train# step 8287, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:25.374650 #train# step 8288, loss = 0.9121, cross_entropy loss = 0.9121, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:26.976778 #train# step 8289, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:28.595821 #train# step 8290, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:30.203028 #train# step 8291, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:31.795354 #train# step 8292, loss = 0.8868, cross_entropy loss = 0.8868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:33.357360 #train# step 8293, loss = 0.9136, cross_entropy loss = 0.9136, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:34.966703 #train# step 8294, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:36.526439 #train# step 8295, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:38.137425 #train# step 8296, loss = 0.8884, cross_entropy loss = 0.8884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:39.726964 #train# step 8297, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:41.316471 #train# step 8298, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:42.903889 #train# step 8299, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:44.500039 #train# step 8300, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:46.084797 #train# step 8301, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:47.706421 #train# step 8302, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:49.277464 #train# step 8303, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:50.869379 #train# step 8304, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:52.442159 #train# step 8305, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:54.030165 #train# step 8306, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:55.617920 #train# step 8307, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:57.201982 #train# step 8308, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:39:58.783341 #train# step 8309, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:00.408085 #train# step 8310, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:01.963305 #train# step 8311, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:03.538259 #train# step 8312, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:05.148146 #train# step 8313, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:06.736546 #train# step 8314, loss = 0.8890, cross_entropy loss = 0.8890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:08.345313 #train# step 8315, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:09.904449 #train# step 8316, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:11.501861 #train# step 8317, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:13.089499 #train# step 8318, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:14.705893 #train# step 8319, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:16.305595 #train# step 8320, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:17.893348 #train# step 8321, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:19.477787 #train# step 8322, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:21.056432 #train# step 8323, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:22.673115 #train# step 8324, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:24.322358 #train# step 8325, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:25.904805 #train# step 8326, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:27.499419 #train# step 8327, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:29.111277 #train# step 8328, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:30.687396 #train# step 8329, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:32.268376 #train# step 8330, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:33.854464 #train# step 8331, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:35.437151 #train# step 8332, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:37.023398 #train# step 8333, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:38.617968 #train# step 8334, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:40.203660 #train# step 8335, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:41.822272 #train# step 8336, loss = 0.8911, cross_entropy loss = 0.8911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:43.437350 #train# step 8337, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:45.018120 #train# step 8338, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:46.630624 #train# step 8339, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:48.219280 #train# step 8340, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:49.842586 #train# step 8341, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:51.430033 #train# step 8342, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:53.019276 #train# step 8343, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:54.591985 #train# step 8344, loss = 0.8823, cross_entropy loss = 0.8823, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:56.189213 #train# step 8345, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:57.803732 #train# step 8346, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:40:59.405134 #train# step 8347, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:01.010424 #train# step 8348, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:02.589180 #train# step 8349, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:04.169560 #train# step 8350, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:05.765628 #train# step 8351, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:07.342139 #train# step 8352, loss = 0.9237, cross_entropy loss = 0.9237, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:08.964842 #train# step 8353, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:10.540964 #train# step 8354, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:12.125982 #train# step 8355, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:13.693587 #train# step 8356, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:15.341370 #train# step 8357, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:16.947766 #train# step 8358, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:18.545361 #train# step 8359, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:20.140151 #train# step 8360, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:21.724514 #train# step 8361, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:23.335803 #train# step 8362, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:24.909618 #train# step 8363, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:26.521347 #train# step 8364, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:28.140605 #train# step 8365, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:29.715828 #train# step 8366, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:31.300634 #train# step 8367, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:32.883674 #train# step 8368, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:34.479832 #train# step 8369, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:36.094787 #train# step 8370, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:37.682775 #train# step 8371, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:39.279142 #train# step 8372, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:40.891198 #train# step 8373, loss = 0.8884, cross_entropy loss = 0.8884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:42.477915 #train# step 8374, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:44.090245 #train# step 8375, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:45.692329 #train# step 8376, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:47.304299 #train# step 8377, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:48.899269 #train# step 8378, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:50.525477 #train# step 8379, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:52.109282 #train# step 8380, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:53.718420 #train# step 8381, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:55.340245 #train# step 8382, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:56.923082 #train# step 8383, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:41:58.521598 #train# step 8384, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:00.106227 #train# step 8385, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:01.654191 #train# step 8386, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:03.250720 #train# step 8387, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:04.876910 #train# step 8388, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:06.472790 #train# step 8389, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:08.046812 #train# step 8390, loss = 0.9220, cross_entropy loss = 0.9220, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:09.612004 #train# step 8391, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:11.211169 #train# step 8392, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:12.819724 #train# step 8393, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:14.432079 #train# step 8394, loss = 0.8869, cross_entropy loss = 0.8869, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:16.008172 #train# step 8395, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:17.638018 #train# step 8396, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:19.245309 #train# step 8397, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:20.850309 #train# step 8398, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:22.439374 #train# step 8399, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:24.023913 #train# step 8400, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:25.595656 #train# step 8401, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:27.175177 #train# step 8402, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:28.773110 #train# step 8403, loss = 0.8828, cross_entropy loss = 0.8828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:30.360643 #train# step 8404, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:31.929786 #train# step 8405, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:33.563283 #train# step 8406, loss = 0.8877, cross_entropy loss = 0.8877, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:35.192190 #train# step 8407, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:36.731388 #train# step 8408, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:38.320853 #train# step 8409, loss = 0.9154, cross_entropy loss = 0.9154, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:39.905178 #train# step 8410, loss = 0.8839, cross_entropy loss = 0.8839, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:41.520564 #train# step 8411, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:43.116634 #train# step 8412, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:44.708142 #train# step 8413, loss = 0.8995, cross_entropy loss = 0.8995, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:46.328248 #train# step 8414, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:47.909494 #train# step 8415, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:49.492625 #train# step 8416, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:51.081651 #train# step 8417, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:52.670370 #train# step 8418, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:54.262400 #train# step 8419, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:55.868802 #train# step 8420, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:57.477569 #train# step 8421, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:42:59.057691 #train# step 8422, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:00.661791 #train# step 8423, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:02.266590 #train# step 8424, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:03.866159 #train# step 8425, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:05.475968 #train# step 8426, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:07.050814 #train# step 8427, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:08.660957 #train# step 8428, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:10.281464 #train# step 8429, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:11.863676 #train# step 8430, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:13.477688 #train# step 8431, loss = 0.8881, cross_entropy loss = 0.8881, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:15.075324 #train# step 8432, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:16.645944 #train# step 8433, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:18.216142 #train# step 8434, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:19.807380 #train# step 8435, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:21.430622 #train# step 8436, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:23.023147 #train# step 8437, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:24.602842 #train# step 8438, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:26.181637 #train# step 8439, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:27.745256 #train# step 8440, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:29.353148 #train# step 8441, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:30.933752 #train# step 8442, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:32.514997 #train# step 8443, loss = 0.9177, cross_entropy loss = 0.9177, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:34.107394 #train# step 8444, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:35.736784 #train# step 8445, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:37.327744 #train# step 8446, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:38.901821 #train# step 8447, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:40.484362 #train# step 8448, loss = 0.9141, cross_entropy loss = 0.9141, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:42.068978 #train# step 8449, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:43.701570 #train# step 8450, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:45.289726 #train# step 8451, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:46.916225 #train# step 8452, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:48.519315 #train# step 8453, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:50.125741 #train# step 8454, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:51.700018 #train# step 8455, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:53.290418 #train# step 8456, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:54.915542 #train# step 8457, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:56.503621 #train# step 8458, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:58.102220 #train# step 8459, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:43:59.682460 #train# step 8460, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:01.285014 #train# step 8461, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:02.863957 #train# step 8462, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:04.490618 #train# step 8463, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:06.099414 #train# step 8464, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:07.699514 #train# step 8465, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:09.280757 #train# step 8466, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:10.846315 #train# step 8467, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:12.445089 #train# step 8468, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:14.062269 #train# step 8469, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:15.642673 #train# step 8470, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:17.238956 #train# step 8471, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:18.834038 #train# step 8472, loss = 0.8883, cross_entropy loss = 0.8883, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:20.432908 #train# step 8473, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:22.000859 #train# step 8474, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:23.626456 #train# step 8475, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:25.213938 #train# step 8476, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:26.814466 #train# step 8477, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:28.436343 #train# step 8478, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:30.016821 #train# step 8479, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:31.618774 #train# step 8480, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:33.236316 #train# step 8481, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:34.843005 #train# step 8482, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:36.459153 #train# step 8483, loss = 0.9118, cross_entropy loss = 0.9118, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:38.043738 #train# step 8484, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:39.640267 #train# step 8485, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:41.206548 #train# step 8486, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:42.786943 #train# step 8487, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:44.370843 #train# step 8488, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:45.947662 #train# step 8489, loss = 0.8849, cross_entropy loss = 0.8849, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:47.551402 #train# step 8490, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:49.140133 #train# step 8491, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:50.775682 #train# step 8492, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:52.352002 #train# step 8493, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:53.964992 #train# step 8494, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:55.519390 #train# step 8495, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:57.113354 #train# step 8496, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:44:58.734164 #train# step 8497, loss = 0.9123, cross_entropy loss = 0.9123, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:00.367407 #train# step 8498, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:01.949170 #train# step 8499, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:03.525020 #train# step 8500, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:05.107609 #train# step 8501, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:06.685960 #train# step 8502, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:08.313069 #train# step 8503, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:09.931002 #train# step 8504, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:11.533064 #train# step 8505, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:13.116969 #train# step 8506, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:14.697212 #train# step 8507, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:16.295843 #train# step 8508, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:17.867431 #train# step 8509, loss = 0.9160, cross_entropy loss = 0.9160, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:19.490854 #train# step 8510, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:21.079847 #train# step 8511, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:22.649238 #train# step 8512, loss = 0.9126, cross_entropy loss = 0.9126, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:24.230642 #train# step 8513, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:25.856752 #train# step 8514, loss = 0.9162, cross_entropy loss = 0.9162, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:27.456855 #train# step 8515, loss = 0.8904, cross_entropy loss = 0.8904, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:29.072141 #train# step 8516, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:30.654935 #train# step 8517, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:32.233631 #train# step 8518, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:33.814740 #train# step 8519, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:35.403205 #train# step 8520, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:36.974253 #train# step 8521, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:38.572657 #train# step 8522, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:40.171467 #train# step 8523, loss = 0.9216, cross_entropy loss = 0.9216, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:41.767706 #train# step 8524, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:43.374372 #train# step 8525, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:44.970304 #train# step 8526, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:46.559477 #train# step 8527, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:48.156551 #train# step 8528, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:49.740699 #train# step 8529, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:51.333791 #train# step 8530, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:52.938686 #train# step 8531, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:54.522870 #train# step 8532, loss = 0.9134, cross_entropy loss = 0.9134, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:56.156571 #train# step 8533, loss = 0.8834, cross_entropy loss = 0.8834, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:57.739123 #train# step 8534, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:45:59.333222 #train# step 8535, loss = 0.8955, cross_entropy loss = 0.8955, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:00.928378 #train# step 8536, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:02.524831 #train# step 8537, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:04.133364 #train# step 8538, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:05.714839 #train# step 8539, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:07.281135 #train# step 8540, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:08.868604 #train# step 8541, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:10.458636 #train# step 8542, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:12.058493 #train# step 8543, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:13.672146 #train# step 8544, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:15.286254 #train# step 8545, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:16.889104 #train# step 8546, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:18.523812 #train# step 8547, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:20.097705 #train# step 8548, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:21.670643 #train# step 8549, loss = 0.8883, cross_entropy loss = 0.8883, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:23.277560 #train# step 8550, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:24.906511 #train# step 8551, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:26.486824 #train# step 8552, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:28.082338 #train# step 8553, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:29.676424 #train# step 8554, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:31.299242 #train# step 8555, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:32.905400 #train# step 8556, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:34.502182 #train# step 8557, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:36.099004 #train# step 8558, loss = 0.8984, cross_entropy loss = 0.8984, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:37.678984 #train# step 8559, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:39.250404 #train# step 8560, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:40.843121 #train# step 8561, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:42.427811 #train# step 8562, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:44.017892 #train# step 8563, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:45.616491 #train# step 8564, loss = 0.8872, cross_entropy loss = 0.8872, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:47.243349 #train# step 8565, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:48.849968 #train# step 8566, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:50.453460 #train# step 8567, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:52.072182 #train# step 8568, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:53.694131 #train# step 8569, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:55.272876 #train# step 8570, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:56.872784 #train# step 8571, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:46:58.477498 #train# step 8572, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:00.107140 #train# step 8573, loss = 0.8899, cross_entropy loss = 0.8899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:01.729056 #train# step 8574, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:03.343093 #train# step 8575, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:04.932352 #train# step 8576, loss = 0.8881, cross_entropy loss = 0.8881, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:06.560452 #train# step 8577, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:08.169647 #train# step 8578, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:09.754438 #train# step 8579, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:11.389742 #train# step 8580, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:12.948473 #train# step 8581, loss = 0.9142, cross_entropy loss = 0.9142, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:14.538623 #train# step 8582, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:16.119664 #train# step 8583, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:17.695028 #train# step 8584, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:19.318577 #train# step 8585, loss = 0.8844, cross_entropy loss = 0.8844, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:20.877244 #train# step 8586, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:22.443782 #train# step 8587, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:24.042612 #train# step 8588, loss = 0.9202, cross_entropy loss = 0.9202, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:25.633189 #train# step 8589, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:27.228389 #train# step 8590, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:28.793030 #train# step 8591, loss = 0.9131, cross_entropy loss = 0.9131, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:30.377635 #train# step 8592, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:31.959485 #train# step 8593, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:33.582499 #train# step 8594, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:35.161567 #train# step 8595, loss = 0.9187, cross_entropy loss = 0.9187, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:36.715007 #train# step 8596, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:38.294682 #train# step 8597, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:39.920101 #train# step 8598, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:41.528534 #train# step 8599, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:43.117344 #train# step 8600, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:44.721490 #train# step 8601, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:46.294023 #train# step 8602, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:47.907737 #train# step 8603, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:49.493506 #train# step 8604, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:51.074090 #train# step 8605, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:52.672086 #train# step 8606, loss = 0.8870, cross_entropy loss = 0.8870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:54.291211 #train# step 8607, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:55.896901 #train# step 8608, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:57.473578 #train# step 8609, loss = 0.9077, cross_entropy loss = 0.9077, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:47:59.096053 #train# step 8610, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:00.720008 #train# step 8611, loss = 0.8862, cross_entropy loss = 0.8862, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:02.292173 #train# step 8612, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:03.891789 #train# step 8613, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:05.487441 #train# step 8614, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:07.083499 #train# step 8615, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:08.666253 #train# step 8616, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:10.253816 #train# step 8617, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:11.838989 #train# step 8618, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:13.436216 #train# step 8619, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:15.024738 #train# step 8620, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:16.626107 #train# step 8621, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:18.208553 #train# step 8622, loss = 0.9190, cross_entropy loss = 0.9190, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:19.791637 #train# step 8623, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:21.419438 #train# step 8624, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:23.011383 #train# step 8625, loss = 0.9163, cross_entropy loss = 0.9163, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:24.615363 #train# step 8626, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:26.185438 #train# step 8627, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:27.769797 #train# step 8628, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:29.369340 #train# step 8629, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:30.954340 #train# step 8630, loss = 0.8863, cross_entropy loss = 0.8863, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:32.549308 #train# step 8631, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:34.153962 #train# step 8632, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:35.725301 #train# step 8633, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:37.296607 #train# step 8634, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:38.886230 #train# step 8635, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:40.478093 #train# step 8636, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:42.074375 #train# step 8637, loss = 0.9149, cross_entropy loss = 0.9149, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:43.639983 #train# step 8638, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:45.233052 #train# step 8639, loss = 0.9138, cross_entropy loss = 0.9138, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:46.842992 #train# step 8640, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:48.421100 #train# step 8641, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:50.038203 #train# step 8642, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:51.637325 #train# step 8643, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:53.246091 #train# step 8644, loss = 0.8911, cross_entropy loss = 0.8911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:54.864233 #train# step 8645, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:56.452088 #train# step 8646, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:58.070825 #train# step 8647, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:48:59.646331 #train# step 8648, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:01.236875 #train# step 8649, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:02.848391 #train# step 8650, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:04.487902 #train# step 8651, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:06.069297 #train# step 8652, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:07.644741 #train# step 8653, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:09.250061 #train# step 8654, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:10.851738 #train# step 8655, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:12.478861 #train# step 8656, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:14.067018 #train# step 8657, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:15.664149 #train# step 8658, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:17.262736 #train# step 8659, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:18.841764 #train# step 8660, loss = 0.9168, cross_entropy loss = 0.9168, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:20.462717 #train# step 8661, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:22.032526 #train# step 8662, loss = 0.8911, cross_entropy loss = 0.8911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:23.617031 #train# step 8663, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:25.217312 #train# step 8664, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:26.849983 #train# step 8665, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:28.420555 #train# step 8666, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:29.997232 #train# step 8667, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:31.587637 #train# step 8668, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:33.204628 #train# step 8669, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:34.792061 #train# step 8670, loss = 0.9077, cross_entropy loss = 0.9077, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:36.369619 #train# step 8671, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:37.959134 #train# step 8672, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:39.577691 #train# step 8673, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:41.159032 #train# step 8674, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:42.734225 #train# step 8675, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:44.319160 #train# step 8676, loss = 0.9132, cross_entropy loss = 0.9132, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:45.913158 #train# step 8677, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:47.528222 #train# step 8678, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:49.127457 #train# step 8679, loss = 0.8877, cross_entropy loss = 0.8877, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:50.713101 #train# step 8680, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:52.292049 #train# step 8681, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:53.868840 #train# step 8682, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:55.466697 #train# step 8683, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:57.045406 #train# step 8684, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:49:58.657178 #train# step 8685, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:00.271021 #train# step 8686, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:01.865943 #train# step 8687, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:03.464149 #train# step 8688, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:05.081145 #train# step 8689, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:06.654355 #train# step 8690, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:08.240468 #train# step 8691, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:09.843900 #train# step 8692, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:11.455197 #train# step 8693, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:13.050049 #train# step 8694, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:14.633651 #train# step 8695, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:16.229926 #train# step 8696, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:17.832585 #train# step 8697, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:19.424330 #train# step 8698, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:21.015361 #train# step 8699, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:22.615367 #train# step 8700, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:24.222842 #train# step 8701, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:25.805819 #train# step 8702, loss = 0.8855, cross_entropy loss = 0.8855, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:27.408939 #train# step 8703, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:28.998322 #train# step 8704, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:30.567818 #train# step 8705, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:32.147499 #train# step 8706, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:33.711685 #train# step 8707, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:35.308236 #train# step 8708, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:36.903721 #train# step 8709, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:38.467460 #train# step 8710, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:40.048518 #train# step 8711, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:41.664464 #train# step 8712, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:43.254912 #train# step 8713, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:44.836655 #train# step 8714, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:46.438761 #train# step 8715, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:48.056917 #train# step 8716, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:49.656100 #train# step 8717, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:51.268553 #train# step 8718, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:52.873038 #train# step 8719, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:54.466300 #train# step 8720, loss = 0.9165, cross_entropy loss = 0.9165, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:56.066406 #train# step 8721, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:57.655519 #train# step 8722, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:50:59.234681 #train# step 8723, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:00.823428 #train# step 8724, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:02.406601 #train# step 8725, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:04.007265 #train# step 8726, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:05.603148 #train# step 8727, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:07.212442 #train# step 8728, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:08.803322 #train# step 8729, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:10.372104 #train# step 8730, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:11.945171 #train# step 8731, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:13.542045 #train# step 8732, loss = 0.8804, cross_entropy loss = 0.8804, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:15.143442 #train# step 8733, loss = 0.8902, cross_entropy loss = 0.8902, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:16.718175 #train# step 8734, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:18.337232 #train# step 8735, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:19.931203 #train# step 8736, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:21.513195 #train# step 8737, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:23.122926 #train# step 8738, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:24.727018 #train# step 8739, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:26.358221 #train# step 8740, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:27.964672 #train# step 8741, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:29.553224 #train# step 8742, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:31.164540 #train# step 8743, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:32.783221 #train# step 8744, loss = 0.9260, cross_entropy loss = 0.9260, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:34.396533 #train# step 8745, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:35.996120 #train# step 8746, loss = 0.8895, cross_entropy loss = 0.8895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:37.599786 #train# step 8747, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:39.224517 #train# step 8748, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:40.841723 #train# step 8749, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:42.436074 #train# step 8750, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:44.006977 #train# step 8751, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:45.630059 #train# step 8752, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:47.216846 #train# step 8753, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:48.796485 #train# step 8754, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:50.369849 #train# step 8755, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:51.992557 #train# step 8756, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:53.584009 #train# step 8757, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:55.172168 #train# step 8758, loss = 0.9102, cross_entropy loss = 0.9102, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:56.780763 #train# step 8759, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:58.374764 #train# step 8760, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:51:59.956469 #train# step 8761, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:01.540394 #train# step 8762, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:03.129487 #train# step 8763, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:04.697752 #train# step 8764, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:06.260514 #train# step 8765, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:07.855432 #train# step 8766, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:09.444203 #train# step 8767, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:11.039975 #train# step 8768, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:12.639159 #train# step 8769, loss = 0.8838, cross_entropy loss = 0.8838, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:14.265243 #train# step 8770, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:15.862784 #train# step 8771, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:17.471244 #train# step 8772, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:19.057931 #train# step 8773, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:20.638025 #train# step 8774, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:22.220416 #train# step 8775, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:23.811698 #train# step 8776, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:25.409760 #train# step 8777, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:27.007483 #train# step 8778, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:28.595037 #train# step 8779, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:30.166575 #train# step 8780, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:31.751335 #train# step 8781, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:33.351383 #train# step 8782, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:34.948380 #train# step 8783, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:36.535142 #train# step 8784, loss = 0.9124, cross_entropy loss = 0.9124, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:38.099730 #train# step 8785, loss = 0.9080, cross_entropy loss = 0.9080, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:39.726481 #train# step 8786, loss = 0.8917, cross_entropy loss = 0.8917, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:41.342812 #train# step 8787, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:42.939110 #train# step 8788, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:44.561386 #train# step 8789, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:46.182496 #train# step 8790, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:47.754735 #train# step 8791, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:49.327870 #train# step 8792, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:50.939829 #train# step 8793, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:52.532558 #train# step 8794, loss = 0.8874, cross_entropy loss = 0.8874, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:54.110858 #train# step 8795, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:55.678558 #train# step 8796, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:57.264989 #train# step 8797, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:52:58.846088 #train# step 8798, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:00.409552 #train# step 8799, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:02.030567 #train# step 8800, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:03.659491 #train# step 8801, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:05.250720 #train# step 8802, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:06.873391 #train# step 8803, loss = 0.8894, cross_entropy loss = 0.8894, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:08.469655 #train# step 8804, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:10.072952 #train# step 8805, loss = 0.8886, cross_entropy loss = 0.8886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:11.659420 #train# step 8806, loss = 0.9042, cross_entropy loss = 0.9042, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:13.231440 #train# step 8807, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:14.825027 #train# step 8808, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:16.388052 #train# step 8809, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:17.995969 #train# step 8810, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:19.608302 #train# step 8811, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:21.196452 #train# step 8812, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:22.784790 #train# step 8813, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:24.370411 #train# step 8814, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:25.986534 #train# step 8815, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:27.564354 #train# step 8816, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:29.154136 #train# step 8817, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:30.757270 #train# step 8818, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:32.355394 #train# step 8819, loss = 0.9127, cross_entropy loss = 0.9127, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:33.984134 #train# step 8820, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:35.569493 #train# step 8821, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:37.160201 #train# step 8822, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:38.765479 #train# step 8823, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:40.364151 #train# step 8824, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:41.963023 #train# step 8825, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:43.581626 #train# step 8826, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:45.217111 #train# step 8827, loss = 0.9059, cross_entropy loss = 0.9059, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:46.829291 #train# step 8828, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:48.397450 #train# step 8829, loss = 0.9166, cross_entropy loss = 0.9166, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:49.977148 #train# step 8830, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:51.570716 #train# step 8831, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:53.191488 #train# step 8832, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:54.814579 #train# step 8833, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:56.408529 #train# step 8834, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:57.994831 #train# step 8835, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:53:59.598773 #train# step 8836, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:01.185507 #train# step 8837, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:02.757384 #train# step 8838, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:04.347613 #train# step 8839, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:05.936589 #train# step 8840, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:07.555464 #train# step 8841, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:09.158321 #train# step 8842, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:10.721688 #train# step 8843, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:12.290635 #train# step 8844, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:13.874515 #train# step 8845, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:15.483488 #train# step 8846, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:17.072572 #train# step 8847, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:18.670470 #train# step 8848, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:20.251667 #train# step 8849, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:21.852195 #train# step 8850, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:23.448080 #train# step 8851, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:25.056203 #train# step 8852, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:26.649697 #train# step 8853, loss = 0.9084, cross_entropy loss = 0.9084, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:28.220112 #train# step 8854, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:29.807341 #train# step 8855, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:31.389531 #train# step 8856, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:32.985343 #train# step 8857, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:34.588416 #train# step 8858, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:36.205379 #train# step 8859, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:37.770716 #train# step 8860, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:39.370063 #train# step 8861, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:40.970573 #train# step 8862, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:42.628793 #train# step 8863, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:44.235686 #train# step 8864, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:45.824713 #train# step 8865, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:47.412918 #train# step 8866, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:49.009681 #train# step 8867, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:50.581297 #train# step 8868, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:52.171045 #train# step 8869, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:53.760711 #train# step 8870, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:55.371254 #train# step 8871, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:56.956590 #train# step 8872, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:54:58.564383 #train# step 8873, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:00.142126 #train# step 8874, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:01.740531 #train# step 8875, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:03.350225 #train# step 8876, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:04.938102 #train# step 8877, loss = 0.9228, cross_entropy loss = 0.9228, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:06.543049 #train# step 8878, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:08.158996 #train# step 8879, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:09.760752 #train# step 8880, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:11.323236 #train# step 8881, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:12.922200 #train# step 8882, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:14.519876 #train# step 8883, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:16.108623 #train# step 8884, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:17.704513 #train# step 8885, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:19.316314 #train# step 8886, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:20.904428 #train# step 8887, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:22.502234 #train# step 8888, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:24.116469 #train# step 8889, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:25.727270 #train# step 8890, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:27.328573 #train# step 8891, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:28.910239 #train# step 8892, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:30.520196 #train# step 8893, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:32.111549 #train# step 8894, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:33.706171 #train# step 8895, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:35.284437 #train# step 8896, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:36.871904 #train# step 8897, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:38.459277 #train# step 8898, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:40.052182 #train# step 8899, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:41.633165 #train# step 8900, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:43.211557 #train# step 8901, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:44.816274 #train# step 8902, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:46.408418 #train# step 8903, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:47.996755 #train# step 8904, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:49.615809 #train# step 8905, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:51.187696 #train# step 8906, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:52.811432 #train# step 8907, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:54.407412 #train# step 8908, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:56.022835 #train# step 8909, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:57.593016 #train# step 8910, loss = 0.9057, cross_entropy loss = 0.9057, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:55:59.191616 #train# step 8911, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:00.775311 #train# step 8912, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:02.371958 #train# step 8913, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:03.945719 #train# step 8914, loss = 0.8981, cross_entropy loss = 0.8981, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:05.542452 #train# step 8915, loss = 0.8858, cross_entropy loss = 0.8858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:07.124993 #train# step 8916, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:08.722106 #train# step 8917, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:10.335617 #train# step 8918, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:11.910705 #train# step 8919, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:13.494733 #train# step 8920, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:15.104865 #train# step 8921, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:16.687458 #train# step 8922, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:18.294046 #train# step 8923, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:19.858533 #train# step 8924, loss = 0.9170, cross_entropy loss = 0.9170, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:21.454634 #train# step 8925, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:23.044351 #train# step 8926, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:24.620595 #train# step 8927, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:26.222997 #train# step 8928, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:27.816963 #train# step 8929, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:29.420129 #train# step 8930, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:30.995931 #train# step 8931, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:32.606665 #train# step 8932, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:34.192189 #train# step 8933, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:35.779604 #train# step 8934, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:37.368816 #train# step 8935, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:38.988929 #train# step 8936, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:40.579475 #train# step 8937, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:42.168695 #train# step 8938, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:43.751667 #train# step 8939, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:45.353400 #train# step 8940, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:46.969285 #train# step 8941, loss = 0.8886, cross_entropy loss = 0.8886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:48.544778 #train# step 8942, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:50.143628 #train# step 8943, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:51.744414 #train# step 8944, loss = 0.8849, cross_entropy loss = 0.8849, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:53.344470 #train# step 8945, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:54.939176 #train# step 8946, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:56.535716 #train# step 8947, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:58.115051 #train# step 8948, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:56:59.725750 #train# step 8949, loss = 0.8870, cross_entropy loss = 0.8870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:01.290043 #train# step 8950, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:02.875737 #train# step 8951, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:04.477534 #train# step 8952, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:06.051493 #train# step 8953, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:07.651606 #train# step 8954, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:09.248548 #train# step 8955, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:10.829768 #train# step 8956, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:12.435683 #train# step 8957, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:14.027475 #train# step 8958, loss = 0.8870, cross_entropy loss = 0.8870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:15.629009 #train# step 8959, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:17.244058 #train# step 8960, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:18.841592 #train# step 8961, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:20.436810 #train# step 8962, loss = 0.8898, cross_entropy loss = 0.8898, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:22.053769 #train# step 8963, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:23.624121 #train# step 8964, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:25.212124 #train# step 8965, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:26.809785 #train# step 8966, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:28.427202 #train# step 8967, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:30.018678 #train# step 8968, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:31.597094 #train# step 8969, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:33.179329 #train# step 8970, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:34.772253 #train# step 8971, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:36.336660 #train# step 8972, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:37.958667 #train# step 8973, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:39.551653 #train# step 8974, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:41.174780 #train# step 8975, loss = 0.9061, cross_entropy loss = 0.9061, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:42.769104 #train# step 8976, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:44.359574 #train# step 8977, loss = 0.8852, cross_entropy loss = 0.8852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:45.945709 #train# step 8978, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:47.542014 #train# step 8979, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:49.129624 #train# step 8980, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:50.710900 #train# step 8981, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:52.300596 #train# step 8982, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:53.934224 #train# step 8983, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:55.540905 #train# step 8984, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:57.153436 #train# step 8985, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:57:58.751844 #train# step 8986, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:00.361638 #train# step 8987, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:01.963778 #train# step 8988, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:03.569160 #train# step 8989, loss = 0.8884, cross_entropy loss = 0.8884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:05.165172 #train# step 8990, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:06.774254 #train# step 8991, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:08.434628 #train# step 8992, loss = 0.8970, cross_entropy loss = 0.8970, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:10.008589 #train# step 8993, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:11.598344 #train# step 8994, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:13.187440 #train# step 8995, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:14.776522 #train# step 8996, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:16.356280 #train# step 8997, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:17.974596 #train# step 8998, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:19.561377 #train# step 8999, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:21.137212 #train# step 9000, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:22.732606 #train# step 9001, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:24.300069 #train# step 9002, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:25.902591 #train# step 9003, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:27.486258 #train# step 9004, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:29.084004 #train# step 9005, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:30.660117 #train# step 9006, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:32.252535 #train# step 9007, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:33.849677 #train# step 9008, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:35.427747 #train# step 9009, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:37.015824 #train# step 9010, loss = 0.9001, cross_entropy loss = 0.9001, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:38.586242 #train# step 9011, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:40.142533 #train# step 9012, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:41.752706 #train# step 9013, loss = 0.9065, cross_entropy loss = 0.9065, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:43.325333 #train# step 9014, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:44.907751 #train# step 9015, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:46.503879 #train# step 9016, loss = 0.8911, cross_entropy loss = 0.8911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:48.131497 #train# step 9017, loss = 0.9008, cross_entropy loss = 0.9008, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:49.702758 #train# step 9018, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:51.324357 #train# step 9019, loss = 0.8852, cross_entropy loss = 0.8852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:52.926201 #train# step 9020, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:54.547482 #train# step 9021, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:56.131421 #train# step 9022, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:57.720386 #train# step 9023, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:58:59.332246 #train# step 9024, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:00.938297 #train# step 9025, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:02.516457 #train# step 9026, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:04.112987 #train# step 9027, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:05.686443 #train# step 9028, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:07.296312 #train# step 9029, loss = 0.8795, cross_entropy loss = 0.8795, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:08.908098 #train# step 9030, loss = 0.9028, cross_entropy loss = 0.9028, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:10.553206 #train# step 9031, loss = 0.9232, cross_entropy loss = 0.9232, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:12.135615 #train# step 9032, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:13.750661 #train# step 9033, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:15.408141 #train# step 9034, loss = 0.9057, cross_entropy loss = 0.9057, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:17.016532 #train# step 9035, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:18.623308 #train# step 9036, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:20.187255 #train# step 9037, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:21.757055 #train# step 9038, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:23.338287 #train# step 9039, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:24.911405 #train# step 9040, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:26.523857 #train# step 9041, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:28.136027 #train# step 9042, loss = 0.8858, cross_entropy loss = 0.8858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:29.712075 #train# step 9043, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:31.294475 #train# step 9044, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:32.881989 #train# step 9045, loss = 0.8869, cross_entropy loss = 0.8869, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:34.479999 #train# step 9046, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:36.051441 #train# step 9047, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:37.634222 #train# step 9048, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:39.221214 #train# step 9049, loss = 0.9095, cross_entropy loss = 0.9095, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:40.830453 #train# step 9050, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:42.420079 #train# step 9051, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:44.025941 #train# step 9052, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:45.624725 #train# step 9053, loss = 0.9052, cross_entropy loss = 0.9052, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:47.212874 #train# step 9054, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:48.784754 #train# step 9055, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:50.379344 #train# step 9056, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:51.964394 #train# step 9057, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:53.555245 #train# step 9058, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:55.159402 #train# step 9059, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:56.717378 #train# step 9060, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:58.340218 #train# step 9061, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 21:59:59.913691 #train# step 9062, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:01.486718 #train# step 9063, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:03.084310 #train# step 9064, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:04.650874 #train# step 9065, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:06.240266 #train# step 9066, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:07.796863 #train# step 9067, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:09.398926 #train# step 9068, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:11.009317 #train# step 9069, loss = 0.9167, cross_entropy loss = 0.9167, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:12.577526 #train# step 9070, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:14.138607 #train# step 9071, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:15.736656 #train# step 9072, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:17.328989 #train# step 9073, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:18.922457 #train# step 9074, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:20.548198 #train# step 9075, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:22.151449 #train# step 9076, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:23.728761 #train# step 9077, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:25.317832 #train# step 9078, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:26.914113 #train# step 9079, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:28.509493 #train# step 9080, loss = 0.8851, cross_entropy loss = 0.8851, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:30.090649 #train# step 9081, loss = 0.9097, cross_entropy loss = 0.9097, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:31.680334 #train# step 9082, loss = 0.8886, cross_entropy loss = 0.8886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:33.280727 #train# step 9083, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:34.887897 #train# step 9084, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:36.474304 #train# step 9085, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:38.066906 #train# step 9086, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:39.644825 #train# step 9087, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:41.232211 #train# step 9088, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:42.824823 #train# step 9089, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:44.387858 #train# step 9090, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:45.956399 #train# step 9091, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:47.516118 #train# step 9092, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:49.119936 #train# step 9093, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:50.701064 #train# step 9094, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:52.278507 #train# step 9095, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:53.828770 #train# step 9096, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:55.414001 #train# step 9097, loss = 0.9099, cross_entropy loss = 0.9099, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:57.010814 #train# step 9098, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:00:58.617148 #train# step 9099, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:00.237211 #train# step 9100, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:01.826501 #train# step 9101, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:03.425183 #train# step 9102, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:05.013674 #train# step 9103, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:06.571875 #train# step 9104, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:08.150457 #train# step 9105, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:09.742121 #train# step 9106, loss = 0.9175, cross_entropy loss = 0.9175, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:11.335353 #train# step 9107, loss = 0.8835, cross_entropy loss = 0.8835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:12.894415 #train# step 9108, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:14.462896 #train# step 9109, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:16.047094 #train# step 9110, loss = 0.8830, cross_entropy loss = 0.8830, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:17.622589 #train# step 9111, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:19.187499 #train# step 9112, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:20.774867 #train# step 9113, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:22.385429 #train# step 9114, loss = 0.9030, cross_entropy loss = 0.9030, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:23.972783 #train# step 9115, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:25.552961 #train# step 9116, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:27.129070 #train# step 9117, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:28.710391 #train# step 9118, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:30.292648 #train# step 9119, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:31.906901 #train# step 9120, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:33.534339 #train# step 9121, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:35.149731 #train# step 9122, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:36.735971 #train# step 9123, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:38.350160 #train# step 9124, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:39.957832 #train# step 9125, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:41.557926 #train# step 9126, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:43.127655 #train# step 9127, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:44.710124 #train# step 9128, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:46.276752 #train# step 9129, loss = 0.8899, cross_entropy loss = 0.8899, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:47.832410 #train# step 9130, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:49.387670 #train# step 9131, loss = 0.8796, cross_entropy loss = 0.8796, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:50.985914 #train# step 9132, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:52.564990 #train# step 9133, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:54.150470 #train# step 9134, loss = 0.9150, cross_entropy loss = 0.9150, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:55.704156 #train# step 9135, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:57.293227 #train# step 9136, loss = 0.9073, cross_entropy loss = 0.9073, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:01:58.900064 #train# step 9137, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:00.508655 #train# step 9138, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:02.120227 #train# step 9139, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:03.723036 #train# step 9140, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:05.308083 #train# step 9141, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:06.860886 #train# step 9142, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:08.455382 #train# step 9143, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:10.012753 #train# step 9144, loss = 0.9085, cross_entropy loss = 0.9085, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:11.605486 #train# step 9145, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:13.179858 #train# step 9146, loss = 0.9116, cross_entropy loss = 0.9116, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:14.784629 #train# step 9147, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:16.368474 #train# step 9148, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:17.944389 #train# step 9149, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:19.552370 #train# step 9150, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:21.135536 #train# step 9151, loss = 0.8908, cross_entropy loss = 0.8908, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:22.708541 #train# step 9152, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:24.261079 #train# step 9153, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:25.864388 #train# step 9154, loss = 0.8877, cross_entropy loss = 0.8877, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:27.466478 #train# step 9155, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:29.043701 #train# step 9156, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:30.632275 #train# step 9157, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:32.194265 #train# step 9158, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:33.789479 #train# step 9159, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:35.366068 #train# step 9160, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:36.938334 #train# step 9161, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:38.518346 #train# step 9162, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:40.103645 #train# step 9163, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:41.673822 #train# step 9164, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:43.267901 #train# step 9165, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:44.868654 #train# step 9166, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:46.439643 #train# step 9167, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:48.023224 #train# step 9168, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:49.595702 #train# step 9169, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:51.175108 #train# step 9170, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:52.763001 #train# step 9171, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:54.357428 #train# step 9172, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:55.970901 #train# step 9173, loss = 0.8893, cross_entropy loss = 0.8893, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:57.569107 #train# step 9174, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:02:59.155474 #train# step 9175, loss = 0.9044, cross_entropy loss = 0.9044, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:00.744820 #train# step 9176, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:02.326554 #train# step 9177, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:03.909110 #train# step 9178, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:05.484243 #train# step 9179, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:07.055928 #train# step 9180, loss = 0.9108, cross_entropy loss = 0.9108, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:08.656090 #train# step 9181, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:10.264863 #train# step 9182, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:11.873247 #train# step 9183, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:13.421580 #train# step 9184, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:15.000353 #train# step 9185, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:16.578074 #train# step 9186, loss = 0.9030, cross_entropy loss = 0.9030, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:18.160511 #train# step 9187, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:19.746636 #train# step 9188, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:21.329003 #train# step 9189, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:22.884181 #train# step 9190, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:24.455495 #train# step 9191, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:26.084167 #train# step 9192, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:27.631801 #train# step 9193, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:29.239635 #train# step 9194, loss = 0.8846, cross_entropy loss = 0.8846, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:30.855870 #train# step 9195, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:32.419589 #train# step 9196, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:34.000277 #train# step 9197, loss = 0.8860, cross_entropy loss = 0.8860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:35.593919 #train# step 9198, loss = 0.8821, cross_entropy loss = 0.8821, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:37.193392 #train# step 9199, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:38.744647 #train# step 9200, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:40.320378 #train# step 9201, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:41.907291 #train# step 9202, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:43.520907 #train# step 9203, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:45.077763 #train# step 9204, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:46.663492 #train# step 9205, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:48.272181 #train# step 9206, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:49.859971 #train# step 9207, loss = 0.8836, cross_entropy loss = 0.8836, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:51.475864 #train# step 9208, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:53.028994 #train# step 9209, loss = 0.9198, cross_entropy loss = 0.9198, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:54.602944 #train# step 9210, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:56.183141 #train# step 9211, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:57.774661 #train# step 9212, loss = 0.9045, cross_entropy loss = 0.9045, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:03:59.336684 #train# step 9213, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:00.930277 #train# step 9214, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:02.510600 #train# step 9215, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:04.076631 #train# step 9216, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:05.674674 #train# step 9217, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:07.257283 #train# step 9218, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:08.832007 #train# step 9219, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:10.440067 #train# step 9220, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:11.992897 #train# step 9221, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:13.558973 #train# step 9222, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:15.137627 #train# step 9223, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:16.722921 #train# step 9224, loss = 0.9111, cross_entropy loss = 0.9111, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:18.304050 #train# step 9225, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:19.870289 #train# step 9226, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:21.469365 #train# step 9227, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:23.044719 #train# step 9228, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:24.637719 #train# step 9229, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:26.243928 #train# step 9230, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:27.835164 #train# step 9231, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:29.442247 #train# step 9232, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:31.035762 #train# step 9233, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:32.617210 #train# step 9234, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:34.189244 #train# step 9235, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:35.798030 #train# step 9236, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:37.384103 #train# step 9237, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:38.972394 #train# step 9238, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:40.577569 #train# step 9239, loss = 0.8835, cross_entropy loss = 0.8835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:42.158352 #train# step 9240, loss = 0.9143, cross_entropy loss = 0.9143, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:43.728514 #train# step 9241, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:45.315069 #train# step 9242, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:46.901780 #train# step 9243, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:48.470292 #train# step 9244, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:50.065164 #train# step 9245, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:51.653811 #train# step 9246, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:53.235197 #train# step 9247, loss = 0.9064, cross_entropy loss = 0.9064, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:54.827319 #train# step 9248, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:56.390186 #train# step 9249, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:57.968186 #train# step 9250, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:04:59.576638 #train# step 9251, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:01.139180 #train# step 9252, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:02.772123 #train# step 9253, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:04.341998 #train# step 9254, loss = 0.8890, cross_entropy loss = 0.8890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:05.927313 #train# step 9255, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:07.488108 #train# step 9256, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:09.109948 #train# step 9257, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:10.713158 #train# step 9258, loss = 0.8798, cross_entropy loss = 0.8798, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:12.307705 #train# step 9259, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:13.894378 #train# step 9260, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:15.472016 #train# step 9261, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:17.039509 #train# step 9262, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:18.662744 #train# step 9263, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:20.243696 #train# step 9264, loss = 0.9105, cross_entropy loss = 0.9105, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:21.815928 #train# step 9265, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:23.386940 #train# step 9266, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:24.954786 #train# step 9267, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:26.529975 #train# step 9268, loss = 0.9146, cross_entropy loss = 0.9146, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:28.113208 #train# step 9269, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:29.679210 #train# step 9270, loss = 0.8858, cross_entropy loss = 0.8858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:31.259598 #train# step 9271, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:32.865099 #train# step 9272, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:34.429297 #train# step 9273, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:36.024617 #train# step 9274, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:37.609986 #train# step 9275, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:39.227278 #train# step 9276, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:40.802596 #train# step 9277, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:42.396766 #train# step 9278, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:43.979249 #train# step 9279, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:45.564336 #train# step 9280, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:47.137708 #train# step 9281, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:48.716224 #train# step 9282, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:50.325712 #train# step 9283, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:51.909075 #train# step 9284, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:53.490206 #train# step 9285, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:55.046387 #train# step 9286, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:56.638535 #train# step 9287, loss = 0.9067, cross_entropy loss = 0.9067, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:58.209946 #train# step 9288, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:05:59.799752 #train# step 9289, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:01.384110 #train# step 9290, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:02.982787 #train# step 9291, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:04.556842 #train# step 9292, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:06.171927 #train# step 9293, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:07.769840 #train# step 9294, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:09.350405 #train# step 9295, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:10.946521 #train# step 9296, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:12.547367 #train# step 9297, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:14.104115 #train# step 9298, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:15.718187 #train# step 9299, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:17.310805 #train# step 9300, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:18.939505 #train# step 9301, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:20.495389 #train# step 9302, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:22.061670 #train# step 9303, loss = 0.9158, cross_entropy loss = 0.9158, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:23.655748 #train# step 9304, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:25.216952 #train# step 9305, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:26.796423 #train# step 9306, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:28.382433 #train# step 9307, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:29.978300 #train# step 9308, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:31.570068 #train# step 9309, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:33.167688 #train# step 9310, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:34.763917 #train# step 9311, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:36.343611 #train# step 9312, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:37.960917 #train# step 9313, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:39.504717 #train# step 9314, loss = 0.9159, cross_entropy loss = 0.9159, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:41.074063 #train# step 9315, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:42.630630 #train# step 9316, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:44.214572 #train# step 9317, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:45.781253 #train# step 9318, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:47.390292 #train# step 9319, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:48.964608 #train# step 9320, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:50.558181 #train# step 9321, loss = 0.8862, cross_entropy loss = 0.8862, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:52.115657 #train# step 9322, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:53.719200 #train# step 9323, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:55.323421 #train# step 9324, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:56.894379 #train# step 9325, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:06:58.493028 #train# step 9326, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:00.070542 #train# step 9327, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:01.649732 #train# step 9328, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:03.222777 #train# step 9329, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:04.894453 #train# step 9330, loss = 0.9136, cross_entropy loss = 0.9136, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:06.485320 #train# step 9331, loss = 0.9109, cross_entropy loss = 0.9109, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:08.083371 #train# step 9332, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:09.653008 #train# step 9333, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:11.289471 #train# step 9334, loss = 0.8973, cross_entropy loss = 0.8973, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:12.885937 #train# step 9335, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:14.467884 #train# step 9336, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:16.045107 #train# step 9337, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:17.632059 #train# step 9338, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:19.253545 #train# step 9339, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:20.839267 #train# step 9340, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:22.396423 #train# step 9341, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:23.978545 #train# step 9342, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:25.578325 #train# step 9343, loss = 0.8922, cross_entropy loss = 0.8922, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:27.185222 #train# step 9344, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:28.798854 #train# step 9345, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:30.352783 #train# step 9346, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:31.965739 #train# step 9347, loss = 0.8911, cross_entropy loss = 0.8911, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:33.537906 #train# step 9348, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:35.126449 #train# step 9349, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:36.704917 #train# step 9350, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:38.269598 #train# step 9351, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:39.855641 #train# step 9352, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:41.433726 #train# step 9353, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:43.017247 #train# step 9354, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:44.588495 #train# step 9355, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:46.204443 #train# step 9356, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:47.782854 #train# step 9357, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:49.346829 #train# step 9358, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:50.938532 #train# step 9359, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:52.490314 #train# step 9360, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:54.073728 #train# step 9361, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:55.628042 #train# step 9362, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:57.201574 #train# step 9363, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:07:58.832546 #train# step 9364, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:00.392477 #train# step 9365, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:01.970224 #train# step 9366, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:03.547215 #train# step 9367, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:05.120646 #train# step 9368, loss = 0.9055, cross_entropy loss = 0.9055, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:06.713971 #train# step 9369, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:08.314948 #train# step 9370, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:09.898444 #train# step 9371, loss = 0.9040, cross_entropy loss = 0.9040, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:11.452589 #train# step 9372, loss = 0.9151, cross_entropy loss = 0.9151, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:13.064269 #train# step 9373, loss = 0.8906, cross_entropy loss = 0.8906, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:14.636605 #train# step 9374, loss = 0.8835, cross_entropy loss = 0.8835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:16.199538 #train# step 9375, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:17.797081 #train# step 9376, loss = 0.8815, cross_entropy loss = 0.8815, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:19.401936 #train# step 9377, loss = 0.9015, cross_entropy loss = 0.9015, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:20.987711 #train# step 9378, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:22.570551 #train# step 9379, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:24.165540 #train# step 9380, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:25.724793 #train# step 9381, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:27.320964 #train# step 9382, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:28.918279 #train# step 9383, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:30.504741 #train# step 9384, loss = 0.8890, cross_entropy loss = 0.8890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:32.075213 #train# step 9385, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:33.677453 #train# step 9386, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:35.306654 #train# step 9387, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:36.896731 #train# step 9388, loss = 0.8956, cross_entropy loss = 0.8956, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:38.504048 #train# step 9389, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:40.109693 #train# step 9390, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:41.707642 #train# step 9391, loss = 0.8882, cross_entropy loss = 0.8882, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:43.298107 #train# step 9392, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:44.878450 #train# step 9393, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:46.475718 #train# step 9394, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:48.050435 #train# step 9395, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:49.622911 #train# step 9396, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:51.177180 #train# step 9397, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:52.778837 #train# step 9398, loss = 0.8904, cross_entropy loss = 0.8904, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:54.357143 #train# step 9399, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:55.941737 #train# step 9400, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:57.557435 #train# step 9401, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:08:59.172323 #train# step 9402, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:00.743675 #train# step 9403, loss = 0.9014, cross_entropy loss = 0.9014, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:02.339809 #train# step 9404, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:03.934586 #train# step 9405, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:05.516298 #train# step 9406, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:07.146613 #train# step 9407, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:08.740765 #train# step 9408, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:10.326281 #train# step 9409, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:11.908069 #train# step 9410, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:13.494286 #train# step 9411, loss = 0.8881, cross_entropy loss = 0.8881, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:15.055781 #train# step 9412, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:16.606825 #train# step 9413, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:18.225727 #train# step 9414, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:19.817806 #train# step 9415, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:21.377444 #train# step 9416, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:22.965585 #train# step 9417, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:24.541521 #train# step 9418, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:26.124155 #train# step 9419, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:27.686506 #train# step 9420, loss = 0.9144, cross_entropy loss = 0.9144, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:29.266457 #train# step 9421, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:30.855062 #train# step 9422, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:32.447068 #train# step 9423, loss = 0.9041, cross_entropy loss = 0.9041, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:34.036117 #train# step 9424, loss = 0.9148, cross_entropy loss = 0.9148, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:35.600919 #train# step 9425, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:37.209172 #train# step 9426, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:38.828335 #train# step 9427, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:40.426487 #train# step 9428, loss = 0.8910, cross_entropy loss = 0.8910, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:42.023985 #train# step 9429, loss = 0.9052, cross_entropy loss = 0.9052, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:43.691451 #train# step 9430, loss = 0.8857, cross_entropy loss = 0.8857, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:45.358595 #train# step 9431, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:46.959455 #train# step 9432, loss = 0.8864, cross_entropy loss = 0.8864, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:48.594008 #train# step 9433, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:50.188769 #train# step 9434, loss = 0.9207, cross_entropy loss = 0.9207, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:51.805257 #train# step 9435, loss = 0.9055, cross_entropy loss = 0.9055, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:53.405449 #train# step 9436, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:54.976961 #train# step 9437, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:56.578941 #train# step 9438, loss = 0.8868, cross_entropy loss = 0.8868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:58.179862 #train# step 9439, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:09:59.943944 #train# step 9440, loss = 0.8917, cross_entropy loss = 0.8917, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:01.986509 #train# step 9441, loss = 0.9034, cross_entropy loss = 0.9034, 1.0 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:03.613132 #train# step 9442, loss = 0.8903, cross_entropy loss = 0.8903, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:05.205189 #train# step 9443, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:06.824494 #train# step 9444, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:08.446100 #train# step 9445, loss = 0.9075, cross_entropy loss = 0.9075, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:10.064278 #train# step 9446, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:11.640394 #train# step 9447, loss = 0.8913, cross_entropy loss = 0.8913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:13.260849 #train# step 9448, loss = 0.8985, cross_entropy loss = 0.8985, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:14.851261 #train# step 9449, loss = 0.9106, cross_entropy loss = 0.9106, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:16.476844 #train# step 9450, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:18.059451 #train# step 9451, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:19.652677 #train# step 9452, loss = 0.8944, cross_entropy loss = 0.8944, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:21.245057 #train# step 9453, loss = 0.9062, cross_entropy loss = 0.9062, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:22.856796 #train# step 9454, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:24.462869 #train# step 9455, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:26.024537 #train# step 9456, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:27.608170 #train# step 9457, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:29.202599 #train# step 9458, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:30.788003 #train# step 9459, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:32.384492 #train# step 9460, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:33.986756 #train# step 9461, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:35.588169 #train# step 9462, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:37.154789 #train# step 9463, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:38.761311 #train# step 9464, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:40.369056 #train# step 9465, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:41.954561 #train# step 9466, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:43.539318 #train# step 9467, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:45.110997 #train# step 9468, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:46.689186 #train# step 9469, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:48.270714 #train# step 9470, loss = 0.8983, cross_entropy loss = 0.8983, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:49.855004 #train# step 9471, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:51.423267 #train# step 9472, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:52.994544 #train# step 9473, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:54.581074 #train# step 9474, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:56.162052 #train# step 9475, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:57.786845 #train# step 9476, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:10:59.371334 #train# step 9477, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:00.996724 #train# step 9478, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:02.622790 #train# step 9479, loss = 0.8859, cross_entropy loss = 0.8859, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:04.242256 #train# step 9480, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:05.824314 #train# step 9481, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:07.432675 #train# step 9482, loss = 0.8985, cross_entropy loss = 0.8985, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:09.039986 #train# step 9483, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:10.624700 #train# step 9484, loss = 0.8841, cross_entropy loss = 0.8841, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:12.218230 #train# step 9485, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:13.801501 #train# step 9486, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:15.390128 #train# step 9487, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:16.999303 #train# step 9488, loss = 0.8807, cross_entropy loss = 0.8807, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:18.586495 #train# step 9489, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:20.174705 #train# step 9490, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:21.748807 #train# step 9491, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:23.356275 #train# step 9492, loss = 0.9161, cross_entropy loss = 0.9161, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:24.957721 #train# step 9493, loss = 0.8851, cross_entropy loss = 0.8851, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:26.593656 #train# step 9494, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:28.196934 #train# step 9495, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:29.799673 #train# step 9496, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:31.378685 #train# step 9497, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:32.933358 #train# step 9498, loss = 0.8975, cross_entropy loss = 0.8975, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:34.529369 #train# step 9499, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:36.129680 #train# step 9500, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:37.696852 #train# step 9501, loss = 0.8978, cross_entropy loss = 0.8978, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:39.295756 #train# step 9502, loss = 0.9080, cross_entropy loss = 0.9080, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:40.892513 #train# step 9503, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:42.486691 #train# step 9504, loss = 0.8963, cross_entropy loss = 0.8963, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:44.030658 #train# step 9505, loss = 0.9086, cross_entropy loss = 0.9086, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:45.629142 #train# step 9506, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:47.229807 #train# step 9507, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:48.811919 #train# step 9508, loss = 0.9060, cross_entropy loss = 0.9060, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:50.388015 #train# step 9509, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:51.959311 #train# step 9510, loss = 0.9090, cross_entropy loss = 0.9090, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:53.555778 #train# step 9511, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:55.144343 #train# step 9512, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:56.719615 #train# step 9513, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:58.279309 #train# step 9514, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:11:59.867781 #train# step 9515, loss = 0.8878, cross_entropy loss = 0.8878, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:01.442437 #train# step 9516, loss = 0.9140, cross_entropy loss = 0.9140, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:03.037259 #train# step 9517, loss = 0.8868, cross_entropy loss = 0.8868, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:04.637676 #train# step 9518, loss = 0.9178, cross_entropy loss = 0.9178, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:06.240523 #train# step 9519, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:07.843389 #train# step 9520, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:09.415620 #train# step 9521, loss = 0.8896, cross_entropy loss = 0.8896, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:11.049206 #train# step 9522, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:12.654956 #train# step 9523, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:14.257440 #train# step 9524, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:15.871175 #train# step 9525, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:17.474301 #train# step 9526, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:19.043409 #train# step 9527, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:20.607371 #train# step 9528, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:22.220852 #train# step 9529, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:23.811985 #train# step 9530, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:25.398364 #train# step 9531, loss = 0.8988, cross_entropy loss = 0.8988, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:26.995801 #train# step 9532, loss = 0.9096, cross_entropy loss = 0.9096, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:28.591562 #train# step 9533, loss = 0.8855, cross_entropy loss = 0.8855, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:30.244789 #train# step 9534, loss = 0.8792, cross_entropy loss = 0.8792, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:31.854419 #train# step 9535, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:33.479724 #train# step 9536, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:35.089381 #train# step 9537, loss = 0.8913, cross_entropy loss = 0.8913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:36.674067 #train# step 9538, loss = 0.9122, cross_entropy loss = 0.9122, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:38.262878 #train# step 9539, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:39.856541 #train# step 9540, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:41.455858 #train# step 9541, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:43.060392 #train# step 9542, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:44.686238 #train# step 9543, loss = 0.8993, cross_entropy loss = 0.8993, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:46.293384 #train# step 9544, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:47.887930 #train# step 9545, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:49.494080 #train# step 9546, loss = 0.8860, cross_entropy loss = 0.8860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:51.077176 #train# step 9547, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:52.625661 #train# step 9548, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:54.240538 #train# step 9549, loss = 0.8922, cross_entropy loss = 0.8922, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:55.827210 #train# step 9550, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:57.408312 #train# step 9551, loss = 0.9133, cross_entropy loss = 0.9133, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:12:58.986946 #train# step 9552, loss = 0.8935, cross_entropy loss = 0.8935, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:00.570083 #train# step 9553, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:02.194884 #train# step 9554, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:03.774471 #train# step 9555, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:05.363583 #train# step 9556, loss = 0.9033, cross_entropy loss = 0.9033, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:06.915606 #train# step 9557, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:08.501012 #train# step 9558, loss = 0.8920, cross_entropy loss = 0.8920, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:10.075239 #train# step 9559, loss = 0.9171, cross_entropy loss = 0.9171, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:11.671517 #train# step 9560, loss = 0.9058, cross_entropy loss = 0.9058, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:13.246872 #train# step 9561, loss = 0.8888, cross_entropy loss = 0.8888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:14.864685 #train# step 9562, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:16.465493 #train# step 9563, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:18.090784 #train# step 9564, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:19.666466 #train# step 9565, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:21.263688 #train# step 9566, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:22.859065 #train# step 9567, loss = 0.8962, cross_entropy loss = 0.8962, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:24.473214 #train# step 9568, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:26.069930 #train# step 9569, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:27.671882 #train# step 9570, loss = 0.8891, cross_entropy loss = 0.8891, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:29.253771 #train# step 9571, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:30.865140 #train# step 9572, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:32.454511 #train# step 9573, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:34.051388 #train# step 9574, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:35.646067 #train# step 9575, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:37.251861 #train# step 9576, loss = 0.8958, cross_entropy loss = 0.8958, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:38.852606 #train# step 9577, loss = 0.8865, cross_entropy loss = 0.8865, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:40.441788 #train# step 9578, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:42.013807 #train# step 9579, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:43.614340 #train# step 9580, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:45.205035 #train# step 9581, loss = 0.9130, cross_entropy loss = 0.9130, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:46.840048 #train# step 9582, loss = 0.9091, cross_entropy loss = 0.9091, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:48.443620 #train# step 9583, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:50.023689 #train# step 9584, loss = 0.9081, cross_entropy loss = 0.9081, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:51.589443 #train# step 9585, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:53.151721 #train# step 9586, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:54.735278 #train# step 9587, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:56.325885 #train# step 9588, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:57.897780 #train# step 9589, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:13:59.503287 #train# step 9590, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:01.092974 #train# step 9591, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:02.663225 #train# step 9592, loss = 0.8879, cross_entropy loss = 0.8879, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:04.264292 #train# step 9593, loss = 0.8989, cross_entropy loss = 0.8989, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:05.852517 #train# step 9594, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:07.440312 #train# step 9595, loss = 0.8867, cross_entropy loss = 0.8867, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:09.064192 #train# step 9596, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:10.679890 #train# step 9597, loss = 0.8896, cross_entropy loss = 0.8896, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:12.271992 #train# step 9598, loss = 0.8887, cross_entropy loss = 0.8887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:13.859373 #train# step 9599, loss = 0.9103, cross_entropy loss = 0.9103, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:15.465417 #train# step 9600, loss = 0.8991, cross_entropy loss = 0.8991, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:17.073487 #train# step 9601, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:18.656030 #train# step 9602, loss = 0.9088, cross_entropy loss = 0.9088, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:20.242926 #train# step 9603, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:21.825549 #train# step 9604, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:23.433132 #train# step 9605, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:25.016106 #train# step 9606, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:26.647006 #train# step 9607, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:28.241830 #train# step 9608, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:29.831467 #train# step 9609, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:31.430902 #train# step 9610, loss = 0.8942, cross_entropy loss = 0.8942, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:32.967030 #train# step 9611, loss = 0.9083, cross_entropy loss = 0.9083, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:34.534165 #train# step 9612, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:36.102811 #train# step 9613, loss = 0.9034, cross_entropy loss = 0.9034, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:37.706411 #train# step 9614, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:39.297176 #train# step 9615, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:40.874420 #train# step 9616, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:42.456717 #train# step 9617, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:44.065456 #train# step 9618, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:45.666214 #train# step 9619, loss = 0.8860, cross_entropy loss = 0.8860, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:47.297036 #train# step 9620, loss = 0.9056, cross_entropy loss = 0.9056, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:48.900771 #train# step 9621, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:50.488027 #train# step 9622, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:52.090121 #train# step 9623, loss = 0.8811, cross_entropy loss = 0.8811, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:53.708666 #train# step 9624, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:55.295906 #train# step 9625, loss = 0.8895, cross_entropy loss = 0.8895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:56.856369 #train# step 9626, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:14:58.463902 #train# step 9627, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:00.058131 #train# step 9628, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:01.812236 #train# step 9629, loss = 0.8773, cross_entropy loss = 0.8773, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:03.415411 #train# step 9630, loss = 0.9016, cross_entropy loss = 0.9016, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:04.975950 #train# step 9631, loss = 0.8984, cross_entropy loss = 0.8984, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:06.586512 #train# step 9632, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:08.163957 #train# step 9633, loss = 0.9026, cross_entropy loss = 0.9026, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:09.758611 #train# step 9634, loss = 0.8878, cross_entropy loss = 0.8878, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:11.355547 #train# step 9635, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:12.965636 #train# step 9636, loss = 0.8848, cross_entropy loss = 0.8848, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:14.533487 #train# step 9637, loss = 0.9061, cross_entropy loss = 0.9061, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:16.159893 #train# step 9638, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:17.777069 #train# step 9639, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:19.366917 #train# step 9640, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:20.935885 #train# step 9641, loss = 0.9046, cross_entropy loss = 0.9046, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:22.509586 #train# step 9642, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:24.100374 #train# step 9643, loss = 0.9098, cross_entropy loss = 0.9098, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:25.670323 #train# step 9644, loss = 0.9020, cross_entropy loss = 0.9020, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:27.282140 #train# step 9645, loss = 0.9120, cross_entropy loss = 0.9120, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:28.892715 #train# step 9646, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:30.474190 #train# step 9647, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:32.045396 #train# step 9648, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:33.646800 #train# step 9649, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:35.236467 #train# step 9650, loss = 0.9129, cross_entropy loss = 0.9129, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:36.833886 #train# step 9651, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:38.405967 #train# step 9652, loss = 0.9113, cross_entropy loss = 0.9113, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:40.013558 #train# step 9653, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:41.612284 #train# step 9654, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:43.184548 #train# step 9655, loss = 0.9035, cross_entropy loss = 0.9035, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:44.754296 #train# step 9656, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:46.350868 #train# step 9657, loss = 0.9072, cross_entropy loss = 0.9072, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:47.962777 #train# step 9658, loss = 0.8835, cross_entropy loss = 0.8835, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:49.545343 #train# step 9659, loss = 0.8896, cross_entropy loss = 0.8896, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:51.125915 #train# step 9660, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:52.730297 #train# step 9661, loss = 0.8890, cross_entropy loss = 0.8890, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:54.325127 #train# step 9662, loss = 0.9019, cross_entropy loss = 0.9019, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:55.928949 #train# step 9663, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:57.488255 #train# step 9664, loss = 0.9119, cross_entropy loss = 0.9119, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:15:59.069157 #train# step 9665, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:00.650007 #train# step 9666, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:02.228165 #train# step 9667, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:03.832945 #train# step 9668, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:05.427598 #train# step 9669, loss = 0.8786, cross_entropy loss = 0.8786, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:07.018561 #train# step 9670, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:08.601800 #train# step 9671, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:10.197093 #train# step 9672, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:11.828220 #train# step 9673, loss = 0.9003, cross_entropy loss = 0.9003, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:13.407796 #train# step 9674, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:15.034689 #train# step 9675, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:16.633432 #train# step 9676, loss = 0.8941, cross_entropy loss = 0.8941, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:18.221826 #train# step 9677, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:19.808186 #train# step 9678, loss = 0.8948, cross_entropy loss = 0.8948, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:21.422986 #train# step 9679, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:23.029642 #train# step 9680, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:24.644045 #train# step 9681, loss = 0.8946, cross_entropy loss = 0.8946, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:26.259583 #train# step 9682, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:27.860870 #train# step 9683, loss = 0.8880, cross_entropy loss = 0.8880, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:29.445682 #train# step 9684, loss = 0.9021, cross_entropy loss = 0.9021, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:31.017602 #train# step 9685, loss = 0.8926, cross_entropy loss = 0.8926, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:32.612358 #train# step 9686, loss = 0.9028, cross_entropy loss = 0.9028, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:34.196079 #train# step 9687, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:35.785436 #train# step 9688, loss = 0.8828, cross_entropy loss = 0.8828, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:37.406708 #train# step 9689, loss = 0.8888, cross_entropy loss = 0.8888, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:38.969315 #train# step 9690, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:40.567974 #train# step 9691, loss = 0.9211, cross_entropy loss = 0.9211, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:42.149116 #train# step 9692, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:43.784205 #train# step 9693, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:45.346407 #train# step 9694, loss = 0.9156, cross_entropy loss = 0.9156, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:46.964689 #train# step 9695, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:48.573381 #train# step 9696, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:50.168693 #train# step 9697, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:51.759506 #train# step 9698, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:53.356267 #train# step 9699, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:54.963065 #train# step 9700, loss = 0.9076, cross_entropy loss = 0.9076, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:56.557575 #train# step 9701, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:58.144375 #train# step 9702, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:16:59.703961 #train# step 9703, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:01.289848 #train# step 9704, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:02.882169 #train# step 9705, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:04.455633 #train# step 9706, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:06.033207 #train# step 9707, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:07.605696 #train# step 9708, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:09.231614 #train# step 9709, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:10.786323 #train# step 9710, loss = 0.9117, cross_entropy loss = 0.9117, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:12.374100 #train# step 9711, loss = 0.8951, cross_entropy loss = 0.8951, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:13.968826 #train# step 9712, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:15.597842 #train# step 9713, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:17.193851 #train# step 9714, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:18.862613 #train# step 9715, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:20.454552 #train# step 9716, loss = 0.8923, cross_entropy loss = 0.8923, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:22.040680 #train# step 9717, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:23.625054 #train# step 9718, loss = 0.8895, cross_entropy loss = 0.8895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:25.224211 #train# step 9719, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:26.821160 #train# step 9720, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:28.409363 #train# step 9721, loss = 0.9039, cross_entropy loss = 0.9039, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:29.979053 #train# step 9722, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:31.584516 #train# step 9723, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:33.172515 #train# step 9724, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:34.746959 #train# step 9725, loss = 0.8895, cross_entropy loss = 0.8895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:36.330580 #train# step 9726, loss = 0.9070, cross_entropy loss = 0.9070, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:37.951204 #train# step 9727, loss = 0.8940, cross_entropy loss = 0.8940, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:39.558867 #train# step 9728, loss = 0.8811, cross_entropy loss = 0.8811, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:41.159960 #train# step 9729, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:42.757793 #train# step 9730, loss = 0.9077, cross_entropy loss = 0.9077, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:44.340968 #train# step 9731, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:45.931128 #train# step 9732, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:47.527072 #train# step 9733, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:49.101750 #train# step 9734, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:50.689627 #train# step 9735, loss = 0.8879, cross_entropy loss = 0.8879, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:52.275071 #train# step 9736, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:53.926981 #train# step 9737, loss = 0.8869, cross_entropy loss = 0.8869, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:55.509576 #train# step 9738, loss = 0.9051, cross_entropy loss = 0.9051, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:57.088670 #train# step 9739, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:17:58.665146 #train# step 9740, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:00.291421 #train# step 9741, loss = 0.8842, cross_entropy loss = 0.8842, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:01.888146 #train# step 9742, loss = 0.9092, cross_entropy loss = 0.9092, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:03.486483 #train# step 9743, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:05.052378 #train# step 9744, loss = 0.9115, cross_entropy loss = 0.9115, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:06.587158 #train# step 9745, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:08.193298 #train# step 9746, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:09.820643 #train# step 9747, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:11.396663 #train# step 9748, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:12.981009 #train# step 9749, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:14.548966 #train# step 9750, loss = 0.8884, cross_entropy loss = 0.8884, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:16.159912 #train# step 9751, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:17.757126 #train# step 9752, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:19.359205 #train# step 9753, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:20.957254 #train# step 9754, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:22.541290 #train# step 9755, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:24.148584 #train# step 9756, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:25.729831 #train# step 9757, loss = 0.8905, cross_entropy loss = 0.8905, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:27.326786 #train# step 9758, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:28.917004 #train# step 9759, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:30.514593 #train# step 9760, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:32.110607 #train# step 9761, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:33.704524 #train# step 9762, loss = 0.8977, cross_entropy loss = 0.8977, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:35.319016 #train# step 9763, loss = 0.9079, cross_entropy loss = 0.9079, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:36.916126 #train# step 9764, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:38.530790 #train# step 9765, loss = 0.9059, cross_entropy loss = 0.9059, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:40.137452 #train# step 9766, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:41.726329 #train# step 9767, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:43.316160 #train# step 9768, loss = 0.8976, cross_entropy loss = 0.8976, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:44.887274 #train# step 9769, loss = 0.8849, cross_entropy loss = 0.8849, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:46.456456 #train# step 9770, loss = 0.9082, cross_entropy loss = 0.9082, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:48.064387 #train# step 9771, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:49.669665 #train# step 9772, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:51.258737 #train# step 9773, loss = 0.9011, cross_entropy loss = 0.9011, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:52.841815 #train# step 9774, loss = 0.8925, cross_entropy loss = 0.8925, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:54.424185 #train# step 9775, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:56.008254 #train# step 9776, loss = 0.8979, cross_entropy loss = 0.8979, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:57.599054 #train# step 9777, loss = 0.9007, cross_entropy loss = 0.9007, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:18:59.183851 #train# step 9778, loss = 0.9093, cross_entropy loss = 0.9093, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:00.755878 #train# step 9779, loss = 0.8967, cross_entropy loss = 0.8967, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:02.358220 #train# step 9780, loss = 0.9038, cross_entropy loss = 0.9038, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:03.929806 #train# step 9781, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:05.516396 #train# step 9782, loss = 0.9049, cross_entropy loss = 0.9049, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:07.110983 #train# step 9783, loss = 0.9180, cross_entropy loss = 0.9180, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:08.694640 #train# step 9784, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:10.295508 #train# step 9785, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:11.929731 #train# step 9786, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:13.478662 #train# step 9787, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:15.089211 #train# step 9788, loss = 0.8886, cross_entropy loss = 0.8886, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:16.731346 #train# step 9789, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:18.322069 #train# step 9790, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:19.898650 #train# step 9791, loss = 0.9176, cross_entropy loss = 0.9176, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:21.484833 #train# step 9792, loss = 0.8910, cross_entropy loss = 0.8910, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:23.062907 #train# step 9793, loss = 0.8810, cross_entropy loss = 0.8810, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:24.652697 #train# step 9794, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:26.272855 #train# step 9795, loss = 0.9066, cross_entropy loss = 0.9066, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:27.865802 #train# step 9796, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:29.435382 #train# step 9797, loss = 0.9128, cross_entropy loss = 0.9128, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:31.014806 #train# step 9798, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:32.607933 #train# step 9799, loss = 0.8931, cross_entropy loss = 0.8931, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:34.207011 #train# step 9800, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:35.777765 #train# step 9801, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:37.382906 #train# step 9802, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:38.966632 #train# step 9803, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:40.579501 #train# step 9804, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:42.173010 #train# step 9805, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:43.782726 #train# step 9806, loss = 0.8856, cross_entropy loss = 0.8856, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:45.384223 #train# step 9807, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:46.954599 #train# step 9808, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:48.532528 #train# step 9809, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:50.114449 #train# step 9810, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:51.685133 #train# step 9811, loss = 0.8987, cross_entropy loss = 0.8987, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:53.296165 #train# step 9812, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:54.895947 #train# step 9813, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:56.499641 #train# step 9814, loss = 0.9009, cross_entropy loss = 0.9009, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:58.115034 #train# step 9815, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:19:59.722355 #train# step 9816, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:01.333306 #train# step 9817, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:02.892891 #train# step 9818, loss = 0.8934, cross_entropy loss = 0.8934, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:04.497317 #train# step 9819, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:06.084812 #train# step 9820, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:07.666423 #train# step 9821, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:09.251852 #train# step 9822, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:10.838226 #train# step 9823, loss = 0.8998, cross_entropy loss = 0.8998, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:12.423668 #train# step 9824, loss = 0.9087, cross_entropy loss = 0.9087, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:14.038696 #train# step 9825, loss = 0.9043, cross_entropy loss = 0.9043, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:15.636620 #train# step 9826, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:17.241467 #train# step 9827, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:18.821076 #train# step 9828, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:20.398937 #train# step 9829, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:21.981762 #train# step 9830, loss = 0.9005, cross_entropy loss = 0.9005, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:23.563094 #train# step 9831, loss = 0.9169, cross_entropy loss = 0.9169, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:25.130803 #train# step 9832, loss = 0.9022, cross_entropy loss = 0.9022, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:26.747875 #train# step 9833, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:28.328080 #train# step 9834, loss = 0.8892, cross_entropy loss = 0.8892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:29.901869 #train# step 9835, loss = 0.8932, cross_entropy loss = 0.8932, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:31.493794 #train# step 9836, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:33.105040 #train# step 9837, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:34.653060 #train# step 9838, loss = 0.9032, cross_entropy loss = 0.9032, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:36.278324 #train# step 9839, loss = 0.9069, cross_entropy loss = 0.9069, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:37.843006 #train# step 9840, loss = 0.9053, cross_entropy loss = 0.9053, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:39.395662 #train# step 9841, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:41.016577 #train# step 9842, loss = 0.9107, cross_entropy loss = 0.9107, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:42.618451 #train# step 9843, loss = 0.8892, cross_entropy loss = 0.8892, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:44.215225 #train# step 9844, loss = 0.8915, cross_entropy loss = 0.8915, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:45.790556 #train# step 9845, loss = 0.9018, cross_entropy loss = 0.9018, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:47.398999 #train# step 9846, loss = 0.8846, cross_entropy loss = 0.8846, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:49.014988 #train# step 9847, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:50.653602 #train# step 9848, loss = 0.8887, cross_entropy loss = 0.8887, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:52.224297 #train# step 9849, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:53.793867 #train# step 9850, loss = 0.9101, cross_entropy loss = 0.9101, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:55.387947 #train# step 9851, loss = 0.8808, cross_entropy loss = 0.8808, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:56.965464 #train# step 9852, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:20:58.556771 #train# step 9853, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:00.164556 #train# step 9854, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:01.762816 #train# step 9855, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:03.341992 #train# step 9856, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:04.954054 #train# step 9857, loss = 0.8953, cross_entropy loss = 0.8953, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:06.528975 #train# step 9858, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:08.133031 #train# step 9859, loss = 0.8918, cross_entropy loss = 0.8918, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:09.738029 #train# step 9860, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:11.317585 #train# step 9861, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:12.904649 #train# step 9862, loss = 0.9025, cross_entropy loss = 0.9025, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:14.481963 #train# step 9863, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:16.078337 #train# step 9864, loss = 0.9010, cross_entropy loss = 0.9010, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:17.680879 #train# step 9865, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:19.281422 #train# step 9866, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:20.888371 #train# step 9867, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:22.508935 #train# step 9868, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:24.086616 #train# step 9869, loss = 0.8916, cross_entropy loss = 0.8916, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:25.679333 #train# step 9870, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:27.297341 #train# step 9871, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:28.888364 #train# step 9872, loss = 0.9050, cross_entropy loss = 0.9050, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:30.475325 #train# step 9873, loss = 0.8971, cross_entropy loss = 0.8971, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:32.079553 #train# step 9874, loss = 0.8982, cross_entropy loss = 0.8982, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:33.692218 #train# step 9875, loss = 0.8981, cross_entropy loss = 0.8981, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:35.300092 #train# step 9876, loss = 0.8980, cross_entropy loss = 0.8980, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:36.913845 #train# step 9877, loss = 0.8993, cross_entropy loss = 0.8993, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:38.523222 #train# step 9878, loss = 0.8986, cross_entropy loss = 0.8986, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:40.112701 #train# step 9879, loss = 0.8933, cross_entropy loss = 0.8933, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:41.723802 #train# step 9880, loss = 0.8826, cross_entropy loss = 0.8826, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:43.325152 #train# step 9881, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:44.924518 #train# step 9882, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:46.495295 #train# step 9883, loss = 0.8894, cross_entropy loss = 0.8894, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:48.061694 #train# step 9884, loss = 0.9094, cross_entropy loss = 0.9094, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:49.678072 #train# step 9885, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:51.288951 #train# step 9886, loss = 0.9024, cross_entropy loss = 0.9024, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:52.887520 #train# step 9887, loss = 0.8952, cross_entropy loss = 0.8952, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:54.452623 #train# step 9888, loss = 0.9074, cross_entropy loss = 0.9074, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:56.035326 #train# step 9889, loss = 0.9147, cross_entropy loss = 0.9147, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:57.611613 #train# step 9890, loss = 0.8889, cross_entropy loss = 0.8889, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:21:59.171298 #train# step 9891, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:00.757718 #train# step 9892, loss = 0.8840, cross_entropy loss = 0.8840, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:02.353029 #train# step 9893, loss = 0.9000, cross_entropy loss = 0.9000, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:03.939775 #train# step 9894, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:05.503271 #train# step 9895, loss = 0.9013, cross_entropy loss = 0.9013, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:07.149116 #train# step 9896, loss = 0.8949, cross_entropy loss = 0.8949, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:08.743425 #train# step 9897, loss = 0.9012, cross_entropy loss = 0.9012, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:10.319595 #train# step 9898, loss = 0.8907, cross_entropy loss = 0.8907, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:11.897673 #train# step 9899, loss = 0.9191, cross_entropy loss = 0.9191, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:13.499629 #train# step 9900, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:15.071718 #train# step 9901, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:16.694924 #train# step 9902, loss = 0.9100, cross_entropy loss = 0.9100, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:18.298029 #train# step 9903, loss = 0.9006, cross_entropy loss = 0.9006, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:19.890846 #train# step 9904, loss = 0.8960, cross_entropy loss = 0.8960, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:21.479485 #train# step 9905, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:23.027018 #train# step 9906, loss = 0.8900, cross_entropy loss = 0.8900, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:24.636495 #train# step 9907, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:26.220711 #train# step 9908, loss = 0.8947, cross_entropy loss = 0.8947, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:27.815425 #train# step 9909, loss = 0.9114, cross_entropy loss = 0.9114, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:29.420174 #train# step 9910, loss = 0.8995, cross_entropy loss = 0.8995, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:31.049701 #train# step 9911, loss = 0.8919, cross_entropy loss = 0.8919, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:32.634007 #train# step 9912, loss = 0.8898, cross_entropy loss = 0.8898, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:34.194111 #train# step 9913, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:35.792583 #train# step 9914, loss = 0.9031, cross_entropy loss = 0.9031, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:37.376225 #train# step 9915, loss = 0.9112, cross_entropy loss = 0.9112, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:38.962730 #train# step 9916, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:40.558092 #train# step 9917, loss = 0.8994, cross_entropy loss = 0.8994, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:42.160937 #train# step 9918, loss = 0.8997, cross_entropy loss = 0.8997, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:43.775831 #train# step 9919, loss = 0.9036, cross_entropy loss = 0.9036, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:45.384041 #train# step 9920, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:46.989882 #train# step 9921, loss = 0.8957, cross_entropy loss = 0.8957, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:48.568239 #train# step 9922, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:50.152106 #train# step 9923, loss = 0.8928, cross_entropy loss = 0.8928, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:51.736296 #train# step 9924, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:53.336120 #train# step 9925, loss = 0.9001, cross_entropy loss = 0.9001, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:54.949154 #train# step 9926, loss = 0.8879, cross_entropy loss = 0.8879, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:56.584803 #train# step 9927, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:58.168034 #train# step 9928, loss = 0.8936, cross_entropy loss = 0.8936, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:22:59.754146 #train# step 9929, loss = 0.8964, cross_entropy loss = 0.8964, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:01.361826 #train# step 9930, loss = 0.8939, cross_entropy loss = 0.8939, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:02.965356 #train# step 9931, loss = 0.9004, cross_entropy loss = 0.9004, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:04.543930 #train# step 9932, loss = 0.8955, cross_entropy loss = 0.8955, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:06.108241 #train# step 9933, loss = 0.9027, cross_entropy loss = 0.9027, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:07.720559 #train# step 9934, loss = 0.8996, cross_entropy loss = 0.8996, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:09.304164 #train# step 9935, loss = 0.8914, cross_entropy loss = 0.8914, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:10.908576 #train# step 9936, loss = 0.8930, cross_entropy loss = 0.8930, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:12.506783 #train# step 9937, loss = 0.9054, cross_entropy loss = 0.9054, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:14.083417 #train# step 9938, loss = 0.8895, cross_entropy loss = 0.8895, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:15.656670 #train# step 9939, loss = 0.9023, cross_entropy loss = 0.9023, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:17.258480 #train# step 9940, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:18.853174 #train# step 9941, loss = 0.8966, cross_entropy loss = 0.8966, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:20.455215 #train# step 9942, loss = 0.9033, cross_entropy loss = 0.9033, 0.9 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:22.063976 #train# step 9943, loss = 0.9078, cross_entropy loss = 0.9078, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:23.660401 #train# step 9944, loss = 0.8854, cross_entropy loss = 0.8854, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:25.251161 #train# step 9945, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:26.836285 #train# step 9946, loss = 0.9071, cross_entropy loss = 0.9071, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:28.425954 #train# step 9947, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:30.021158 #train# step 9948, loss = 0.8954, cross_entropy loss = 0.8954, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:31.589802 #train# step 9949, loss = 0.8974, cross_entropy loss = 0.8974, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:33.202829 #train# step 9950, loss = 0.9157, cross_entropy loss = 0.9157, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:34.795901 #train# step 9951, loss = 0.8913, cross_entropy loss = 0.8913, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:36.381903 #train# step 9952, loss = 0.9002, cross_entropy loss = 0.9002, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:37.950682 #train# step 9953, loss = 0.9047, cross_entropy loss = 0.9047, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:39.533709 #train# step 9954, loss = 0.9089, cross_entropy loss = 0.9089, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:41.142854 #train# step 9955, loss = 0.8944, cross_entropy loss = 0.8944, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:42.711712 #train# step 9956, loss = 0.8990, cross_entropy loss = 0.8990, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:44.306242 #train# step 9957, loss = 0.8961, cross_entropy loss = 0.8961, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:45.927473 #train# step 9958, loss = 0.8858, cross_entropy loss = 0.8858, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:47.525781 #train# step 9959, loss = 0.9068, cross_entropy loss = 0.9068, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:49.123196 #train# step 9960, loss = 0.8912, cross_entropy loss = 0.8912, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:50.665445 #train# step 9961, loss = 0.9256, cross_entropy loss = 0.9256, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:52.235334 #train# step 9962, loss = 0.8970, cross_entropy loss = 0.8970, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:53.846776 #train# step 9963, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:55.422254 #train# step 9964, loss = 0.8937, cross_entropy loss = 0.8937, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:57.010224 #train# step 9965, loss = 0.8903, cross_entropy loss = 0.8903, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:23:58.581517 #train# step 9966, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:00.152043 #train# step 9967, loss = 0.8929, cross_entropy loss = 0.8929, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:01.740095 #train# step 9968, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:03.332115 #train# step 9969, loss = 0.8959, cross_entropy loss = 0.8959, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:04.925788 #train# step 9970, loss = 0.8921, cross_entropy loss = 0.8921, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:06.481886 #train# step 9971, loss = 0.9104, cross_entropy loss = 0.9104, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:08.040424 #train# step 9972, loss = 0.8870, cross_entropy loss = 0.8870, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:09.628760 #train# step 9973, loss = 0.9017, cross_entropy loss = 0.9017, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:11.230443 #train# step 9974, loss = 0.8968, cross_entropy loss = 0.8968, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:12.851762 #train# step 9975, loss = 0.8973, cross_entropy loss = 0.8973, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:14.422216 #train# step 9976, loss = 0.8992, cross_entropy loss = 0.8992, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:16.006373 #train# step 9977, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:17.605445 #train# step 9978, loss = 0.8950, cross_entropy loss = 0.8950, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:19.207537 #train# step 9979, loss = 0.8972, cross_entropy loss = 0.8972, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:20.829056 #train# step 9980, loss = 0.8852, cross_entropy loss = 0.8852, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:22.444675 #train# step 9981, loss = 0.8924, cross_entropy loss = 0.8924, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:24.015367 #train# step 9982, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:25.625639 #train# step 9983, loss = 0.8901, cross_entropy loss = 0.8901, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:27.233359 #train# step 9984, loss = 0.8927, cross_entropy loss = 0.8927, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:28.815311 #train# step 9985, loss = 0.8965, cross_entropy loss = 0.8965, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:30.383781 #train# step 9986, loss = 0.9048, cross_entropy loss = 0.9048, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:31.979095 #train# step 9987, loss = 0.8938, cross_entropy loss = 0.8938, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:33.585956 #train# step 9988, loss = 0.9042, cross_entropy loss = 0.9042, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:35.191985 #train# step 9989, loss = 0.8917, cross_entropy loss = 0.8917, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:36.772780 #train# step 9990, loss = 0.8999, cross_entropy loss = 0.8999, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:38.359144 #train# step 9991, loss = 0.8827, cross_entropy loss = 0.8827, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:40.007137 #train# step 9992, loss = 0.8943, cross_entropy loss = 0.8943, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:41.587701 #train# step 9993, loss = 0.8949, cross_entropy loss = 0.8949, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:43.191939 #train# step 9994, loss = 0.8909, cross_entropy loss = 0.8909, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:44.780704 #train# step 9995, loss = 0.9037, cross_entropy loss = 0.9037, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:46.337791 #train# step 9996, loss = 0.8945, cross_entropy loss = 0.8945, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:47.941289 #train# step 9997, loss = 0.8885, cross_entropy loss = 0.8885, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:49.511264 #train# step 9998, loss = 0.9029, cross_entropy loss = 0.9029, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:51.130619 #train# step 9999, loss = 0.8969, cross_entropy loss = 0.8969, 0.8 sec/batch
the output has dimension (800, 512)

the output occupies 1638400 bytes
2021-01-22 22:24:52.723510 #train# step 10000, loss = 0.9063, cross_entropy loss = 0.9063, 0.8 sec/batch
2021-01-22 22:24:52.723819 #traing# finish training
saving model to ./models/lr_5e-05_cqlambda_0.0_alpha_10.0_dataset_VeRi_hashbit_512.npy
model saved
{'R': 5000,
 'alpha': 10.0,
 'batch_size': 800,
 'cq_lambda': 0.0,
 'dataset': 'VeRi',
 'decay_step': 5000,
 'device': '/gpu:0',
 'finetune_all': True,
 'img_db': '../../data/VeRi/database.txt',
 'img_model': 'alexnet',
 'img_te': '../../data/VeRi/test.txt',
 'img_tr': '../../data/VeRi/train.txt',
 'label_dim': 576,
 'learning_rate': 5e-05,
 'learning_rate_decay_factor': 0.5,
 'log_dir': 'tflog',
 'loss_type': 'normed_cross_entropy',
 'max_iter': 10000,
 'model_weights': '../../architecture/pretrained_model/reference_pretrain.npy',
 'output_dim': 512,
 'save_dir': './models/',
 'val_batch_size': 100}
